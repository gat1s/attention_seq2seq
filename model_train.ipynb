{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1667993530412,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "yTweMLOmR9Vi"
   },
   "outputs": [],
   "source": [
    "# This notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sr_old/Desktop/attention_seq2seq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993531067,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "j_4Zesv4R0pw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sr_old/Desktop/attention_seq2seq/p3.10_attention_seq2seq/bin/python\n",
      "3.10.13 (main, Aug 24 2023, 22:36:46) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993531068,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "veX5fP1AvWnY"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18907,
     "status": "ok",
     "timestamp": 1667993549968,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "4M82QOCQSNzt",
    "outputId": "3eb3d522-f6de-4126-94eb-d7dd3bd38ae3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1667993549969,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "uKCSSSzgR0px"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXN7_Zd8R0py"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993549971,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "v_OTN1RsR0pz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1667993551882,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "gjvOdrVQR0p0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "#from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, DataLoader #, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551882,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "c0HRxPJgR0p0"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551883,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "RfXhEsSJsGwd"
   },
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667993551883,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "yNLQt7gkR0p1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "from matplotlib.pyplot import rcParams\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 5,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551885,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "u_3G23IeR0p2"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993551886,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "GraMD30TR0p3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep_functions import LanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t9E_mHER0p5"
   },
   "source": [
    "## Device and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1667993553717,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "C7zP9bB0R0p7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553718,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "LBEwQWsOR0p9"
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553719,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "VP88-LbZR0p9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "#rng = np.random.default_rng(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553720,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "_utQ_MlrR0p-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL-ZtZWPR0p-"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553941,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "EQaVXJaCR0qA"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "  path = \"/content/gdrive/MyDrive/attention_seq2seq/datasets\"\n",
    "  results_path = \"results\"\n",
    "\n",
    "else:\n",
    "    # Name of the folder where data is accessed and saved\n",
    "    path = \"datasets\"\n",
    "    # Name of the folder for training results\n",
    "    results_path = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993553941,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "9eK6QXRKR0qA"
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdbLKfzPR0qB"
   },
   "source": [
    "## Loading the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling\n",
    "with open(path + \"/input_lang.txt\", \"rb\") as y:\n",
    "    input_lang = pickle.load(y)\n",
    "with open(path + \"/output_lang.txt\", \"rb\") as y:\n",
    "    output_lang = pickle.load(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a small dataset, useful for debugging.\n",
    "trial_dataset1 = torch.load(path + '/trial1.pt', weights_only=False)\n",
    "trial_dataset2 = torch.load(path + '/trial2.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 10,   7, 154, 357],\n",
       "          [117,   4,  50,  88],\n",
       "          [  3,   2, 646,   9],\n",
       "          [ 62,   0, 450,   2],\n",
       "          [  6,   0,   6,   0],\n",
       "          [  2,   0,   2,   0]]),\n",
       "  [6, 3, 6, 4]),\n",
       " (tensor([[113,  24,  92, 162],\n",
       "          [611,  60, 178, 430],\n",
       "          [194,   6, 701,  42],\n",
       "          [ 76,   2, 410, 191],\n",
       "          [  4,   0,   4,   8],\n",
       "          [  2,   0,   2,   2]]),\n",
       "  [6, 4, 6, 6]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_dataset1[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(path + '/train.pt', weights_only=False)\n",
    "val_dataset = torch.load(path + '/val.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5159"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADBctWXOR0qO"
   },
   "source": [
    "## Checking the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Luong_full(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(655, 2)\n",
       "    (gru): GRU(2, 1, num_layers=2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): LuongDecoder(\n",
       "    (embedding): Embedding(705, 2)\n",
       "    (gru): GRU(2, 2, num_layers=2)\n",
       "    (joinerFF): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (projFF): Linear(in_features=2, out_features=705, bias=True)\n",
       "    (dropout_layer): Dropout(p=0, inplace=False)\n",
       "    (alignment_vector): Attn()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Luong_full(vocab = input_lang.n_words, h_size = 2, dropout = 0, n_layers = 2, \n",
    "                    att_method = 'dot', vocab_out = output_lang.n_words, device = device)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993570260,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "NrRJ0jqBR0qQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xzu9e8QJR0qZ"
   },
   "source": [
    "## Now train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter definitions:\n",
    "#\n",
    "#       lrate - learning rate\n",
    "#\n",
    "#       ratio - we set the decoder learning rate to lrate*ratio\n",
    "#\n",
    "#       bsize*acc_steps - this multiple gives the true batch size; acc_steps is the number of gradient accumulation steps done at training\n",
    "#\n",
    "#       bsize_eval - the batch size used when evaluating the model at the end of an epoch (train and val losses)\n",
    "#\n",
    "#       patience - regulates early stopping\n",
    "#\n",
    "#       h_size - this regulates the dimensionality of the neural nets used\n",
    "#\n",
    "#       dropout - we haev inserted dropout in multiple places\n",
    "#\n",
    "#       n_layers - the number of layers in the encoder and decoder GRUs\n",
    "#\n",
    "#       att_method - one of ['dot', 'general', 'concat']\n",
    "#\n",
    "#       c - a string to be added in the saved files' filename\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "YDztUeoMLbbc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:48:49  Starting epoch 0\n",
      "18:49:34  Calculating figures\n",
      "18:49:51  Ending epoch 0    train_loss: 3.32   val_loss: 3.34\n",
      "18:49:51  Starting epoch 1\n",
      "18:50:36  Calculating figures\n",
      "18:50:55  Ending epoch 1    train_loss: 2.92   val_loss: 2.98\n",
      "18:50:55  Starting epoch 2\n",
      "18:51:42  Calculating figures\n",
      "18:52:02  Ending epoch 2    train_loss: 2.69   val_loss: 2.76\n",
      "18:52:02  Starting epoch 3\n",
      "18:52:48  Calculating figures\n",
      "18:53:09  Ending epoch 3    train_loss: 2.5   val_loss: 2.63\n",
      "18:53:09  Starting epoch 4\n",
      "18:53:56  Calculating figures\n",
      "18:54:19  Ending epoch 4    train_loss: 2.38   val_loss: 2.53\n",
      "18:54:19  Starting epoch 5\n",
      "18:55:07  Calculating figures\n",
      "18:55:31  Ending epoch 5    train_loss: 2.32   val_loss: 2.5\n",
      "18:55:31  Starting epoch 6\n",
      "18:56:20  Calculating figures\n",
      "18:56:44  Ending epoch 6    train_loss: 2.22   val_loss: 2.42\n",
      "18:56:44  Starting epoch 7\n",
      "18:57:34  Calculating figures\n",
      "18:58:00  Ending epoch 7    train_loss: 2.14   val_loss: 2.37\n",
      "\n",
      "best training_loss = 2.1409, best validation_loss = 2.3704\n",
      "Duration_: 0:09:11.821124\n",
      "best training_loss = 2.1409, best validation_loss = 2.3704\n",
      "Duration_: 0:09:11.821124\n",
      "18:58:00  END RUN_MODEL CALL\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   192|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   193|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   194|         0|            0|            0|  0.00%|      tuple ``(sW,)``. Default: 1\n",
      "   195|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   196|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   197|         0|            0|            0|  0.00%|      ``(padW,)``. Default: 0\n",
      "   198|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   199|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padW)``. Default: 0\n",
      "   200|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   201|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   202|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   203|         0|            0|            0|  0.00%|      a tuple ``(dW,)``. Default: 1\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|Examples::\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50)\n",
      "   208|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 5)\n",
      "   209|         0|            0|            0|  0.00%|    >>> F.conv_transpose1d(inputs, weights)\n",
      "   210|         0|            0|            0|  0.00%|\"\"\",\n",
      "   211|         0|            0|            0|  0.00%|)\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|conv_transpose2d = _add_docstr(\n",
      "   214|         0|            0|            0|  0.00%|    torch.conv_transpose2d,\n",
      "   215|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   216|         0|            0|            0|  0.00%|conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "   217|         0|            0|            0|  0.00%|\n",
      "   218|         0|            0|            0|  0.00%|Applies a 2D transposed convolution operator over an input image\n",
      "   219|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called \"deconvolution\".\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose2d` for details and output shape.\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|Note:\n",
      "   226|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   227|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   228|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   229|         0|            0|            0|  0.00%|    )\n",
      "   230|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   231|         0|            0|            0|  0.00%|\n",
      "   232|         0|            0|            0|  0.00%|Args:\n",
      "   233|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "   234|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW)`\n",
      "   235|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   236|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   237|         0|            0|            0|  0.00%|      tuple ``(sH, sW)``. Default: 1\n",
      "   238|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   239|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   240|         0|            0|            0|  0.00%|      ``(padH, padW)``. Default: 0\n",
      "   241|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   242|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padH, out_padW)``.\n",
      "   243|         0|            0|            0|  0.00%|      Default: 0\n",
      "   244|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   245|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   246|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   247|         0|            0|            0|  0.00%|      a tuple ``(dH, dW)``. Default: 1\n",
      "   248|         0|            0|            0|  0.00%|\n",
      "   249|         0|            0|            0|  0.00%|Examples::\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         0|            0|            0|  0.00%|    >>> # With square kernels and equal stride\n",
      "   252|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(1, 4, 5, 5)\n",
      "   253|         0|            0|            0|  0.00%|    >>> weights = torch.randn(4, 8, 3, 3)\n",
      "   254|         0|            0|            0|  0.00%|    >>> F.conv_transpose2d(inputs, weights, padding=1)\n",
      "   255|         0|            0|            0|  0.00%|\"\"\",\n",
      "   256|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   257|         0|            0|            0|  0.00%|\n",
      "   258|         0|            0|            0|  0.00%|conv_transpose3d = _add_docstr(\n",
      "   259|         0|            0|            0|  0.00%|    torch.conv_transpose3d,\n",
      "   260|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   261|         0|            0|            0|  0.00%|conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|Applies a 3D transposed convolution operator over an input image\n",
      "   264|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called \"deconvolution\"\n",
      "   265|         0|            0|            0|  0.00%|\n",
      "   266|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose3d` for details and output shape.\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         0|            0|            0|  0.00%|Note:\n",
      "   271|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   272|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   273|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   274|         0|            0|            0|  0.00%|    )\n",
      "   275|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   276|         0|            0|            0|  0.00%|\n",
      "   277|         0|            0|            0|  0.00%|Args:\n",
      "   278|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n",
      "   279|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW)`\n",
      "   280|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   281|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   282|         0|            0|            0|  0.00%|      tuple ``(sT, sH, sW)``. Default: 1\n",
      "   283|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   284|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   285|         0|            0|            0|  0.00%|      ``(padT, padH, padW)``. Default: 0\n",
      "   286|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   287|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple\n",
      "   288|         0|            0|            0|  0.00%|      ``(out_padT, out_padH, out_padW)``. Default: 0\n",
      "   289|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   290|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   291|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   292|         0|            0|            0|  0.00%|      a tuple `(dT, dH, dW)`. Default: 1\n",
      "   293|         0|            0|            0|  0.00%|\n",
      "   294|         0|            0|            0|  0.00%|Examples::\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50, 10, 20)\n",
      "   297|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 3, 3, 3)\n",
      "   298|         0|            0|            0|  0.00%|    >>> F.conv_transpose3d(inputs, weights)\n",
      "   299|         0|            0|            0|  0.00%|\"\"\",\n",
      "   300|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|conv_tbc = _add_docstr(\n",
      "   303|         0|            0|            0|  0.00%|    torch.conv_tbc,\n",
      "   304|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   305|         0|            0|            0|  0.00%|Applies a 1-dimensional sequence convolution over an input sequence.\n",
      "   306|         0|            0|            0|  0.00%|Input and output dimensions are (Time, Batch, Channels) - hence TBC.\n",
      "   307|         0|            0|            0|  0.00%|\n",
      "   308|         0|            0|            0|  0.00%|Args:\n",
      "   309|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{sequence length} \\times batch \\times \\text{in\\_channels})`\n",
      "   310|         0|            0|            0|  0.00%|    weight: filter of shape (:math:`\\text{kernel width} \\times \\text{in\\_channels} \\times \\text{out\\_channels}`)\n",
      "   311|         0|            0|            0|  0.00%|    bias: bias of shape (:math:`\\text{out\\_channels}`)\n",
      "   312|         0|            0|            0|  0.00%|    pad: number of timesteps to pad. Default: 0\n",
      "   313|         0|            0|            0|  0.00%|\"\"\",\n",
      "   314|         0|            0|            0|  0.00%|)\n",
      "   315|         0|            0|            0|  0.00%|\n",
      "   316|         0|            0|            0|  0.00%|\n",
      "   317|         0|            0|            0|  0.00%|# Pooling\n",
      "   318|         0|            0|            0|  0.00%|avg_pool1d = _add_docstr(\n",
      "   319|         0|            0|            0|  0.00%|    torch.avg_pool1d,\n",
      "   320|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   321|         0|            0|            0|  0.00%|avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|Applies a 1D average pooling over an input signal composed of several\n",
      "   324|         0|            0|            0|  0.00%|input planes.\n",
      "   325|         0|            0|            0|  0.00%|\n",
      "   326|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool1d` for details and output shape.\n",
      "   327|         0|            0|            0|  0.00%|\n",
      "   328|         0|            0|            0|  0.00%|Args:\n",
      "   329|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "   330|         0|            0|            0|  0.00%|    kernel_size: the size of the window. Can be a single number or a\n",
      "   331|         0|            0|            0|  0.00%|      tuple `(kW,)`\n",
      "   332|         0|            0|            0|  0.00%|    stride: the stride of the window. Can be a single number or a tuple\n",
      "   333|         0|            0|            0|  0.00%|      `(sW,)`. Default: :attr:`kernel_size`\n",
      "   334|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   335|         0|            0|            0|  0.00%|      single number or a tuple `(padW,)`. Default: 0\n",
      "   336|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` to compute the\n",
      "   337|         0|            0|            0|  0.00%|        output shape. Default: ``False``\n",
      "   338|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   339|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|Examples::\n",
      "   342|         0|            0|            0|  0.00%|\n",
      "   343|         0|            0|            0|  0.00%|    >>> # pool of square window of size=3, stride=2\n",
      "   344|         0|            0|            0|  0.00%|    >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)\n",
      "   345|         0|            0|            0|  0.00%|    >>> F.avg_pool1d(input, kernel_size=3, stride=2)\n",
      "   346|         0|            0|            0|  0.00%|    tensor([[[ 2.,  4.,  6.]]])\n",
      "   347|         0|            0|            0|  0.00%|\n",
      "   348|         0|            0|            0|  0.00%|\"\"\",\n",
      "   349|         0|            0|            0|  0.00%|)\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|avg_pool2d = _add_docstr(\n",
      "   353|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool2d,\n",
      "   354|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   355|         0|            0|            0|  0.00%|avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n",
      "   356|         0|            0|            0|  0.00%|\n",
      "   357|         0|            0|            0|  0.00%|Applies 2D average-pooling operation in :math:`kH \\times kW` regions by step size\n",
      "   358|         0|            0|            0|  0.00%|:math:`sH \\times sW` steps. The number of output features is equal to the number of\n",
      "   359|         0|            0|            0|  0.00%|input planes.\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool2d` for details and output shape.\n",
      "   362|         0|            0|            0|  0.00%|\n",
      "   363|         0|            0|            0|  0.00%|Args:\n",
      "   364|         0|            0|            0|  0.00%|    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "   365|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a\n",
      "   366|         0|            0|            0|  0.00%|      tuple `(kH, kW)`\n",
      "   367|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a\n",
      "   368|         0|            0|            0|  0.00%|      tuple `(sH, sW)`. Default: :attr:`kernel_size`\n",
      "   369|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   370|         0|            0|            0|  0.00%|      single number or a tuple `(padH, padW)`. Default: 0\n",
      "   371|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n",
      "   372|         0|            0|            0|  0.00%|        to compute the output shape. Default: ``False``\n",
      "   373|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   374|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``\n",
      "   375|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise\n",
      "   376|         0|            0|            0|  0.00%|         size of the pooling region will be used. Default: None\n",
      "   377|         0|            0|            0|  0.00%|\"\"\",\n",
      "   378|         0|            0|            0|  0.00%|)\n",
      "   379|         0|            0|            0|  0.00%|\n",
      "   380|         0|            0|            0|  0.00%|avg_pool3d = _add_docstr(\n",
      "   381|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool3d,\n",
      "   382|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   383|         0|            0|            0|  0.00%|avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n",
      "   384|         0|            0|            0|  0.00%|\n",
      "   385|         0|            0|            0|  0.00%|Applies 3D average-pooling operation in :math:`kT \\times kH \\times kW` regions by step\n",
      "   386|         0|            0|            0|  0.00%|size :math:`sT \\times sH \\times sW` steps. The number of output features is equal to\n",
      "   387|         0|            0|            0|  0.00%|:math:`\\lfloor\\frac{\\text{input planes}}{sT}\\rfloor`.\n",
      "   388|         0|            0|            0|  0.00%|\n",
      "   389|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool3d` for details and output shape.\n",
      "   390|         0|            0|            0|  0.00%|\n",
      "   391|         0|            0|            0|  0.00%|Args:\n",
      "   392|         0|            0|            0|  0.00%|    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iT \\times iH , iW)`\n",
      "   393|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a\n",
      "   394|         0|            0|            0|  0.00%|      tuple `(kT, kH, kW)`\n",
      "   395|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a\n",
      "   396|         0|            0|            0|  0.00%|      tuple `(sT, sH, sW)`. Default: :attr:`kernel_size`\n",
      "   397|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   398|         0|            0|            0|  0.00%|      single number or a tuple `(padT, padH, padW)`, Default: 0\n",
      "   399|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n",
      "   400|         0|            0|            0|  0.00%|        to compute the output shape\n",
      "   401|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   402|         0|            0|            0|  0.00%|        averaging calculation\n",
      "   403|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise\n",
      "   404|         0|            0|            0|  0.00%|        size of the pooling region will be used. Default: None\n",
      "   405|         0|            0|            0|  0.00%|\"\"\",\n",
      "   406|         0|            0|            0|  0.00%|)\n",
      "   407|         0|            0|            0|  0.00%|\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|def fractional_max_pool2d_with_indices(\n",
      "   410|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   411|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,\n",
      "   412|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,\n",
      "   413|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   414|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   415|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   416|         0|            0|            0|  0.00%|    r\"\"\"Applies 2D fractional max pooling over an input signal composed of several input planes.\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n",
      "   419|         0|            0|            0|  0.00%|\n",
      "   420|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kH \\times kW` regions by a stochastic\n",
      "   421|         0|            0|            0|  0.00%|    step size determined by the target output size.\n",
      "   422|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.\n",
      "   423|         0|            0|            0|  0.00%|\n",
      "   424|         0|            0|            0|  0.00%|    Args:\n",
      "   425|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.\n",
      "   426|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \\times k`)\n",
      "   427|         0|            0|            0|  0.00%|                     or a tuple `(kH, kW)`\n",
      "   428|         0|            0|            0|  0.00%|        output_size: the target output size of the image of the form :math:`oH \\times oW`.\n",
      "   429|         0|            0|            0|  0.00%|                     Can be a tuple `(oH, oW)` or a single number :math:`oH` for a square image :math:`oH \\times oH`\n",
      "   430|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n",
      "   431|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)\n",
      "   432|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.\n",
      "   433|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool2d`.\n",
      "   434|         0|            0|            0|  0.00%|\n",
      "   435|         0|            0|            0|  0.00%|    Examples::\n",
      "   436|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32)\n",
      "   437|         0|            0|            0|  0.00%|        >>> # pool of square window of size=3, and target output size 13x12\n",
      "   438|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_size=(13, 12))\n",
      "   439|         0|            0|            0|  0.00%|        >>> # pool of square window and target output size being half of input image size\n",
      "   440|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_ratio=(0.5, 0.5))\n",
      "   441|         0|            0|            0|  0.00%|\n",
      "   442|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:\n",
      "   443|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071\n",
      "   444|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   445|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   446|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   447|         0|            0|            0|  0.00%|            fractional_max_pool2d_with_indices,\n",
      "   448|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   449|         0|            0|            0|  0.00%|            input,\n",
      "   450|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   451|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   452|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   453|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   454|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   455|         0|            0|            0|  0.00%|        )\n",
      "   456|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:\n",
      "   457|         0|            0|            0|  0.00%|        raise ValueError(\"fractional_max_pool2d requires specifying either \" \"an output_size or an output_ratio\")\n",
      "   458|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   459|         0|            0|            0|  0.00%|        assert output_ratio is not None\n",
      "   460|         0|            0|            0|  0.00%|        _output_ratio = _pair(output_ratio)\n",
      "   461|         0|            0|            0|  0.00%|        output_size = [int(input.size(-2) * _output_ratio[0]), int(input.size(-1) * _output_ratio[1])]\n",
      "   462|         0|            0|            0|  0.00%|\n",
      "   463|         0|            0|            0|  0.00%|    if _random_samples is None:\n",
      "   464|         0|            0|            0|  0.00%|        n_batch = 1 if input.dim() == 3 else input.size(0)\n",
      "   465|         0|            0|            0|  0.00%|        _random_samples = torch.rand(n_batch, input.size(-3), 2, dtype=input.dtype, device=input.device)\n",
      "   466|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool2d(input, kernel_size, output_size, _random_samples)\n",
      "   467|         0|            0|            0|  0.00%|\n",
      "   468|         0|            0|            0|  0.00%|\n",
      "   469|         0|            0|            0|  0.00%|def _fractional_max_pool2d(\n",
      "   470|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   471|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,\n",
      "   472|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,\n",
      "   473|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   474|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   475|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   476|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   477|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   478|         0|            0|            0|  0.00%|            fractional_max_pool2d,\n",
      "   479|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   480|         0|            0|            0|  0.00%|            input,\n",
      "   481|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   482|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   483|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   484|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   485|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   486|         0|            0|            0|  0.00%|        )\n",
      "   487|         0|            0|            0|  0.00%|    return fractional_max_pool2d_with_indices(\n",
      "   488|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples\n",
      "   489|         0|            0|            0|  0.00%|    )[0]\n",
      "   490|         0|            0|            0|  0.00%|\n",
      "   491|         0|            0|            0|  0.00%|\n",
      "   492|         0|            0|            0|  0.00%|fractional_max_pool2d = boolean_dispatch(\n",
      "   493|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   494|         0|            0|            0|  0.00%|    arg_index=4,\n",
      "   495|         0|            0|            0|  0.00%|    default=False,\n",
      "   496|         0|            0|            0|  0.00%|    if_true=fractional_max_pool2d_with_indices,\n",
      "   497|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool2d,\n",
      "   498|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   499|         0|            0|            0|  0.00%|    func_name=\"fractional_max_pool2d\",\n",
      "   500|         0|            0|            0|  0.00%|)\n",
      "   501|         0|            0|            0|  0.00%|\n",
      "   502|         0|            0|            0|  0.00%|\n",
      "   503|         0|            0|            0|  0.00%|def fractional_max_pool3d_with_indices(\n",
      "   504|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   505|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,\n",
      "   506|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,\n",
      "   507|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   508|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   509|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   510|         0|            0|            0|  0.00%|    r\"\"\"Applies 3D fractional max pooling over an input signal composed of several input planes.\n",
      "   511|         0|            0|            0|  0.00%|\n",
      "   512|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n",
      "   513|         0|            0|            0|  0.00%|\n",
      "   514|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kT \\times kH \\times kW` regions by a stochastic\n",
      "   515|         0|            0|            0|  0.00%|    step size determined by the target output size.\n",
      "   516|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.\n",
      "   517|         0|            0|            0|  0.00%|\n",
      "   518|         0|            0|            0|  0.00%|    Args:\n",
      "   519|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.\n",
      "   520|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \\times k \\times k`)\n",
      "   521|         0|            0|            0|  0.00%|                     or a tuple `(kT, kH, kW)`\n",
      "   522|         0|            0|            0|  0.00%|        output_size: the target output size of the form :math:`oT \\times oH \\times oW`.\n",
      "   523|         0|            0|            0|  0.00%|                     Can be a tuple `(oT, oH, oW)` or a single number :math:`oH` for a cubic output\n",
      "   524|         0|            0|            0|  0.00%|                     :math:`oH \\times oH \\times oH`\n",
      "   525|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n",
      "   526|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)\n",
      "   527|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.\n",
      "   528|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool3d`.\n",
      "   529|         0|            0|            0|  0.00%|\n",
      "   530|         0|            0|            0|  0.00%|    Examples::\n",
      "   531|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32, 16)\n",
      "   532|         0|            0|            0|  0.00%|        >>> # pool of cubic window of size=3, and target output size 13x12x11\n",
      "   533|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_size=(13, 12, 11))\n",
      "   534|         0|            0|            0|  0.00%|        >>> # pool of cubic window and target output size being half of input size\n",
      "   535|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_ratio=(0.5, 0.5, 0.5))\n",
      "   536|         0|            0|            0|  0.00%|\n",
      "   537|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:\n",
      "   538|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071\n",
      "   539|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   540|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   541|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   542|         0|            0|            0|  0.00%|            fractional_max_pool3d_with_indices,\n",
      "   543|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   544|         0|            0|            0|  0.00%|            input,\n",
      "   545|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   546|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   547|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   548|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   549|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   550|         0|            0|            0|  0.00%|        )\n",
      "   551|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:\n",
      "   552|         0|            0|            0|  0.00%|        raise ValueError(\"fractional_max_pool3d requires specifying either \" \"an output_size or an output_ratio\")\n",
      "   553|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   554|         0|            0|            0|  0.00%|        assert output_ratio is not None\n",
      "   555|         0|            0|            0|  0.00%|        _output_ratio = _triple(output_ratio)\n",
      "   556|         0|            0|            0|  0.00%|        output_size = [\n",
      "   557|         0|            0|            0|  0.00%|            int(input.size(2) * _output_ratio[0]),\n",
      "   558|         0|            0|            0|  0.00%|            int(input.size(3) * _output_ratio[1]),\n",
      "   559|         0|            0|            0|  0.00%|            int(input.size(4) * _output_ratio[2]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   560|         0|            0|            0|  0.00%|        ]\n",
      "   561|         0|            0|            0|  0.00%|\n",
      "   562|         0|            0|            0|  0.00%|    if _random_samples is None:\n",
      "   563|         0|            0|            0|  0.00%|        _random_samples = torch.rand(input.size(0), input.size(1), 3, dtype=input.dtype, device=input.device)\n",
      "   564|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool3d(input, kernel_size, output_size, _random_samples)\n",
      "   565|         0|            0|            0|  0.00%|\n",
      "   566|         0|            0|            0|  0.00%|\n",
      "   567|         0|            0|            0|  0.00%|def _fractional_max_pool3d(\n",
      "   568|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   569|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,\n",
      "   570|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,\n",
      "   571|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   572|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   573|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   574|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   575|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   576|         0|            0|            0|  0.00%|            fractional_max_pool3d,\n",
      "   577|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   578|         0|            0|            0|  0.00%|            input,\n",
      "   579|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   580|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   581|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   582|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   583|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   584|         0|            0|            0|  0.00%|        )\n",
      "   585|         0|            0|            0|  0.00%|    return fractional_max_pool3d_with_indices(\n",
      "   586|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples\n",
      "   587|         0|            0|            0|  0.00%|    )[0]\n",
      "   588|         0|            0|            0|  0.00%|\n",
      "   589|         0|            0|            0|  0.00%|\n",
      "   590|         0|            0|            0|  0.00%|fractional_max_pool3d = boolean_dispatch(\n",
      "   591|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   592|         0|            0|            0|  0.00%|    arg_index=4,\n",
      "   593|         0|            0|            0|  0.00%|    default=False,\n",
      "   594|         0|            0|            0|  0.00%|    if_true=fractional_max_pool3d_with_indices,\n",
      "   595|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool3d,\n",
      "   596|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   597|         0|            0|            0|  0.00%|    func_name=\"fractional_max_pool3d\",\n",
      "   598|         0|            0|            0|  0.00%|)\n",
      "   599|         0|            0|            0|  0.00%|\n",
      "   600|         0|            0|            0|  0.00%|\n",
      "   601|         0|            0|            0|  0.00%|def max_pool1d_with_indices(\n",
      "   602|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],\n",
      "   603|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   604|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   605|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,\n",
      "   606|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   607|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   608|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   609|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D max pooling over an input signal composed of several input\n",
      "   610|         0|            0|            0|  0.00%|    planes.\n",
      "   611|         0|            0|            0|  0.00%|\n",
      "   612|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool1d` for details.\n",
      "   613|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   614|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   615|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   616|         0|            0|            0|  0.00%|            max_pool1d_with_indices,\n",
      "   617|         0|            0|            0|  0.00%|            (input,),\n",
      "   618|         0|            0|            0|  0.00%|            input,\n",
      "   619|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   620|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   621|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   622|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   623|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   624|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   625|         0|            0|            0|  0.00%|        )\n",
      "   626|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   627|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   628|         0|            0|            0|  0.00%|    return torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   629|         0|            0|            0|  0.00%|\n",
      "   630|         0|            0|            0|  0.00%|\n",
      "   631|         0|            0|            0|  0.00%|def _max_pool1d(\n",
      "   632|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],\n",
      "   633|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   634|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   635|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,\n",
      "   636|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   637|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   638|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   639|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   640|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   641|         0|            0|            0|  0.00%|            max_pool1d,\n",
      "   642|         0|            0|            0|  0.00%|            (input,),\n",
      "   643|         0|            0|            0|  0.00%|            input,\n",
      "   644|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   645|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   646|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   647|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   648|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   649|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   650|         0|            0|            0|  0.00%|        )\n",
      "   651|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   652|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   653|         0|            0|            0|  0.00%|    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   654|         0|            0|            0|  0.00%|\n",
      "   655|         0|            0|            0|  0.00%|\n",
      "   656|         0|            0|            0|  0.00%|max_pool1d = boolean_dispatch(\n",
      "   657|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   658|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   659|         0|            0|            0|  0.00%|    default=False,\n",
      "   660|         0|            0|            0|  0.00%|    if_true=max_pool1d_with_indices,\n",
      "   661|         0|            0|            0|  0.00%|    if_false=_max_pool1d,\n",
      "   662|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   663|         0|            0|            0|  0.00%|    func_name=\"max_pool1d\",\n",
      "   664|         0|            0|            0|  0.00%|)\n",
      "   665|         0|            0|            0|  0.00%|\n",
      "   666|         0|            0|            0|  0.00%|\n",
      "   667|         0|            0|            0|  0.00%|def max_pool2d_with_indices(\n",
      "   668|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   669|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   670|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   671|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "   672|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   673|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   674|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   675|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D max pooling over an input signal composed of several input\n",
      "   676|         0|            0|            0|  0.00%|    planes.\n",
      "   677|         0|            0|            0|  0.00%|\n",
      "   678|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool2d` for details.\n",
      "   679|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   680|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   681|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   682|         0|            0|            0|  0.00%|            max_pool2d_with_indices,\n",
      "   683|         0|            0|            0|  0.00%|            (input,),\n",
      "   684|         0|            0|            0|  0.00%|            input,\n",
      "   685|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   686|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   687|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   688|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   689|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   690|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   691|         0|            0|            0|  0.00%|        )\n",
      "   692|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   693|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   694|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   695|         0|            0|            0|  0.00%|\n",
      "   696|         0|            0|            0|  0.00%|\n",
      "   697|         0|            0|            0|  0.00%|def _max_pool2d(\n",
      "   698|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   699|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   700|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   701|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "   702|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   703|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   704|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   705|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   706|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   707|         0|            0|            0|  0.00%|            max_pool2d,\n",
      "   708|         0|            0|            0|  0.00%|            (input,),\n",
      "   709|         0|            0|            0|  0.00%|            input,\n",
      "   710|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   711|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   712|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   713|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   714|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   715|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   716|         0|            0|            0|  0.00%|        )\n",
      "   717|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   718|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   719|         0|            0|            0|  0.00%|    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|\n",
      "   722|         0|            0|            0|  0.00%|max_pool2d = boolean_dispatch(\n",
      "   723|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   724|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   725|         0|            0|            0|  0.00%|    default=False,\n",
      "   726|         0|            0|            0|  0.00%|    if_true=max_pool2d_with_indices,\n",
      "   727|         0|            0|            0|  0.00%|    if_false=_max_pool2d,\n",
      "   728|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   729|         0|            0|            0|  0.00%|    func_name=\"max_pool2d\",\n",
      "   730|         0|            0|            0|  0.00%|)\n",
      "   731|         0|            0|            0|  0.00%|\n",
      "   732|         0|            0|            0|  0.00%|\n",
      "   733|         0|            0|            0|  0.00%|def max_pool3d_with_indices(\n",
      "   734|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   735|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   736|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   737|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,\n",
      "   738|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   739|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   740|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   741|         0|            0|            0|  0.00%|    r\"\"\"Applies a 3D max pooling over an input signal composed of several input\n",
      "   742|         0|            0|            0|  0.00%|    planes.\n",
      "   743|         0|            0|            0|  0.00%|\n",
      "   744|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool3d` for details.\n",
      "   745|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   746|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   747|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   748|         0|            0|            0|  0.00%|            max_pool3d_with_indices,\n",
      "   749|         0|            0|            0|  0.00%|            (input,),\n",
      "   750|         0|            0|            0|  0.00%|            input,\n",
      "   751|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   752|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   753|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   754|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   755|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   756|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   757|         0|            0|            0|  0.00%|        )\n",
      "   758|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   759|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   760|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|\n",
      "   763|         0|            0|            0|  0.00%|def _max_pool3d(\n",
      "   764|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   765|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   766|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   767|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,\n",
      "   768|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   769|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   770|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   771|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   772|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   773|         0|            0|            0|  0.00%|            max_pool3d,\n",
      "   774|         0|            0|            0|  0.00%|            (input,),\n",
      "   775|         0|            0|            0|  0.00%|            input,\n",
      "   776|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   777|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   778|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   779|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   780|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   781|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   782|         0|            0|            0|  0.00%|        )\n",
      "   783|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   784|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   785|         0|            0|            0|  0.00%|    return torch.max_pool3d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   786|         0|            0|            0|  0.00%|\n",
      "   787|         0|            0|            0|  0.00%|\n",
      "   788|         0|            0|            0|  0.00%|max_pool3d = boolean_dispatch(\n",
      "   789|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   790|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   791|         0|            0|            0|  0.00%|    default=False,\n",
      "   792|         0|            0|            0|  0.00%|    if_true=max_pool3d_with_indices,\n",
      "   793|         0|            0|            0|  0.00%|    if_false=_max_pool3d,\n",
      "   794|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   795|         0|            0|            0|  0.00%|    func_name=\"max_pool3d\",\n",
      "   796|         0|            0|            0|  0.00%|)\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|\n",
      "   799|         0|            0|            0|  0.00%|def _unpool_output_size(\n",
      "   800|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: List[int], stride: List[int], padding: List[int], output_size: Optional[List[int]]\n",
      "   801|         0|            0|            0|  0.00%|) -> List[int]:\n",
      "   802|         0|            0|            0|  0.00%|    input_size = input.size()\n",
      "   803|         0|            0|            0|  0.00%|    default_size = torch.jit.annotate(List[int], [])\n",
      "   804|         0|            0|            0|  0.00%|    for d in range(len(kernel_size)):\n",
      "   805|         0|            0|            0|  0.00%|        default_size.append((input_size[-len(kernel_size) + d] - 1) * stride[d] + kernel_size[d] - 2 * padding[d])\n",
      "   806|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   807|         0|            0|            0|  0.00%|        ret = default_size\n",
      "   808|         0|            0|            0|  0.00%|    else:\n",
      "   809|         0|            0|            0|  0.00%|        if len(output_size) == len(kernel_size) + 2:\n",
      "   810|         0|            0|            0|  0.00%|            output_size = output_size[2:]\n",
      "   811|         0|            0|            0|  0.00%|        if len(output_size) != len(kernel_size):\n",
      "   812|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   813|         0|            0|            0|  0.00%|                \"output_size should be a sequence containing \"\n",
      "   814|         0|            0|            0|  0.00%|                \"{} or {} elements, but it has a length of '{}'\".format(\n",
      "   815|         0|            0|            0|  0.00%|                    len(kernel_size), len(kernel_size) + 2, len(output_size)\n",
      "   816|         0|            0|            0|  0.00%|                )\n",
      "   817|         0|            0|            0|  0.00%|            )\n",
      "   818|         0|            0|            0|  0.00%|        for d in range(len(kernel_size)):\n",
      "   819|         0|            0|            0|  0.00%|            min_size = default_size[d] - stride[d]\n",
      "   820|         0|            0|            0|  0.00%|            max_size = default_size[d] + stride[d]\n",
      "   821|         0|            0|            0|  0.00%|            if not (min_size < output_size[d] < max_size):\n",
      "   822|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "   823|         0|            0|            0|  0.00%|                    'invalid output_size \"{}\" (dim {} must be between {} and {})'.format(\n",
      "   824|         0|            0|            0|  0.00%|                        output_size, d, min_size, max_size\n",
      "   825|         0|            0|            0|  0.00%|                    )\n",
      "   826|         0|            0|            0|  0.00%|                )\n",
      "   827|         0|            0|            0|  0.00%|\n",
      "   828|         0|            0|            0|  0.00%|        ret = output_size\n",
      "   829|         0|            0|            0|  0.00%|    return ret\n",
      "   830|         0|            0|            0|  0.00%|\n",
      "   831|         0|            0|            0|  0.00%|\n",
      "   832|         0|            0|            0|  0.00%|def max_unpool1d(\n",
      "   833|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   834|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList1[int],\n",
      "   835|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   836|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   837|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList1[int]] = None\n",
      "   838|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   839|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool1d`.\n",
      "   840|         0|            0|            0|  0.00%|\n",
      "   841|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool1d` for details.\n",
      "   842|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   843|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   844|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   845|         0|            0|            0|  0.00%|            max_unpool1d,\n",
      "   846|         0|            0|            0|  0.00%|            (input,),\n",
      "   847|         0|            0|            0|  0.00%|            input,\n",
      "   848|         0|            0|            0|  0.00%|            indices,\n",
      "   849|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   850|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   851|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   852|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   853|         0|            0|            0|  0.00%|        )\n",
      "   854|         0|            0|            0|  0.00%|    kernel_size = _single(kernel_size)\n",
      "   855|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   856|         0|            0|            0|  0.00%|        _stride = _single(stride)\n",
      "   857|         0|            0|            0|  0.00%|    else:\n",
      "   858|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   859|         0|            0|            0|  0.00%|    padding = _single(padding)\n",
      "   860|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   861|         0|            0|            0|  0.00%|    if isinstance(output_size, list):\n",
      "   862|         0|            0|            0|  0.00%|        output_size = output_size + [1]\n",
      "   863|         0|            0|            0|  0.00%|    else:\n",
      "   864|         0|            0|            0|  0.00%|        output_size = output_size + (1,)\n",
      "   865|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)\n",
      "   866|         0|            0|            0|  0.00%|\n",
      "   867|         0|            0|            0|  0.00%|\n",
      "   868|         0|            0|            0|  0.00%|def max_unpool2d(\n",
      "   869|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   870|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],\n",
      "   871|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   872|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   873|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None\n",
      "   874|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   875|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool2d`.\n",
      "   876|         0|            0|            0|  0.00%|\n",
      "   877|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool2d` for details.\n",
      "   878|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   879|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   880|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   881|         0|            0|            0|  0.00%|            max_unpool2d,\n",
      "   882|         0|            0|            0|  0.00%|            (input,),\n",
      "   883|         0|            0|            0|  0.00%|            input,\n",
      "   884|         0|            0|            0|  0.00%|            indices,\n",
      "   885|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   886|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   887|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   888|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   889|         0|            0|            0|  0.00%|        )\n",
      "   890|         0|            0|            0|  0.00%|    kernel_size = _pair(kernel_size)\n",
      "   891|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   892|         0|            0|            0|  0.00%|        _stride = _pair(stride)\n",
      "   893|         0|            0|            0|  0.00%|    else:\n",
      "   894|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   895|         0|            0|            0|  0.00%|    padding = _pair(padding)\n",
      "   896|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   897|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input, indices, output_size)\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|\n",
      "   900|         0|            0|            0|  0.00%|def max_unpool3d(\n",
      "   901|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   902|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList3[int],\n",
      "   903|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   904|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   905|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None\n",
      "   906|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   907|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool3d`.\n",
      "   908|         0|            0|            0|  0.00%|\n",
      "   909|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool3d` for details.\n",
      "   910|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   911|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   912|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   913|         0|            0|            0|  0.00%|            max_unpool3d,\n",
      "   914|         0|            0|            0|  0.00%|            (input,),\n",
      "   915|         0|            0|            0|  0.00%|            input,\n",
      "   916|         0|            0|            0|  0.00%|            indices,\n",
      "   917|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   918|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   919|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   920|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   921|         0|            0|            0|  0.00%|        )\n",
      "   922|         0|            0|            0|  0.00%|    kernel_size = _triple(kernel_size)\n",
      "   923|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   924|         0|            0|            0|  0.00%|        _stride = _triple(stride)\n",
      "   925|         0|            0|            0|  0.00%|    else:\n",
      "   926|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   927|         0|            0|            0|  0.00%|    padding = _triple(padding)\n",
      "   928|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   929|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool3d(input, indices, output_size, _stride, padding)\n",
      "   930|         0|            0|            0|  0.00%|\n",
      "   931|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   932|         0|            0|            0|  0.00%|def lp_pool2d(\n",
      "   933|         0|            0|            0|  0.00%|    input: Tensor, norm_type: float,\n",
      "   934|         0|            0|            0|  0.00%|    kernel_size: int,\n",
      "   935|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   936|         0|            0|            0|  0.00%|    ceil_mode: bool = False\n",
      "   937|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   938|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D power-average pooling over an input signal composed of\n",
      "   939|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is\n",
      "   940|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.\n",
      "   941|         0|            0|            0|  0.00%|\n",
      "   942|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool2d` for details.\n",
      "   943|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   944|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   945|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   946|         0|            0|            0|  0.00%|            lp_pool2d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode\n",
      "   947|         0|            0|            0|  0.00%|        )\n",
      "   948|         0|            0|            0|  0.00%|    kw, kh = utils._pair(kernel_size)\n",
      "   949|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   950|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n",
      "   951|         0|            0|            0|  0.00%|    else:\n",
      "   952|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)\n",
      "   953|         0|            0|            0|  0.00%|\n",
      "   954|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kw * kh).pow(1.0 / norm_type)\n",
      "   955|         0|            0|            0|  0.00%|\n",
      "   956|         0|            0|            0|  0.00%|\n",
      "   957|         0|            0|            0|  0.00%|def lp_pool1d(\n",
      "   958|         0|            0|            0|  0.00%|    input: Tensor, norm_type: float,\n",
      "   959|         0|            0|            0|  0.00%|    kernel_size: int,\n",
      "   960|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   961|         0|            0|            0|  0.00%|    ceil_mode: bool = False\n",
      "   962|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   963|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D power-average pooling over an input signal composed of\n",
      "   964|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is\n",
      "   965|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.\n",
      "   966|         0|            0|            0|  0.00%|\n",
      "   967|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool1d` for details.\n",
      "   968|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   969|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   970|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   971|         0|            0|            0|  0.00%|            lp_pool1d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode\n",
      "   972|         0|            0|            0|  0.00%|        )\n",
      "   973|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   974|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n",
      "   975|         0|            0|            0|  0.00%|    else:\n",
      "   976|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)\n",
      "   977|         0|            0|            0|  0.00%|\n",
      "   978|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kernel_size).pow(1.0 / norm_type)\n",
      "   979|         0|            0|            0|  0.00%|\n",
      "   980|         0|            0|            0|  0.00%|\n",
      "   981|         0|            0|            0|  0.00%|def adaptive_max_pool1d_with_indices(\n",
      "   982|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False\n",
      "   983|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   984|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D adaptive max pooling over an input signal composed of\n",
      "   985|         0|            0|            0|  0.00%|    several input planes.\n",
      "   986|         0|            0|            0|  0.00%|\n",
      "   987|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool1d` for details and output shape.\n",
      "   988|         0|            0|            0|  0.00%|\n",
      "   989|         0|            0|            0|  0.00%|    Args:\n",
      "   990|         0|            0|            0|  0.00%|        output_size: the target output size (single integer)\n",
      "   991|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "   992|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   993|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   994|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   995|         0|            0|            0|  0.00%|            adaptive_max_pool1d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "   996|         0|            0|            0|  0.00%|        )\n",
      "   997|         0|            0|            0|  0.00%|    return torch.adaptive_max_pool1d(input, output_size)\n",
      "   998|         0|            0|            0|  0.00%|\n",
      "   999|         0|            0|            0|  0.00%|\n",
      "  1000|         0|            0|            0|  0.00%|def _adaptive_max_pool1d(input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False) -> Tensor:\n",
      "  1001|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1002|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1003|         0|            0|            0|  0.00%|            adaptive_max_pool1d, (input,), input, output_size, return_indices=return_indices\n",
      "  1004|         0|            0|            0|  0.00%|        )\n",
      "  1005|         0|            0|            0|  0.00%|    return adaptive_max_pool1d_with_indices(input, output_size)[0]\n",
      "  1006|         0|            0|            0|  0.00%|\n",
      "  1007|         0|            0|            0|  0.00%|\n",
      "  1008|         0|            0|            0|  0.00%|adaptive_max_pool1d = boolean_dispatch(\n",
      "  1009|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1010|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1011|         0|            0|            0|  0.00%|    default=False,\n",
      "  1012|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool1d_with_indices,\n",
      "  1013|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool1d,\n",
      "  1014|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1015|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool1d\",\n",
      "  1016|         0|            0|            0|  0.00%|)\n",
      "  1017|         0|            0|            0|  0.00%|\n",
      "  1018|         0|            0|            0|  0.00%|\n",
      "  1019|         0|            0|            0|  0.00%|def adaptive_max_pool2d_with_indices(\n",
      "  1020|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],\n",
      "  1021|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "  1022|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  1023|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D adaptive max pooling over an input signal composed of\n",
      "  1024|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1025|         0|            0|            0|  0.00%|\n",
      "  1026|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool2d` for details and output shape.\n",
      "  1027|         0|            0|            0|  0.00%|\n",
      "  1028|         0|            0|            0|  0.00%|    Args:\n",
      "  1029|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1030|         0|            0|            0|  0.00%|            double-integer tuple)\n",
      "  1031|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "  1032|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1033|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1034|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1035|         0|            0|            0|  0.00%|            adaptive_max_pool2d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "  1036|         0|            0|            0|  0.00%|        )\n",
      "  1037|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())\n",
      "  1038|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool2d(input, output_size)\n",
      "  1039|         0|            0|            0|  0.00%|\n",
      "  1040|         0|            0|            0|  0.00%|\n",
      "  1041|         0|            0|            0|  0.00%|def _adaptive_max_pool2d(input: Tensor, output_size: BroadcastingList2[int], return_indices: bool = False) -> Tensor:\n",
      "  1042|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1043|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1044|         0|            0|            0|  0.00%|            adaptive_max_pool2d, (input,), input, output_size, return_indices=return_indices\n",
      "  1045|         0|            0|            0|  0.00%|        )\n",
      "  1046|         0|            0|            0|  0.00%|    return adaptive_max_pool2d_with_indices(input, output_size)[0]\n",
      "  1047|         0|            0|            0|  0.00%|\n",
      "  1048|         0|            0|            0|  0.00%|\n",
      "  1049|         0|            0|            0|  0.00%|adaptive_max_pool2d = boolean_dispatch(\n",
      "  1050|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1051|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1052|         0|            0|            0|  0.00%|    default=False,\n",
      "  1053|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool2d_with_indices,\n",
      "  1054|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool2d,\n",
      "  1055|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1056|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool2d\",\n",
      "  1057|         0|            0|            0|  0.00%|)\n",
      "  1058|         0|            0|            0|  0.00%|\n",
      "  1059|         0|            0|            0|  0.00%|\n",
      "  1060|         0|            0|            0|  0.00%|def adaptive_max_pool3d_with_indices(\n",
      "  1061|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList3[int],\n",
      "  1062|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "  1063|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  1064|         0|            0|            0|  0.00%|    r\"\"\"Applies a 3D adaptive max pooling over an input signal composed of\n",
      "  1065|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1066|         0|            0|            0|  0.00%|\n",
      "  1067|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool3d` for details and output shape.\n",
      "  1068|         0|            0|            0|  0.00%|\n",
      "  1069|         0|            0|            0|  0.00%|    Args:\n",
      "  1070|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1071|         0|            0|            0|  0.00%|            triple-integer tuple)\n",
      "  1072|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "  1073|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1074|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1075|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1076|         0|            0|            0|  0.00%|            adaptive_max_pool3d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "  1077|         0|            0|            0|  0.00%|        )\n",
      "  1078|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())\n",
      "  1079|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool3d(input, output_size)\n",
      "  1080|         0|            0|            0|  0.00%|\n",
      "  1081|         0|            0|            0|  0.00%|\n",
      "  1082|         0|            0|            0|  0.00%|def _adaptive_max_pool3d(input: Tensor, output_size: BroadcastingList3[int], return_indices: bool = False) -> Tensor:\n",
      "  1083|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1084|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1085|         0|            0|            0|  0.00%|            adaptive_max_pool3d, (input,), input, output_size, return_indices=return_indices\n",
      "  1086|         0|            0|            0|  0.00%|        )\n",
      "  1087|         0|            0|            0|  0.00%|    return adaptive_max_pool3d_with_indices(input, output_size)[0]\n",
      "  1088|         0|            0|            0|  0.00%|\n",
      "  1089|         0|            0|            0|  0.00%|\n",
      "  1090|         0|            0|            0|  0.00%|adaptive_max_pool3d = boolean_dispatch(\n",
      "  1091|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1092|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1093|         0|            0|            0|  0.00%|    default=False,\n",
      "  1094|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool3d_with_indices,\n",
      "  1095|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool3d,\n",
      "  1096|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1097|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool3d\",\n",
      "  1098|         0|            0|            0|  0.00%|)\n",
      "  1099|         0|            0|            0|  0.00%|\n",
      "  1100|         0|            0|            0|  0.00%|\n",
      "  1101|         0|            0|            0|  0.00%|adaptive_avg_pool1d = _add_docstr(\n",
      "  1102|         0|            0|            0|  0.00%|    torch.adaptive_avg_pool1d,\n",
      "  1103|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1104|         0|            0|            0|  0.00%|adaptive_avg_pool1d(input, output_size) -> Tensor\n",
      "  1105|         0|            0|            0|  0.00%|\n",
      "  1106|         0|            0|            0|  0.00%|Applies a 1D adaptive average pooling over an input signal composed of\n",
      "  1107|         0|            0|            0|  0.00%|several input planes.\n",
      "  1108|         0|            0|            0|  0.00%|\n",
      "  1109|         0|            0|            0|  0.00%|See :class:`~torch.nn.AdaptiveAvgPool1d` for details and output shape.\n",
      "  1110|         0|            0|            0|  0.00%|\n",
      "  1111|         0|            0|            0|  0.00%|Args:\n",
      "  1112|         0|            0|            0|  0.00%|    output_size: the target output size (single integer)\n",
      "  1113|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1114|         0|            0|            0|  0.00%|)\n",
      "  1115|         0|            0|            0|  0.00%|\n",
      "  1116|         0|            0|            0|  0.00%|\n",
      "  1117|         0|            0|            0|  0.00%|def adaptive_avg_pool2d(input: Tensor, output_size: BroadcastingList2[int]) -> Tensor:\n",
      "  1118|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1119|         0|            0|            0|  0.00%|    Applies a 2D adaptive average pooling over an input signal composed of\n",
      "  1120|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1121|         0|            0|            0|  0.00%|\n",
      "  1122|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool2d` for details and output shape.\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    Args:\n",
      "  1125|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1126|         0|            0|            0|  0.00%|            double-integer tuple)\n",
      "  1127|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1128|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1129|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool2d, (input,), input, output_size)\n",
      "  1130|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())\n",
      "  1131|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n",
      "  1132|         0|            0|            0|  0.00%|\n",
      "  1133|         0|            0|            0|  0.00%|\n",
      "  1134|         0|            0|            0|  0.00%|def adaptive_avg_pool3d(input: Tensor, output_size: BroadcastingList3[int]) -> Tensor:\n",
      "  1135|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1136|         0|            0|            0|  0.00%|    Applies a 3D adaptive average pooling over an input signal composed of\n",
      "  1137|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1138|         0|            0|            0|  0.00%|\n",
      "  1139|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool3d` for details and output shape.\n",
      "  1140|         0|            0|            0|  0.00%|\n",
      "  1141|         0|            0|            0|  0.00%|    Args:\n",
      "  1142|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1143|         0|            0|            0|  0.00%|            triple-integer tuple)\n",
      "  1144|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1145|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1146|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool3d, (input,), input, output_size)\n",
      "  1147|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())\n",
      "  1148|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool3d(input, _output_size)\n",
      "  1149|         0|            0|            0|  0.00%|\n",
      "  1150|         0|            0|            0|  0.00%|\n",
      "  1151|         0|            0|            0|  0.00%|# Activation functions\n",
      "  1152|         0|            0|            0|  0.00%|def dropout(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1153|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1154|         0|            0|            0|  0.00%|    During training, randomly zeroes some of the elements of the input\n",
      "  1155|         0|            0|            0|  0.00%|    tensor with probability :attr:`p` using samples from a Bernoulli\n",
      "  1156|         0|            0|            0|  0.00%|    distribution.\n",
      "  1157|         0|            0|            0|  0.00%|\n",
      "  1158|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout` for details.\n",
      "  1159|         0|            0|            0|  0.00%|\n",
      "  1160|         0|            0|            0|  0.00%|    Args:\n",
      "  1161|         0|            0|            0|  0.00%|        p: probability of an element to be zeroed. Default: 0.5\n",
      "  1162|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1163|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1164|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1165|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1166|         0|            0|            0|  0.00%|        return handle_torch_function(dropout, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1167|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1168|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1169|         0|            0|            0|  0.00%|    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "  1170|         0|            0|            0|  0.00%|\n",
      "  1171|         0|            0|            0|  0.00%|\n",
      "  1172|         0|            0|            0|  0.00%|def alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:\n",
      "  1173|         0|            0|            0|  0.00%|    r\"\"\"Applies alpha dropout to the input.\n",
      "  1174|         0|            0|            0|  0.00%|\n",
      "  1175|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AlphaDropout` for details.\n",
      "  1176|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1177|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1178|         0|            0|            0|  0.00%|        return handle_torch_function(alpha_dropout, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1179|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1180|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1181|         0|            0|            0|  0.00%|    return _VF.alpha_dropout_(input, p, training) if inplace else _VF.alpha_dropout(input, p, training)\n",
      "  1182|         0|            0|            0|  0.00%|\n",
      "  1183|         0|            0|            0|  0.00%|\n",
      "  1184|         0|            0|            0|  0.00%|def dropout2d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1185|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1186|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 2D feature map,\n",
      "  1187|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the\n",
      "  1188|         0|            0|            0|  0.00%|    batched input is a 2D tensor :math:`\\text{input}[i, j]`) of the input tensor).\n",
      "  1189|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with\n",
      "  1190|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1191|         0|            0|            0|  0.00%|\n",
      "  1192|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout2d` for details.\n",
      "  1193|         0|            0|            0|  0.00%|\n",
      "  1194|         0|            0|            0|  0.00%|    Args:\n",
      "  1195|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5\n",
      "  1196|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1197|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1198|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1199|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1200|         0|            0|            0|  0.00%|        return handle_torch_function(dropout2d, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1201|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1202|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1203|         0|            0|            0|  0.00%|    return _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)\n",
      "  1204|         0|            0|            0|  0.00%|\n",
      "  1205|         0|            0|            0|  0.00%|\n",
      "  1206|         0|            0|            0|  0.00%|def dropout3d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1207|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1208|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 3D feature map,\n",
      "  1209|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the\n",
      "  1210|         0|            0|            0|  0.00%|    batched input is a 3D tensor :math:`\\text{input}[i, j]`) of the input tensor).\n",
      "  1211|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with\n",
      "  1212|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1213|         0|            0|            0|  0.00%|\n",
      "  1214|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout3d` for details.\n",
      "  1215|         0|            0|            0|  0.00%|\n",
      "  1216|         0|            0|            0|  0.00%|    Args:\n",
      "  1217|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5\n",
      "  1218|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1219|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1220|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1221|         0|            0|            0|  0.00%|    # This is 100% the same code as dropout2d. We duplicate this code so that\n",
      "  1222|         0|            0|            0|  0.00%|    # stack traces are not confusing.\n",
      "  1223|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1224|         0|            0|            0|  0.00%|        return handle_torch_function(dropout3d, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1225|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1226|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1227|         0|            0|            0|  0.00%|    return _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)\n",
      "  1228|         0|            0|            0|  0.00%|\n",
      "  1229|         0|            0|            0|  0.00%|\n",
      "  1230|         0|            0|            0|  0.00%|def feature_alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:\n",
      "  1231|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1232|         0|            0|            0|  0.00%|    Randomly masks out entire channels (a channel is a feature map,\n",
      "  1233|         0|            0|            0|  0.00%|    e.g. the :math:`j`-th channel of the :math:`i`-th sample in the batch input\n",
      "  1234|         0|            0|            0|  0.00%|    is a tensor :math:`\\text{input}[i, j]`) of the input tensor). Instead of\n",
      "  1235|         0|            0|            0|  0.00%|    setting activations to zero, as in regular Dropout, the activations are set\n",
      "  1236|         0|            0|            0|  0.00%|    to the negative saturation value of the SELU activation function.\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    Each element will be masked independently on every forward call with\n",
      "  1239|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1240|         0|            0|            0|  0.00%|    The elements to be masked are randomized on every forward call, and scaled\n",
      "  1241|         0|            0|            0|  0.00%|    and shifted to maintain zero mean and unit variance.\n",
      "  1242|         0|            0|            0|  0.00%|\n",
      "  1243|         0|            0|            0|  0.00%|    See :class:`~torch.nn.FeatureAlphaDropout` for details.\n",
      "  1244|         0|            0|            0|  0.00%|\n",
      "  1245|         0|            0|            0|  0.00%|    Args:\n",
      "  1246|         0|            0|            0|  0.00%|        p: dropout probability of a channel to be zeroed. Default: 0.5\n",
      "  1247|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1248|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1249|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1250|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1251|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1252|         0|            0|            0|  0.00%|            feature_alpha_dropout, (input,), input, p=p, training=training, inplace=inplace\n",
      "  1253|         0|            0|            0|  0.00%|        )\n",
      "  1254|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1255|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1256|         0|            0|            0|  0.00%|    return _VF.feature_alpha_dropout_(input, p, training) if inplace else _VF.feature_alpha_dropout(input, p, training)\n",
      "  1257|         0|            0|            0|  0.00%|\n",
      "  1258|         0|            0|            0|  0.00%|\n",
      "  1259|         0|            0|            0|  0.00%|def _threshold(input: Tensor, threshold: float, value: float, inplace: bool = False) -> Tensor:\n",
      "  1260|         0|            0|            0|  0.00%|    r\"\"\"Thresholds each element of the input Tensor.\n",
      "  1261|         0|            0|            0|  0.00%|\n",
      "  1262|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Threshold` for more details.\n",
      "  1263|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1264|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1265|         0|            0|            0|  0.00%|        return handle_torch_function(_threshold, (input,), input, threshold, value, inplace=inplace)\n",
      "  1266|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1267|         0|            0|            0|  0.00%|        result = _VF.threshold_(input, threshold, value)\n",
      "  1268|         0|            0|            0|  0.00%|    else:\n",
      "  1269|         0|            0|            0|  0.00%|        result = _VF.threshold(input, threshold, value)\n",
      "  1270|         0|            0|            0|  0.00%|    return result\n",
      "  1271|         0|            0|            0|  0.00%|\n",
      "  1272|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1273|         0|            0|            0|  0.00%|# We define this function as _threshold because it takes an argument\n",
      "  1274|         0|            0|            0|  0.00%|# named threshold, which clobbers the recursive reference to the\n",
      "  1275|         0|            0|            0|  0.00%|# function needed for __torch_function__ support\n",
      "  1276|         0|            0|            0|  0.00%|threshold = _threshold\n",
      "  1277|         0|            0|            0|  0.00%|\n",
      "  1278|         0|            0|            0|  0.00%|threshold_ = _add_docstr(\n",
      "  1279|         0|            0|            0|  0.00%|    _VF.threshold_,\n",
      "  1280|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1281|         0|            0|            0|  0.00%|threshold_(input, threshold, value) -> Tensor\n",
      "  1282|         0|            0|            0|  0.00%|\n",
      "  1283|         0|            0|            0|  0.00%|In-place version of :func:`~threshold`.\n",
      "  1284|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1285|         0|            0|            0|  0.00%|)\n",
      "  1286|         0|            0|            0|  0.00%|\n",
      "  1287|         0|            0|            0|  0.00%|\n",
      "  1288|         0|            0|            0|  0.00%|def relu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1289|         0|            0|            0|  0.00%|    r\"\"\"relu(input, inplace=False) -> Tensor\n",
      "  1290|         0|            0|            0|  0.00%|\n",
      "  1291|         0|            0|            0|  0.00%|    Applies the rectified linear unit function element-wise. See\n",
      "  1292|         0|            0|            0|  0.00%|    :class:`~torch.nn.ReLU` for more details.\n",
      "  1293|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1294|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1295|         0|            0|            0|  0.00%|        return handle_torch_function(relu, (input,), input, inplace=inplace)\n",
      "  1296|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1297|         0|            0|            0|  0.00%|        result = torch.relu_(input)\n",
      "  1298|         0|            0|            0|  0.00%|    else:\n",
      "  1299|         0|            0|            0|  0.00%|        result = torch.relu(input)\n",
      "  1300|         0|            0|            0|  0.00%|    return result\n",
      "  1301|         0|            0|            0|  0.00%|\n",
      "  1302|         0|            0|            0|  0.00%|\n",
      "  1303|         0|            0|            0|  0.00%|relu_ = _add_docstr(\n",
      "  1304|         0|            0|            0|  0.00%|    torch.relu_,\n",
      "  1305|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1306|         0|            0|            0|  0.00%|relu_(input) -> Tensor\n",
      "  1307|         0|            0|            0|  0.00%|\n",
      "  1308|         0|            0|            0|  0.00%|In-place version of :func:`~relu`.\n",
      "  1309|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1310|         0|            0|            0|  0.00%|)\n",
      "  1311|         0|            0|            0|  0.00%|\n",
      "  1312|         0|            0|            0|  0.00%|\n",
      "  1313|         0|            0|            0|  0.00%|def glu(input: Tensor, dim: int = -1) -> Tensor:\n",
      "  1314|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1315|         0|            0|            0|  0.00%|    glu(input, dim=-1) -> Tensor\n",
      "  1316|         0|            0|            0|  0.00%|\n",
      "  1317|         0|            0|            0|  0.00%|    The gated linear unit. Computes:\n",
      "  1318|         0|            0|            0|  0.00%|\n",
      "  1319|         0|            0|            0|  0.00%|    .. math ::\n",
      "  1320|         0|            0|            0|  0.00%|        \\text{GLU}(a, b) = a \\otimes \\sigma(b)\n",
      "  1321|         0|            0|            0|  0.00%|\n",
      "  1322|         0|            0|            0|  0.00%|    where `input` is split in half along `dim` to form `a` and `b`, :math:`\\sigma`\n",
      "  1323|         0|            0|            0|  0.00%|    is the sigmoid function and :math:`\\otimes` is the element-wise product between matrices.\n",
      "  1324|         0|            0|            0|  0.00%|\n",
      "  1325|         0|            0|            0|  0.00%|    See `Language Modeling with Gated Convolutional Networks <https://arxiv.org/abs/1612.08083>`_.\n",
      "  1326|         0|            0|            0|  0.00%|\n",
      "  1327|         0|            0|            0|  0.00%|    Args:\n",
      "  1328|         0|            0|            0|  0.00%|        input (Tensor): input tensor\n",
      "  1329|         0|            0|            0|  0.00%|        dim (int): dimension on which to split the input. Default: -1\n",
      "  1330|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1331|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1332|         0|            0|            0|  0.00%|        return handle_torch_function(glu, (input,), input, dim=dim)\n",
      "  1333|         0|            0|            0|  0.00%|    if input.dim() == 0:\n",
      "  1334|         0|            0|            0|  0.00%|        raise RuntimeError(\"glu does not support scalars because halving size must be even\")\n",
      "  1335|         0|            0|            0|  0.00%|    return torch._C._nn.glu(input, dim)\n",
      "  1336|         0|            0|            0|  0.00%|\n",
      "  1337|         0|            0|            0|  0.00%|\n",
      "  1338|         0|            0|            0|  0.00%|def hardtanh(input: Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1339|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1340|         0|            0|            0|  0.00%|    hardtanh(input, min_val=-1., max_val=1., inplace=False) -> Tensor\n",
      "  1341|         0|            0|            0|  0.00%|\n",
      "  1342|         0|            0|            0|  0.00%|    Applies the HardTanh function element-wise. See :class:`~torch.nn.Hardtanh` for more\n",
      "  1343|         0|            0|            0|  0.00%|    details.\n",
      "  1344|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1345|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1346|         0|            0|            0|  0.00%|        return handle_torch_function(hardtanh, (input,), input, min_val=min_val, max_val=max_val, inplace=inplace)\n",
      "  1347|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1348|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh_(input, min_val, max_val)\n",
      "  1349|         0|            0|            0|  0.00%|    else:\n",
      "  1350|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh(input, min_val, max_val)\n",
      "  1351|         0|            0|            0|  0.00%|    return result\n",
      "  1352|         0|            0|            0|  0.00%|\n",
      "  1353|         0|            0|            0|  0.00%|\n",
      "  1354|         0|            0|            0|  0.00%|hardtanh_ = _add_docstr(\n",
      "  1355|         0|            0|            0|  0.00%|    torch._C._nn.hardtanh_,\n",
      "  1356|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1357|         0|            0|            0|  0.00%|hardtanh_(input, min_val=-1., max_val=1.) -> Tensor\n",
      "  1358|         0|            0|            0|  0.00%|\n",
      "  1359|         0|            0|            0|  0.00%|In-place version of :func:`~hardtanh`.\n",
      "  1360|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1361|         0|            0|            0|  0.00%|)\n",
      "  1362|         0|            0|            0|  0.00%|\n",
      "  1363|         0|            0|            0|  0.00%|\n",
      "  1364|         0|            0|            0|  0.00%|def relu6(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1365|         0|            0|            0|  0.00%|    r\"\"\"relu6(input, inplace=False) -> Tensor\n",
      "  1366|         0|            0|            0|  0.00%|\n",
      "  1367|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\\text{ReLU6}(x) = \\min(\\max(0,x), 6)`.\n",
      "  1368|         0|            0|            0|  0.00%|\n",
      "  1369|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ReLU6` for more details.\n",
      "  1370|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1371|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1372|         0|            0|            0|  0.00%|        return handle_torch_function(relu6, (input,), input, inplace=inplace)\n",
      "  1373|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1374|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6_(input)\n",
      "  1375|         0|            0|            0|  0.00%|    else:\n",
      "  1376|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6(input)\n",
      "  1377|         0|            0|            0|  0.00%|    return result\n",
      "  1378|         0|            0|            0|  0.00%|\n",
      "  1379|         0|            0|            0|  0.00%|\n",
      "  1380|         0|            0|            0|  0.00%|def elu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1381|         0|            0|            0|  0.00%|    r\"\"\"Applies element-wise,\n",
      "  1382|         0|            0|            0|  0.00%|    :math:`\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))`.\n",
      "  1383|         0|            0|            0|  0.00%|\n",
      "  1384|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ELU` for more details.\n",
      "  1385|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1386|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1387|         0|            0|            0|  0.00%|        return handle_torch_function(elu, (input,), input, alpha=alpha, inplace=inplace)\n",
      "  1388|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1389|         0|            0|            0|  0.00%|        result = torch._C._nn.elu_(input, alpha)\n",
      "  1390|         0|            0|            0|  0.00%|    else:\n",
      "  1391|         0|            0|            0|  0.00%|        result = torch._C._nn.elu(input, alpha)\n",
      "  1392|         0|            0|            0|  0.00%|    return result\n",
      "  1393|         0|            0|            0|  0.00%|\n",
      "  1394|         0|            0|            0|  0.00%|\n",
      "  1395|         0|            0|            0|  0.00%|elu_ = _add_docstr(\n",
      "  1396|         0|            0|            0|  0.00%|    torch._C._nn.elu_,\n",
      "  1397|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1398|         0|            0|            0|  0.00%|elu_(input, alpha=1.) -> Tensor\n",
      "  1399|         0|            0|            0|  0.00%|\n",
      "  1400|         0|            0|            0|  0.00%|In-place version of :func:`~elu`.\n",
      "  1401|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1402|         0|            0|            0|  0.00%|)\n",
      "  1403|         0|            0|            0|  0.00%|\n",
      "  1404|         0|            0|            0|  0.00%|\n",
      "  1405|         0|            0|            0|  0.00%|def selu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1406|         0|            0|            0|  0.00%|    r\"\"\"selu(input, inplace=False) -> Tensor\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1409|         0|            0|            0|  0.00%|    :math:`\\text{SELU}(x) = scale * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))`,\n",
      "  1410|         0|            0|            0|  0.00%|    with :math:`\\alpha=1.6732632423543772848170429916717` and\n",
      "  1411|         0|            0|            0|  0.00%|    :math:`scale=1.0507009873554804934193349852946`.\n",
      "  1412|         0|            0|            0|  0.00%|\n",
      "  1413|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SELU` for more details.\n",
      "  1414|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1415|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1416|         0|            0|            0|  0.00%|        return handle_torch_function(selu, (input,), input, inplace=inplace)\n",
      "  1417|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1418|         0|            0|            0|  0.00%|        result = torch.selu_(input)\n",
      "  1419|         0|            0|            0|  0.00%|    else:\n",
      "  1420|         0|            0|            0|  0.00%|        result = torch.selu(input)\n",
      "  1421|         0|            0|            0|  0.00%|    return result\n",
      "  1422|         0|            0|            0|  0.00%|\n",
      "  1423|         0|            0|            0|  0.00%|\n",
      "  1424|         0|            0|            0|  0.00%|selu_ = _add_docstr(\n",
      "  1425|         0|            0|            0|  0.00%|    torch.selu_,\n",
      "  1426|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1427|         0|            0|            0|  0.00%|selu_(input) -> Tensor\n",
      "  1428|         0|            0|            0|  0.00%|\n",
      "  1429|         0|            0|            0|  0.00%|In-place version of :func:`~selu`.\n",
      "  1430|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1431|         0|            0|            0|  0.00%|)\n",
      "  1432|         0|            0|            0|  0.00%|\n",
      "  1433|         0|            0|            0|  0.00%|\n",
      "  1434|         0|            0|            0|  0.00%|def celu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1435|         0|            0|            0|  0.00%|    r\"\"\"celu(input, alpha=1., inplace=False) -> Tensor\n",
      "  1436|         0|            0|            0|  0.00%|\n",
      "  1437|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1438|         0|            0|            0|  0.00%|    :math:`\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))`.\n",
      "  1439|         0|            0|            0|  0.00%|\n",
      "  1440|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CELU` for more details.\n",
      "  1441|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1442|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1443|         0|            0|            0|  0.00%|        return handle_torch_function(celu, (input,), input, alpha=alpha, inplace=inplace)\n",
      "  1444|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1445|         0|            0|            0|  0.00%|        result = torch.celu_(input, alpha)\n",
      "  1446|         0|            0|            0|  0.00%|    else:\n",
      "  1447|         0|            0|            0|  0.00%|        result = torch.celu(input, alpha)\n",
      "  1448|         0|            0|            0|  0.00%|    return result\n",
      "  1449|         0|            0|            0|  0.00%|\n",
      "  1450|         0|            0|            0|  0.00%|\n",
      "  1451|         0|            0|            0|  0.00%|celu_ = _add_docstr(\n",
      "  1452|         0|            0|            0|  0.00%|    torch.celu_,\n",
      "  1453|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1454|         0|            0|            0|  0.00%|celu_(input, alpha=1.) -> Tensor\n",
      "  1455|         0|            0|            0|  0.00%|\n",
      "  1456|         0|            0|            0|  0.00%|In-place version of :func:`~celu`.\n",
      "  1457|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1458|         0|            0|            0|  0.00%|)\n",
      "  1459|         0|            0|            0|  0.00%|\n",
      "  1460|         0|            0|            0|  0.00%|\n",
      "  1461|         0|            0|            0|  0.00%|def leaky_relu(input: Tensor, negative_slope: float = 0.01, inplace: bool = False) -> Tensor:\n",
      "  1462|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1463|         0|            0|            0|  0.00%|    leaky_relu(input, negative_slope=0.01, inplace=False) -> Tensor\n",
      "  1464|         0|            0|            0|  0.00%|\n",
      "  1465|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1466|         0|            0|            0|  0.00%|    :math:`\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)`\n",
      "  1467|         0|            0|            0|  0.00%|\n",
      "  1468|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LeakyReLU` for more details.\n",
      "  1469|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1470|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1471|         0|            0|            0|  0.00%|        return handle_torch_function(leaky_relu, (input,), input, negative_slope=negative_slope, inplace=inplace)\n",
      "  1472|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1473|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu_(input, negative_slope)\n",
      "  1474|         0|            0|            0|  0.00%|    else:\n",
      "  1475|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "  1476|         0|            0|            0|  0.00%|    return result\n",
      "  1477|         0|            0|            0|  0.00%|\n",
      "  1478|         0|            0|            0|  0.00%|\n",
      "  1479|         0|            0|            0|  0.00%|leaky_relu_ = _add_docstr(\n",
      "  1480|         0|            0|            0|  0.00%|    torch._C._nn.leaky_relu_,\n",
      "  1481|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1482|         0|            0|            0|  0.00%|leaky_relu_(input, negative_slope=0.01) -> Tensor\n",
      "  1483|         0|            0|            0|  0.00%|\n",
      "  1484|         0|            0|            0|  0.00%|In-place version of :func:`~leaky_relu`.\n",
      "  1485|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1486|         0|            0|            0|  0.00%|)\n",
      "  1487|         0|            0|            0|  0.00%|\n",
      "  1488|         0|            0|            0|  0.00%|\n",
      "  1489|         0|            0|            0|  0.00%|def prelu(input: Tensor, weight: Tensor) -> Tensor:\n",
      "  1490|         0|            0|            0|  0.00%|    r\"\"\"prelu(input, weight) -> Tensor\n",
      "  1491|         0|            0|            0|  0.00%|\n",
      "  1492|         0|            0|            0|  0.00%|    Applies element-wise the function\n",
      "  1493|         0|            0|            0|  0.00%|    :math:`\\text{PReLU}(x) = \\max(0,x) + \\text{weight} * \\min(0,x)` where weight is a\n",
      "  1494|         0|            0|            0|  0.00%|    learnable parameter.\n",
      "  1495|         0|            0|            0|  0.00%|\n",
      "  1496|         0|            0|            0|  0.00%|    See :class:`~torch.nn.PReLU` for more details.\n",
      "  1497|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1498|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1499|         0|            0|            0|  0.00%|        return handle_torch_function(prelu, (input,), input, weight)\n",
      "  1500|         0|            0|            0|  0.00%|    return torch.prelu(input, weight)\n",
      "  1501|         0|            0|            0|  0.00%|\n",
      "  1502|         0|            0|            0|  0.00%|\n",
      "  1503|         0|            0|            0|  0.00%|def rrelu(\n",
      "  1504|         0|            0|            0|  0.00%|    input: Tensor, lower: float = 1.0 / 8, upper: float = 1.0 / 3, training: bool = False, inplace: bool = False\n",
      "  1505|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  1506|         0|            0|            0|  0.00%|    r\"\"\"rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False) -> Tensor\n",
      "  1507|         0|            0|            0|  0.00%|\n",
      "  1508|         0|            0|            0|  0.00%|    Randomized leaky ReLU.\n",
      "  1509|         0|            0|            0|  0.00%|\n",
      "  1510|         0|            0|            0|  0.00%|    See :class:`~torch.nn.RReLU` for more details.\n",
      "  1511|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1512|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1513|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1514|         0|            0|            0|  0.00%|            rrelu, (input,), input, lower=lower, upper=upper, training=training, inplace=inplace\n",
      "  1515|         0|            0|            0|  0.00%|        )\n",
      "  1516|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1517|         0|            0|            0|  0.00%|        result = torch.rrelu_(input, lower, upper, training)\n",
      "  1518|         0|            0|            0|  0.00%|    else:\n",
      "  1519|         0|            0|            0|  0.00%|        result = torch.rrelu(input, lower, upper, training)\n",
      "  1520|         0|            0|            0|  0.00%|    return result\n",
      "  1521|         0|            0|            0|  0.00%|\n",
      "  1522|         0|            0|            0|  0.00%|\n",
      "  1523|         0|            0|            0|  0.00%|rrelu_ = _add_docstr(\n",
      "  1524|         0|            0|            0|  0.00%|    torch.rrelu_,\n",
      "  1525|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1526|         0|            0|            0|  0.00%|rrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor\n",
      "  1527|         0|            0|            0|  0.00%|\n",
      "  1528|         0|            0|            0|  0.00%|In-place version of :func:`~rrelu`.\n",
      "  1529|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1530|         0|            0|            0|  0.00%|)\n",
      "  1531|         0|            0|            0|  0.00%|\n",
      "  1532|         0|            0|            0|  0.00%|logsigmoid = _add_docstr(\n",
      "  1533|         0|            0|            0|  0.00%|    torch._C._nn.log_sigmoid,\n",
      "  1534|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1535|         0|            0|            0|  0.00%|logsigmoid(input) -> Tensor\n",
      "  1536|         0|            0|            0|  0.00%|\n",
      "  1537|         0|            0|            0|  0.00%|Applies element-wise :math:`\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)`\n",
      "  1538|         0|            0|            0|  0.00%|\n",
      "  1539|         0|            0|            0|  0.00%|See :class:`~torch.nn.LogSigmoid` for more details.\n",
      "  1540|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1541|         0|            0|            0|  0.00%|)\n",
      "  1542|         0|            0|            0|  0.00%|\n",
      "  1543|         0|            0|            0|  0.00%|\n",
      "  1544|         0|            0|            0|  0.00%|def gelu(input):\n",
      "  1545|         0|            0|            0|  0.00%|    r\"\"\"gelu(input) -> Tensor\n",
      "  1546|         0|            0|            0|  0.00%|\n",
      "  1547|         0|            0|            0|  0.00%|    Applies element-wise the function\n",
      "  1548|         0|            0|            0|  0.00%|    :math:`\\text{GELU}(x) = x * \\Phi(x)`\n",
      "  1549|         0|            0|            0|  0.00%|\n",
      "  1550|         0|            0|            0|  0.00%|    where :math:`\\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.\n",
      "  1551|         0|            0|            0|  0.00%|\n",
      "  1552|         0|            0|            0|  0.00%|    See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_.\n",
      "  1553|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1554|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1555|         0|            0|            0|  0.00%|        return handle_torch_function(gelu, (input,), input)\n",
      "  1556|         0|            0|            0|  0.00%|    return torch._C._nn.gelu(input)\n",
      "  1557|         0|            0|            0|  0.00%|\n",
      "  1558|         0|            0|            0|  0.00%|\n",
      "  1559|         0|            0|            0|  0.00%|def hardshrink(input: Tensor, lambd: float = 0.5) -> Tensor:\n",
      "  1560|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1561|         0|            0|            0|  0.00%|    hardshrink(input, lambd=0.5) -> Tensor\n",
      "  1562|         0|            0|            0|  0.00%|\n",
      "  1563|         0|            0|            0|  0.00%|    Applies the hard shrinkage function element-wise\n",
      "  1564|         0|            0|            0|  0.00%|\n",
      "  1565|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardshrink` for more details.\n",
      "  1566|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1567|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1568|         0|            0|            0|  0.00%|        return handle_torch_function(hardshrink, (input,), input, lambd=lambd)\n",
      "  1569|         0|            0|            0|  0.00%|    return torch.hardshrink(input, lambd)\n",
      "  1570|         0|            0|            0|  0.00%|\n",
      "  1571|         0|            0|            0|  0.00%|\n",
      "  1572|         0|            0|            0|  0.00%|def tanhshrink(input):\n",
      "  1573|         0|            0|            0|  0.00%|    r\"\"\"tanhshrink(input) -> Tensor\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|    Applies element-wise, :math:`\\text{Tanhshrink}(x) = x - \\text{Tanh}(x)`\n",
      "  1576|         0|            0|            0|  0.00%|\n",
      "  1577|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanhshrink` for more details.\n",
      "  1578|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1579|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1580|         0|            0|            0|  0.00%|        return handle_torch_function(tanhshrink, (input,), input)\n",
      "  1581|         0|            0|            0|  0.00%|    return input - input.tanh()\n",
      "  1582|         0|            0|            0|  0.00%|\n",
      "  1583|         0|            0|            0|  0.00%|\n",
      "  1584|         0|            0|            0|  0.00%|def softsign(input):\n",
      "  1585|         0|            0|            0|  0.00%|    r\"\"\"softsign(input) -> Tensor\n",
      "  1586|         0|            0|            0|  0.00%|\n",
      "  1587|         0|            0|            0|  0.00%|    Applies element-wise, the function :math:`\\text{SoftSign}(x) = \\frac{x}{1 + |x|}`\n",
      "  1588|         0|            0|            0|  0.00%|\n",
      "  1589|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softsign` for more details.\n",
      "  1590|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1591|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1592|         0|            0|            0|  0.00%|        return handle_torch_function(softsign, (input,), input)\n",
      "  1593|         0|            0|            0|  0.00%|    return input / (input.abs() + 1)\n",
      "  1594|         0|            0|            0|  0.00%|\n",
      "  1595|         0|            0|            0|  0.00%|\n",
      "  1596|         0|            0|            0|  0.00%|softplus = _add_docstr(\n",
      "  1597|         0|            0|            0|  0.00%|    torch._C._nn.softplus,\n",
      "  1598|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1599|         0|            0|            0|  0.00%|softplus(input, beta=1, threshold=20) -> Tensor\n",
      "  1600|         0|            0|            0|  0.00%|\n",
      "  1601|         0|            0|            0|  0.00%|Applies element-wise, the function :math:`\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))`.\n",
      "  1602|         0|            0|            0|  0.00%|\n",
      "  1603|         0|            0|            0|  0.00%|For numerical stability the implementation reverts to the linear function\n",
      "  1604|         0|            0|            0|  0.00%|when :math:`input \\times \\beta > threshold`.\n",
      "  1605|         0|            0|            0|  0.00%|\n",
      "  1606|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softplus` for more details.\n",
      "  1607|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1608|         0|            0|            0|  0.00%|)\n",
      "  1609|         0|            0|            0|  0.00%|\n",
      "  1610|         0|            0|            0|  0.00%|\n",
      "  1611|         0|            0|            0|  0.00%|def _get_softmax_dim(name: str, ndim: int, stacklevel: int) -> int:\n",
      "  1612|         0|            0|            0|  0.00%|    warnings.warn(\n",
      "  1613|         0|            0|            0|  0.00%|        \"Implicit dimension choice for {} has been deprecated. \"\n",
      "  1614|         0|            0|            0|  0.00%|        \"Change the call to include dim=X as an argument.\".format(name),\n",
      "  1615|         0|            0|            0|  0.00%|        stacklevel=stacklevel,\n",
      "  1616|         0|            0|            0|  0.00%|    )\n",
      "  1617|         0|            0|            0|  0.00%|    if ndim == 0 or ndim == 1 or ndim == 3:\n",
      "  1618|         0|            0|            0|  0.00%|        ret = 0\n",
      "  1619|         0|            0|            0|  0.00%|    else:\n",
      "  1620|         0|            0|            0|  0.00%|        ret = 1\n",
      "  1621|         0|            0|            0|  0.00%|    return ret\n",
      "  1622|         0|            0|            0|  0.00%|\n",
      "  1623|         0|            0|            0|  0.00%|\n",
      "  1624|         0|            0|            0|  0.00%|def softmin(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1625|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmin function.\n",
      "  1626|         0|            0|            0|  0.00%|\n",
      "  1627|         0|            0|            0|  0.00%|    Note that :math:`\\text{Softmin}(x) = \\text{Softmax}(-x)`. See softmax definition for mathematical formula.\n",
      "  1628|         0|            0|            0|  0.00%|\n",
      "  1629|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmin` for more details.\n",
      "  1630|         0|            0|            0|  0.00%|\n",
      "  1631|         0|            0|            0|  0.00%|    Args:\n",
      "  1632|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1633|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmin will be computed (so every slice\n",
      "  1634|         0|            0|            0|  0.00%|            along dim will sum to 1).\n",
      "  1635|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1636|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "  1637|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1638|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1639|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1640|         0|            0|            0|  0.00%|        return handle_torch_function(softmin, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1641|         0|            0|            0|  0.00%|    if dim is None:\n",
      "  1642|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"softmin\", input.dim(), _stacklevel)\n",
      "  1643|         0|            0|            0|  0.00%|    if dtype is None:\n",
      "  1644|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim)\n",
      "  1645|         0|            0|            0|  0.00%|    else:\n",
      "  1646|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim, dtype=dtype)\n",
      "  1647|         0|            0|            0|  0.00%|    return ret\n",
      "  1648|         0|            0|            0|  0.00%|\n",
      "  1649|         0|            0|            0|  0.00%|\n",
      "  1650|         8|  3.19481e-05|  3.99351e-06|  0.01%|def softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1651|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmax function.\n",
      "  1652|         0|            0|            0|  0.00%|\n",
      "  1653|         0|            0|            0|  0.00%|    Softmax is defined as:\n",
      "  1654|         0|            0|            0|  0.00%|\n",
      "  1655|         0|            0|            0|  0.00%|    :math:`\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}`\n",
      "  1656|         0|            0|            0|  0.00%|\n",
      "  1657|         0|            0|            0|  0.00%|    It is applied to all slices along dim, and will re-scale them so that the elements\n",
      "  1658|         0|            0|            0|  0.00%|    lie in the range `[0, 1]` and sum to 1.\n",
      "  1659|         0|            0|            0|  0.00%|\n",
      "  1660|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmax` for more details.\n",
      "  1661|         0|            0|            0|  0.00%|\n",
      "  1662|         0|            0|            0|  0.00%|    Args:\n",
      "  1663|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1664|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmax will be computed.\n",
      "  1665|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1666|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "  1667|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1668|         0|            0|            0|  0.00%|\n",
      "  1669|         0|            0|            0|  0.00%|    .. note::\n",
      "  1670|         0|            0|            0|  0.00%|        This function doesn't work directly with NLLLoss,\n",
      "  1671|         0|            0|            0|  0.00%|        which expects the Log to be computed between the Softmax and itself.\n",
      "  1672|         0|            0|            0|  0.00%|        Use log_softmax instead (it's faster and has better numerical properties).\n",
      "  1673|         0|            0|            0|  0.00%|\n",
      "  1674|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1675|         8|  3.00407e-05|  3.75509e-06|  0.01%|    if has_torch_function_unary(input):\n",
      "  1676|         0|            0|            0|  0.00%|        return handle_torch_function(softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1677|         8|  2.24113e-05|  2.80142e-06|  0.01%|    if dim is None:\n",
      "  1678|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"softmax\", input.dim(), _stacklevel)\n",
      "  1679|         8|  1.90735e-05|  2.38419e-06|  0.01%|    if dtype is None:\n",
      "  1680|         8|  0.000112772|  1.40965e-05|  0.05%|        ret = input.softmax(dim)\n",
      "  1681|         0|            0|            0|  0.00%|    else:\n",
      "  1682|         0|            0|            0|  0.00%|        ret = input.softmax(dim, dtype=dtype)\n",
      "  1683|         8|  2.45571e-05|  3.06964e-06|  0.01%|    return ret\n",
      "  1684|         0|            0|            0|  0.00%|\n",
      "  1685|         0|            0|            0|  0.00%|\n",
      "  1686|         0|            0|            0|  0.00%|def gumbel_softmax(logits: Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> Tensor:\n",
      "  1687|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1688|         0|            0|            0|  0.00%|    Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.\n",
      "  1689|         0|            0|            0|  0.00%|\n",
      "  1690|         0|            0|            0|  0.00%|    Args:\n",
      "  1691|         0|            0|            0|  0.00%|      logits: `[..., num_features]` unnormalized log probabilities\n",
      "  1692|         0|            0|            0|  0.00%|      tau: non-negative scalar temperature\n",
      "  1693|         0|            0|            0|  0.00%|      hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n",
      "  1694|         0|            0|            0|  0.00%|            but will be differentiated as if it is the soft sample in autograd\n",
      "  1695|         0|            0|            0|  0.00%|      dim (int): A dimension along which softmax will be computed. Default: -1.\n",
      "  1696|         0|            0|            0|  0.00%|\n",
      "  1697|         0|            0|            0|  0.00%|    Returns:\n",
      "  1698|         0|            0|            0|  0.00%|      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n",
      "  1699|         0|            0|            0|  0.00%|      If ``hard=True``, the returned samples will be one-hot, otherwise they will\n",
      "  1700|         0|            0|            0|  0.00%|      be probability distributions that sum to 1 across `dim`.\n",
      "  1701|         0|            0|            0|  0.00%|\n",
      "  1702|         0|            0|            0|  0.00%|    .. note::\n",
      "  1703|         0|            0|            0|  0.00%|      This function is here for legacy reasons, may be removed from nn.Functional in the future.\n",
      "  1704|         0|            0|            0|  0.00%|\n",
      "  1705|         0|            0|            0|  0.00%|    .. note::\n",
      "  1706|         0|            0|            0|  0.00%|      The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`\n",
      "  1707|         0|            0|            0|  0.00%|\n",
      "  1708|         0|            0|            0|  0.00%|      It achieves two things:\n",
      "  1709|         0|            0|            0|  0.00%|      - makes the output value exactly one-hot\n",
      "  1710|         0|            0|            0|  0.00%|      (since we add then subtract y_soft value)\n",
      "  1711|         0|            0|            0|  0.00%|      - makes the gradient equal to y_soft gradient\n",
      "  1712|         0|            0|            0|  0.00%|      (since we strip all other gradients)\n",
      "  1713|         0|            0|            0|  0.00%|\n",
      "  1714|         0|            0|            0|  0.00%|    Examples::\n",
      "  1715|         0|            0|            0|  0.00%|        >>> logits = torch.randn(20, 32)\n",
      "  1716|         0|            0|            0|  0.00%|        >>> # Sample soft categorical using reparametrization trick:\n",
      "  1717|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=False)\n",
      "  1718|         0|            0|            0|  0.00%|        >>> # Sample hard categorical using \"Straight-through\" trick:\n",
      "  1719|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=True)\n",
      "  1720|         0|            0|            0|  0.00%|\n",
      "  1721|         0|            0|            0|  0.00%|    .. _Link 1:\n",
      "  1722|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.00712\n",
      "  1723|         0|            0|            0|  0.00%|    .. _Link 2:\n",
      "  1724|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.01144\n",
      "  1725|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1726|         0|            0|            0|  0.00%|    if has_torch_function_unary(logits):\n",
      "  1727|         0|            0|            0|  0.00%|        return handle_torch_function(gumbel_softmax, (logits,), logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
      "  1728|         0|            0|            0|  0.00%|    if eps != 1e-10:\n",
      "  1729|         0|            0|            0|  0.00%|        warnings.warn(\"`eps` parameter is deprecated and has no effect.\")\n",
      "  1730|         0|            0|            0|  0.00%|\n",
      "  1731|         0|            0|            0|  0.00%|    gumbels = (\n",
      "  1732|         0|            0|            0|  0.00%|        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
      "  1733|         0|            0|            0|  0.00%|    )  # ~Gumbel(0,1)\n",
      "  1734|         0|            0|            0|  0.00%|    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
      "  1735|         0|            0|            0|  0.00%|    y_soft = gumbels.softmax(dim)\n",
      "  1736|         0|            0|            0|  0.00%|\n",
      "  1737|         0|            0|            0|  0.00%|    if hard:\n",
      "  1738|         0|            0|            0|  0.00%|        # Straight through.\n",
      "  1739|         0|            0|            0|  0.00%|        index = y_soft.max(dim, keepdim=True)[1]\n",
      "  1740|         0|            0|            0|  0.00%|        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
      "  1741|         0|            0|            0|  0.00%|        ret = y_hard - y_soft.detach() + y_soft\n",
      "  1742|         0|            0|            0|  0.00%|    else:\n",
      "  1743|         0|            0|            0|  0.00%|        # Reparametrization trick.\n",
      "  1744|         0|            0|            0|  0.00%|        ret = y_soft\n",
      "  1745|         0|            0|            0|  0.00%|    return ret\n",
      "  1746|         0|            0|            0|  0.00%|\n",
      "  1747|         0|            0|            0|  0.00%|\n",
      "  1748|         0|            0|            0|  0.00%|def log_softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1749|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmax followed by a logarithm.\n",
      "  1750|         0|            0|            0|  0.00%|\n",
      "  1751|         0|            0|            0|  0.00%|    While mathematically equivalent to log(softmax(x)), doing these two\n",
      "  1752|         0|            0|            0|  0.00%|    operations separately is slower and numerically unstable. This function\n",
      "  1753|         0|            0|            0|  0.00%|    uses an alternative formulation to compute the output and gradient correctly.\n",
      "  1754|         0|            0|            0|  0.00%|\n",
      "  1755|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LogSoftmax` for more details.\n",
      "  1756|         0|            0|            0|  0.00%|\n",
      "  1757|         0|            0|            0|  0.00%|    Args:\n",
      "  1758|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1759|         0|            0|            0|  0.00%|        dim (int): A dimension along which log_softmax will be computed.\n",
      "  1760|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1761|         0|            0|            0|  0.00%|          If specified, the input tensor is cast to :attr:`dtype` before the operation\n",
      "  1762|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1763|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1764|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1765|         0|            0|            0|  0.00%|        return handle_torch_function(log_softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1766|         0|            0|            0|  0.00%|    if dim is None:\n",
      "  1767|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"log_softmax\", input.dim(), _stacklevel)\n",
      "  1768|         0|            0|            0|  0.00%|    if dtype is None:\n",
      "  1769|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim)\n",
      "  1770|         0|            0|            0|  0.00%|    else:\n",
      "  1771|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim, dtype=dtype)\n",
      "  1772|         0|            0|            0|  0.00%|    return ret\n",
      "  1773|         0|            0|            0|  0.00%|\n",
      "  1774|         0|            0|            0|  0.00%|\n",
      "  1775|         0|            0|            0|  0.00%|softshrink = _add_docstr(\n",
      "  1776|         0|            0|            0|  0.00%|    torch._C._nn.softshrink,\n",
      "  1777|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1778|         0|            0|            0|  0.00%|softshrink(input, lambd=0.5) -> Tensor\n",
      "  1779|         0|            0|            0|  0.00%|\n",
      "  1780|         0|            0|            0|  0.00%|Applies the soft shrinkage function elementwise\n",
      "  1781|         0|            0|            0|  0.00%|\n",
      "  1782|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softshrink` for more details.\n",
      "  1783|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1784|         0|            0|            0|  0.00%|)\n",
      "  1785|         0|            0|            0|  0.00%|\n",
      "  1786|         0|            0|            0|  0.00%|\n",
      "  1787|         0|            0|            0|  0.00%|def tanh(input):\n",
      "  1788|         0|            0|            0|  0.00%|    r\"\"\"tanh(input) -> Tensor\n",
      "  1789|         0|            0|            0|  0.00%|\n",
      "  1790|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1791|         0|            0|            0|  0.00%|    :math:`\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}`\n",
      "  1792|         0|            0|            0|  0.00%|\n",
      "  1793|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanh` for more details.\n",
      "  1794|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1795|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "  1796|         0|            0|            0|  0.00%|    return input.tanh()\n",
      "  1797|         0|            0|            0|  0.00%|\n",
      "  1798|         0|            0|            0|  0.00%|\n",
      "  1799|         0|            0|            0|  0.00%|def sigmoid(input):\n",
      "  1800|         0|            0|            0|  0.00%|    r\"\"\"sigmoid(input) -> Tensor\n",
      "  1801|         0|            0|            0|  0.00%|\n",
      "  1802|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\n",
      "  1803|         0|            0|            0|  0.00%|\n",
      "  1804|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Sigmoid` for more details.\n",
      "  1805|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1806|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "  1807|         0|            0|            0|  0.00%|    return input.sigmoid()\n",
      "  1808|         0|            0|            0|  0.00%|\n",
      "  1809|         0|            0|            0|  0.00%|\n",
      "  1810|         0|            0|            0|  0.00%|def hardsigmoid(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1811|         0|            0|            0|  0.00%|    r\"\"\"Applies the element-wise function\n",
      "  1812|         0|            0|            0|  0.00%|\n",
      "  1813|         0|            0|            0|  0.00%|    .. math::\n",
      "  1814|         0|            0|            0|  0.00%|        \\text{Hardsigmoid}(x) = \\begin{cases}\n",
      "  1815|         0|            0|            0|  0.00%|            0 & \\text{if~} x \\le -3, \\\\\n",
      "  1816|         0|            0|            0|  0.00%|            1 & \\text{if~} x \\ge +3, \\\\\n",
      "  1817|         0|            0|            0|  0.00%|            x / 6 + 1 / 2 & \\text{otherwise}\n",
      "  1818|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1819|         0|            0|            0|  0.00%|\n",
      "  1820|         0|            0|            0|  0.00%|    Args:\n",
      "  1821|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1822|         0|            0|            0|  0.00%|\n",
      "  1823|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardsigmoid` for more details.\n",
      "  1824|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1825|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1826|         0|            0|            0|  0.00%|        return handle_torch_function(hardsigmoid, (input,), input, inplace=inplace)\n",
      "  1827|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1828|         0|            0|            0|  0.00%|        return torch._C._nn.hardsigmoid_(input)\n",
      "  1829|         0|            0|            0|  0.00%|    return torch._C._nn.hardsigmoid(input)\n",
      "  1830|         0|            0|            0|  0.00%|\n",
      "  1831|         0|            0|            0|  0.00%|\n",
      "  1832|        16|  3.48091e-05|  2.17557e-06|  0.02%|def linear(input: Tensor, weight: Tensor, bias: Optional[Tensor] = None) -> Tensor:\n",
      "  1833|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1834|         0|            0|            0|  0.00%|    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
      "  1835|         0|            0|            0|  0.00%|\n",
      "  1836|         0|            0|            0|  0.00%|    This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "  1837|         0|            0|            0|  0.00%|\n",
      "  1838|         0|            0|            0|  0.00%|    Shape:\n",
      "  1839|         0|            0|            0|  0.00%|\n",
      "  1840|         0|            0|            0|  0.00%|        - Input: :math:`(N, *, in\\_features)` N is the batch size, `*` means any number of\n",
      "  1841|         0|            0|            0|  0.00%|          additional dimensions\n",
      "  1842|         0|            0|            0|  0.00%|        - Weight: :math:`(out\\_features, in\\_features)`\n",
      "  1843|         0|            0|            0|  0.00%|        - Bias: :math:`(out\\_features)`\n",
      "  1844|         0|            0|            0|  0.00%|        - Output: :math:`(N, *, out\\_features)`\n",
      "  1845|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1846|        16|  4.07696e-05|   2.5481e-06|  0.02%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  1847|         0|            0|            0|  0.00%|        return handle_torch_function(linear, (input, weight, bias), input, weight, bias=bias)\n",
      "  1848|        16|   0.00180387|  0.000112742|  0.80%|    return torch._C._nn.linear(input, weight, bias)\n",
      "  1849|         0|            0|            0|  0.00%|\n",
      "  1850|         0|            0|            0|  0.00%|\n",
      "  1851|         0|            0|            0|  0.00%|def bilinear(input1: Tensor, input2: Tensor, weight: Tensor, bias: Optional[Tensor] = None) -> Tensor:\n",
      "  1852|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1853|         0|            0|            0|  0.00%|    Applies a bilinear transformation to the incoming data:\n",
      "  1854|         0|            0|            0|  0.00%|    :math:`y = x_1^T A x_2 + b`\n",
      "  1855|         0|            0|            0|  0.00%|\n",
      "  1856|         0|            0|            0|  0.00%|    Shape:\n",
      "  1857|         0|            0|            0|  0.00%|\n",
      "  1858|         0|            0|            0|  0.00%|        - input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\\text{in1\\_features}`\n",
      "  1859|         0|            0|            0|  0.00%|          and :math:`*` means any number of additional dimensions.\n",
      "  1860|         0|            0|            0|  0.00%|          All but the last dimension of the inputs should be the same.\n",
      "  1861|         0|            0|            0|  0.00%|        - input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\\text{in2\\_features}`\n",
      "  1862|         0|            0|            0|  0.00%|        - weight: :math:`(\\text{out\\_features}, \\text{in1\\_features},\n",
      "  1863|         0|            0|            0|  0.00%|          \\text{in2\\_features})`\n",
      "  1864|         0|            0|            0|  0.00%|        - bias: :math:`(\\text{out\\_features})`\n",
      "  1865|         0|            0|            0|  0.00%|        - output: :math:`(N, *, H_{out})` where :math:`H_{out}=\\text{out\\_features}`\n",
      "  1866|         0|            0|            0|  0.00%|          and all but the last dimension are the same shape as the input.\n",
      "  1867|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1868|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, weight, bias):\n",
      "  1869|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1870|         0|            0|            0|  0.00%|            bilinear,\n",
      "  1871|         0|            0|            0|  0.00%|            (input1, input2, weight, bias),\n",
      "  1872|         0|            0|            0|  0.00%|            input1, input2, weight,\n",
      "  1873|         0|            0|            0|  0.00%|            bias=bias\n",
      "  1874|         0|            0|            0|  0.00%|        )\n",
      "  1875|         0|            0|            0|  0.00%|    return torch.bilinear(input1, input2, weight, bias)\n",
      "  1876|         0|            0|            0|  0.00%|\n",
      "  1877|         0|            0|            0|  0.00%|\n",
      "  1878|         0|            0|            0|  0.00%|def silu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1879|         0|            0|            0|  0.00%|    r\"\"\"Applies the Sigmoid Linear Unit (SiLU) function, element-wise.\n",
      "  1880|         0|            0|            0|  0.00%|    The SiLU function is also known as the swish function.\n",
      "  1881|         0|            0|            0|  0.00%|\n",
      "  1882|         0|            0|            0|  0.00%|    .. math::\n",
      "  1883|         0|            0|            0|  0.00%|        \\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\n",
      "  1884|         0|            0|            0|  0.00%|\n",
      "  1885|         0|            0|            0|  0.00%|    .. note::\n",
      "  1886|         0|            0|            0|  0.00%|        See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_\n",
      "  1887|         0|            0|            0|  0.00%|        where the SiLU (Sigmoid Linear Unit) was originally coined, and see\n",
      "  1888|         0|            0|            0|  0.00%|        `Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n",
      "  1889|         0|            0|            0|  0.00%|        in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:\n",
      "  1890|         0|            0|            0|  0.00%|        a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_\n",
      "  1891|         0|            0|            0|  0.00%|        where the SiLU was experimented with later.\n",
      "  1892|         0|            0|            0|  0.00%|\n",
      "  1893|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SiLU` for more details.\n",
      "  1894|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1895|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1896|         0|            0|            0|  0.00%|        return handle_torch_function(silu, (input,), input, inplace=inplace)\n",
      "  1897|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1898|         0|            0|            0|  0.00%|        return torch._C._nn.silu_(input)\n",
      "  1899|         0|            0|            0|  0.00%|    return torch._C._nn.silu(input)\n",
      "  1900|         0|            0|            0|  0.00%|\n",
      "  1901|         0|            0|            0|  0.00%|\n",
      "  1902|         0|            0|            0|  0.00%|def mish(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1903|         0|            0|            0|  0.00%|    r\"\"\"Applies the Mish function, element-wise.\n",
      "  1904|         0|            0|            0|  0.00%|    Mish: A Self Regularized Non-Monotonic Neural Activation Function.\n",
      "  1905|         0|            0|            0|  0.00%|\n",
      "  1906|         0|            0|            0|  0.00%|    .. math::\n",
      "  1907|         0|            0|            0|  0.00%|        \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n",
      "  1908|         0|            0|            0|  0.00%|\n",
      "  1909|         0|            0|            0|  0.00%|    .. note::\n",
      "  1910|         0|            0|            0|  0.00%|        See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n",
      "  1911|         0|            0|            0|  0.00%|\n",
      "  1912|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Mish` for more details.\n",
      "  1913|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1914|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1915|         0|            0|            0|  0.00%|        return handle_torch_function(mish, (input,), input, inplace=inplace)\n",
      "  1916|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1917|         0|            0|            0|  0.00%|        return torch._C._nn.mish_(input)\n",
      "  1918|         0|            0|            0|  0.00%|    return torch._C._nn.mish(input)\n",
      "  1919|         0|            0|            0|  0.00%|\n",
      "  1920|         0|            0|            0|  0.00%|\n",
      "  1921|         0|            0|            0|  0.00%|def hardswish(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1922|         0|            0|            0|  0.00%|    r\"\"\"Applies the hardswish function, element-wise, as described in the paper:\n",
      "  1923|         0|            0|            0|  0.00%|\n",
      "  1924|         0|            0|            0|  0.00%|    `Searching for MobileNetV3`_.\n",
      "  1925|         0|            0|            0|  0.00%|\n",
      "  1926|         0|            0|            0|  0.00%|    .. math::\n",
      "  1927|         0|            0|            0|  0.00%|        \\text{Hardswish}(x) = \\begin{cases}\n",
      "  1928|         0|            0|            0|  0.00%|            0 & \\text{if~} x \\le -3, \\\\\n",
      "  1929|         0|            0|            0|  0.00%|            x & \\text{if~} x \\ge +3, \\\\\n",
      "  1930|         0|            0|            0|  0.00%|            x \\cdot (x + 3) /6 & \\text{otherwise}\n",
      "  1931|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1932|         0|            0|            0|  0.00%|\n",
      "  1933|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardswish` for more details.\n",
      "  1934|         0|            0|            0|  0.00%|\n",
      "  1935|         0|            0|            0|  0.00%|    .. _`Searching for MobileNetV3`:\n",
      "  1936|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1905.02244\n",
      "  1937|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1938|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1939|         0|            0|            0|  0.00%|        return handle_torch_function(hardswish, (input,), input, inplace=inplace)\n",
      "  1940|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1941|         0|            0|            0|  0.00%|        return torch._C._nn.hardswish_(input)\n",
      "  1942|         0|            0|            0|  0.00%|    return torch._C._nn.hardswish(input)\n",
      "  1943|         0|            0|            0|  0.00%|\n",
      "  1944|         0|            0|            0|  0.00%|\n",
      "  1945|         0|            0|            0|  0.00%|def _no_grad_embedding_renorm_(weight: Tensor, input: Tensor, max_norm: float, norm_type: float) -> Tensor:\n",
      "  1946|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "  1947|         0|            0|            0|  0.00%|        torch.embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  1948|         0|            0|            0|  0.00%|\n",
      "  1949|         0|            0|            0|  0.00%|\n",
      "  1950|         9|   3.3617e-05|  3.73522e-06|  0.01%|def embedding(\n",
      "  1951|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  1952|         0|            0|            0|  0.00%|    weight: Tensor,\n",
      "  1953|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,\n",
      "  1954|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,\n",
      "  1955|         0|            0|            0|  0.00%|    norm_type: float = 2.0,\n",
      "  1956|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,\n",
      "  1957|         0|            0|            0|  0.00%|    sparse: bool = False,\n",
      "  1958|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  1959|         0|            0|            0|  0.00%|    r\"\"\"A simple lookup table that looks up embeddings in a fixed dictionary and size.\n",
      "  1960|         0|            0|            0|  0.00%|\n",
      "  1961|         0|            0|            0|  0.00%|    This module is often used to retrieve word embeddings using indices.\n",
      "  1962|         0|            0|            0|  0.00%|    The input to the module is a list of indices, and the embedding matrix,\n",
      "  1963|         0|            0|            0|  0.00%|    and the output is the corresponding word embeddings.\n",
      "  1964|         0|            0|            0|  0.00%|\n",
      "  1965|         0|            0|            0|  0.00%|    See :class:`torch.nn.Embedding` for more details.\n",
      "  1966|         0|            0|            0|  0.00%|\n",
      "  1967|         0|            0|            0|  0.00%|    Args:\n",
      "  1968|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing indices into the embedding matrix\n",
      "  1969|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,\n",
      "  1970|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size\n",
      "  1971|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "  1972|         0|            0|            0|  0.00%|                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "  1973|         0|            0|            0|  0.00%|                                     i.e. it remains as a fixed \"pad\".\n",
      "  1974|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "  1975|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "  1976|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.\n",
      "  1977|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "  1978|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      "  1979|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "  1980|         0|            0|            0|  0.00%|        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under\n",
      "  1981|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.\n",
      "  1982|         0|            0|            0|  0.00%|\n",
      "  1983|         0|            0|            0|  0.00%|    Shape:\n",
      "  1984|         0|            0|            0|  0.00%|        - Input: LongTensor of arbitrary shape containing the indices to extract\n",
      "  1985|         0|            0|            0|  0.00%|        - Weight: Embedding matrix of floating point type with shape `(V, embedding_dim)`,\n",
      "  1986|         0|            0|            0|  0.00%|          where V = maximum index + 1 and embedding_dim = the embedding size\n",
      "  1987|         0|            0|            0|  0.00%|        - Output: `(*, embedding_dim)`, where `*` is the input shape\n",
      "  1988|         0|            0|            0|  0.00%|\n",
      "  1989|         0|            0|            0|  0.00%|    Examples::\n",
      "  1990|         0|            0|            0|  0.00%|\n",
      "  1991|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "  1992|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[1,2,4,5],[4,3,2,9]])\n",
      "  1993|         0|            0|            0|  0.00%|        >>> # an embedding matrix containing 10 tensors of size 3\n",
      "  1994|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  1995|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix)\n",
      "  1996|         0|            0|            0|  0.00%|        tensor([[[ 0.8490,  0.9625,  0.6753],\n",
      "  1997|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],\n",
      "  1998|         0|            0|            0|  0.00%|                 [ 0.6246,  0.9751,  0.3618],\n",
      "  1999|         0|            0|            0|  0.00%|                 [ 0.4161,  0.2419,  0.7383]],\n",
      "  2000|         0|            0|            0|  0.00%|\n",
      "  2001|         0|            0|            0|  0.00%|                [[ 0.6246,  0.9751,  0.3618],\n",
      "  2002|         0|            0|            0|  0.00%|                 [ 0.0237,  0.7794,  0.0528],\n",
      "  2003|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],\n",
      "  2004|         0|            0|            0|  0.00%|                 [ 0.3385,  0.8612,  0.1867]]])\n",
      "  2005|         0|            0|            0|  0.00%|\n",
      "  2006|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "  2007|         0|            0|            0|  0.00%|        >>> weights = torch.rand(10, 3)\n",
      "  2008|         0|            0|            0|  0.00%|        >>> weights[0, :].zero_()\n",
      "  2009|         0|            0|            0|  0.00%|        >>> embedding_matrix = weights\n",
      "  2010|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[0,2,0,5]])\n",
      "  2011|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix, padding_idx=0)\n",
      "  2012|         0|            0|            0|  0.00%|        tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "  2013|         0|            0|            0|  0.00%|                 [ 0.5609,  0.5384,  0.8720],\n",
      "  2014|         0|            0|            0|  0.00%|                 [ 0.0000,  0.0000,  0.0000],\n",
      "  2015|         0|            0|            0|  0.00%|                 [ 0.6262,  0.2438,  0.7471]]])\n",
      "  2016|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2017|         0|            0|            0|  0.00%|\n",
      "  2018|         9|  3.02792e-05|  3.36435e-06|  0.01%|    if has_torch_function_variadic(input, weight):\n",
      "  2019|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2020|         0|            0|            0|  0.00%|            embedding, (input, weight),\n",
      "  2021|         0|            0|            0|  0.00%|            input, weight, padding_idx, max_norm, norm_type,\n",
      "  2022|         0|            0|            0|  0.00%|            scale_grad_by_freq, sparse\n",
      "  2023|         0|            0|            0|  0.00%|        )\n",
      "  2024|         9|  2.69413e-05|  2.99348e-06|  0.01%|    if padding_idx is not None:\n",
      "  2025|         0|            0|            0|  0.00%|        if padding_idx > 0:\n",
      "  2026|         0|            0|            0|  0.00%|            assert padding_idx < weight.size(0), \"Padding_idx must be within num_embeddings\"\n",
      "  2027|         0|            0|            0|  0.00%|        elif padding_idx < 0:\n",
      "  2028|         0|            0|            0|  0.00%|            assert padding_idx >= -weight.size(0), \"Padding_idx must be within num_embeddings\"\n",
      "  2029|         0|            0|            0|  0.00%|            padding_idx = weight.size(0) + padding_idx\n",
      "  2030|         0|            0|            0|  0.00%|    else:\n",
      "  2031|         9|  1.95503e-05|  2.17226e-06|  0.01%|        padding_idx = -1\n",
      "  2032|         9|  2.43187e-05|  2.70208e-06|  0.01%|    if max_norm is not None:\n",
      "  2033|         0|            0|            0|  0.00%|        # Note [embedding_renorm contiguous]\n",
      "  2034|         0|            0|            0|  0.00%|        # `embedding_renorm_` will call .contiguous() on input anyways, so we\n",
      "  2035|         0|            0|            0|  0.00%|        # call it here and take advantage of the improved locality in the\n",
      "  2036|         0|            0|            0|  0.00%|        # `embedding` call below too.\n",
      "  2037|         0|            0|            0|  0.00%|        input = input.contiguous()\n",
      "  2038|         0|            0|            0|  0.00%|        # Note [embedding_renorm set_grad_enabled]\n",
      "  2039|         0|            0|            0|  0.00%|        # XXX: equivalent to\n",
      "  2040|         0|            0|            0|  0.00%|        # with torch.no_grad():\n",
      "  2041|         0|            0|            0|  0.00%|        #   torch.embedding_renorm_\n",
      "  2042|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled\n",
      "  2043|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  2044|         9|   0.00079608|  8.84533e-05|  0.35%|    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "  2045|         0|            0|            0|  0.00%|\n",
      "  2046|         0|            0|            0|  0.00%|\n",
      "  2047|         0|            0|            0|  0.00%|def embedding_bag(\n",
      "  2048|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2049|         0|            0|            0|  0.00%|    weight: Tensor,\n",
      "  2050|         0|            0|            0|  0.00%|    offsets: Optional[Tensor] = None,\n",
      "  2051|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,\n",
      "  2052|         0|            0|            0|  0.00%|    norm_type: float = 2,\n",
      "  2053|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,\n",
      "  2054|         0|            0|            0|  0.00%|    mode: str = \"mean\",\n",
      "  2055|         0|            0|            0|  0.00%|    sparse: bool = False,\n",
      "  2056|         0|            0|            0|  0.00%|    per_sample_weights: Optional[Tensor] = None,\n",
      "  2057|         0|            0|            0|  0.00%|    include_last_offset: bool = False,\n",
      "  2058|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,\n",
      "  2059|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2060|         0|            0|            0|  0.00%|    r\"\"\"Computes sums, means or maxes of `bags` of embeddings, without instantiating the\n",
      "  2061|         0|            0|            0|  0.00%|    intermediate embeddings.\n",
      "  2062|         0|            0|            0|  0.00%|\n",
      "  2063|         0|            0|            0|  0.00%|    See :class:`torch.nn.EmbeddingBag` for more details.\n",
      "  2064|         0|            0|            0|  0.00%|\n",
      "  2065|         0|            0|            0|  0.00%|    Note:\n",
      "  2066|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  2067|         0|            0|            0|  0.00%|\n",
      "  2068|         0|            0|            0|  0.00%|    Args:\n",
      "  2069|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing bags of indices into the embedding matrix\n",
      "  2070|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,\n",
      "  2071|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size\n",
      "  2072|         0|            0|            0|  0.00%|        offsets (LongTensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines\n",
      "  2073|         0|            0|            0|  0.00%|                             the starting index position of each bag (sequence) in :attr:`input`.\n",
      "  2074|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "  2075|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "  2076|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.\n",
      "  2077|         0|            0|            0|  0.00%|        norm_type (float, optional): The ``p`` in the ``p``-norm to compute for the :attr:`max_norm` option.\n",
      "  2078|         0|            0|            0|  0.00%|                                     Default ``2``.\n",
      "  2079|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
      "  2080|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "  2081|         0|            0|            0|  0.00%|                                                Note: this option is not supported when ``mode=\"max\"``.\n",
      "  2082|         0|            0|            0|  0.00%|        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
      "  2083|         0|            0|            0|  0.00%|                                 Default: ``\"mean\"``\n",
      "  2084|         0|            0|            0|  0.00%|        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under\n",
      "  2085|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.\n",
      "  2086|         0|            0|            0|  0.00%|                                 Note: this option is not supported when ``mode=\"max\"``.\n",
      "  2087|         0|            0|            0|  0.00%|        per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
      "  2088|         0|            0|            0|  0.00%|            to indicate all weights should be taken to be 1. If specified, :attr:`per_sample_weights`\n",
      "  2089|         0|            0|            0|  0.00%|            must have exactly the same shape as input and is treated as having the same\n",
      "  2090|         0|            0|            0|  0.00%|            :attr:`offsets`, if those are not None.\n",
      "  2091|         0|            0|            0|  0.00%|\n",
      "  2092|         0|            0|            0|  0.00%|        include_last_offset (bool, optional): if ``True``, the size of offsets is equal to the number of bags + 1.\n",
      "  2093|         0|            0|            0|  0.00%|            The last element is the size of the input, or the ending index position of the last bag (sequence).\n",
      "  2094|         0|            0|            0|  0.00%|\n",
      "  2095|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the\n",
      "  2096|         0|            0|            0|  0.00%|                                     gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated\n",
      "  2097|         0|            0|            0|  0.00%|                                     during training, i.e. it remains as a fixed \"pad\". Note that the embedding\n",
      "  2098|         0|            0|            0|  0.00%|                                     vector at :attr:`padding_idx` is excluded from the reduction.\n",
      "  2099|         0|            0|            0|  0.00%|\n",
      "  2100|         0|            0|            0|  0.00%|    Shape:\n",
      "  2101|         0|            0|            0|  0.00%|        - :attr:`input` (LongTensor) and :attr:`offsets` (LongTensor, optional)\n",
      "  2102|         0|            0|            0|  0.00%|\n",
      "  2103|         0|            0|            0|  0.00%|          - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)\n",
      "  2104|         0|            0|            0|  0.00%|            each of fixed length ``N``, and this will return ``B`` values aggregated in a way\n",
      "  2105|         0|            0|            0|  0.00%|            depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
      "  2106|         0|            0|            0|  0.00%|\n",
      "  2107|         0|            0|            0|  0.00%|          - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of\n",
      "  2108|         0|            0|            0|  0.00%|            multiple bags (sequences). :attr:`offsets` is required to be a 1D tensor containing\n",
      "  2109|         0|            0|            0|  0.00%|            the starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2110|         0|            0|            0|  0.00%|            of shape `(B)`, :attr:`input` will be viewed as having ``B`` bags.\n",
      "  2111|         0|            0|            0|  0.00%|            Empty bags (i.e., having 0-length) will have returned vectors filled by zeros.\n",
      "  2112|         0|            0|            0|  0.00%|\n",
      "  2113|         0|            0|            0|  0.00%|        - :attr:`weight` (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`\n",
      "  2114|         0|            0|            0|  0.00%|\n",
      "  2115|         0|            0|            0|  0.00%|        - :attr:`per_sample_weights` (Tensor, optional). Has the same shape as :attr:`input`.\n",
      "  2116|         0|            0|            0|  0.00%|\n",
      "  2117|         0|            0|            0|  0.00%|        - :attr:`output`: aggregated embedding values of shape `(B, embedding_dim)`\n",
      "  2118|         0|            0|            0|  0.00%|\n",
      "  2119|         0|            0|            0|  0.00%|    Examples::\n",
      "  2120|         0|            0|            0|  0.00%|\n",
      "  2121|         0|            0|            0|  0.00%|        >>> # an Embedding module containing 10 tensors of size 3\n",
      "  2122|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  2123|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "  2124|         0|            0|            0|  0.00%|        >>> input = torch.tensor([1,2,4,5,4,3,2,9])\n",
      "  2125|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])\n",
      "  2126|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets)\n",
      "  2127|         0|            0|            0|  0.00%|        tensor([[ 0.3397,  0.3552,  0.5545],\n",
      "  2128|         0|            0|            0|  0.00%|                [ 0.5893,  0.4386,  0.5882]])\n",
      "  2129|         0|            0|            0|  0.00%|\n",
      "  2130|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "  2131|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  2132|         0|            0|            0|  0.00%|        >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9])\n",
      "  2133|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])\n",
      "  2134|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets, padding_idx=2, mode='sum')\n",
      "  2135|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "  2136|         0|            0|            0|  0.00%|                [-0.7082,  3.2145, -2.6251]])\n",
      "  2137|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2138|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, offsets, per_sample_weights):\n",
      "  2139|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2140|         0|            0|            0|  0.00%|            embedding_bag,\n",
      "  2141|         0|            0|            0|  0.00%|            (input, weight, offsets, per_sample_weights),\n",
      "  2142|         0|            0|            0|  0.00%|            input,\n",
      "  2143|         0|            0|            0|  0.00%|            weight,\n",
      "  2144|         0|            0|            0|  0.00%|            offsets=offsets,\n",
      "  2145|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "  2146|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "  2147|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "  2148|         0|            0|            0|  0.00%|            mode=mode,\n",
      "  2149|         0|            0|            0|  0.00%|            sparse=sparse,\n",
      "  2150|         0|            0|            0|  0.00%|            per_sample_weights=per_sample_weights,\n",
      "  2151|         0|            0|            0|  0.00%|            include_last_offset=include_last_offset,\n",
      "  2152|         0|            0|            0|  0.00%|            padding_idx=padding_idx,\n",
      "  2153|         0|            0|            0|  0.00%|        )\n",
      "  2154|         0|            0|            0|  0.00%|    # Check for backward compatibility.\n",
      "  2155|         0|            0|            0|  0.00%|    # Used to be embedding_bag(weight, input, ...)\n",
      "  2156|         0|            0|            0|  0.00%|    # Now is     embedding_bag(input, weight, ...)\n",
      "  2157|         0|            0|            0|  0.00%|    if weight.dtype == torch.long and input.is_floating_point():\n",
      "  2158|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  2159|         0|            0|            0|  0.00%|            \"Argument order of nn.functional.embedding_bag was changed. \"\n",
      "  2160|         0|            0|            0|  0.00%|            \"Usage `embedding_bag(weight, input, ...)` is deprecated, \"\n",
      "  2161|         0|            0|            0|  0.00%|            \"and should now be `embedding_bag(input, weight, ...)`.\"\n",
      "  2162|         0|            0|            0|  0.00%|        )\n",
      "  2163|         0|            0|            0|  0.00%|        weight, input = input, weight\n",
      "  2164|         0|            0|            0|  0.00%|\n",
      "  2165|         0|            0|            0|  0.00%|    if per_sample_weights is not None and input.size() != per_sample_weights.size():\n",
      "  2166|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2167|         0|            0|            0|  0.00%|            \"embedding_bag: If per_sample_weights ({}) is not None, \"\n",
      "  2168|         0|            0|            0|  0.00%|            \"then it must have the same shape as the input ({})\".format(per_sample_weights.shape, input.shape)\n",
      "  2169|         0|            0|            0|  0.00%|        )\n",
      "  2170|         0|            0|            0|  0.00%|\n",
      "  2171|         0|            0|            0|  0.00%|    if input.dim() == 2:\n",
      "  2172|         0|            0|            0|  0.00%|        if offsets is not None:\n",
      "  2173|         0|            0|            0|  0.00%|            type_str = \"<unknown>\"\n",
      "  2174|         0|            0|            0|  0.00%|            # TODO: Remove this once script supports type() calls\n",
      "  2175|         0|            0|            0|  0.00%|            if not torch.jit.is_scripting():\n",
      "  2176|         0|            0|            0|  0.00%|                type_str = str(type(offsets))\n",
      "  2177|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  2178|         0|            0|            0|  0.00%|                \"if input is 2D, then offsets has to be None\"\n",
      "  2179|         0|            0|            0|  0.00%|                \", as input is treated is a mini-batch of\"\n",
      "  2180|         0|            0|            0|  0.00%|                \" fixed length sequences. However, found \"\n",
      "  2181|         0|            0|            0|  0.00%|                \"offsets of type {}\".format(type_str)\n",
      "  2182|         0|            0|            0|  0.00%|            )\n",
      "  2183|         0|            0|            0|  0.00%|        offsets = torch.arange(0, input.numel(), input.size(1), dtype=input.dtype, device=input.device)\n",
      "  2184|         0|            0|            0|  0.00%|\n",
      "  2185|         0|            0|            0|  0.00%|        input = input.reshape(-1)\n",
      "  2186|         0|            0|            0|  0.00%|        if per_sample_weights is not None:\n",
      "  2187|         0|            0|            0|  0.00%|            per_sample_weights = per_sample_weights.reshape(-1)\n",
      "  2188|         0|            0|            0|  0.00%|    elif input.dim() == 1:\n",
      "  2189|         0|            0|            0|  0.00%|        if offsets is None:\n",
      "  2190|         0|            0|            0|  0.00%|            raise ValueError(\"offsets has to be a 1D Tensor but got None\")\n",
      "  2191|         0|            0|            0|  0.00%|        if offsets.dim() != 1:\n",
      "  2192|         0|            0|            0|  0.00%|            raise ValueError(\"offsets has to be a 1D Tensor\")\n",
      "  2193|         0|            0|            0|  0.00%|    else:\n",
      "  2194|         0|            0|            0|  0.00%|        raise ValueError(\"input has to be 1D or 2D Tensor,\" \" but got Tensor of dimension {}\".format(input.dim()))\n",
      "  2195|         0|            0|            0|  0.00%|    if mode == \"sum\":\n",
      "  2196|         0|            0|            0|  0.00%|        mode_enum = 0\n",
      "  2197|         0|            0|            0|  0.00%|    elif mode == \"mean\":\n",
      "  2198|         0|            0|            0|  0.00%|        mode_enum = 1\n",
      "  2199|         0|            0|            0|  0.00%|    elif mode == \"max\":\n",
      "  2200|         0|            0|            0|  0.00%|        mode_enum = 2\n",
      "  2201|         0|            0|            0|  0.00%|\n",
      "  2202|         0|            0|            0|  0.00%|        if scale_grad_by_freq:\n",
      "  2203|         0|            0|            0|  0.00%|            raise ValueError(\"max mode does not support scaling the gradient by the frequency\")\n",
      "  2204|         0|            0|            0|  0.00%|\n",
      "  2205|         0|            0|            0|  0.00%|        if sparse:\n",
      "  2206|         0|            0|            0|  0.00%|            raise ValueError(\"max mode does not support sparse weights\")\n",
      "  2207|         0|            0|            0|  0.00%|\n",
      "  2208|         0|            0|            0|  0.00%|    else:\n",
      "  2209|         0|            0|            0|  0.00%|        raise ValueError(\"mode has to be one of sum, mean or max\")\n",
      "  2210|         0|            0|            0|  0.00%|\n",
      "  2211|         0|            0|            0|  0.00%|    if max_norm is not None:\n",
      "  2212|         0|            0|            0|  0.00%|        # XXX: equivalent to\n",
      "  2213|         0|            0|            0|  0.00%|        # with torch.no_grad():\n",
      "  2214|         0|            0|            0|  0.00%|        #   torch.nembedding_renorm_\n",
      "  2215|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled\n",
      "  2216|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  2217|         0|            0|            0|  0.00%|\n",
      "  2218|         0|            0|            0|  0.00%|    if per_sample_weights is not None and mode != \"sum\":\n",
      "  2219|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  2220|         0|            0|            0|  0.00%|            \"embedding_bag: per_sample_weights was not None. \"\n",
      "  2221|         0|            0|            0|  0.00%|            \"per_sample_weights is only supported for mode='sum' \"\n",
      "  2222|         0|            0|            0|  0.00%|            \"(got mode='{}'). Please open a feature request on GitHub.\".format(mode)\n",
      "  2223|         0|            0|            0|  0.00%|        )\n",
      "  2224|         0|            0|            0|  0.00%|\n",
      "  2225|         0|            0|            0|  0.00%|    ret, _, _, _ = torch.embedding_bag(\n",
      "  2226|         0|            0|            0|  0.00%|        weight, input, offsets, scale_grad_by_freq, mode_enum, sparse, per_sample_weights, include_last_offset, padding_idx\n",
      "  2227|         0|            0|            0|  0.00%|    )\n",
      "  2228|         0|            0|            0|  0.00%|    return ret\n",
      "  2229|         0|            0|            0|  0.00%|\n",
      "  2230|         0|            0|            0|  0.00%|\n",
      "  2231|         0|            0|            0|  0.00%|embedding_bag.__doc__ = embedding_bag.__doc__.format(**reproducibility_notes)\n",
      "  2232|         0|            0|            0|  0.00%|\n",
      "  2233|         0|            0|            0|  0.00%|\n",
      "  2234|         0|            0|            0|  0.00%|def _verify_batch_size(size: List[int]) -> None:\n",
      "  2235|         0|            0|            0|  0.00%|    # XXX: JIT script does not support the reduce from functools, and mul op is a\n",
      "  2236|         0|            0|            0|  0.00%|    # builtin, which cannot be used as a value to a func yet, so rewrite this size\n",
      "  2237|         0|            0|            0|  0.00%|    # check to a simple equivalent for loop\n",
      "  2238|         0|            0|            0|  0.00%|    #\n",
      "  2239|         0|            0|            0|  0.00%|    # TODO: make use of reduce like below when JIT is ready with the missing features:\n",
      "  2240|         0|            0|            0|  0.00%|    # from operator import mul\n",
      "  2241|         0|            0|            0|  0.00%|    # from functools import reduce\n",
      "  2242|         0|            0|            0|  0.00%|    #\n",
      "  2243|         0|            0|            0|  0.00%|    #   if reduce(mul, size[2:], size[0]) == 1\n",
      "  2244|         0|            0|            0|  0.00%|    size_prods = size[0]\n",
      "  2245|         0|            0|            0|  0.00%|    for i in range(len(size) - 2):\n",
      "  2246|         0|            0|            0|  0.00%|        size_prods *= size[i + 2]\n",
      "  2247|         0|            0|            0|  0.00%|    if size_prods == 1:\n",
      "  2248|         0|            0|            0|  0.00%|        raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n",
      "  2249|         0|            0|            0|  0.00%|\n",
      "  2250|         0|            0|            0|  0.00%|\n",
      "  2251|         0|            0|            0|  0.00%|def batch_norm(\n",
      "  2252|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2253|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor],\n",
      "  2254|         0|            0|            0|  0.00%|    running_var: Optional[Tensor],\n",
      "  2255|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2256|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2257|         0|            0|            0|  0.00%|    training: bool = False,\n",
      "  2258|         0|            0|            0|  0.00%|    momentum: float = 0.1,\n",
      "  2259|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2260|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2261|         0|            0|            0|  0.00%|    r\"\"\"Applies Batch Normalization for each channel across a batch of data.\n",
      "  2262|         0|            0|            0|  0.00%|\n",
      "  2263|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BatchNorm1d`, :class:`~torch.nn.BatchNorm2d`,\n",
      "  2264|         0|            0|            0|  0.00%|    :class:`~torch.nn.BatchNorm3d` for details.\n",
      "  2265|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2266|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n",
      "  2267|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2268|         0|            0|            0|  0.00%|            batch_norm,\n",
      "  2269|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),\n",
      "  2270|         0|            0|            0|  0.00%|            input,\n",
      "  2271|         0|            0|            0|  0.00%|            running_mean,\n",
      "  2272|         0|            0|            0|  0.00%|            running_var,\n",
      "  2273|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2274|         0|            0|            0|  0.00%|            bias=bias,\n",
      "  2275|         0|            0|            0|  0.00%|            training=training,\n",
      "  2276|         0|            0|            0|  0.00%|            momentum=momentum,\n",
      "  2277|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2278|         0|            0|            0|  0.00%|        )\n",
      "  2279|         0|            0|            0|  0.00%|    if training:\n",
      "  2280|         0|            0|            0|  0.00%|        _verify_batch_size(input.size())\n",
      "  2281|         0|            0|            0|  0.00%|\n",
      "  2282|         0|            0|            0|  0.00%|    return torch.batch_norm(\n",
      "  2283|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n",
      "  2284|         0|            0|            0|  0.00%|    )\n",
      "  2285|         0|            0|            0|  0.00%|\n",
      "  2286|         0|            0|            0|  0.00%|\n",
      "  2287|         0|            0|            0|  0.00%|def _verify_spatial_size(size: List[int]) -> None:\n",
      "  2288|         0|            0|            0|  0.00%|    # Verify that there is > 1 spatial element for instance norm calculation.\n",
      "  2289|         0|            0|            0|  0.00%|    size_prods = 1\n",
      "  2290|         0|            0|            0|  0.00%|    for i in range(2, len(size)):\n",
      "  2291|         0|            0|            0|  0.00%|        size_prods *= size[i]\n",
      "  2292|         0|            0|            0|  0.00%|    if size_prods == 1:\n",
      "  2293|         0|            0|            0|  0.00%|        raise ValueError(\"Expected more than 1 spatial element when training, got input size {}\".format(size))\n",
      "  2294|         0|            0|            0|  0.00%|\n",
      "  2295|         0|            0|            0|  0.00%|\n",
      "  2296|         0|            0|            0|  0.00%|def instance_norm(\n",
      "  2297|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2298|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor] = None,\n",
      "  2299|         0|            0|            0|  0.00%|    running_var: Optional[Tensor] = None,\n",
      "  2300|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2301|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2302|         0|            0|            0|  0.00%|    use_input_stats: bool = True,\n",
      "  2303|         0|            0|            0|  0.00%|    momentum: float = 0.1,\n",
      "  2304|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2305|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2306|         0|            0|            0|  0.00%|    r\"\"\"Applies Instance Normalization for each channel in each data sample in a\n",
      "  2307|         0|            0|            0|  0.00%|    batch.\n",
      "  2308|         0|            0|            0|  0.00%|\n",
      "  2309|         0|            0|            0|  0.00%|    See :class:`~torch.nn.InstanceNorm1d`, :class:`~torch.nn.InstanceNorm2d`,\n",
      "  2310|         0|            0|            0|  0.00%|    :class:`~torch.nn.InstanceNorm3d` for details.\n",
      "  2311|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2312|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n",
      "  2313|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2314|         0|            0|            0|  0.00%|            instance_norm,\n",
      "  2315|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),\n",
      "  2316|         0|            0|            0|  0.00%|            input,\n",
      "  2317|         0|            0|            0|  0.00%|            running_mean=running_mean,\n",
      "  2318|         0|            0|            0|  0.00%|            running_var=running_var,\n",
      "  2319|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2320|         0|            0|            0|  0.00%|            bias=bias,\n",
      "  2321|         0|            0|            0|  0.00%|            use_input_stats=use_input_stats,\n",
      "  2322|         0|            0|            0|  0.00%|            momentum=momentum,\n",
      "  2323|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2324|         0|            0|            0|  0.00%|        )\n",
      "  2325|         0|            0|            0|  0.00%|    if use_input_stats:\n",
      "  2326|         0|            0|            0|  0.00%|        _verify_spatial_size(input.size())\n",
      "  2327|         0|            0|            0|  0.00%|    return torch.instance_norm(\n",
      "  2328|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, use_input_stats, momentum, eps, torch.backends.cudnn.enabled\n",
      "  2329|         0|            0|            0|  0.00%|    )\n",
      "  2330|         0|            0|            0|  0.00%|\n",
      "  2331|         0|            0|            0|  0.00%|\n",
      "  2332|         0|            0|            0|  0.00%|def layer_norm(\n",
      "  2333|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2334|         0|            0|            0|  0.00%|    normalized_shape: List[int],\n",
      "  2335|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2336|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2337|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2338|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2339|         0|            0|            0|  0.00%|    r\"\"\"Applies Layer Normalization for last certain number of dimensions.\n",
      "  2340|         0|            0|            0|  0.00%|\n",
      "  2341|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LayerNorm` for details.\n",
      "  2342|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2343|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  2344|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2345|         0|            0|            0|  0.00%|            layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps\n",
      "  2346|         0|            0|            0|  0.00%|        )\n",
      "  2347|         0|            0|            0|  0.00%|    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "  2348|         0|            0|            0|  0.00%|\n",
      "  2349|         0|            0|            0|  0.00%|\n",
      "  2350|         0|            0|            0|  0.00%|def group_norm(\n",
      "  2351|         0|            0|            0|  0.00%|    input: Tensor, num_groups: int, weight: Optional[Tensor] = None, bias: Optional[Tensor] = None, eps: float = 1e-5\n",
      "  2352|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2353|         0|            0|            0|  0.00%|    r\"\"\"Applies Group Normalization for last certain number of dimensions.\n",
      "  2354|         0|            0|            0|  0.00%|\n",
      "  2355|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GroupNorm` for details.\n",
      "  2356|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2357|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  2358|         0|            0|            0|  0.00%|        return handle_torch_function(group_norm, (input, weight, bias,), input, num_groups, weight=weight, bias=bias, eps=eps)\n",
      "  2359|         0|            0|            0|  0.00%|    _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "  2360|         0|            0|            0|  0.00%|    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "  2361|         0|            0|            0|  0.00%|\n",
      "  2362|         0|            0|            0|  0.00%|\n",
      "  2363|         0|            0|            0|  0.00%|def local_response_norm(input: Tensor, size: int, alpha: float = 1e-4, beta: float = 0.75, k: float = 1.0) -> Tensor:\n",
      "  2364|         0|            0|            0|  0.00%|    r\"\"\"Applies local response normalization over an input signal composed of\n",
      "  2365|         0|            0|            0|  0.00%|    several input planes, where channels occupy the second dimension.\n",
      "  2366|         0|            0|            0|  0.00%|    Applies normalization across channels.\n",
      "  2367|         0|            0|            0|  0.00%|\n",
      "  2368|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LocalResponseNorm` for details.\n",
      "  2369|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2370|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  2371|         0|            0|            0|  0.00%|        return handle_torch_function(local_response_norm, (input,), input, size, alpha=alpha, beta=beta, k=k)\n",
      "  2372|         0|            0|            0|  0.00%|    dim = input.dim()\n",
      "  2373|         0|            0|            0|  0.00%|    if dim < 3:\n",
      "  2374|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2375|         0|            0|            0|  0.00%|            \"Expected 3D or higher dimensionality \\\n",
      "  2376|         0|            0|            0|  0.00%|                         input (got {} dimensions)\".format(\n",
      "  2377|         0|            0|            0|  0.00%|                dim\n",
      "  2378|         0|            0|            0|  0.00%|            )\n",
      "  2379|         0|            0|            0|  0.00%|        )\n",
      "  2380|         0|            0|            0|  0.00%|\n",
      "  2381|         0|            0|            0|  0.00%|    if input.numel() == 0:\n",
      "  2382|         0|            0|            0|  0.00%|        return input\n",
      "  2383|         0|            0|            0|  0.00%|\n",
      "  2384|         0|            0|            0|  0.00%|    div = input.mul(input).unsqueeze(1)\n",
      "  2385|         0|            0|            0|  0.00%|    if dim == 3:\n",
      "  2386|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, size // 2, (size - 1) // 2))\n",
      "  2387|         0|            0|            0|  0.00%|        div = avg_pool2d(div, (size, 1), stride=1).squeeze(1)\n",
      "  2388|         0|            0|            0|  0.00%|    else:\n",
      "  2389|         0|            0|            0|  0.00%|        sizes = input.size()\n",
      "  2390|         0|            0|            0|  0.00%|        div = div.view(sizes[0], 1, sizes[1], sizes[2], -1)\n",
      "  2391|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, 0, 0, size // 2, (size - 1) // 2))\n",
      "  2392|         0|            0|            0|  0.00%|        div = avg_pool3d(div, (size, 1, 1), stride=1).squeeze(1)\n",
      "  2393|         0|            0|            0|  0.00%|        div = div.view(sizes)\n",
      "  2394|         0|            0|            0|  0.00%|    div = div.mul(alpha).add(k).pow(beta)\n",
      "  2395|         0|            0|            0|  0.00%|    return input / div\n",
      "  2396|         0|            0|            0|  0.00%|\n",
      "  2397|         0|            0|            0|  0.00%|\n",
      "  2398|         0|            0|            0|  0.00%|# loss\n",
      "  2399|         0|            0|            0|  0.00%|\n",
      "  2400|         0|            0|            0|  0.00%|\n",
      "  2401|         0|            0|            0|  0.00%|def ctc_loss(\n",
      "  2402|         0|            0|            0|  0.00%|    log_probs: Tensor,\n",
      "  2403|         0|            0|            0|  0.00%|    targets: Tensor,\n",
      "  2404|         0|            0|            0|  0.00%|    input_lengths: Tensor,\n",
      "  2405|         0|            0|            0|  0.00%|    target_lengths: Tensor,\n",
      "  2406|         0|            0|            0|  0.00%|    blank: int = 0,\n",
      "  2407|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2408|         0|            0|            0|  0.00%|    zero_infinity: bool = False,\n",
      "  2409|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2410|         0|            0|            0|  0.00%|    r\"\"\"The Connectionist Temporal Classification loss.\n",
      "  2411|         0|            0|            0|  0.00%|\n",
      "  2412|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CTCLoss` for details.\n",
      "  2413|         0|            0|            0|  0.00%|\n",
      "  2414|         0|            0|            0|  0.00%|    Note:\n",
      "  2415|         0|            0|            0|  0.00%|        {cudnn_reproducibility_note}\n",
      "  2416|         0|            0|            0|  0.00%|\n",
      "  2417|         0|            0|            0|  0.00%|    Note:\n",
      "  2418|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  2419|         0|            0|            0|  0.00%|\n",
      "  2420|         0|            0|            0|  0.00%|    Args:\n",
      "  2421|         0|            0|            0|  0.00%|        log_probs: :math:`(T, N, C)` where `C = number of characters in alphabet including blank`,\n",
      "  2422|         0|            0|            0|  0.00%|            `T = input length`, and `N = batch size`.\n",
      "  2423|         0|            0|            0|  0.00%|            The logarithmized probabilities of the outputs\n",
      "  2424|         0|            0|            0|  0.00%|            (e.g. obtained with :func:`torch.nn.functional.log_softmax`).\n",
      "  2425|         0|            0|            0|  0.00%|        targets: :math:`(N, S)` or `(sum(target_lengths))`.\n",
      "  2426|         0|            0|            0|  0.00%|            Targets cannot be blank. In the second form, the targets are assumed to be concatenated.\n",
      "  2427|         0|            0|            0|  0.00%|        input_lengths: :math:`(N)`.\n",
      "  2428|         0|            0|            0|  0.00%|            Lengths of the inputs (must each be :math:`\\leq T`)\n",
      "  2429|         0|            0|            0|  0.00%|        target_lengths: :math:`(N)`.\n",
      "  2430|         0|            0|            0|  0.00%|            Lengths of the targets\n",
      "  2431|         0|            0|            0|  0.00%|        blank (int, optional):\n",
      "  2432|         0|            0|            0|  0.00%|            Blank label. Default :math:`0`.\n",
      "  2433|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2434|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2435|         0|            0|            0|  0.00%|            ``'mean'``: the output losses will be divided by the target lengths and\n",
      "  2436|         0|            0|            0|  0.00%|            then the mean over the batch is taken, ``'sum'``: the output will be\n",
      "  2437|         0|            0|            0|  0.00%|            summed. Default: ``'mean'``\n",
      "  2438|         0|            0|            0|  0.00%|        zero_infinity (bool, optional):\n",
      "  2439|         0|            0|            0|  0.00%|            Whether to zero infinite losses and the associated gradients.\n",
      "  2440|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  2441|         0|            0|            0|  0.00%|            Infinite losses mainly occur when the inputs are too short\n",
      "  2442|         0|            0|            0|  0.00%|            to be aligned to the targets.\n",
      "  2443|         0|            0|            0|  0.00%|\n",
      "  2444|         0|            0|            0|  0.00%|    Example::\n",
      "  2445|         0|            0|            0|  0.00%|\n",
      "  2446|         0|            0|            0|  0.00%|        >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()\n",
      "  2447|         0|            0|            0|  0.00%|        >>> targets = torch.randint(1, 20, (16, 30), dtype=torch.long)\n",
      "  2448|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full((16,), 50, dtype=torch.long)\n",
      "  2449|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n",
      "  2450|         0|            0|            0|  0.00%|        >>> loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
      "  2451|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2452|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2453|         0|            0|            0|  0.00%|    if has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n",
      "  2454|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2455|         0|            0|            0|  0.00%|            ctc_loss,\n",
      "  2456|         0|            0|            0|  0.00%|            (log_probs, targets, input_lengths, target_lengths),\n",
      "  2457|         0|            0|            0|  0.00%|            log_probs, targets, input_lengths, target_lengths,\n",
      "  2458|         0|            0|            0|  0.00%|            blank=blank, reduction=reduction, zero_infinity=zero_infinity\n",
      "  2459|         0|            0|            0|  0.00%|        )\n",
      "  2460|         0|            0|            0|  0.00%|    return torch.ctc_loss(\n",
      "  2461|         0|            0|            0|  0.00%|        log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction), zero_infinity\n",
      "  2462|         0|            0|            0|  0.00%|    )\n",
      "  2463|         0|            0|            0|  0.00%|\n",
      "  2464|         0|            0|            0|  0.00%|\n",
      "  2465|         0|            0|            0|  0.00%|ctc_loss.__doc__ = ctc_loss.__doc__.format(**reproducibility_notes)\n",
      "  2466|         0|            0|            0|  0.00%|\n",
      "  2467|         0|            0|            0|  0.00%|\n",
      "  2468|         0|            0|            0|  0.00%|def nll_loss(\n",
      "  2469|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2470|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2471|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2472|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2473|         0|            0|            0|  0.00%|    ignore_index: int = -100,\n",
      "  2474|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2475|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2476|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2477|         0|            0|            0|  0.00%|    r\"\"\"The negative log likelihood loss.\n",
      "  2478|         0|            0|            0|  0.00%|\n",
      "  2479|         0|            0|            0|  0.00%|    See :class:`~torch.nn.NLLLoss` for details.\n",
      "  2480|         0|            0|            0|  0.00%|\n",
      "  2481|         0|            0|            0|  0.00%|    Args:\n",
      "  2482|         0|            0|            0|  0.00%|        input: :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
      "  2483|         0|            0|            0|  0.00%|            in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \\geq 1`\n",
      "  2484|         0|            0|            0|  0.00%|            in the case of K-dimensional loss. `input` is expected to be log-probabilities.\n",
      "  2485|         0|            0|            0|  0.00%|        target: :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`,\n",
      "  2486|         0|            0|            0|  0.00%|            or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \\geq 1` for\n",
      "  2487|         0|            0|            0|  0.00%|            K-dimensional loss.\n",
      "  2488|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  2489|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`\n",
      "  2490|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2491|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2492|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2493|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2494|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2495|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  2496|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  2497|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Default: -100\n",
      "  2498|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2499|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2500|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2501|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2502|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2503|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2504|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2505|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2506|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2507|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2508|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2509|         0|            0|            0|  0.00%|    Example::\n",
      "  2510|         0|            0|            0|  0.00%|\n",
      "  2511|         0|            0|            0|  0.00%|        >>> # input is of size N x C = 3 x 5\n",
      "  2512|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2513|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "  2514|         0|            0|            0|  0.00%|        >>> target = torch.tensor([1, 0, 4])\n",
      "  2515|         0|            0|            0|  0.00%|        >>> output = F.nll_loss(F.log_softmax(input), target)\n",
      "  2516|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  2517|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2518|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2519|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2520|         0|            0|            0|  0.00%|            nll_loss,\n",
      "  2521|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2522|         0|            0|            0|  0.00%|            input,\n",
      "  2523|         0|            0|            0|  0.00%|            target,\n",
      "  2524|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2525|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2526|         0|            0|            0|  0.00%|            ignore_index=ignore_index,\n",
      "  2527|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2528|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2529|         0|            0|            0|  0.00%|        )\n",
      "  2530|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2531|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2532|         0|            0|            0|  0.00%|    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n",
      "  2533|         0|            0|            0|  0.00%|\n",
      "  2534|         0|            0|            0|  0.00%|\n",
      "  2535|         0|            0|            0|  0.00%|def poisson_nll_loss(\n",
      "  2536|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2537|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2538|         0|            0|            0|  0.00%|    log_input: bool = True,\n",
      "  2539|         0|            0|            0|  0.00%|    full: bool = False,\n",
      "  2540|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2541|         0|            0|            0|  0.00%|    eps: float = 1e-8,\n",
      "  2542|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2543|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2544|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2545|         0|            0|            0|  0.00%|    r\"\"\"Poisson negative log likelihood loss.\n",
      "  2546|         0|            0|            0|  0.00%|\n",
      "  2547|         0|            0|            0|  0.00%|    See :class:`~torch.nn.PoissonNLLLoss` for details.\n",
      "  2548|         0|            0|            0|  0.00%|\n",
      "  2549|         0|            0|            0|  0.00%|    Args:\n",
      "  2550|         0|            0|            0|  0.00%|        input: expectation of underlying Poisson distribution.\n",
      "  2551|         0|            0|            0|  0.00%|        target: random sample :math:`target \\sim \\text{Poisson}(input)`.\n",
      "  2552|         0|            0|            0|  0.00%|        log_input: if ``True`` the loss is computed as\n",
      "  2553|         0|            0|            0|  0.00%|            :math:`\\exp(\\text{input}) - \\text{target} * \\text{input}`, if ``False`` then loss is\n",
      "  2554|         0|            0|            0|  0.00%|            :math:`\\text{input} - \\text{target} * \\log(\\text{input}+\\text{eps})`. Default: ``True``\n",
      "  2555|         0|            0|            0|  0.00%|        full: whether to compute full loss, i. e. to add the Stirling\n",
      "  2556|         0|            0|            0|  0.00%|            approximation term. Default: ``False``\n",
      "  2557|         0|            0|            0|  0.00%|            :math:`\\text{target} * \\log(\\text{target}) - \\text{target} + 0.5 * \\log(2 * \\pi * \\text{target})`.\n",
      "  2558|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2559|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2560|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2561|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2562|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2563|         0|            0|            0|  0.00%|        eps (float, optional): Small value to avoid evaluation of :math:`\\log(0)` when\n",
      "  2564|         0|            0|            0|  0.00%|            :attr:`log_input`\\ =\\ ``False``. Default: 1e-8\n",
      "  2565|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2566|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2567|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2568|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2569|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2570|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2571|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2572|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2573|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2574|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2575|         0|            0|            0|  0.00%|\n",
      "  2576|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2577|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2578|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2579|         0|            0|            0|  0.00%|            poisson_nll_loss,\n",
      "  2580|         0|            0|            0|  0.00%|            (input, target),\n",
      "  2581|         0|            0|            0|  0.00%|            input,\n",
      "  2582|         0|            0|            0|  0.00%|            target,\n",
      "  2583|         0|            0|            0|  0.00%|            log_input=log_input,\n",
      "  2584|         0|            0|            0|  0.00%|            full=full,\n",
      "  2585|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2586|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2587|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2588|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2589|         0|            0|            0|  0.00%|        )\n",
      "  2590|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2591|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2592|         0|            0|            0|  0.00%|    if reduction != \"none\" and reduction != \"mean\" and reduction != \"sum\":\n",
      "  2593|         0|            0|            0|  0.00%|        ret = input\n",
      "  2594|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  2595|         0|            0|            0|  0.00%|\n",
      "  2596|         0|            0|            0|  0.00%|    ret = torch.poisson_nll_loss(input, target, log_input, full, eps, _Reduction.get_enum(reduction))\n",
      "  2597|         0|            0|            0|  0.00%|    return ret\n",
      "  2598|         0|            0|            0|  0.00%|\n",
      "  2599|         0|            0|            0|  0.00%|\n",
      "  2600|         0|            0|            0|  0.00%|def gaussian_nll_loss(\n",
      "  2601|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2602|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2603|         0|            0|            0|  0.00%|    var: Tensor,\n",
      "  2604|         0|            0|            0|  0.00%|    full: bool = False,\n",
      "  2605|         0|            0|            0|  0.00%|    eps: float = 1e-6,\n",
      "  2606|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2607|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2608|         0|            0|            0|  0.00%|    r\"\"\"Gaussian negative log likelihood loss.\n",
      "  2609|         0|            0|            0|  0.00%|\n",
      "  2610|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GaussianNLLLoss` for details.\n",
      "  2611|         0|            0|            0|  0.00%|\n",
      "  2612|         0|            0|            0|  0.00%|    Args:\n",
      "  2613|         0|            0|            0|  0.00%|        input: expectation of the Gaussian distribution.\n",
      "  2614|         0|            0|            0|  0.00%|        target: sample from the Gaussian distribution.\n",
      "  2615|         0|            0|            0|  0.00%|        var: tensor of positive variance(s), one for each of the expectations\n",
      "  2616|         0|            0|            0|  0.00%|            in the input (heteroscedastic), or a single one (homoscedastic).\n",
      "  2617|         0|            0|            0|  0.00%|        full (bool, optional): include the constant term in the loss calculation. Default: ``False``.\n",
      "  2618|         0|            0|            0|  0.00%|        eps (float, optional): value added to var, for stability. Default: 1e-6.\n",
      "  2619|         0|            0|            0|  0.00%|        reduction (string, optional): specifies the reduction to apply to the output:\n",
      "  2620|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2621|         0|            0|            0|  0.00%|            ``'mean'``: the output is the average of all batch member losses,\n",
      "  2622|         0|            0|            0|  0.00%|            ``'sum'``: the output is the sum of all batch member losses.\n",
      "  2623|         0|            0|            0|  0.00%|            Default: ``'mean'``.\n",
      "  2624|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2625|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, var):\n",
      "  2626|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2627|         0|            0|            0|  0.00%|            gaussian_nll_loss,\n",
      "  2628|         0|            0|            0|  0.00%|            (input, target, var),\n",
      "  2629|         0|            0|            0|  0.00%|            input,\n",
      "  2630|         0|            0|            0|  0.00%|            target,\n",
      "  2631|         0|            0|            0|  0.00%|            var,\n",
      "  2632|         0|            0|            0|  0.00%|            full=full,\n",
      "  2633|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2634|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2635|         0|            0|            0|  0.00%|        )\n",
      "  2636|         0|            0|            0|  0.00%|\n",
      "  2637|         0|            0|            0|  0.00%|    # Check var size\n",
      "  2638|         0|            0|            0|  0.00%|    # If var.size == input.size, the case is heteroscedastic and no further checks are needed.\n",
      "  2639|         0|            0|            0|  0.00%|    # Otherwise:\n",
      "  2640|         0|            0|            0|  0.00%|    if var.size() != input.size():\n",
      "  2641|         0|            0|            0|  0.00%|\n",
      "  2642|         0|            0|            0|  0.00%|        # If var is one dimension short of input, but the sizes match otherwise, then this is a homoscedastic case.\n",
      "  2643|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2)\n",
      "  2644|         0|            0|            0|  0.00%|        # -> unsqueeze var so that var.shape = (10, 2, 1)\n",
      "  2645|         0|            0|            0|  0.00%|        # this is done so that broadcasting can happen in the loss calculation\n",
      "  2646|         0|            0|            0|  0.00%|        if input.size()[:-1] == var.size():\n",
      "  2647|         0|            0|            0|  0.00%|            var = torch.unsqueeze(var, -1)\n",
      "  2648|         0|            0|            0|  0.00%|\n",
      "  2649|         0|            0|            0|  0.00%|        # This checks if the sizes match up to the final dimension, and the final dimension of var is of size 1.\n",
      "  2650|         0|            0|            0|  0.00%|        # This is also a homoscedastic case.\n",
      "  2651|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2, 1)\n",
      "  2652|         0|            0|            0|  0.00%|        elif input.size()[:-1] == var.size()[:-1] and var.size(-1) == 1:  # Heteroscedastic case\n",
      "  2653|         0|            0|            0|  0.00%|            pass\n",
      "  2654|         0|            0|            0|  0.00%|\n",
      "  2655|         0|            0|            0|  0.00%|        # If none of the above pass, then the size of var is incorrect.\n",
      "  2656|         0|            0|            0|  0.00%|        else:\n",
      "  2657|         0|            0|            0|  0.00%|            raise ValueError(\"var is of incorrect size\")\n",
      "  2658|         0|            0|            0|  0.00%|\n",
      "  2659|         0|            0|            0|  0.00%|    # Check validity of reduction mode\n",
      "  2660|         0|            0|            0|  0.00%|    if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n",
      "  2661|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  2662|         0|            0|            0|  0.00%|\n",
      "  2663|         0|            0|            0|  0.00%|    # Entries of var must be non-negative\n",
      "  2664|         0|            0|            0|  0.00%|    if torch.any(var < 0):\n",
      "  2665|         0|            0|            0|  0.00%|        raise ValueError(\"var has negative entry/entries\")\n",
      "  2666|         0|            0|            0|  0.00%|\n",
      "  2667|         0|            0|            0|  0.00%|    # Clamp for stability\n",
      "  2668|         0|            0|            0|  0.00%|    var = var.clone()\n",
      "  2669|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "  2670|         0|            0|            0|  0.00%|        var.clamp_(min=eps)\n",
      "  2671|         0|            0|            0|  0.00%|\n",
      "  2672|         0|            0|            0|  0.00%|    # Calculate the loss\n",
      "  2673|         0|            0|            0|  0.00%|    loss = 0.5 * (torch.log(var) + (input - target)**2 / var)\n",
      "  2674|         0|            0|            0|  0.00%|    if full:\n",
      "  2675|         0|            0|            0|  0.00%|        loss += 0.5 * math.log(2 * math.pi)\n",
      "  2676|         0|            0|            0|  0.00%|\n",
      "  2677|         0|            0|            0|  0.00%|    if reduction == 'mean':\n",
      "  2678|         0|            0|            0|  0.00%|        return loss.mean()\n",
      "  2679|         0|            0|            0|  0.00%|    elif reduction == 'sum':\n",
      "  2680|         0|            0|            0|  0.00%|        return loss.sum()\n",
      "  2681|         0|            0|            0|  0.00%|    else:\n",
      "  2682|         0|            0|            0|  0.00%|        return loss\n",
      "  2683|         0|            0|            0|  0.00%|\n",
      "  2684|         0|            0|            0|  0.00%|\n",
      "  2685|         0|            0|            0|  0.00%|def kl_div(\n",
      "  2686|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2687|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2688|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2689|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2690|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2691|         0|            0|            0|  0.00%|    log_target: bool = False,\n",
      "  2692|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2693|         0|            0|            0|  0.00%|    r\"\"\"The `Kullback-Leibler divergence Loss\n",
      "  2694|         0|            0|            0|  0.00%|    <https://en.wikipedia.org/wiki/Kullback-Leibler_divergence>`__\n",
      "  2695|         0|            0|            0|  0.00%|\n",
      "  2696|         0|            0|            0|  0.00%|    See :class:`~torch.nn.KLDivLoss` for details.\n",
      "  2697|         0|            0|            0|  0.00%|\n",
      "  2698|         0|            0|            0|  0.00%|    Args:\n",
      "  2699|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape in log-probabilities.\n",
      "  2700|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input. See :attr:`log_target` for\n",
      "  2701|         0|            0|            0|  0.00%|            the target's interpretation.\n",
      "  2702|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2703|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2704|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2705|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2706|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2707|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2708|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2709|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2710|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2711|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2712|         0|            0|            0|  0.00%|            ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.\n",
      "  2713|         0|            0|            0|  0.00%|            ``'none'``: no reduction will be applied\n",
      "  2714|         0|            0|            0|  0.00%|            ``'batchmean'``: the sum of the output will be divided by the batchsize\n",
      "  2715|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed\n",
      "  2716|         0|            0|            0|  0.00%|            ``'mean'``: the output will be divided by the number of elements in the output\n",
      "  2717|         0|            0|            0|  0.00%|            Default: ``'mean'``\n",
      "  2718|         0|            0|            0|  0.00%|        log_target (bool): A flag indicating whether ``target`` is passed in the log space.\n",
      "  2719|         0|            0|            0|  0.00%|            It is recommended to pass certain distributions (like ``softmax``)\n",
      "  2720|         0|            0|            0|  0.00%|            in the log space to avoid numerical issues caused by explicit ``log``.\n",
      "  2721|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  2722|         0|            0|            0|  0.00%|\n",
      "  2723|         0|            0|            0|  0.00%|    .. note::\n",
      "  2724|         0|            0|            0|  0.00%|        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,\n",
      "  2725|         0|            0|            0|  0.00%|        and in the meantime, specifying either of those two args will override :attr:`reduction`.\n",
      "  2726|         0|            0|            0|  0.00%|\n",
      "  2727|         0|            0|            0|  0.00%|    .. note::\n",
      "  2728|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use\n",
      "  2729|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.\n",
      "  2730|         0|            0|            0|  0.00%|        In the next major release, ``'mean'`` will be changed to be the same as 'batchmean'.\n",
      "  2731|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2732|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2733|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2734|         0|            0|            0|  0.00%|            kl_div,\n",
      "  2735|         0|            0|            0|  0.00%|            (input, target),\n",
      "  2736|         0|            0|            0|  0.00%|            input,\n",
      "  2737|         0|            0|            0|  0.00%|            target,\n",
      "  2738|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2739|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2740|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2741|         0|            0|            0|  0.00%|            log_target=log_target,\n",
      "  2742|         0|            0|            0|  0.00%|        )\n",
      "  2743|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2744|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2745|         0|            0|            0|  0.00%|    else:\n",
      "  2746|         0|            0|            0|  0.00%|        if reduction == \"mean\":\n",
      "  2747|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  2748|         0|            0|            0|  0.00%|                \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "  2749|         0|            0|            0|  0.00%|                \"'batchmean' divides only by the batch size, and aligns with the KL div math definition.\"\n",
      "  2750|         0|            0|            0|  0.00%|                \"'mean' will be changed to behave the same as 'batchmean' in the next major release.\"\n",
      "  2751|         0|            0|            0|  0.00%|            )\n",
      "  2752|         0|            0|            0|  0.00%|\n",
      "  2753|         0|            0|            0|  0.00%|        # special case for batchmean\n",
      "  2754|         0|            0|            0|  0.00%|        if reduction == \"batchmean\":\n",
      "  2755|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum(\"sum\")\n",
      "  2756|         0|            0|            0|  0.00%|        else:\n",
      "  2757|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2758|         0|            0|            0|  0.00%|\n",
      "  2759|         0|            0|            0|  0.00%|    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)\n",
      "  2760|         0|            0|            0|  0.00%|\n",
      "  2761|         0|            0|            0|  0.00%|    if reduction == \"batchmean\" and input.dim() != 0:\n",
      "  2762|         0|            0|            0|  0.00%|        reduced = reduced / input.size()[0]\n",
      "  2763|         0|            0|            0|  0.00%|\n",
      "  2764|         0|            0|            0|  0.00%|    return reduced\n",
      "  2765|         0|            0|            0|  0.00%|\n",
      "  2766|         0|            0|            0|  0.00%|\n",
      "  2767|         1|  1.71661e-05|  1.71661e-05|  0.01%|def cross_entropy(\n",
      "  2768|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2769|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2770|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2771|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2772|         0|            0|            0|  0.00%|    ignore_index: int = -100,\n",
      "  2773|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2774|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2775|         0|            0|            0|  0.00%|    label_smoothing: float = 0.0,\n",
      "  2776|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2777|         0|            0|            0|  0.00%|    r\"\"\"This criterion computes the cross entropy loss between input and target.\n",
      "  2778|         0|            0|            0|  0.00%|\n",
      "  2779|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
      "  2780|         0|            0|            0|  0.00%|\n",
      "  2781|         0|            0|            0|  0.00%|    Args:\n",
      "  2782|         0|            0|            0|  0.00%|        input (Tensor) : :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
      "  2783|         0|            0|            0|  0.00%|            in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \\geq 1`\n",
      "  2784|         0|            0|            0|  0.00%|            in the case of K-dimensional loss. `input` is expected to contain unnormalized scores\n",
      "  2785|         0|            0|            0|  0.00%|            (often referred to as logits).\n",
      "  2786|         0|            0|            0|  0.00%|        target (Tensor) : If containing class indices, shape :math:`(N)` where each value is\n",
      "  2787|         0|            0|            0|  0.00%|            :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "  2788|         0|            0|            0|  0.00%|            :math:`K \\geq 1` in the case of K-dimensional loss. If containing class probabilities,\n",
      "  2789|         0|            0|            0|  0.00%|            same shape as the input.\n",
      "  2790|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  2791|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`\n",
      "  2792|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2793|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2794|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2795|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2796|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2797|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  2798|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  2799|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "  2800|         0|            0|            0|  0.00%|            :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "  2801|         0|            0|            0|  0.00%|            Default: -100\n",
      "  2802|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2803|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2804|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2805|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2806|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2807|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2808|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2809|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2810|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2811|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2812|         0|            0|            0|  0.00%|        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "  2813|         0|            0|            0|  0.00%|            of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "  2814|         0|            0|            0|  0.00%|            become a mixture of the original ground truth and a uniform distribution as described in\n",
      "  2815|         0|            0|            0|  0.00%|            `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "  2816|         0|            0|            0|  0.00%|\n",
      "  2817|         0|            0|            0|  0.00%|    Examples::\n",
      "  2818|         0|            0|            0|  0.00%|\n",
      "  2819|         0|            0|            0|  0.00%|        >>> # Example of target with class indices\n",
      "  2820|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2821|         0|            0|            0|  0.00%|        >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
      "  2822|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)\n",
      "  2823|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2824|         0|            0|            0|  0.00%|        >>>\n",
      "  2825|         0|            0|            0|  0.00%|        >>> # Example of target with class probabilities\n",
      "  2826|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2827|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "  2828|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)\n",
      "  2829|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2830|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2831|         1|  4.76837e-06|  4.76837e-06|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2832|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2833|         0|            0|            0|  0.00%|            cross_entropy,\n",
      "  2834|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2835|         0|            0|            0|  0.00%|            input,\n",
      "  2836|         0|            0|            0|  0.00%|            target,\n",
      "  2837|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2838|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2839|         0|            0|            0|  0.00%|            ignore_index=ignore_index,\n",
      "  2840|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2841|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2842|         0|            0|            0|  0.00%|            label_smoothing=label_smoothing,\n",
      "  2843|         0|            0|            0|  0.00%|        )\n",
      "  2844|         1|  3.09944e-06|  3.09944e-06|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2845|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2846|         1|   0.00424099|   0.00424099|  1.88%|    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "(call)|         1|  2.40803e-05|  2.40803e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/_reduction.py:7 get_enum\n",
      "  2847|         0|            0|            0|  0.00%|\n",
      "  2848|         0|            0|            0|  0.00%|\n",
      "  2849|         0|            0|            0|  0.00%|def binary_cross_entropy(\n",
      "  2850|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2851|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2852|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2853|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2854|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2855|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2856|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2857|         0|            0|            0|  0.00%|    r\"\"\"Function that measures the Binary Cross Entropy between the target and input\n",
      "  2858|         0|            0|            0|  0.00%|    probabilities.\n",
      "  2859|         0|            0|            0|  0.00%|\n",
      "  2860|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCELoss` for details.\n",
      "  2861|         0|            0|            0|  0.00%|\n",
      "  2862|         0|            0|            0|  0.00%|    Args:\n",
      "  2863|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as probabilities.\n",
      "  2864|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1.\n",
      "  2865|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight\n",
      "  2866|         0|            0|            0|  0.00%|                if provided it's repeated to match input tensor shape\n",
      "  2867|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2868|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2869|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2870|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2871|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2872|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2873|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2874|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2875|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2876|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2877|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2878|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2879|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2880|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2881|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2882|         0|            0|            0|  0.00%|\n",
      "  2883|         0|            0|            0|  0.00%|    Examples::\n",
      "  2884|         0|            0|            0|  0.00%|\n",
      "  2885|         0|            0|            0|  0.00%|        >>> input = torch.randn((3, 2), requires_grad=True)\n",
      "  2886|         0|            0|            0|  0.00%|        >>> target = torch.rand((3, 2), requires_grad=False)\n",
      "  2887|         0|            0|            0|  0.00%|        >>> loss = F.binary_cross_entropy(F.sigmoid(input), target)\n",
      "  2888|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2889|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2890|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2891|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2892|         0|            0|            0|  0.00%|            binary_cross_entropy,\n",
      "  2893|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2894|         0|            0|            0|  0.00%|            input,\n",
      "  2895|         0|            0|            0|  0.00%|            target,\n",
      "  2896|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2897|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2898|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2899|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2900|         0|            0|            0|  0.00%|        )\n",
      "  2901|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2902|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2903|         0|            0|            0|  0.00%|    else:\n",
      "  2904|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2905|         0|            0|            0|  0.00%|    if target.size() != input.size():\n",
      "  2906|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2907|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n",
      "  2908|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size())\n",
      "  2909|         0|            0|            0|  0.00%|        )\n",
      "  2910|         0|            0|            0|  0.00%|\n",
      "  2911|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  2912|         0|            0|            0|  0.00%|        new_size = _infer_size(target.size(), weight.size())\n",
      "  2913|         0|            0|            0|  0.00%|        weight = weight.expand(new_size)\n",
      "  2914|         0|            0|            0|  0.00%|\n",
      "  2915|         0|            0|            0|  0.00%|    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\n",
      "  2916|         0|            0|            0|  0.00%|\n",
      "  2917|         0|            0|            0|  0.00%|\n",
      "  2918|         0|            0|            0|  0.00%|def binary_cross_entropy_with_logits(\n",
      "  2919|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2920|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2921|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2922|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2923|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2924|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2925|         0|            0|            0|  0.00%|    pos_weight: Optional[Tensor] = None,\n",
      "  2926|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2927|         0|            0|            0|  0.00%|    r\"\"\"Function that measures Binary Cross Entropy between target and input\n",
      "  2928|         0|            0|            0|  0.00%|    logits.\n",
      "  2929|         0|            0|            0|  0.00%|\n",
      "  2930|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCEWithLogitsLoss` for details.\n",
      "  2931|         0|            0|            0|  0.00%|\n",
      "  2932|         0|            0|            0|  0.00%|    Args:\n",
      "  2933|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as unnormalized scores (often referred to as logits).\n",
      "  2934|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1\n",
      "  2935|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight\n",
      "  2936|         0|            0|            0|  0.00%|            if provided it's repeated to match input tensor shape\n",
      "  2937|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2938|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2939|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2940|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2941|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2942|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2943|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2944|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2945|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2946|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2947|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2948|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2949|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2950|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2951|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2952|         0|            0|            0|  0.00%|        pos_weight (Tensor, optional): a weight of positive examples.\n",
      "  2953|         0|            0|            0|  0.00%|                Must be a vector with length equal to the number of classes.\n",
      "  2954|         0|            0|            0|  0.00%|\n",
      "  2955|         0|            0|            0|  0.00%|    Examples::\n",
      "  2956|         0|            0|            0|  0.00%|\n",
      "  2957|         0|            0|            0|  0.00%|         >>> input = torch.randn(3, requires_grad=True)\n",
      "  2958|         0|            0|            0|  0.00%|         >>> target = torch.empty(3).random_(2)\n",
      "  2959|         0|            0|            0|  0.00%|         >>> loss = F.binary_cross_entropy_with_logits(input, target)\n",
      "  2960|         0|            0|            0|  0.00%|         >>> loss.backward()\n",
      "  2961|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2962|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight, pos_weight):\n",
      "  2963|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2964|         0|            0|            0|  0.00%|            binary_cross_entropy_with_logits,\n",
      "  2965|         0|            0|            0|  0.00%|            (input, target, weight, pos_weight),\n",
      "  2966|         0|            0|            0|  0.00%|            input,\n",
      "  2967|         0|            0|            0|  0.00%|            target,\n",
      "  2968|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2969|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2970|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2971|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2972|         0|            0|            0|  0.00%|            pos_weight=pos_weight,\n",
      "  2973|         0|            0|            0|  0.00%|        )\n",
      "  2974|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2975|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2976|         0|            0|            0|  0.00%|    else:\n",
      "  2977|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2978|         0|            0|            0|  0.00%|\n",
      "  2979|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  2980|         0|            0|            0|  0.00%|        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "  2981|         0|            0|            0|  0.00%|\n",
      "  2982|         0|            0|            0|  0.00%|    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n",
      "  2983|         0|            0|            0|  0.00%|\n",
      "  2984|         0|            0|            0|  0.00%|\n",
      "  2985|         0|            0|            0|  0.00%|def smooth_l1_loss(\n",
      "  2986|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2987|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2988|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2989|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2990|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2991|         0|            0|            0|  0.00%|    beta: float = 1.0,\n",
      "  2992|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2993|         0|            0|            0|  0.00%|    r\"\"\"Function that uses a squared term if the absolute\n",
      "  2994|         0|            0|            0|  0.00%|    element-wise error falls below beta and an L1 term otherwise.\n",
      "  2995|         0|            0|            0|  0.00%|\n",
      "  2996|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SmoothL1Loss` for details.\n",
      "  2997|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2998|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2999|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3000|         0|            0|            0|  0.00%|            smooth_l1_loss,\n",
      "  3001|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3002|         0|            0|            0|  0.00%|            input,\n",
      "  3003|         0|            0|            0|  0.00%|            target,\n",
      "  3004|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3005|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3006|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3007|         0|            0|            0|  0.00%|            beta=beta,\n",
      "  3008|         0|            0|            0|  0.00%|        )\n",
      "  3009|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3010|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3011|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3012|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3013|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3014|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3015|         0|            0|            0|  0.00%|        )\n",
      "  3016|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3017|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3018|         0|            0|            0|  0.00%|\n",
      "  3019|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3020|         0|            0|            0|  0.00%|    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)\n",
      "  3021|         0|            0|            0|  0.00%|\n",
      "  3022|         0|            0|            0|  0.00%|\n",
      "  3023|         0|            0|            0|  0.00%|def huber_loss(\n",
      "  3024|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3025|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3026|         0|            0|            0|  0.00%|    reduction: str = 'mean',\n",
      "  3027|         0|            0|            0|  0.00%|    delta: float = 1.0,\n",
      "  3028|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3029|         0|            0|            0|  0.00%|    r\"\"\"Function that uses a squared term if the absolute\n",
      "  3030|         0|            0|            0|  0.00%|    element-wise error falls below delta and a delta-scaled L1 term otherwise.\n",
      "  3031|         0|            0|            0|  0.00%|\n",
      "  3032|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HuberLoss` for details.\n",
      "  3033|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3034|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3035|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3036|         0|            0|            0|  0.00%|            huber_loss,\n",
      "  3037|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3038|         0|            0|            0|  0.00%|            input,\n",
      "  3039|         0|            0|            0|  0.00%|            target,\n",
      "  3040|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3041|         0|            0|            0|  0.00%|            delta=delta,\n",
      "  3042|         0|            0|            0|  0.00%|        )\n",
      "  3043|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3044|         0|            0|            0|  0.00%|        warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3045|         0|            0|            0|  0.00%|                      \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3046|         0|            0|            0|  0.00%|                      \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3047|         0|            0|            0|  0.00%|                      stacklevel=2)\n",
      "  3048|         0|            0|            0|  0.00%|\n",
      "  3049|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3050|         0|            0|            0|  0.00%|    return torch._C._nn.huber_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), delta)\n",
      "  3051|         0|            0|            0|  0.00%|\n",
      "  3052|         0|            0|            0|  0.00%|\n",
      "  3053|         0|            0|            0|  0.00%|def l1_loss(\n",
      "  3054|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3055|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3056|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3057|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3058|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3059|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3060|         0|            0|            0|  0.00%|    r\"\"\"l1_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3061|         0|            0|            0|  0.00%|\n",
      "  3062|         0|            0|            0|  0.00%|    Function that takes the mean element-wise absolute value difference.\n",
      "  3063|         0|            0|            0|  0.00%|\n",
      "  3064|         0|            0|            0|  0.00%|    See :class:`~torch.nn.L1Loss` for details.\n",
      "  3065|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3066|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3067|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3068|         0|            0|            0|  0.00%|            l1_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3069|         0|            0|            0|  0.00%|        )\n",
      "  3070|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3071|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3072|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3073|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3074|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3075|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3076|         0|            0|            0|  0.00%|        )\n",
      "  3077|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3078|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3079|         0|            0|            0|  0.00%|\n",
      "  3080|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3081|         0|            0|            0|  0.00%|    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "  3082|         0|            0|            0|  0.00%|\n",
      "  3083|         0|            0|            0|  0.00%|\n",
      "  3084|         0|            0|            0|  0.00%|def mse_loss(\n",
      "  3085|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3086|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3087|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3088|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3089|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3090|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3091|         0|            0|            0|  0.00%|    r\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3092|         0|            0|            0|  0.00%|\n",
      "  3093|         0|            0|            0|  0.00%|    Measures the element-wise mean squared error.\n",
      "  3094|         0|            0|            0|  0.00%|\n",
      "  3095|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MSELoss` for details.\n",
      "  3096|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3097|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3098|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3099|         0|            0|            0|  0.00%|            mse_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3100|         0|            0|            0|  0.00%|        )\n",
      "  3101|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3102|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3103|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3104|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3105|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3106|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3107|         0|            0|            0|  0.00%|        )\n",
      "  3108|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3109|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3110|         0|            0|            0|  0.00%|\n",
      "  3111|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3112|         0|            0|            0|  0.00%|    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "  3113|         0|            0|            0|  0.00%|\n",
      "  3114|         0|            0|            0|  0.00%|\n",
      "  3115|         0|            0|            0|  0.00%|def margin_ranking_loss(\n",
      "  3116|         0|            0|            0|  0.00%|    input1: Tensor,\n",
      "  3117|         0|            0|            0|  0.00%|    input2: Tensor,\n",
      "  3118|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3119|         0|            0|            0|  0.00%|    margin: float = 0,\n",
      "  3120|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3121|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3122|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3123|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3124|         0|            0|            0|  0.00%|    r\"\"\"margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3125|         0|            0|            0|  0.00%|\n",
      "  3126|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MarginRankingLoss` for details.\n",
      "  3127|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3128|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):\n",
      "  3129|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3130|         0|            0|            0|  0.00%|            margin_ranking_loss,\n",
      "  3131|         0|            0|            0|  0.00%|            (input1, input2, target),\n",
      "  3132|         0|            0|            0|  0.00%|            input1,\n",
      "  3133|         0|            0|            0|  0.00%|            input2,\n",
      "  3134|         0|            0|            0|  0.00%|            target,\n",
      "  3135|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3136|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3137|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3138|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3139|         0|            0|            0|  0.00%|        )\n",
      "  3140|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3141|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3142|         0|            0|            0|  0.00%|    else:\n",
      "  3143|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3144|         0|            0|            0|  0.00%|    if input1.dim() == 0 or input2.dim() == 0 or target.dim() == 0:\n",
      "  3145|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "  3146|         0|            0|            0|  0.00%|            (\n",
      "  3147|         0|            0|            0|  0.00%|                \"margin_ranking_loss does not support scalars, got sizes: \"\n",
      "  3148|         0|            0|            0|  0.00%|                \"input1: {}, input2: {}, target: {} \".format(input1.size(), input2.size(), target.size())\n",
      "  3149|         0|            0|            0|  0.00%|            )\n",
      "  3150|         0|            0|            0|  0.00%|        )\n",
      "  3151|         0|            0|            0|  0.00%|    return torch.margin_ranking_loss(input1, input2, target, margin, reduction_enum)\n",
      "  3152|         0|            0|            0|  0.00%|\n",
      "  3153|         0|            0|            0|  0.00%|\n",
      "  3154|         0|            0|            0|  0.00%|def hinge_embedding_loss(\n",
      "  3155|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3156|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3157|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  3158|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3159|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3160|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3161|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3162|         0|            0|            0|  0.00%|    r\"\"\"hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3163|         0|            0|            0|  0.00%|\n",
      "  3164|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HingeEmbeddingLoss` for details.\n",
      "  3165|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3166|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3167|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3168|         0|            0|            0|  0.00%|            hinge_embedding_loss,\n",
      "  3169|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3170|         0|            0|            0|  0.00%|            input,\n",
      "  3171|         0|            0|            0|  0.00%|            target,\n",
      "  3172|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3173|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3174|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3175|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3176|         0|            0|            0|  0.00%|        )\n",
      "  3177|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3178|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3179|         0|            0|            0|  0.00%|    else:\n",
      "  3180|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3181|         0|            0|            0|  0.00%|    return torch.hinge_embedding_loss(input, target, margin, reduction_enum)\n",
      "  3182|         0|            0|            0|  0.00%|\n",
      "  3183|         0|            0|            0|  0.00%|\n",
      "  3184|         0|            0|            0|  0.00%|def multilabel_margin_loss(\n",
      "  3185|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3186|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3187|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3188|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3189|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3190|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3191|         0|            0|            0|  0.00%|    r\"\"\"multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3192|         0|            0|            0|  0.00%|\n",
      "  3193|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelMarginLoss` for details.\n",
      "  3194|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3195|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3196|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3197|         0|            0|            0|  0.00%|            multilabel_margin_loss,\n",
      "  3198|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3199|         0|            0|            0|  0.00%|            input,\n",
      "  3200|         0|            0|            0|  0.00%|            target,\n",
      "  3201|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3202|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3203|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3204|         0|            0|            0|  0.00%|        )\n",
      "  3205|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3206|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3207|         0|            0|            0|  0.00%|    else:\n",
      "  3208|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3209|         0|            0|            0|  0.00%|    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)\n",
      "  3210|         0|            0|            0|  0.00%|\n",
      "  3211|         0|            0|            0|  0.00%|\n",
      "  3212|         0|            0|            0|  0.00%|def soft_margin_loss(\n",
      "  3213|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3214|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3215|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3216|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3217|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3218|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3219|         0|            0|            0|  0.00%|    r\"\"\"soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3220|         0|            0|            0|  0.00%|\n",
      "  3221|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SoftMarginLoss` for details.\n",
      "  3222|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3223|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3224|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3225|         0|            0|            0|  0.00%|            soft_margin_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3226|         0|            0|            0|  0.00%|        )\n",
      "  3227|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3228|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3229|         0|            0|            0|  0.00%|    else:\n",
      "  3230|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3231|         0|            0|            0|  0.00%|    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)\n",
      "  3232|         0|            0|            0|  0.00%|\n",
      "  3233|         0|            0|            0|  0.00%|\n",
      "  3234|         0|            0|            0|  0.00%|def multilabel_soft_margin_loss(\n",
      "  3235|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3236|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3237|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  3238|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3239|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3240|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3241|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3242|         0|            0|            0|  0.00%|    r\"\"\"multilabel_soft_margin_loss(input, target, weight=None, size_average=None) -> Tensor\n",
      "  3243|         0|            0|            0|  0.00%|\n",
      "  3244|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelSoftMarginLoss` for details.\n",
      "  3245|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3246|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  3247|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3248|         0|            0|            0|  0.00%|            multilabel_soft_margin_loss,\n",
      "  3249|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  3250|         0|            0|            0|  0.00%|            input,\n",
      "  3251|         0|            0|            0|  0.00%|            target,\n",
      "  3252|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  3253|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3254|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3255|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3256|         0|            0|            0|  0.00%|        )\n",
      "  3257|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3258|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3259|         0|            0|            0|  0.00%|\n",
      "  3260|         0|            0|            0|  0.00%|    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))\n",
      "  3261|         0|            0|            0|  0.00%|\n",
      "  3262|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  3263|         0|            0|            0|  0.00%|        loss = loss * weight\n",
      "  3264|         0|            0|            0|  0.00%|\n",
      "  3265|         0|            0|            0|  0.00%|    loss = loss.sum(dim=1) / input.size(1)  # only return N loss values\n",
      "  3266|         0|            0|            0|  0.00%|\n",
      "  3267|         0|            0|            0|  0.00%|    if reduction == \"none\":\n",
      "  3268|         0|            0|            0|  0.00%|        ret = loss\n",
      "  3269|         0|            0|            0|  0.00%|    elif reduction == \"mean\":\n",
      "  3270|         0|            0|            0|  0.00%|        ret = loss.mean()\n",
      "  3271|         0|            0|            0|  0.00%|    elif reduction == \"sum\":\n",
      "  3272|         0|            0|            0|  0.00%|        ret = loss.sum()\n",
      "  3273|         0|            0|            0|  0.00%|    else:\n",
      "  3274|         0|            0|            0|  0.00%|        ret = input\n",
      "  3275|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  3276|         0|            0|            0|  0.00%|    return ret\n",
      "  3277|         0|            0|            0|  0.00%|\n",
      "  3278|         0|            0|            0|  0.00%|\n",
      "  3279|         0|            0|            0|  0.00%|def cosine_embedding_loss(\n",
      "  3280|         0|            0|            0|  0.00%|    input1: Tensor,\n",
      "  3281|         0|            0|            0|  0.00%|    input2: Tensor,\n",
      "  3282|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3283|         0|            0|            0|  0.00%|    margin: float = 0,\n",
      "  3284|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3285|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3286|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3287|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3288|         0|            0|            0|  0.00%|    r\"\"\"cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3289|         0|            0|            0|  0.00%|\n",
      "  3290|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CosineEmbeddingLoss` for details.\n",
      "  3291|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3292|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):\n",
      "  3293|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3294|         0|            0|            0|  0.00%|            cosine_embedding_loss,\n",
      "  3295|         0|            0|            0|  0.00%|            (input1, input2, target),\n",
      "  3296|         0|            0|            0|  0.00%|            input1,\n",
      "  3297|         0|            0|            0|  0.00%|            input2,\n",
      "  3298|         0|            0|            0|  0.00%|            target,\n",
      "  3299|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3300|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3301|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3302|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3303|         0|            0|            0|  0.00%|        )\n",
      "  3304|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3305|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3306|         0|            0|            0|  0.00%|    else:\n",
      "  3307|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3308|         0|            0|            0|  0.00%|    return torch.cosine_embedding_loss(input1, input2, target, margin, reduction_enum)\n",
      "  3309|         0|            0|            0|  0.00%|\n",
      "  3310|         0|            0|            0|  0.00%|\n",
      "  3311|         0|            0|            0|  0.00%|def multi_margin_loss(\n",
      "  3312|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3313|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3314|         0|            0|            0|  0.00%|    p: int = 1,\n",
      "  3315|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  3316|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  3317|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3318|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3319|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3320|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3321|         0|            0|            0|  0.00%|    r\"\"\"multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None,\n",
      "  3322|         0|            0|            0|  0.00%|                          reduce=None, reduction='mean') -> Tensor\n",
      "  3323|         0|            0|            0|  0.00%|\n",
      "  3324|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiMarginLoss` for details.\n",
      "  3325|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3326|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  3327|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3328|         0|            0|            0|  0.00%|            multi_margin_loss,\n",
      "  3329|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  3330|         0|            0|            0|  0.00%|            input,\n",
      "  3331|         0|            0|            0|  0.00%|            target,\n",
      "  3332|         0|            0|            0|  0.00%|            p=p,\n",
      "  3333|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3334|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  3335|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3336|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3337|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3338|         0|            0|            0|  0.00%|        )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3339|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3340|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3341|         0|            0|            0|  0.00%|    else:\n",
      "  3342|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3343|         0|            0|            0|  0.00%|    if p != 1 and p != 2:\n",
      "  3344|         0|            0|            0|  0.00%|        raise ValueError(\"only p == 1 and p == 2 supported\")\n",
      "  3345|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  3346|         0|            0|            0|  0.00%|        if weight.dim() != 1:\n",
      "  3347|         0|            0|            0|  0.00%|            raise ValueError(\"weight must be one-dimensional\")\n",
      "  3348|         0|            0|            0|  0.00%|\n",
      "  3349|         0|            0|            0|  0.00%|    return torch._C._nn.multi_margin_loss(input, target, p, margin, weight, reduction_enum)\n",
      "  3350|         0|            0|            0|  0.00%|\n",
      "  3351|         0|            0|            0|  0.00%|\n",
      "  3352|         0|            0|            0|  0.00%|pixel_shuffle = _add_docstr(\n",
      "  3353|         0|            0|            0|  0.00%|    torch.pixel_shuffle,\n",
      "  3354|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3355|         0|            0|            0|  0.00%|pixel_shuffle(input, upscale_factor) -> Tensor\n",
      "  3356|         0|            0|            0|  0.00%|\n",
      "  3357|         0|            0|            0|  0.00%|Rearranges elements in a tensor of shape :math:`(*, C \\times r^2, H, W)` to a\n",
      "  3358|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \\times r, W \\times r)`, where r is the :attr:`upscale_factor`.\n",
      "  3359|         0|            0|            0|  0.00%|\n",
      "  3360|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelShuffle` for details.\n",
      "  3361|         0|            0|            0|  0.00%|\n",
      "  3362|         0|            0|            0|  0.00%|Args:\n",
      "  3363|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3364|         0|            0|            0|  0.00%|    upscale_factor (int): factor to increase spatial resolution by\n",
      "  3365|         0|            0|            0|  0.00%|\n",
      "  3366|         0|            0|            0|  0.00%|Examples::\n",
      "  3367|         0|            0|            0|  0.00%|\n",
      "  3368|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 9, 4, 4)\n",
      "  3369|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_shuffle(input, 3)\n",
      "  3370|         0|            0|            0|  0.00%|    >>> print(output.size())\n",
      "  3371|         0|            0|            0|  0.00%|    torch.Size([1, 1, 12, 12])\n",
      "  3372|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3373|         0|            0|            0|  0.00%|)\n",
      "  3374|         0|            0|            0|  0.00%|\n",
      "  3375|         0|            0|            0|  0.00%|pixel_unshuffle = _add_docstr(\n",
      "  3376|         0|            0|            0|  0.00%|    torch.pixel_unshuffle,\n",
      "  3377|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3378|         0|            0|            0|  0.00%|pixel_unshuffle(input, downscale_factor) -> Tensor\n",
      "  3379|         0|            0|            0|  0.00%|\n",
      "  3380|         0|            0|            0|  0.00%|Reverses the :class:`~torch.nn.PixelShuffle` operation by rearranging elements in a\n",
      "  3381|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \\times r, W \\times r)` to a tensor of shape\n",
      "  3382|         0|            0|            0|  0.00%|:math:`(*, C \\times r^2, H, W)`, where r is the :attr:`downscale_factor`.\n",
      "  3383|         0|            0|            0|  0.00%|\n",
      "  3384|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelUnshuffle` for details.\n",
      "  3385|         0|            0|            0|  0.00%|\n",
      "  3386|         0|            0|            0|  0.00%|Args:\n",
      "  3387|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3388|         0|            0|            0|  0.00%|    downscale_factor (int): factor to increase spatial resolution by\n",
      "  3389|         0|            0|            0|  0.00%|\n",
      "  3390|         0|            0|            0|  0.00%|Examples::\n",
      "  3391|         0|            0|            0|  0.00%|\n",
      "  3392|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 1, 12, 12)\n",
      "  3393|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_unshuffle(input, 3)\n",
      "  3394|         0|            0|            0|  0.00%|    >>> print(output.size())\n",
      "  3395|         0|            0|            0|  0.00%|    torch.Size([1, 9, 4, 4])\n",
      "  3396|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3397|         0|            0|            0|  0.00%|)\n",
      "  3398|         0|            0|            0|  0.00%|\n",
      "  3399|         0|            0|            0|  0.00%|channel_shuffle = _add_docstr(\n",
      "  3400|         0|            0|            0|  0.00%|    torch.channel_shuffle,\n",
      "  3401|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3402|         0|            0|            0|  0.00%|channel_shuffle(input, groups) -> Tensor\n",
      "  3403|         0|            0|            0|  0.00%|\n",
      "  3404|         0|            0|            0|  0.00%|Divide the channels in a tensor of shape :math:`(*, C , H, W)`\n",
      "  3405|         0|            0|            0|  0.00%|into g groups and rearrange them as :math:`(*, C \\frac g, g, H, W)`,\n",
      "  3406|         0|            0|            0|  0.00%|while keeping the original tensor shape.\n",
      "  3407|         0|            0|            0|  0.00%|\n",
      "  3408|         0|            0|            0|  0.00%|See :class:`~torch.nn.ChannelShuffle` for details.\n",
      "  3409|         0|            0|            0|  0.00%|\n",
      "  3410|         0|            0|            0|  0.00%|Args:\n",
      "  3411|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3412|         0|            0|            0|  0.00%|    groups (int): number of groups to divide channels in and rearrange.\n",
      "  3413|         0|            0|            0|  0.00%|\n",
      "  3414|         0|            0|            0|  0.00%|Examples::\n",
      "  3415|         0|            0|            0|  0.00%|\n",
      "  3416|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 4, 2, 2)\n",
      "  3417|         0|            0|            0|  0.00%|    >>> print(input)\n",
      "  3418|         0|            0|            0|  0.00%|    [[[[1, 2],\n",
      "  3419|         0|            0|            0|  0.00%|       [3, 4]],\n",
      "  3420|         0|            0|            0|  0.00%|      [[5, 6],\n",
      "  3421|         0|            0|            0|  0.00%|       [7, 8]],\n",
      "  3422|         0|            0|            0|  0.00%|      [[9, 10],\n",
      "  3423|         0|            0|            0|  0.00%|       [11, 12]],\n",
      "  3424|         0|            0|            0|  0.00%|      [[13, 14],\n",
      "  3425|         0|            0|            0|  0.00%|       [15, 16]],\n",
      "  3426|         0|            0|            0|  0.00%|     ]]\n",
      "  3427|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.channel_shuffle(input, 2)\n",
      "  3428|         0|            0|            0|  0.00%|    >>> print(output)\n",
      "  3429|         0|            0|            0|  0.00%|    [[[[1, 2],\n",
      "  3430|         0|            0|            0|  0.00%|       [3, 4]],\n",
      "  3431|         0|            0|            0|  0.00%|      [[9, 10],\n",
      "  3432|         0|            0|            0|  0.00%|       [11, 12]],\n",
      "  3433|         0|            0|            0|  0.00%|      [[5, 6],\n",
      "  3434|         0|            0|            0|  0.00%|       [7, 8]],\n",
      "  3435|         0|            0|            0|  0.00%|      [[13, 14],\n",
      "  3436|         0|            0|            0|  0.00%|       [15, 16]],\n",
      "  3437|         0|            0|            0|  0.00%|     ]]\n",
      "  3438|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3439|         0|            0|            0|  0.00%|)\n",
      "  3440|         0|            0|            0|  0.00%|\n",
      "  3441|         0|            0|            0|  0.00%|\n",
      "  3442|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3443|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = \"nearest\", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3444|         0|            0|            0|  0.00%|    pass\n",
      "  3445|         0|            0|            0|  0.00%|\n",
      "  3446|         0|            0|            0|  0.00%|\n",
      "  3447|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3448|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None, mode: str = \"nearest\", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3449|         0|            0|            0|  0.00%|    pass\n",
      "  3450|         0|            0|            0|  0.00%|\n",
      "  3451|         0|            0|            0|  0.00%|\n",
      "  3452|         0|            0|            0|  0.00%|def upsample(input, size=None, scale_factor=None, mode=\"nearest\", align_corners=None):  # noqa: F811\n",
      "  3453|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input to either the given :attr:`size` or the given\n",
      "  3454|         0|            0|            0|  0.00%|    :attr:`scale_factor`\n",
      "  3455|         0|            0|            0|  0.00%|\n",
      "  3456|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3457|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3458|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(...)``.\n",
      "  3459|         0|            0|            0|  0.00%|\n",
      "  3460|         0|            0|            0|  0.00%|    Note:\n",
      "  3461|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3462|         0|            0|            0|  0.00%|\n",
      "  3463|         0|            0|            0|  0.00%|    The algorithm used for upsampling is determined by :attr:`mode`.\n",
      "  3464|         0|            0|            0|  0.00%|\n",
      "  3465|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric upsampling are supported, i.e.\n",
      "  3466|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.\n",
      "  3467|         0|            0|            0|  0.00%|\n",
      "  3468|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:\n",
      "  3469|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.\n",
      "  3470|         0|            0|            0|  0.00%|\n",
      "  3471|         0|            0|            0|  0.00%|    The modes available for upsampling are: `nearest`, `linear` (3D-only),\n",
      "  3472|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only)\n",
      "  3473|         0|            0|            0|  0.00%|\n",
      "  3474|         0|            0|            0|  0.00%|    Args:\n",
      "  3475|         0|            0|            0|  0.00%|        input (Tensor): the input tensor\n",
      "  3476|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):\n",
      "  3477|         0|            0|            0|  0.00%|            output spatial size.\n",
      "  3478|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. Has to match input size if it is a tuple.\n",
      "  3479|         0|            0|            0|  0.00%|        mode (string): algorithm used for upsampling:\n",
      "  3480|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |\n",
      "  3481|         0|            0|            0|  0.00%|            ``'trilinear'``. Default: ``'nearest'``\n",
      "  3482|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3483|         0|            0|            0|  0.00%|            input and output as squares rather than points.\n",
      "  3484|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the\n",
      "  3485|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.\n",
      "  3486|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner\n",
      "  3487|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding\n",
      "  3488|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size\n",
      "  3489|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`\n",
      "  3490|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.\n",
      "  3491|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3492|         0|            0|            0|  0.00%|\n",
      "  3493|         0|            0|            0|  0.00%|    .. note::\n",
      "  3494|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce\n",
      "  3495|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.\n",
      "  3496|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot\n",
      "  3497|         0|            0|            0|  0.00%|        when displaying the image.\n",
      "  3498|         0|            0|            0|  0.00%|\n",
      "  3499|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3500|         0|            0|            0|  0.00%|        With ``align_corners = True``, the linearly interpolating modes\n",
      "  3501|         0|            0|            0|  0.00%|        (`linear`, `bilinear`, and `trilinear`) don't proportionally align the\n",
      "  3502|         0|            0|            0|  0.00%|        output and input pixels, and thus the output values can depend on the\n",
      "  3503|         0|            0|            0|  0.00%|        input size. This was the default behavior for these modes up to version\n",
      "  3504|         0|            0|            0|  0.00%|        0.3.1. Since then, the default behavior is ``align_corners = False``.\n",
      "  3505|         0|            0|            0|  0.00%|        See :class:`~torch.nn.Upsample` for concrete examples on how this\n",
      "  3506|         0|            0|            0|  0.00%|        affects the outputs.\n",
      "  3507|         0|            0|            0|  0.00%|\n",
      "  3508|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3509|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3510|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode, align_corners)\n",
      "  3511|         0|            0|            0|  0.00%|\n",
      "  3512|         0|            0|            0|  0.00%|\n",
      "  3513|         0|            0|            0|  0.00%|upsample.__doc__ = upsample.__doc__.format(**reproducibility_notes)\n",
      "  3514|         0|            0|            0|  0.00%|\n",
      "  3515|         0|            0|            0|  0.00%|\n",
      "  3516|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3517|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3518|         0|            0|            0|  0.00%|    pass\n",
      "  3519|         0|            0|            0|  0.00%|\n",
      "  3520|         0|            0|            0|  0.00%|\n",
      "  3521|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3522|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3523|         0|            0|            0|  0.00%|    pass\n",
      "  3524|         0|            0|            0|  0.00%|\n",
      "  3525|         0|            0|            0|  0.00%|\n",
      "  3526|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3527|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3528|         0|            0|            0|  0.00%|    pass\n",
      "  3529|         0|            0|            0|  0.00%|\n",
      "  3530|         0|            0|            0|  0.00%|\n",
      "  3531|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3532|         0|            0|            0|  0.00%|def interpolate(  # noqa: F811\n",
      "  3533|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3534|         0|            0|            0|  0.00%|    size: Optional[List[int]] = None,\n",
      "  3535|         0|            0|            0|  0.00%|    scale_factor: Optional[float] = None,\n",
      "  3536|         0|            0|            0|  0.00%|    mode: str = \"nearest\",\n",
      "  3537|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,\n",
      "  3538|         0|            0|            0|  0.00%|    recompute_scale_factor: Optional[bool] = None,\n",
      "  3539|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3540|         0|            0|            0|  0.00%|    pass\n",
      "  3541|         0|            0|            0|  0.00%|\n",
      "  3542|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3543|         0|            0|            0|  0.00%|    r\"\"\"Down/up samples the input to either the given :attr:`size` or the given\n",
      "  3544|         0|            0|            0|  0.00%|    :attr:`scale_factor`\n",
      "  3545|         0|            0|            0|  0.00%|\n",
      "  3546|         0|            0|            0|  0.00%|    The algorithm used for interpolation is determined by :attr:`mode`.\n",
      "  3547|         0|            0|            0|  0.00%|\n",
      "  3548|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric sampling are supported, i.e.\n",
      "  3549|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.\n",
      "  3550|         0|            0|            0|  0.00%|\n",
      "  3551|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:\n",
      "  3552|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.\n",
      "  3553|         0|            0|            0|  0.00%|\n",
      "  3554|         0|            0|            0|  0.00%|    The modes available for resizing are: `nearest`, `linear` (3D-only),\n",
      "  3555|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`\n",
      "  3556|         0|            0|            0|  0.00%|\n",
      "  3557|         0|            0|            0|  0.00%|    Args:\n",
      "  3558|         0|            0|            0|  0.00%|        input (Tensor): the input tensor\n",
      "  3559|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):\n",
      "  3560|         0|            0|            0|  0.00%|            output spatial size.\n",
      "  3561|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,\n",
      "  3562|         0|            0|            0|  0.00%|            its length has to match `input.dim()`.\n",
      "  3563|         0|            0|            0|  0.00%|        mode (str): algorithm used for upsampling:\n",
      "  3564|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |\n",
      "  3565|         0|            0|            0|  0.00%|            ``'trilinear'`` | ``'area'``. Default: ``'nearest'``\n",
      "  3566|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3567|         0|            0|            0|  0.00%|            input and output as squares rather than points.\n",
      "  3568|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the\n",
      "  3569|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.\n",
      "  3570|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner\n",
      "  3571|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding\n",
      "  3572|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size\n",
      "  3573|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`\n",
      "  3574|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.\n",
      "  3575|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3576|         0|            0|            0|  0.00%|        recompute_scale_factor (bool, optional): recompute the scale_factor for use in the\n",
      "  3577|         0|            0|            0|  0.00%|            interpolation calculation. If `recompute_scale_factor` is ``True``, then\n",
      "  3578|         0|            0|            0|  0.00%|            `scale_factor` must be passed in and `scale_factor` is used to compute the\n",
      "  3579|         0|            0|            0|  0.00%|            output `size`. The computed output `size` will be used to infer new scales for\n",
      "  3580|         0|            0|            0|  0.00%|            the interpolation. Note that when `scale_factor` is floating-point, it may differ\n",
      "  3581|         0|            0|            0|  0.00%|            from the recomputed `scale_factor` due to rounding and precision issues.\n",
      "  3582|         0|            0|            0|  0.00%|            If `recomputed_scale_factor` is ``False``, then `size` or `scale_factor` will\n",
      "  3583|         0|            0|            0|  0.00%|            be used directly for interpolation.\n",
      "  3584|         0|            0|            0|  0.00%|\n",
      "  3585|         0|            0|            0|  0.00%|    .. note::\n",
      "  3586|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce\n",
      "  3587|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.\n",
      "  3588|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot\n",
      "  3589|         0|            0|            0|  0.00%|        when displaying the image.\n",
      "  3590|         0|            0|            0|  0.00%|\n",
      "  3591|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3592|         0|            0|            0|  0.00%|        With ``align_corners = True``, the linearly interpolating modes\n",
      "  3593|         0|            0|            0|  0.00%|        (`linear`, `bilinear`, and `trilinear`) don't proportionally align the\n",
      "  3594|         0|            0|            0|  0.00%|        output and input pixels, and thus the output values can depend on the\n",
      "  3595|         0|            0|            0|  0.00%|        input size. This was the default behavior for these modes up to version\n",
      "  3596|         0|            0|            0|  0.00%|        0.3.1. Since then, the default behavior is ``align_corners = False``.\n",
      "  3597|         0|            0|            0|  0.00%|        See :class:`~torch.nn.Upsample` for concrete examples on how this\n",
      "  3598|         0|            0|            0|  0.00%|        affects the outputs.\n",
      "  3599|         0|            0|            0|  0.00%|\n",
      "  3600|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3601|         0|            0|            0|  0.00%|        When scale_factor is specified, if recompute_scale_factor=True,\n",
      "  3602|         0|            0|            0|  0.00%|        scale_factor is used to compute the output_size which will then\n",
      "  3603|         0|            0|            0|  0.00%|        be used to infer new scales for the interpolation.\n",
      "  3604|         0|            0|            0|  0.00%|        The default behavior for recompute_scale_factor changed to False\n",
      "  3605|         0|            0|            0|  0.00%|        in 1.6.0, and scale_factor is used in the interpolation\n",
      "  3606|         0|            0|            0|  0.00%|        calculation.\n",
      "  3607|         0|            0|            0|  0.00%|\n",
      "  3608|         0|            0|            0|  0.00%|    Note:\n",
      "  3609|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3610|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3611|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  3612|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3613|         0|            0|            0|  0.00%|            interpolate,\n",
      "  3614|         0|            0|            0|  0.00%|            (input,),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3615|         0|            0|            0|  0.00%|            input,\n",
      "  3616|         0|            0|            0|  0.00%|            size=size,\n",
      "  3617|         0|            0|            0|  0.00%|            scale_factor=scale_factor,\n",
      "  3618|         0|            0|            0|  0.00%|            mode=mode,\n",
      "  3619|         0|            0|            0|  0.00%|            align_corners=align_corners,\n",
      "  3620|         0|            0|            0|  0.00%|            recompute_scale_factor=recompute_scale_factor,\n",
      "  3621|         0|            0|            0|  0.00%|        )\n",
      "  3622|         0|            0|            0|  0.00%|\n",
      "  3623|         0|            0|            0|  0.00%|    if mode in (\"nearest\", \"area\"):\n",
      "  3624|         0|            0|            0|  0.00%|        if align_corners is not None:\n",
      "  3625|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  3626|         0|            0|            0|  0.00%|                \"align_corners option can only be set with the \"\n",
      "  3627|         0|            0|            0|  0.00%|                \"interpolating modes: linear | bilinear | bicubic | trilinear\"\n",
      "  3628|         0|            0|            0|  0.00%|            )\n",
      "  3629|         0|            0|            0|  0.00%|    else:\n",
      "  3630|         0|            0|            0|  0.00%|        if align_corners is None:\n",
      "  3631|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  3632|         0|            0|            0|  0.00%|                \"Default upsampling behavior when mode={} is changed \"\n",
      "  3633|         0|            0|            0|  0.00%|                \"to align_corners=False since 0.4.0. Please specify \"\n",
      "  3634|         0|            0|            0|  0.00%|                \"align_corners=True if the old behavior is desired. \"\n",
      "  3635|         0|            0|            0|  0.00%|                \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "  3636|         0|            0|            0|  0.00%|            )\n",
      "  3637|         0|            0|            0|  0.00%|            align_corners = False\n",
      "  3638|         0|            0|            0|  0.00%|\n",
      "  3639|         0|            0|            0|  0.00%|    dim = input.dim() - 2  # Number of spatial dimensions.\n",
      "  3640|         0|            0|            0|  0.00%|\n",
      "  3641|         0|            0|            0|  0.00%|    # Process size and scale_factor.  Validate that exactly one is set.\n",
      "  3642|         0|            0|            0|  0.00%|    # Validate its length if it is a list, or expand it if it is a scalar.\n",
      "  3643|         0|            0|            0|  0.00%|    # After this block, exactly one of output_size and scale_factors will\n",
      "  3644|         0|            0|            0|  0.00%|    # be non-None, and it will be a list (or tuple).\n",
      "  3645|         0|            0|            0|  0.00%|    if size is not None and scale_factor is not None:\n",
      "  3646|         0|            0|            0|  0.00%|        raise ValueError(\"only one of size or scale_factor should be defined\")\n",
      "  3647|         0|            0|            0|  0.00%|    elif size is not None:\n",
      "  3648|         0|            0|            0|  0.00%|        assert scale_factor is None\n",
      "  3649|         0|            0|            0|  0.00%|        scale_factors = None\n",
      "  3650|         0|            0|            0|  0.00%|        if isinstance(size, (list, tuple)):\n",
      "  3651|         0|            0|            0|  0.00%|            if len(size) != dim:\n",
      "  3652|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "  3653|         0|            0|            0|  0.00%|                    \"size shape must match input shape. \" \"Input is {}D, size is {}\".format(dim, len(size))\n",
      "  3654|         0|            0|            0|  0.00%|                )\n",
      "  3655|         0|            0|            0|  0.00%|            output_size = size\n",
      "  3656|         0|            0|            0|  0.00%|        else:\n",
      "  3657|         0|            0|            0|  0.00%|            output_size = [size for _ in range(dim)]\n",
      "  3658|         0|            0|            0|  0.00%|    elif scale_factor is not None:\n",
      "  3659|         0|            0|            0|  0.00%|        assert size is None\n",
      "  3660|         0|            0|            0|  0.00%|        output_size = None\n",
      "  3661|         0|            0|            0|  0.00%|        if isinstance(scale_factor, (list, tuple)):\n",
      "  3662|         0|            0|            0|  0.00%|            if len(scale_factor) != dim:\n",
      "  3663|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "  3664|         0|            0|            0|  0.00%|                    \"scale_factor shape must match input shape. \"\n",
      "  3665|         0|            0|            0|  0.00%|                    \"Input is {}D, scale_factor is {}\".format(dim, len(scale_factor))\n",
      "  3666|         0|            0|            0|  0.00%|                )\n",
      "  3667|         0|            0|            0|  0.00%|            scale_factors = scale_factor\n",
      "  3668|         0|            0|            0|  0.00%|        else:\n",
      "  3669|         0|            0|            0|  0.00%|            scale_factors = [scale_factor for _ in range(dim)]\n",
      "  3670|         0|            0|            0|  0.00%|    else:\n",
      "  3671|         0|            0|            0|  0.00%|        raise ValueError(\"either size or scale_factor should be defined\")\n",
      "  3672|         0|            0|            0|  0.00%|\n",
      "  3673|         0|            0|            0|  0.00%|    if recompute_scale_factor is None:\n",
      "  3674|         0|            0|            0|  0.00%|        # only warn when the scales have floating values since\n",
      "  3675|         0|            0|            0|  0.00%|        # the result for ints is the same with/without recompute_scale_factor\n",
      "  3676|         0|            0|            0|  0.00%|        if scale_factors is not None:\n",
      "  3677|         0|            0|            0|  0.00%|            for scale in scale_factors:\n",
      "  3678|         0|            0|            0|  0.00%|                if math.floor(scale) != scale:\n",
      "  3679|         0|            0|            0|  0.00%|                    warnings.warn(\n",
      "  3680|         0|            0|            0|  0.00%|                        \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "  3681|         0|            0|            0|  0.00%|                        \"in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, \"\n",
      "  3682|         0|            0|            0|  0.00%|                        \"instead of relying on the computed output size. \"\n",
      "  3683|         0|            0|            0|  0.00%|                        \"If you wish to restore the old behavior, please set recompute_scale_factor=True. \"\n",
      "  3684|         0|            0|            0|  0.00%|                        \"See the documentation of nn.Upsample for details. \"\n",
      "  3685|         0|            0|            0|  0.00%|                    )\n",
      "  3686|         0|            0|            0|  0.00%|                    break\n",
      "  3687|         0|            0|            0|  0.00%|    elif recompute_scale_factor and size is not None:\n",
      "  3688|         0|            0|            0|  0.00%|        raise ValueError(\"recompute_scale_factor is not meaningful with an explicit size.\")\n",
      "  3689|         0|            0|            0|  0.00%|\n",
      "  3690|         0|            0|            0|  0.00%|    # \"area\" mode always requires an explicit size rather than scale factor.\n",
      "  3691|         0|            0|            0|  0.00%|    # Re-use the recompute_scale_factor code path.\n",
      "  3692|         0|            0|            0|  0.00%|    if mode == \"area\" and output_size is None:\n",
      "  3693|         0|            0|            0|  0.00%|        recompute_scale_factor = True\n",
      "  3694|         0|            0|            0|  0.00%|\n",
      "  3695|         0|            0|            0|  0.00%|    if recompute_scale_factor is not None and recompute_scale_factor:\n",
      "  3696|         0|            0|            0|  0.00%|        # We compute output_size here, then un-set scale_factors.\n",
      "  3697|         0|            0|            0|  0.00%|        # The C++ code will recompute it based on the (integer) output size.\n",
      "  3698|         0|            0|            0|  0.00%|        if not torch.jit.is_scripting() and torch._C._get_tracing_state():\n",
      "  3699|         0|            0|            0|  0.00%|            # make scale_factor a tensor in tracing so constant doesn't get baked in\n",
      "  3700|         0|            0|            0|  0.00%|            output_size = [\n",
      "  3701|         0|            0|            0|  0.00%|                (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
      "  3702|         0|            0|            0|  0.00%|                for i in range(dim)\n",
      "  3703|         0|            0|            0|  0.00%|            ]\n",
      "  3704|         0|            0|            0|  0.00%|        else:\n",
      "  3705|         0|            0|            0|  0.00%|            assert scale_factors is not None\n",
      "  3706|         0|            0|            0|  0.00%|            output_size = [int(math.floor(float(input.size(i + 2)) * scale_factors[i])) for i in range(dim)]\n",
      "  3707|         0|            0|            0|  0.00%|        scale_factors = None\n",
      "  3708|         0|            0|            0|  0.00%|\n",
      "  3709|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"nearest\":\n",
      "  3710|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)\n",
      "  3711|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"nearest\":\n",
      "  3712|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n",
      "  3713|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"nearest\":\n",
      "  3714|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)\n",
      "  3715|         0|            0|            0|  0.00%|\n",
      "  3716|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"area\":\n",
      "  3717|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3718|         0|            0|            0|  0.00%|        return adaptive_avg_pool1d(input, output_size)\n",
      "  3719|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"area\":\n",
      "  3720|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3721|         0|            0|            0|  0.00%|        return adaptive_avg_pool2d(input, output_size)\n",
      "  3722|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"area\":\n",
      "  3723|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3724|         0|            0|            0|  0.00%|        return adaptive_avg_pool3d(input, output_size)\n",
      "  3725|         0|            0|            0|  0.00%|\n",
      "  3726|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"linear\":\n",
      "  3727|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3728|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_linear1d(input, output_size, align_corners, scale_factors)\n",
      "  3729|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"bilinear\":\n",
      "  3730|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3731|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)\n",
      "  3732|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"trilinear\":\n",
      "  3733|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3734|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_trilinear3d(input, output_size, align_corners, scale_factors)\n",
      "  3735|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"bicubic\":\n",
      "  3736|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3737|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n",
      "  3738|         0|            0|            0|  0.00%|\n",
      "  3739|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"bilinear\":\n",
      "  3740|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 3D input, but bilinear mode needs 4D input\")\n",
      "  3741|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"trilinear\":\n",
      "  3742|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 3D input, but trilinear mode needs 5D input\")\n",
      "  3743|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"linear\":\n",
      "  3744|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 4D input, but linear mode needs 3D input\")\n",
      "  3745|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"trilinear\":\n",
      "  3746|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 4D input, but trilinear mode needs 5D input\")\n",
      "  3747|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"linear\":\n",
      "  3748|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 5D input, but linear mode needs 3D input\")\n",
      "  3749|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"bilinear\":\n",
      "  3750|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 5D input, but bilinear mode needs 4D input\")\n",
      "  3751|         0|            0|            0|  0.00%|\n",
      "  3752|         0|            0|            0|  0.00%|    raise NotImplementedError(\n",
      "  3753|         0|            0|            0|  0.00%|        \"Input Error: Only 3D, 4D and 5D input Tensors supported\"\n",
      "  3754|         0|            0|            0|  0.00%|        \" (got {}D) for the modes: nearest | linear | bilinear | bicubic | trilinear\"\n",
      "  3755|         0|            0|            0|  0.00%|        \" (got {})\".format(input.dim(), mode)\n",
      "  3756|         0|            0|            0|  0.00%|    )\n",
      "  3757|         0|            0|            0|  0.00%|\n",
      "  3758|         0|            0|            0|  0.00%|\n",
      "  3759|         0|            0|            0|  0.00%|interpolate.__doc__ = interpolate.__doc__.format(**reproducibility_notes)\n",
      "  3760|         0|            0|            0|  0.00%|\n",
      "  3761|         0|            0|            0|  0.00%|\n",
      "  3762|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3763|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811\n",
      "  3764|         0|            0|            0|  0.00%|    pass\n",
      "  3765|         0|            0|            0|  0.00%|\n",
      "  3766|         0|            0|            0|  0.00%|\n",
      "  3767|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3768|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811\n",
      "  3769|         0|            0|            0|  0.00%|    pass\n",
      "  3770|         0|            0|            0|  0.00%|\n",
      "  3771|         0|            0|            0|  0.00%|\n",
      "  3772|         0|            0|            0|  0.00%|def upsample_nearest(input, size=None, scale_factor=None):  # noqa: F811\n",
      "  3773|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input, using nearest neighbours' pixel values.\n",
      "  3774|         0|            0|            0|  0.00%|\n",
      "  3775|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3776|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3777|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(..., mode='nearest')``.\n",
      "  3778|         0|            0|            0|  0.00%|\n",
      "  3779|         0|            0|            0|  0.00%|    Currently spatial and volumetric upsampling are supported (i.e. expected\n",
      "  3780|         0|            0|            0|  0.00%|    inputs are 4 or 5 dimensional).\n",
      "  3781|         0|            0|            0|  0.00%|\n",
      "  3782|         0|            0|            0|  0.00%|    Args:\n",
      "  3783|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  3784|         0|            0|            0|  0.00%|        size (int or Tuple[int, int] or Tuple[int, int, int]): output spatia\n",
      "  3785|         0|            0|            0|  0.00%|            size.\n",
      "  3786|         0|            0|            0|  0.00%|        scale_factor (int): multiplier for spatial size. Has to be an integer.\n",
      "  3787|         0|            0|            0|  0.00%|\n",
      "  3788|         0|            0|            0|  0.00%|    Note:\n",
      "  3789|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3790|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3791|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default\n",
      "  3792|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3793|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode=\"nearest\")\n",
      "  3794|         0|            0|            0|  0.00%|\n",
      "  3795|         0|            0|            0|  0.00%|\n",
      "  3796|         0|            0|            0|  0.00%|upsample_nearest.__doc__ = upsample_nearest.__doc__.format(**reproducibility_notes)\n",
      "  3797|         0|            0|            0|  0.00%|\n",
      "  3798|         0|            0|            0|  0.00%|\n",
      "  3799|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3800|         0|            0|            0|  0.00%|def upsample_bilinear(\n",
      "  3801|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None\n",
      "  3802|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3803|         0|            0|            0|  0.00%|    pass\n",
      "  3804|         0|            0|            0|  0.00%|\n",
      "  3805|         0|            0|            0|  0.00%|\n",
      "  3806|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3807|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3808|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None\n",
      "  3809|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3810|         0|            0|            0|  0.00%|    pass\n",
      "  3811|         0|            0|            0|  0.00%|\n",
      "  3812|         0|            0|            0|  0.00%|\n",
      "  3813|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3814|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3815|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None\n",
      "  3816|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3817|         0|            0|            0|  0.00%|    pass\n",
      "  3818|         0|            0|            0|  0.00%|\n",
      "  3819|         0|            0|            0|  0.00%|\n",
      "  3820|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3821|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3822|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None\n",
      "  3823|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3824|         0|            0|            0|  0.00%|    pass\n",
      "  3825|         0|            0|            0|  0.00%|\n",
      "  3826|         0|            0|            0|  0.00%|\n",
      "  3827|         0|            0|            0|  0.00%|def upsample_bilinear(input, size=None, scale_factor=None):  # noqa: F811\n",
      "  3828|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input, using bilinear upsampling.\n",
      "  3829|         0|            0|            0|  0.00%|\n",
      "  3830|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3831|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3832|         0|            0|            0|  0.00%|        This is equivalent with\n",
      "  3833|         0|            0|            0|  0.00%|        ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.\n",
      "  3834|         0|            0|            0|  0.00%|\n",
      "  3835|         0|            0|            0|  0.00%|    Expected inputs are spatial (4 dimensional). Use `upsample_trilinear` fo\n",
      "  3836|         0|            0|            0|  0.00%|    volumetric (5 dimensional) inputs.\n",
      "  3837|         0|            0|            0|  0.00%|\n",
      "  3838|         0|            0|            0|  0.00%|    Args:\n",
      "  3839|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  3840|         0|            0|            0|  0.00%|        size (int or Tuple[int, int]): output spatial size.\n",
      "  3841|         0|            0|            0|  0.00%|        scale_factor (int or Tuple[int, int]): multiplier for spatial size\n",
      "  3842|         0|            0|            0|  0.00%|\n",
      "  3843|         0|            0|            0|  0.00%|    Note:\n",
      "  3844|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3845|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3846|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default\n",
      "  3847|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3848|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode=\"bilinear\", align_corners=True)\n",
      "  3849|         0|            0|            0|  0.00%|\n",
      "  3850|         0|            0|            0|  0.00%|\n",
      "  3851|         0|            0|            0|  0.00%|upsample_bilinear.__doc__ = upsample_bilinear.__doc__.format(**reproducibility_notes)\n",
      "  3852|         0|            0|            0|  0.00%|\n",
      "  3853|         0|            0|            0|  0.00%|GRID_SAMPLE_INTERPOLATION_MODES = {\n",
      "  3854|         0|            0|            0|  0.00%|    \"bilinear\": 0,\n",
      "  3855|         0|            0|            0|  0.00%|    \"nearest\": 1,\n",
      "  3856|         0|            0|            0|  0.00%|    \"bicubic\": 2,\n",
      "  3857|         0|            0|            0|  0.00%|}\n",
      "  3858|         0|            0|            0|  0.00%|\n",
      "  3859|         0|            0|            0|  0.00%|GRID_SAMPLE_PADDING_MODES = {\n",
      "  3860|         0|            0|            0|  0.00%|    \"zeros\": 0,\n",
      "  3861|         0|            0|            0|  0.00%|    \"border\": 1,\n",
      "  3862|         0|            0|            0|  0.00%|    \"reflection\": 2,\n",
      "  3863|         0|            0|            0|  0.00%|}\n",
      "  3864|         0|            0|            0|  0.00%|\n",
      "  3865|         0|            0|            0|  0.00%|\n",
      "  3866|         0|            0|            0|  0.00%|def grid_sample(\n",
      "  3867|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3868|         0|            0|            0|  0.00%|    grid: Tensor,\n",
      "  3869|         0|            0|            0|  0.00%|    mode: str = \"bilinear\",\n",
      "  3870|         0|            0|            0|  0.00%|    padding_mode: str = \"zeros\",\n",
      "  3871|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,\n",
      "  3872|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3873|         0|            0|            0|  0.00%|    r\"\"\"Given an :attr:`input` and a flow-field :attr:`grid`, computes the\n",
      "  3874|         0|            0|            0|  0.00%|    ``output`` using :attr:`input` values and pixel locations from :attr:`grid`.\n",
      "  3875|         0|            0|            0|  0.00%|\n",
      "  3876|         0|            0|            0|  0.00%|    Currently, only spatial (4-D) and volumetric (5-D) :attr:`input` are\n",
      "  3877|         0|            0|            0|  0.00%|    supported.\n",
      "  3878|         0|            0|            0|  0.00%|\n",
      "  3879|         0|            0|            0|  0.00%|    In the spatial (4-D) case, for :attr:`input` with shape\n",
      "  3880|         0|            0|            0|  0.00%|    :math:`(N, C, H_\\text{in}, W_\\text{in})` and :attr:`grid` with shape\n",
      "  3881|         0|            0|            0|  0.00%|    :math:`(N, H_\\text{out}, W_\\text{out}, 2)`, the output will have shape\n",
      "  3882|         0|            0|            0|  0.00%|    :math:`(N, C, H_\\text{out}, W_\\text{out})`.\n",
      "  3883|         0|            0|            0|  0.00%|\n",
      "  3884|         0|            0|            0|  0.00%|    For each output location ``output[n, :, h, w]``, the size-2 vector\n",
      "  3885|         0|            0|            0|  0.00%|    ``grid[n, h, w]`` specifies :attr:`input` pixel locations ``x`` and ``y``,\n",
      "  3886|         0|            0|            0|  0.00%|    which are used to interpolate the output value ``output[n, :, h, w]``.\n",
      "  3887|         0|            0|            0|  0.00%|    In the case of 5D inputs, ``grid[n, d, h, w]`` specifies the\n",
      "  3888|         0|            0|            0|  0.00%|    ``x``, ``y``, ``z`` pixel locations for interpolating\n",
      "  3889|         0|            0|            0|  0.00%|    ``output[n, :, d, h, w]``. :attr:`mode` argument specifies ``nearest`` or\n",
      "  3890|         0|            0|            0|  0.00%|    ``bilinear`` interpolation method to sample the input pixels.\n",
      "  3891|         0|            0|            0|  0.00%|\n",
      "  3892|         0|            0|            0|  0.00%|    :attr:`grid` specifies the sampling pixel locations normalized by the\n",
      "  3893|         0|            0|            0|  0.00%|    :attr:`input` spatial dimensions. Therefore, it should have most values in\n",
      "  3894|         0|            0|            0|  0.00%|    the range of ``[-1, 1]``. For example, values ``x = -1, y = -1`` is the\n",
      "  3895|         0|            0|            0|  0.00%|    left-top pixel of :attr:`input`, and values  ``x = 1, y = 1`` is the\n",
      "  3896|         0|            0|            0|  0.00%|    right-bottom pixel of :attr:`input`.\n",
      "  3897|         0|            0|            0|  0.00%|\n",
      "  3898|         0|            0|            0|  0.00%|    If :attr:`grid` has values outside the range of ``[-1, 1]``, the corresponding\n",
      "  3899|         0|            0|            0|  0.00%|    outputs are handled as defined by :attr:`padding_mode`. Options are\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3900|         0|            0|            0|  0.00%|\n",
      "  3901|         0|            0|            0|  0.00%|        * ``padding_mode=\"zeros\"``: use ``0`` for out-of-bound grid locations,\n",
      "  3902|         0|            0|            0|  0.00%|        * ``padding_mode=\"border\"``: use border values for out-of-bound grid locations,\n",
      "  3903|         0|            0|            0|  0.00%|        * ``padding_mode=\"reflection\"``: use values at locations reflected by\n",
      "  3904|         0|            0|            0|  0.00%|          the border for out-of-bound grid locations. For location far away\n",
      "  3905|         0|            0|            0|  0.00%|          from the border, it will keep being reflected until becoming in bound,\n",
      "  3906|         0|            0|            0|  0.00%|          e.g., (normalized) pixel location ``x = -3.5`` reflects by border ``-1``\n",
      "  3907|         0|            0|            0|  0.00%|          and becomes ``x' = 1.5``, then reflects by border ``1`` and becomes\n",
      "  3908|         0|            0|            0|  0.00%|          ``x'' = -0.5``.\n",
      "  3909|         0|            0|            0|  0.00%|\n",
      "  3910|         0|            0|            0|  0.00%|    Note:\n",
      "  3911|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`affine_grid`\n",
      "  3912|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .\n",
      "  3913|         0|            0|            0|  0.00%|\n",
      "  3914|         0|            0|            0|  0.00%|    Note:\n",
      "  3915|         0|            0|            0|  0.00%|        When using the CUDA backend, this operation may induce nondeterministic\n",
      "  3916|         0|            0|            0|  0.00%|        behaviour in its backward pass that is not easily switched off.\n",
      "  3917|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  3918|         0|            0|            0|  0.00%|\n",
      "  3919|         0|            0|            0|  0.00%|    Note:\n",
      "  3920|         0|            0|            0|  0.00%|        NaN values in :attr:`grid` would be interpreted as ``-1``.\n",
      "  3921|         0|            0|            0|  0.00%|\n",
      "  3922|         0|            0|            0|  0.00%|    Args:\n",
      "  3923|         0|            0|            0|  0.00%|        input (Tensor): input of shape :math:`(N, C, H_\\text{in}, W_\\text{in})` (4-D case)\n",
      "  3924|         0|            0|            0|  0.00%|                        or :math:`(N, C, D_\\text{in}, H_\\text{in}, W_\\text{in})` (5-D case)\n",
      "  3925|         0|            0|            0|  0.00%|        grid (Tensor): flow-field of shape :math:`(N, H_\\text{out}, W_\\text{out}, 2)` (4-D case)\n",
      "  3926|         0|            0|            0|  0.00%|                       or :math:`(N, D_\\text{out}, H_\\text{out}, W_\\text{out}, 3)` (5-D case)\n",
      "  3927|         0|            0|            0|  0.00%|        mode (str): interpolation mode to calculate output values\n",
      "  3928|         0|            0|            0|  0.00%|            ``'bilinear'`` | ``'nearest'`` | ``'bicubic'``. Default: ``'bilinear'``\n",
      "  3929|         0|            0|            0|  0.00%|            Note: ``mode='bicubic'`` supports only 4-D input.\n",
      "  3930|         0|            0|            0|  0.00%|            When ``mode='bilinear'`` and the input is 5-D, the interpolation mode\n",
      "  3931|         0|            0|            0|  0.00%|            used internally will actually be trilinear. However, when the input is 4-D,\n",
      "  3932|         0|            0|            0|  0.00%|            the interpolation mode will legitimately be bilinear.\n",
      "  3933|         0|            0|            0|  0.00%|        padding_mode (str): padding mode for outside grid values\n",
      "  3934|         0|            0|            0|  0.00%|            ``'zeros'`` | ``'border'`` | ``'reflection'``. Default: ``'zeros'``\n",
      "  3935|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3936|         0|            0|            0|  0.00%|            input  as squares rather than points.\n",
      "  3937|         0|            0|            0|  0.00%|            If set to ``True``, the extrema (``-1`` and ``1``) are considered as referring\n",
      "  3938|         0|            0|            0|  0.00%|            to the center points of the input's corner pixels. If set to ``False``, they\n",
      "  3939|         0|            0|            0|  0.00%|            are instead considered as referring to the corner points of the input's corner\n",
      "  3940|         0|            0|            0|  0.00%|            pixels, making the sampling more resolution agnostic.\n",
      "  3941|         0|            0|            0|  0.00%|            This option parallels the ``align_corners`` option in\n",
      "  3942|         0|            0|            0|  0.00%|            :func:`interpolate`, and so whichever option is used here\n",
      "  3943|         0|            0|            0|  0.00%|            should also be used there to resize the input image before grid sampling.\n",
      "  3944|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3945|         0|            0|            0|  0.00%|\n",
      "  3946|         0|            0|            0|  0.00%|    Returns:\n",
      "  3947|         0|            0|            0|  0.00%|        output (Tensor): output Tensor\n",
      "  3948|         0|            0|            0|  0.00%|\n",
      "  3949|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:\n",
      "  3950|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025\n",
      "  3951|         0|            0|            0|  0.00%|\n",
      "  3952|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3953|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel\n",
      "  3954|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by\n",
      "  3955|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different\n",
      "  3956|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).\n",
      "  3957|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.\n",
      "  3958|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,\n",
      "  3959|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.\n",
      "  3960|         0|            0|            0|  0.00%|\n",
      "  3961|         0|            0|            0|  0.00%|    .. note::\n",
      "  3962|         0|            0|            0|  0.00%|        ``mode='bicubic'`` is implemented using the `cubic convolution algorithm`_ with :math:`\\alpha=-0.75`.\n",
      "  3963|         0|            0|            0|  0.00%|        The constant :math:`\\alpha` might be different from packages to packages.\n",
      "  3964|         0|            0|            0|  0.00%|        For example, `PIL`_ and `OpenCV`_ use -0.5 and -0.75 respectively.\n",
      "  3965|         0|            0|            0|  0.00%|        This algorithm may \"overshoot\" the range of values it's interpolating.\n",
      "  3966|         0|            0|            0|  0.00%|        For example, it may produce negative values or values greater than 255 when interpolating input in [0, 255].\n",
      "  3967|         0|            0|            0|  0.00%|        Clamp the results with :func: `torch.clamp` to ensure they are within the valid range.\n",
      "  3968|         0|            0|            0|  0.00%|    .. _`cubic convolution algorithm`: https://en.wikipedia.org/wiki/Bicubic_interpolation\n",
      "  3969|         0|            0|            0|  0.00%|    .. _`PIL`: https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51\n",
      "  3970|         0|            0|            0|  0.00%|    .. _`OpenCV`: https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908\n",
      "  3971|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3972|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, grid):\n",
      "  3973|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3974|         0|            0|            0|  0.00%|            grid_sample, (input, grid), input, grid, mode=mode, padding_mode=padding_mode, align_corners=align_corners\n",
      "  3975|         0|            0|            0|  0.00%|        )\n",
      "  3976|         0|            0|            0|  0.00%|    if mode != \"bilinear\" and mode != \"nearest\" and mode != \"bicubic\":\n",
      "  3977|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  3978|         0|            0|            0|  0.00%|            \"nn.functional.grid_sample(): expected mode to be \"\n",
      "  3979|         0|            0|            0|  0.00%|            \"'bilinear', 'nearest' or 'bicubic', but got: '{}'\".format(mode)\n",
      "  3980|         0|            0|            0|  0.00%|        )\n",
      "  3981|         0|            0|            0|  0.00%|    if padding_mode != \"zeros\" and padding_mode != \"border\" and padding_mode != \"reflection\":\n",
      "  3982|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  3983|         0|            0|            0|  0.00%|            \"nn.functional.grid_sample(): expected padding_mode \"\n",
      "  3984|         0|            0|            0|  0.00%|            \"to be 'zeros', 'border', or 'reflection', \"\n",
      "  3985|         0|            0|            0|  0.00%|            \"but got: '{}'\".format(padding_mode)\n",
      "  3986|         0|            0|            0|  0.00%|        )\n",
      "  3987|         0|            0|            0|  0.00%|\n",
      "  3988|         0|            0|            0|  0.00%|    if mode == \"bilinear\":\n",
      "  3989|         0|            0|            0|  0.00%|        mode_enum = 0\n",
      "  3990|         0|            0|            0|  0.00%|    elif mode == \"nearest\":\n",
      "  3991|         0|            0|            0|  0.00%|        mode_enum = 1\n",
      "  3992|         0|            0|            0|  0.00%|    else:  # mode == 'bicubic'\n",
      "  3993|         0|            0|            0|  0.00%|        mode_enum = 2\n",
      "  3994|         0|            0|            0|  0.00%|\n",
      "  3995|         0|            0|            0|  0.00%|    if padding_mode == \"zeros\":\n",
      "  3996|         0|            0|            0|  0.00%|        padding_mode_enum = 0\n",
      "  3997|         0|            0|            0|  0.00%|    elif padding_mode == \"border\":\n",
      "  3998|         0|            0|            0|  0.00%|        padding_mode_enum = 1\n",
      "  3999|         0|            0|            0|  0.00%|    else:  # padding_mode == 'reflection'\n",
      "  4000|         0|            0|            0|  0.00%|        padding_mode_enum = 2\n",
      "  4001|         0|            0|            0|  0.00%|\n",
      "  4002|         0|            0|            0|  0.00%|    if align_corners is None:\n",
      "  4003|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4004|         0|            0|            0|  0.00%|            \"Default grid_sample and affine_grid behavior has changed \"\n",
      "  4005|         0|            0|            0|  0.00%|            \"to align_corners=False since 1.3.0. Please specify \"\n",
      "  4006|         0|            0|            0|  0.00%|            \"align_corners=True if the old behavior is desired. \"\n",
      "  4007|         0|            0|            0|  0.00%|            \"See the documentation of grid_sample for details.\"\n",
      "  4008|         0|            0|            0|  0.00%|        )\n",
      "  4009|         0|            0|            0|  0.00%|        align_corners = False\n",
      "  4010|         0|            0|            0|  0.00%|\n",
      "  4011|         0|            0|            0|  0.00%|    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "  4012|         0|            0|            0|  0.00%|\n",
      "  4013|         0|            0|            0|  0.00%|\n",
      "  4014|         0|            0|            0|  0.00%|def affine_grid(theta: Tensor, size: List[int], align_corners: Optional[bool] = None) -> Tensor:\n",
      "  4015|         0|            0|            0|  0.00%|    r\"\"\"Generates a 2D or 3D flow field (sampling grid), given a batch of\n",
      "  4016|         0|            0|            0|  0.00%|    affine matrices :attr:`theta`.\n",
      "  4017|         0|            0|            0|  0.00%|\n",
      "  4018|         0|            0|            0|  0.00%|    .. note::\n",
      "  4019|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`grid_sample`\n",
      "  4020|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .\n",
      "  4021|         0|            0|            0|  0.00%|\n",
      "  4022|         0|            0|            0|  0.00%|    Args:\n",
      "  4023|         0|            0|            0|  0.00%|        theta (Tensor): input batch of affine matrices with shape\n",
      "  4024|         0|            0|            0|  0.00%|            (:math:`N \\times 2 \\times 3`) for 2D or\n",
      "  4025|         0|            0|            0|  0.00%|            (:math:`N \\times 3 \\times 4`) for 3D\n",
      "  4026|         0|            0|            0|  0.00%|        size (torch.Size): the target output image size.\n",
      "  4027|         0|            0|            0|  0.00%|            (:math:`N \\times C \\times H \\times W` for 2D or\n",
      "  4028|         0|            0|            0|  0.00%|            :math:`N \\times C \\times D \\times H \\times W` for 3D)\n",
      "  4029|         0|            0|            0|  0.00%|            Example: torch.Size((32, 3, 24, 24))\n",
      "  4030|         0|            0|            0|  0.00%|        align_corners (bool, optional): if ``True``, consider ``-1`` and ``1``\n",
      "  4031|         0|            0|            0|  0.00%|            to refer to the centers of the corner pixels rather than the image corners.\n",
      "  4032|         0|            0|            0|  0.00%|            Refer to :func:`grid_sample` for a more complete description.\n",
      "  4033|         0|            0|            0|  0.00%|            A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`\n",
      "  4034|         0|            0|            0|  0.00%|            with the same setting for this option.\n",
      "  4035|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  4036|         0|            0|            0|  0.00%|\n",
      "  4037|         0|            0|            0|  0.00%|    Returns:\n",
      "  4038|         0|            0|            0|  0.00%|        output (Tensor): output Tensor of size (:math:`N \\times H \\times W \\times 2`)\n",
      "  4039|         0|            0|            0|  0.00%|\n",
      "  4040|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:\n",
      "  4041|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025\n",
      "  4042|         0|            0|            0|  0.00%|\n",
      "  4043|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4044|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel\n",
      "  4045|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by\n",
      "  4046|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different\n",
      "  4047|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).\n",
      "  4048|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.\n",
      "  4049|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,\n",
      "  4050|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.\n",
      "  4051|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4052|         0|            0|            0|  0.00%|        When ``align_corners = True``, 2D affine transforms on 1D data and\n",
      "  4053|         0|            0|            0|  0.00%|        3D affine transforms on 2D data (that is, when one of the spatial\n",
      "  4054|         0|            0|            0|  0.00%|        dimensions has unit size) are ill-defined, and not an intended use case.\n",
      "  4055|         0|            0|            0|  0.00%|        This is not a problem when ``align_corners = False``.\n",
      "  4056|         0|            0|            0|  0.00%|        Up to version 1.2.0, all grid points along a unit dimension were\n",
      "  4057|         0|            0|            0|  0.00%|        considered arbitrarily to be at ``-1``.\n",
      "  4058|         0|            0|            0|  0.00%|        From version 1.3.0, under ``align_corners = True`` all grid points\n",
      "  4059|         0|            0|            0|  0.00%|        along a unit dimension are considered to be at ``0``\n",
      "  4060|         0|            0|            0|  0.00%|        (the center of the input image).\n",
      "  4061|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4062|         0|            0|            0|  0.00%|    if has_torch_function_unary(theta):\n",
      "  4063|         0|            0|            0|  0.00%|        return handle_torch_function(affine_grid, (theta,), theta, size, align_corners=align_corners)\n",
      "  4064|         0|            0|            0|  0.00%|    if align_corners is None:\n",
      "  4065|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4066|         0|            0|            0|  0.00%|            \"Default grid_sample and affine_grid behavior has changed \"\n",
      "  4067|         0|            0|            0|  0.00%|            \"to align_corners=False since 1.3.0. Please specify \"\n",
      "  4068|         0|            0|            0|  0.00%|            \"align_corners=True if the old behavior is desired. \"\n",
      "  4069|         0|            0|            0|  0.00%|            \"See the documentation of grid_sample for details.\"\n",
      "  4070|         0|            0|            0|  0.00%|        )\n",
      "  4071|         0|            0|            0|  0.00%|        align_corners = False\n",
      "  4072|         0|            0|            0|  0.00%|\n",
      "  4073|         0|            0|            0|  0.00%|    # enforce floating point dtype on theta\n",
      "  4074|         0|            0|            0|  0.00%|    if not theta.is_floating_point():\n",
      "  4075|         0|            0|            0|  0.00%|        raise ValueError(\"Expected theta to have floating point type, but got {}\".format(theta.dtype))\n",
      "  4076|         0|            0|            0|  0.00%|    # check that shapes and sizes match\n",
      "  4077|         0|            0|            0|  0.00%|    if len(size) == 4:\n",
      "  4078|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:\n",
      "  4079|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  4080|         0|            0|            0|  0.00%|                \"Expected a batch of 2D affine matrices of shape Nx2x3 \"\n",
      "  4081|         0|            0|            0|  0.00%|                \"for size {}. Got {}.\".format(size, theta.shape)\n",
      "  4082|         0|            0|            0|  0.00%|            )\n",
      "  4083|         0|            0|            0|  0.00%|        spatial_size = size[-2:]  # spatial dimension sizes\n",
      "  4084|         0|            0|            0|  0.00%|    elif len(size) == 5:\n",
      "  4085|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 3 or theta.shape[-1] != 4:\n",
      "  4086|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  4087|         0|            0|            0|  0.00%|                \"Expected a batch of 3D affine matrices of shape Nx3x4 \"\n",
      "  4088|         0|            0|            0|  0.00%|                \"for size {}. Got {}.\".format(size, theta.shape)\n",
      "  4089|         0|            0|            0|  0.00%|            )\n",
      "  4090|         0|            0|            0|  0.00%|        spatial_size = size[-3:]  # spatial dimension sizes\n",
      "  4091|         0|            0|            0|  0.00%|    else:\n",
      "  4092|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  4093|         0|            0|            0|  0.00%|            \"affine_grid only supports 4D and 5D sizes, \"\n",
      "  4094|         0|            0|            0|  0.00%|            \"for 2D and 3D affine transforms, respectively. \"\n",
      "  4095|         0|            0|            0|  0.00%|            \"Got size {}.\".format(size)\n",
      "  4096|         0|            0|            0|  0.00%|        )\n",
      "  4097|         0|            0|            0|  0.00%|    # check for empty span\n",
      "  4098|         0|            0|            0|  0.00%|    if align_corners and min(spatial_size) == 1:\n",
      "  4099|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4100|         0|            0|            0|  0.00%|            \"Since version 1.3.0, affine_grid behavior has changed \"\n",
      "  4101|         0|            0|            0|  0.00%|            \"for unit-size grids when align_corners=True. \"\n",
      "  4102|         0|            0|            0|  0.00%|            \"This is not an intended use case of affine_grid. \"\n",
      "  4103|         0|            0|            0|  0.00%|            \"See the documentation of affine_grid for details.\"\n",
      "  4104|         0|            0|            0|  0.00%|        )\n",
      "  4105|         0|            0|            0|  0.00%|    elif min(size) <= 0:\n",
      "  4106|         0|            0|            0|  0.00%|        raise ValueError(\"Expected non-zero, positive output size. Got {}\".format(size))\n",
      "  4107|         0|            0|            0|  0.00%|\n",
      "  4108|         0|            0|            0|  0.00%|    return torch.affine_grid_generator(theta, size, align_corners)\n",
      "  4109|         0|            0|            0|  0.00%|\n",
      "  4110|         0|            0|            0|  0.00%|\n",
      "  4111|         0|            0|            0|  0.00%|def _pad(input: Tensor, pad: List[int], mode: str = \"constant\", value: float = 0.0) -> Tensor:\n",
      "  4112|         0|            0|            0|  0.00%|    r\"\"\"Pads tensor.\n",
      "  4113|         0|            0|            0|  0.00%|\n",
      "  4114|         0|            0|            0|  0.00%|    Padding size:\n",
      "  4115|         0|            0|            0|  0.00%|        The padding size by which to pad some dimensions of :attr:`input`\n",
      "  4116|         0|            0|            0|  0.00%|        are described starting from the last dimension and moving forward.\n",
      "  4117|         0|            0|            0|  0.00%|        :math:`\\left\\lfloor\\frac{\\text{len(pad)}}{2}\\right\\rfloor` dimensions\n",
      "  4118|         0|            0|            0|  0.00%|        of ``input`` will be padded.\n",
      "  4119|         0|            0|            0|  0.00%|        For example, to pad only the last dimension of the input tensor, then\n",
      "  4120|         0|            0|            0|  0.00%|        :attr:`pad` has the form\n",
      "  4121|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right})`;\n",
      "  4122|         0|            0|            0|  0.00%|        to pad the last 2 dimensions of the input tensor, then use\n",
      "  4123|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "  4124|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_top}, \\text{padding\\_bottom})`;\n",
      "  4125|         0|            0|            0|  0.00%|        to pad the last 3 dimensions, use\n",
      "  4126|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "  4127|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_top}, \\text{padding\\_bottom}`\n",
      "  4128|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_front}, \\text{padding\\_back})`.\n",
      "  4129|         0|            0|            0|  0.00%|\n",
      "  4130|         0|            0|            0|  0.00%|    Padding mode:\n",
      "  4131|         0|            0|            0|  0.00%|        See :class:`torch.nn.ConstantPad2d`, :class:`torch.nn.ReflectionPad2d`, and\n",
      "  4132|         0|            0|            0|  0.00%|        :class:`torch.nn.ReplicationPad2d` for concrete examples on how each of the\n",
      "  4133|         0|            0|            0|  0.00%|        padding modes works. Constant padding is implemented for arbitrary dimensions.\n",
      "  4134|         0|            0|            0|  0.00%|        Replicate and reflection padding is implemented for padding the last 3\n",
      "  4135|         0|            0|            0|  0.00%|        dimensions of 5D input tensor, or the last 2 dimensions of 4D input\n",
      "  4136|         0|            0|            0|  0.00%|        tensor, or the last dimension of 3D input tensor.\n",
      "  4137|         0|            0|            0|  0.00%|\n",
      "  4138|         0|            0|            0|  0.00%|    Note:\n",
      "  4139|         0|            0|            0|  0.00%|        When using the CUDA backend, this operation may induce nondeterministic\n",
      "  4140|         0|            0|            0|  0.00%|        behaviour in its backward pass that is not easily switched off.\n",
      "  4141|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  4142|         0|            0|            0|  0.00%|\n",
      "  4143|         0|            0|            0|  0.00%|    Args:\n",
      "  4144|         0|            0|            0|  0.00%|        input (Tensor): N-dimensional tensor\n",
      "  4145|         0|            0|            0|  0.00%|        pad (tuple): m-elements tuple, where\n",
      "  4146|         0|            0|            0|  0.00%|            :math:`\\frac{m}{2} \\leq` input dimensions and :math:`m` is even.\n",
      "  4147|         0|            0|            0|  0.00%|        mode: ``'constant'``, ``'reflect'``, ``'replicate'`` or ``'circular'``.\n",
      "  4148|         0|            0|            0|  0.00%|            Default: ``'constant'``\n",
      "  4149|         0|            0|            0|  0.00%|        value: fill value for ``'constant'`` padding. Default: ``0``\n",
      "  4150|         0|            0|            0|  0.00%|\n",
      "  4151|         0|            0|            0|  0.00%|    Examples::\n",
      "  4152|         0|            0|            0|  0.00%|\n",
      "  4153|         0|            0|            0|  0.00%|        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "  4154|         0|            0|            0|  0.00%|        >>> p1d = (1, 1) # pad last dim by 1 on each side\n",
      "  4155|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
      "  4156|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4157|         0|            0|            0|  0.00%|        torch.Size([3, 3, 4, 4])\n",
      "  4158|         0|            0|            0|  0.00%|        >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n",
      "  4159|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p2d, \"constant\", 0)\n",
      "  4160|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4161|         0|            0|            0|  0.00%|        torch.Size([3, 3, 8, 4])\n",
      "  4162|         0|            0|            0|  0.00%|        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "  4163|         0|            0|            0|  0.00%|        >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)\n",
      "  4164|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p3d, \"constant\", 0)\n",
      "  4165|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4166|         0|            0|            0|  0.00%|        torch.Size([3, 9, 7, 3])\n",
      "  4167|         0|            0|            0|  0.00%|\n",
      "  4168|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4169|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4170|         0|            0|            0|  0.00%|        return handle_torch_function(_pad, (input,), input, pad, mode=mode, value=value)\n",
      "  4171|         0|            0|            0|  0.00%|    assert len(pad) % 2 == 0, \"Padding length must be divisible by 2\"\n",
      "  4172|         0|            0|            0|  0.00%|    assert len(pad) // 2 <= input.dim(), \"Padding length too large\"\n",
      "  4173|         0|            0|            0|  0.00%|    if mode == \"constant\":\n",
      "  4174|         0|            0|            0|  0.00%|        return _VF.constant_pad_nd(input, pad, value)\n",
      "  4175|         0|            0|            0|  0.00%|    else:\n",
      "  4176|         0|            0|            0|  0.00%|        assert value == 0.0, 'Padding mode \"{}\"\" doesn\\'t take in value argument'.format(mode)\n",
      "  4177|         0|            0|            0|  0.00%|        if len(pad) == 2 and (input.dim() == 2 or input.dim() == 3):\n",
      "  4178|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4179|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad1d(input, pad)\n",
      "  4180|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4181|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad1d(input, pad)\n",
      "  4182|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4183|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4184|         0|            0|            0|  0.00%|            else:\n",
      "  4185|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4186|         0|            0|            0|  0.00%|\n",
      "  4187|         0|            0|            0|  0.00%|        elif len(pad) == 4 and (input.dim() == 3 or input.dim() == 4):\n",
      "  4188|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4189|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad2d(input, pad)\n",
      "  4190|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4191|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad2d(input, pad)\n",
      "  4192|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4193|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4194|         0|            0|            0|  0.00%|            else:\n",
      "  4195|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4196|         0|            0|            0|  0.00%|\n",
      "  4197|         0|            0|            0|  0.00%|        elif len(pad) == 6 and (input.dim() == 4 or input.dim() == 5):\n",
      "  4198|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4199|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad3d(input, pad)\n",
      "  4200|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4201|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad3d(input, pad)\n",
      "  4202|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4203|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4204|         0|            0|            0|  0.00%|            else:\n",
      "  4205|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4206|         0|            0|            0|  0.00%|        else:\n",
      "  4207|         0|            0|            0|  0.00%|            raise NotImplementedError(\"Only 2D, 3D, 4D, 5D padding with non-constant padding are supported for now\")\n",
      "  4208|         0|            0|            0|  0.00%|\n",
      "  4209|         0|            0|            0|  0.00%|\n",
      "  4210|         0|            0|            0|  0.00%|# We define this function as _pad because it takes an argument\n",
      "  4211|         0|            0|            0|  0.00%|# named pad, which clobbers the recursive reference to the pad\n",
      "  4212|         0|            0|            0|  0.00%|# function needed for __torch_function__ support\n",
      "  4213|         0|            0|            0|  0.00%|pad = _pad\n",
      "  4214|         0|            0|            0|  0.00%|\n",
      "  4215|         0|            0|            0|  0.00%|# distance\n",
      "  4216|         0|            0|            0|  0.00%|\n",
      "  4217|         0|            0|            0|  0.00%|\n",
      "  4218|         0|            0|            0|  0.00%|def pairwise_distance(x1: Tensor, x2: Tensor, p: float = 2.0, eps: float = 1e-6, keepdim: bool = False) -> Tensor:\n",
      "  4219|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4220|         0|            0|            0|  0.00%|    See :class:`torch.nn.PairwiseDistance` for details\n",
      "  4221|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4222|         0|            0|            0|  0.00%|    if has_torch_function_variadic(x1, x2):\n",
      "  4223|         0|            0|            0|  0.00%|        return handle_torch_function(pairwise_distance, (x1, x2), x1, x2, p=p, eps=eps, keepdim=keepdim)\n",
      "  4224|         0|            0|            0|  0.00%|    return torch.pairwise_distance(x1, x2, p, eps, keepdim)\n",
      "  4225|         0|            0|            0|  0.00%|\n",
      "  4226|         0|            0|            0|  0.00%|\n",
      "  4227|         0|            0|            0|  0.00%|pdist = _add_docstr(\n",
      "  4228|         0|            0|            0|  0.00%|    torch.pdist,\n",
      "  4229|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4230|         0|            0|            0|  0.00%|pdist(input, p=2) -> Tensor\n",
      "  4231|         0|            0|            0|  0.00%|\n",
      "  4232|         0|            0|            0|  0.00%|Computes the p-norm distance between every pair of row vectors in the input.\n",
      "  4233|         0|            0|            0|  0.00%|This is identical to the upper triangular portion, excluding the diagonal, of\n",
      "  4234|         0|            0|            0|  0.00%|`torch.norm(input[:, None] - input, dim=2, p=p)`. This function will be faster\n",
      "  4235|         0|            0|            0|  0.00%|if the rows are contiguous.\n",
      "  4236|         0|            0|            0|  0.00%|\n",
      "  4237|         0|            0|            0|  0.00%|If input has shape :math:`N \\times M` then the output will have shape\n",
      "  4238|         0|            0|            0|  0.00%|:math:`\\frac{1}{2} N (N - 1)`.\n",
      "  4239|         0|            0|            0|  0.00%|\n",
      "  4240|         0|            0|            0|  0.00%|This function is equivalent to `scipy.spatial.distance.pdist(input,\n",
      "  4241|         0|            0|            0|  0.00%|'minkowski', p=p)` if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is\n",
      "  4242|         0|            0|            0|  0.00%|equivalent to `scipy.spatial.distance.pdist(input, 'hamming') * M`.\n",
      "  4243|         0|            0|            0|  0.00%|When :math:`p = \\infty`, the closest scipy function is\n",
      "  4244|         0|            0|            0|  0.00%|`scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())`.\n",
      "  4245|         0|            0|            0|  0.00%|\n",
      "  4246|         0|            0|            0|  0.00%|Args:\n",
      "  4247|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`N \\times M`.\n",
      "  4248|         0|            0|            0|  0.00%|    p: p value for the p-norm distance to calculate between each vector pair\n",
      "  4249|         0|            0|            0|  0.00%|        :math:`\\in [0, \\infty]`.\n",
      "  4250|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4251|         0|            0|            0|  0.00%|)\n",
      "  4252|         0|            0|            0|  0.00%|\n",
      "  4253|         0|            0|            0|  0.00%|\n",
      "  4254|         0|            0|            0|  0.00%|cosine_similarity = _add_docstr(\n",
      "  4255|         0|            0|            0|  0.00%|    torch.cosine_similarity,\n",
      "  4256|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4257|         0|            0|            0|  0.00%|cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor\n",
      "  4258|         0|            0|            0|  0.00%|\n",
      "  4259|         0|            0|            0|  0.00%|Returns cosine similarity between ``x1`` and ``x2``, computed along dim. ``x1`` and ``x2`` must be broadcastable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4260|         0|            0|            0|  0.00%|to a common shape. ``dim`` refers to the dimension in this common shape. Dimension ``dim`` of the output is\n",
      "  4261|         0|            0|            0|  0.00%|squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "  4262|         0|            0|            0|  0.00%|output tensor having 1 fewer dimension.\n",
      "  4263|         0|            0|            0|  0.00%|\n",
      "  4264|         0|            0|            0|  0.00%|.. math ::\n",
      "  4265|         0|            0|            0|  0.00%|    \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n",
      "  4266|         0|            0|            0|  0.00%|\n",
      "  4267|         0|            0|            0|  0.00%|Supports :ref:`type promotion <type-promotion-doc>`.\n",
      "  4268|         0|            0|            0|  0.00%|\n",
      "  4269|         0|            0|            0|  0.00%|Args:\n",
      "  4270|         0|            0|            0|  0.00%|    x1 (Tensor): First input.\n",
      "  4271|         0|            0|            0|  0.00%|    x2 (Tensor): Second input.\n",
      "  4272|         0|            0|            0|  0.00%|    dim (int, optional): Dimension along which cosine similarity is computed. Default: 1\n",
      "  4273|         0|            0|            0|  0.00%|    eps (float, optional): Small value to avoid division by zero.\n",
      "  4274|         0|            0|            0|  0.00%|        Default: 1e-8\n",
      "  4275|         0|            0|            0|  0.00%|\n",
      "  4276|         0|            0|            0|  0.00%|Example::\n",
      "  4277|         0|            0|            0|  0.00%|\n",
      "  4278|         0|            0|            0|  0.00%|    >>> input1 = torch.randn(100, 128)\n",
      "  4279|         0|            0|            0|  0.00%|    >>> input2 = torch.randn(100, 128)\n",
      "  4280|         0|            0|            0|  0.00%|    >>> output = F.cosine_similarity(input1, input2)\n",
      "  4281|         0|            0|            0|  0.00%|    >>> print(output)\n",
      "  4282|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4283|         0|            0|            0|  0.00%|)\n",
      "  4284|         0|            0|            0|  0.00%|\n",
      "  4285|         0|            0|            0|  0.00%|\n",
      "  4286|         0|            0|            0|  0.00%|one_hot = _add_docstr(\n",
      "  4287|         0|            0|            0|  0.00%|    torch._C._nn.one_hot,\n",
      "  4288|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4289|         0|            0|            0|  0.00%|one_hot(tensor, num_classes=-1) -> LongTensor\n",
      "  4290|         0|            0|            0|  0.00%|\n",
      "  4291|         0|            0|            0|  0.00%|Takes LongTensor with index values of shape ``(*)`` and returns a tensor\n",
      "  4292|         0|            0|            0|  0.00%|of shape ``(*, num_classes)`` that have zeros everywhere except where the\n",
      "  4293|         0|            0|            0|  0.00%|index of last dimension matches the corresponding value of the input tensor,\n",
      "  4294|         0|            0|            0|  0.00%|in which case it will be 1.\n",
      "  4295|         0|            0|            0|  0.00%|\n",
      "  4296|         0|            0|            0|  0.00%|See also `One-hot on Wikipedia`_ .\n",
      "  4297|         0|            0|            0|  0.00%|\n",
      "  4298|         0|            0|            0|  0.00%|.. _One-hot on Wikipedia:\n",
      "  4299|         0|            0|            0|  0.00%|    https://en.wikipedia.org/wiki/One-hot\n",
      "  4300|         0|            0|            0|  0.00%|\n",
      "  4301|         0|            0|            0|  0.00%|Arguments:\n",
      "  4302|         0|            0|            0|  0.00%|    tensor (LongTensor): class values of any shape.\n",
      "  4303|         0|            0|            0|  0.00%|    num_classes (int):  Total number of classes. If set to -1, the number\n",
      "  4304|         0|            0|            0|  0.00%|        of classes will be inferred as one greater than the largest class\n",
      "  4305|         0|            0|            0|  0.00%|        value in the input tensor.\n",
      "  4306|         0|            0|            0|  0.00%|\n",
      "  4307|         0|            0|            0|  0.00%|Returns:\n",
      "  4308|         0|            0|            0|  0.00%|    LongTensor that has one more dimension with 1 values at the\n",
      "  4309|         0|            0|            0|  0.00%|    index of last dimension indicated by the input, and 0 everywhere\n",
      "  4310|         0|            0|            0|  0.00%|    else.\n",
      "  4311|         0|            0|            0|  0.00%|\n",
      "  4312|         0|            0|            0|  0.00%|Examples:\n",
      "  4313|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3)\n",
      "  4314|         0|            0|            0|  0.00%|    tensor([[1, 0, 0],\n",
      "  4315|         0|            0|            0|  0.00%|            [0, 1, 0],\n",
      "  4316|         0|            0|            0|  0.00%|            [0, 0, 1],\n",
      "  4317|         0|            0|            0|  0.00%|            [1, 0, 0],\n",
      "  4318|         0|            0|            0|  0.00%|            [0, 1, 0]])\n",
      "  4319|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\n",
      "  4320|         0|            0|            0|  0.00%|    tensor([[1, 0, 0, 0, 0],\n",
      "  4321|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0],\n",
      "  4322|         0|            0|            0|  0.00%|            [0, 0, 1, 0, 0],\n",
      "  4323|         0|            0|            0|  0.00%|            [1, 0, 0, 0, 0],\n",
      "  4324|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0]])\n",
      "  4325|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3)\n",
      "  4326|         0|            0|            0|  0.00%|    tensor([[[1, 0, 0],\n",
      "  4327|         0|            0|            0|  0.00%|             [0, 1, 0]],\n",
      "  4328|         0|            0|            0|  0.00%|            [[0, 0, 1],\n",
      "  4329|         0|            0|            0|  0.00%|             [1, 0, 0]],\n",
      "  4330|         0|            0|            0|  0.00%|            [[0, 1, 0],\n",
      "  4331|         0|            0|            0|  0.00%|             [0, 0, 1]]])\n",
      "  4332|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4333|         0|            0|            0|  0.00%|)\n",
      "  4334|         0|            0|            0|  0.00%|\n",
      "  4335|         0|            0|            0|  0.00%|\n",
      "  4336|         0|            0|            0|  0.00%|def triplet_margin_loss(\n",
      "  4337|         0|            0|            0|  0.00%|    anchor: Tensor,\n",
      "  4338|         0|            0|            0|  0.00%|    positive: Tensor,\n",
      "  4339|         0|            0|            0|  0.00%|    negative: Tensor,\n",
      "  4340|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  4341|         0|            0|            0|  0.00%|    p: float = 2,\n",
      "  4342|         0|            0|            0|  0.00%|    eps: float = 1e-6,\n",
      "  4343|         0|            0|            0|  0.00%|    swap: bool = False,\n",
      "  4344|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  4345|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  4346|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  4347|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4348|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4349|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginLoss` for details\n",
      "  4350|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4351|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):\n",
      "  4352|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4353|         0|            0|            0|  0.00%|            triplet_margin_loss,\n",
      "  4354|         0|            0|            0|  0.00%|            (anchor, positive, negative),\n",
      "  4355|         0|            0|            0|  0.00%|            anchor,\n",
      "  4356|         0|            0|            0|  0.00%|            positive,\n",
      "  4357|         0|            0|            0|  0.00%|            negative,\n",
      "  4358|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  4359|         0|            0|            0|  0.00%|            p=p,\n",
      "  4360|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  4361|         0|            0|            0|  0.00%|            swap=swap,\n",
      "  4362|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  4363|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  4364|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  4365|         0|            0|            0|  0.00%|        )\n",
      "  4366|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  4367|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  4368|         0|            0|            0|  0.00%|    else:\n",
      "  4369|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  4370|         0|            0|            0|  0.00%|    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)\n",
      "  4371|         0|            0|            0|  0.00%|\n",
      "  4372|         0|            0|            0|  0.00%|\n",
      "  4373|         0|            0|            0|  0.00%|def triplet_margin_with_distance_loss(\n",
      "  4374|         0|            0|            0|  0.00%|    anchor: Tensor,\n",
      "  4375|         0|            0|            0|  0.00%|    positive: Tensor,\n",
      "  4376|         0|            0|            0|  0.00%|    negative: Tensor,\n",
      "  4377|         0|            0|            0|  0.00%|    *,\n",
      "  4378|         0|            0|            0|  0.00%|    distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n",
      "  4379|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  4380|         0|            0|            0|  0.00%|    swap: bool = False,\n",
      "  4381|         0|            0|            0|  0.00%|    reduction: str = \"mean\"\n",
      "  4382|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4383|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4384|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginWithDistanceLoss` for details.\n",
      "  4385|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4386|         0|            0|            0|  0.00%|    if torch.jit.is_scripting():\n",
      "  4387|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  4388|         0|            0|            0|  0.00%|            \"F.triplet_margin_with_distance_loss does not support JIT scripting: \"\n",
      "  4389|         0|            0|            0|  0.00%|            \"functions requiring Callables cannot be scripted.\"\n",
      "  4390|         0|            0|            0|  0.00%|        )\n",
      "  4391|         0|            0|            0|  0.00%|\n",
      "  4392|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):\n",
      "  4393|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4394|         0|            0|            0|  0.00%|            triplet_margin_with_distance_loss,\n",
      "  4395|         0|            0|            0|  0.00%|            (anchor, positive, negative),\n",
      "  4396|         0|            0|            0|  0.00%|            anchor,\n",
      "  4397|         0|            0|            0|  0.00%|            positive,\n",
      "  4398|         0|            0|            0|  0.00%|            negative,\n",
      "  4399|         0|            0|            0|  0.00%|            distance_function=distance_function,\n",
      "  4400|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  4401|         0|            0|            0|  0.00%|            swap=swap,\n",
      "  4402|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  4403|         0|            0|            0|  0.00%|        )\n",
      "  4404|         0|            0|            0|  0.00%|\n",
      "  4405|         0|            0|            0|  0.00%|    distance_function = distance_function if distance_function is not None else pairwise_distance\n",
      "  4406|         0|            0|            0|  0.00%|\n",
      "  4407|         0|            0|            0|  0.00%|    positive_dist = distance_function(anchor, positive)\n",
      "  4408|         0|            0|            0|  0.00%|    negative_dist = distance_function(anchor, negative)\n",
      "  4409|         0|            0|            0|  0.00%|\n",
      "  4410|         0|            0|            0|  0.00%|    if swap:\n",
      "  4411|         0|            0|            0|  0.00%|        swap_dist = distance_function(positive, negative)\n",
      "  4412|         0|            0|            0|  0.00%|        negative_dist = torch.min(negative_dist, swap_dist)\n",
      "  4413|         0|            0|            0|  0.00%|\n",
      "  4414|         0|            0|            0|  0.00%|    output = torch.clamp(positive_dist - negative_dist + margin, min=0.0)\n",
      "  4415|         0|            0|            0|  0.00%|\n",
      "  4416|         0|            0|            0|  0.00%|    reduction_enum = _Reduction.get_enum(reduction)\n",
      "  4417|         0|            0|            0|  0.00%|    if reduction_enum == 1:\n",
      "  4418|         0|            0|            0|  0.00%|        return output.mean()\n",
      "  4419|         0|            0|            0|  0.00%|    elif reduction_enum == 2:\n",
      "  4420|         0|            0|            0|  0.00%|        return output.sum()\n",
      "  4421|         0|            0|            0|  0.00%|    else:\n",
      "  4422|         0|            0|            0|  0.00%|        return output\n",
      "  4423|         0|            0|            0|  0.00%|\n",
      "  4424|         0|            0|            0|  0.00%|\n",
      "  4425|         0|            0|            0|  0.00%|def normalize(input: Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[Tensor] = None) -> Tensor:\n",
      "  4426|         0|            0|            0|  0.00%|    r\"\"\"Performs :math:`L_p` normalization of inputs over specified dimension.\n",
      "  4427|         0|            0|            0|  0.00%|\n",
      "  4428|         0|            0|            0|  0.00%|    For a tensor :attr:`input` of sizes :math:`(n_0, ..., n_{dim}, ..., n_k)`, each\n",
      "  4429|         0|            0|            0|  0.00%|    :math:`n_{dim}` -element vector :math:`v` along dimension :attr:`dim` is transformed as\n",
      "  4430|         0|            0|            0|  0.00%|\n",
      "  4431|         0|            0|            0|  0.00%|    .. math::\n",
      "  4432|         0|            0|            0|  0.00%|        v = \\frac{v}{\\max(\\lVert v \\rVert_p, \\epsilon)}.\n",
      "  4433|         0|            0|            0|  0.00%|\n",
      "  4434|         0|            0|            0|  0.00%|    With the default arguments it uses the Euclidean norm over vectors along dimension :math:`1` for normalization.\n",
      "  4435|         0|            0|            0|  0.00%|\n",
      "  4436|         0|            0|            0|  0.00%|    Args:\n",
      "  4437|         0|            0|            0|  0.00%|        input: input tensor of any shape\n",
      "  4438|         0|            0|            0|  0.00%|        p (float): the exponent value in the norm formulation. Default: 2\n",
      "  4439|         0|            0|            0|  0.00%|        dim (int): the dimension to reduce. Default: 1\n",
      "  4440|         0|            0|            0|  0.00%|        eps (float): small value to avoid division by zero. Default: 1e-12\n",
      "  4441|         0|            0|            0|  0.00%|        out (Tensor, optional): the output tensor. If :attr:`out` is used, this\n",
      "  4442|         0|            0|            0|  0.00%|                                operation won't be differentiable.\n",
      "  4443|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4444|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, out):\n",
      "  4445|         0|            0|            0|  0.00%|        return handle_torch_function(normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out)\n",
      "  4446|         0|            0|            0|  0.00%|    if out is None:\n",
      "  4447|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)\n",
      "  4448|         0|            0|            0|  0.00%|        return input / denom\n",
      "  4449|         0|            0|            0|  0.00%|    else:\n",
      "  4450|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min_(eps).expand_as(input)\n",
      "  4451|         0|            0|            0|  0.00%|        return torch.div(input, denom, out=out)\n",
      "  4452|         0|            0|            0|  0.00%|\n",
      "  4453|         0|            0|            0|  0.00%|\n",
      "  4454|         0|            0|            0|  0.00%|def assert_int_or_pair(arg: List[int], arg_name: str, message: str) -> None:\n",
      "  4455|         0|            0|            0|  0.00%|    assert isinstance(arg, int) or len(arg) == 2, message.format(arg_name)\n",
      "  4456|         0|            0|            0|  0.00%|\n",
      "  4457|         0|            0|            0|  0.00%|\n",
      "  4458|         0|            0|            0|  0.00%|def unfold(\n",
      "  4459|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "  4460|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "  4461|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "  4462|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1\n",
      "  4463|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4464|         0|            0|            0|  0.00%|    r\"\"\"Extracts sliding local blocks from a batched input tensor.\n",
      "  4465|         0|            0|            0|  0.00%|\n",
      "  4466|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4467|         0|            0|            0|  0.00%|        Currently, only 4-D input tensors (batched image-like tensors) are\n",
      "  4468|         0|            0|            0|  0.00%|        supported.\n",
      "  4469|         0|            0|            0|  0.00%|\n",
      "  4470|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4471|         0|            0|            0|  0.00%|\n",
      "  4472|         0|            0|            0|  0.00%|        More than one element of the unfolded tensor may refer to a single\n",
      "  4473|         0|            0|            0|  0.00%|        memory location. As a result, in-place operations (especially ones that\n",
      "  4474|         0|            0|            0|  0.00%|        are vectorized) may result in incorrect behavior. If you need to write\n",
      "  4475|         0|            0|            0|  0.00%|        to the tensor, please clone it first.\n",
      "  4476|         0|            0|            0|  0.00%|\n",
      "  4477|         0|            0|            0|  0.00%|\n",
      "  4478|         0|            0|            0|  0.00%|    See :class:`torch.nn.Unfold` for details\n",
      "  4479|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4480|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4481|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4482|         0|            0|            0|  0.00%|            unfold, (input,), input, kernel_size, dilation=dilation, padding=padding, stride=stride\n",
      "  4483|         0|            0|            0|  0.00%|        )\n",
      "  4484|         0|            0|            0|  0.00%|    if input.dim() == 4:\n",
      "  4485|         0|            0|            0|  0.00%|        msg = \"{} must be int or 2-tuple for 4D input\"\n",
      "  4486|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, \"kernel_size\", msg)\n",
      "  4487|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, \"dilation\", msg)\n",
      "  4488|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, \"padding\", msg)\n",
      "  4489|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, \"stride\", msg)\n",
      "  4490|         0|            0|            0|  0.00%|\n",
      "  4491|         0|            0|            0|  0.00%|        return torch._C._nn.im2col(input, _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride))\n",
      "  4492|         0|            0|            0|  0.00%|    else:\n",
      "  4493|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Input Error: Only 4D input Tensors are supported (got {}D)\".format(input.dim()))\n",
      "  4494|         0|            0|            0|  0.00%|\n",
      "  4495|         0|            0|            0|  0.00%|\n",
      "  4496|         0|            0|            0|  0.00%|def fold(\n",
      "  4497|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],\n",
      "  4498|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],\n",
      "  4499|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "  4500|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "  4501|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1\n",
      "  4502|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4503|         0|            0|            0|  0.00%|    r\"\"\"Combines an array of sliding local blocks into a large containing\n",
      "  4504|         0|            0|            0|  0.00%|    tensor.\n",
      "  4505|         0|            0|            0|  0.00%|\n",
      "  4506|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4507|         0|            0|            0|  0.00%|        Currently, only 3-D output tensors (unfolded batched image-like tensors) are\n",
      "  4508|         0|            0|            0|  0.00%|        supported.\n",
      "  4509|         0|            0|            0|  0.00%|\n",
      "  4510|         0|            0|            0|  0.00%|    See :class:`torch.nn.Fold` for details\n",
      "  4511|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4512|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4513|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4514|         0|            0|            0|  0.00%|            fold, (input,), input, output_size, kernel_size, dilation=dilation, padding=padding, stride=stride\n",
      "  4515|         0|            0|            0|  0.00%|        )\n",
      "  4516|         0|            0|            0|  0.00%|    if input.dim() == 3:\n",
      "  4517|         0|            0|            0|  0.00%|        msg = \"{} must be int or 2-tuple for 3D input\"\n",
      "  4518|         0|            0|            0|  0.00%|        assert_int_or_pair(output_size, \"output_size\", msg)\n",
      "  4519|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, \"kernel_size\", msg)\n",
      "  4520|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, \"dilation\", msg)\n",
      "  4521|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, \"padding\", msg)\n",
      "  4522|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, \"stride\", msg)\n",
      "  4523|         0|            0|            0|  0.00%|\n",
      "  4524|         0|            0|            0|  0.00%|        return torch._C._nn.col2im(\n",
      "  4525|         0|            0|            0|  0.00%|            input, _pair(output_size), _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride)\n",
      "  4526|         0|            0|            0|  0.00%|        )\n",
      "  4527|         0|            0|            0|  0.00%|    else:\n",
      "  4528|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Input Error: Only 3D input Tensors are supported (got {}D)\".format(input.dim()))\n",
      "  4529|         0|            0|            0|  0.00%|\n",
      "  4530|         0|            0|            0|  0.00%|\n",
      "  4531|         0|            0|            0|  0.00%|def _pad_circular(input: Tensor, padding: List[int]) -> Tensor:\n",
      "  4532|         0|            0|            0|  0.00%|    \"\"\"Circularly pads tensor.\n",
      "  4533|         0|            0|            0|  0.00%|\n",
      "  4534|         0|            0|            0|  0.00%|    Tensor values at the beginning are used to pad the end, and values at the\n",
      "  4535|         0|            0|            0|  0.00%|    end are used to pad the beginning. For example, consider a single dimension\n",
      "  4536|         0|            0|            0|  0.00%|    with values [0, 1, 2, 3]. With circular padding of (1, 1) it would be\n",
      "  4537|         0|            0|            0|  0.00%|    padded to [3, 0, 1, 2, 3, 0], and with padding (1, 2) it would be padded to\n",
      "  4538|         0|            0|            0|  0.00%|    [3, 0, 1, 2, 3, 0, 1]. If negative padding is applied then the ends of the\n",
      "  4539|         0|            0|            0|  0.00%|    tensor get removed. With circular padding of (-1, -1) the previous example\n",
      "  4540|         0|            0|            0|  0.00%|    would become [1, 2]. Circular padding of (-1, 1) would produce\n",
      "  4541|         0|            0|            0|  0.00%|    [1, 2, 3, 1].\n",
      "  4542|         0|            0|            0|  0.00%|\n",
      "  4543|         0|            0|            0|  0.00%|    The first and second dimensions of the tensor are not padded.\n",
      "  4544|         0|            0|            0|  0.00%|\n",
      "  4545|         0|            0|            0|  0.00%|    Args:\n",
      "  4546|         0|            0|            0|  0.00%|        input: Tensor with shape :math:`(N, C, D[, H, W])`.\n",
      "  4547|         0|            0|            0|  0.00%|        padding: Tuple containing the number of elements to pad each side of\n",
      "  4548|         0|            0|            0|  0.00%|            the tensor. The length of padding must be twice the number of\n",
      "  4549|         0|            0|            0|  0.00%|            paddable dimensions. For example, the length of padding should be 4\n",
      "  4550|         0|            0|            0|  0.00%|            for a tensor of shape :math:`(N, C, H, W)`, and the length should\n",
      "  4551|         0|            0|            0|  0.00%|            be 6 for a tensor of shape :math:`(N, C, D, H, W)`.\n",
      "  4552|         0|            0|            0|  0.00%|\n",
      "  4553|         0|            0|            0|  0.00%|    Examples::\n",
      "  4554|         0|            0|            0|  0.00%|\n",
      "  4555|         0|            0|            0|  0.00%|        >>> x = torch.tensor([[[[0, 1, 2], [3, 4, 5]]]])  # Create tensor\n",
      "  4556|         0|            0|            0|  0.00%|        >>> # Example 1\n",
      "  4557|         0|            0|            0|  0.00%|        >>> padding = (1, 1, 1, 1)\n",
      "  4558|         0|            0|            0|  0.00%|        >>> y = F.pad(x, padding, mode='circular')\n",
      "  4559|         0|            0|            0|  0.00%|        >>> print(y)\n",
      "  4560|         0|            0|            0|  0.00%|        tensor([[[[5, 3, 4, 5, 3],\n",
      "  4561|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4562|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4563|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0]]]])\n",
      "  4564|         0|            0|            0|  0.00%|        >>> print(y.shape)\n",
      "  4565|         0|            0|            0|  0.00%|        torch.Size([1, 1, 4, 5])\n",
      "  4566|         0|            0|            0|  0.00%|        >>> # Example 2\n",
      "  4567|         0|            0|            0|  0.00%|        >>> padding = (1, 1, 2, 2)\n",
      "  4568|         0|            0|            0|  0.00%|        >>> z = F.pad(x, padding, mode='circular')\n",
      "  4569|         0|            0|            0|  0.00%|        >>> print(z)\n",
      "  4570|         0|            0|            0|  0.00%|        tensor([[[[2, 0, 1, 2, 0],\n",
      "  4571|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4572|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4573|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4574|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4575|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3]]]])\n",
      "  4576|         0|            0|            0|  0.00%|        >>> print(z.shape)\n",
      "  4577|         0|            0|            0|  0.00%|        torch.Size([1, 1, 6, 5])\n",
      "  4578|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4579|         0|            0|            0|  0.00%|    in_shape = input.shape\n",
      "  4580|         0|            0|            0|  0.00%|    paddable_shape = in_shape[2:]\n",
      "  4581|         0|            0|            0|  0.00%|    ndim = len(paddable_shape)\n",
      "  4582|         0|            0|            0|  0.00%|\n",
      "  4583|         0|            0|            0|  0.00%|    for idx, size in enumerate(paddable_shape):\n",
      "  4584|         0|            0|            0|  0.00%|        # Only supports wrapping around once\n",
      "  4585|         0|            0|            0|  0.00%|        assert padding[-(idx * 2 + 1)] <= size, \"Padding value causes wrapping around more than once.\"\n",
      "  4586|         0|            0|            0|  0.00%|        assert padding[-(idx * 2 + 2)] <= size, \"Padding value causes wrapping around more than once.\"\n",
      "  4587|         0|            0|            0|  0.00%|        # Negative padding should not result in negative sizes\n",
      "  4588|         0|            0|            0|  0.00%|        assert (\n",
      "  4589|         0|            0|            0|  0.00%|            padding[-(idx * 2 + 1)] + padding[-(idx * 2 + 2)] + size >= 0\n",
      "  4590|         0|            0|            0|  0.00%|        ), \"Negative padding value is resulting in an empty dimension.\"\n",
      "  4591|         0|            0|            0|  0.00%|\n",
      "  4592|         0|            0|            0|  0.00%|    # Get shape of padded tensor\n",
      "  4593|         0|            0|            0|  0.00%|    out_shape = in_shape[:2]\n",
      "  4594|         0|            0|            0|  0.00%|    for idx, size in enumerate(paddable_shape):\n",
      "  4595|         0|            0|            0|  0.00%|        out_shape += (size + padding[-(idx * 2 + 1)] + padding[-(idx * 2 + 2)],)\n",
      "  4596|         0|            0|            0|  0.00%|\n",
      "  4597|         0|            0|            0|  0.00%|    out = torch.empty(out_shape, dtype=input.dtype, layout=input.layout, device=input.device)\n",
      "  4598|         0|            0|            0|  0.00%|\n",
      "  4599|         0|            0|            0|  0.00%|    # Put original array in padded array\n",
      "  4600|         0|            0|            0|  0.00%|    if ndim == 1:\n",
      "  4601|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4602|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4603|         0|            0|            0|  0.00%|\n",
      "  4604|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4605|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4606|         0|            0|            0|  0.00%|\n",
      "  4607|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1] = input[..., in_d0:in_d1]\n",
      "  4608|         0|            0|            0|  0.00%|    elif ndim == 2:\n",
      "  4609|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4610|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4611|         0|            0|            0|  0.00%|\n",
      "  4612|         0|            0|            0|  0.00%|        out_h0 = max(padding[-4], 0)\n",
      "  4613|         0|            0|            0|  0.00%|        out_h1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4614|         0|            0|            0|  0.00%|\n",
      "  4615|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4616|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4617|         0|            0|            0|  0.00%|\n",
      "  4618|         0|            0|            0|  0.00%|        in_h0 = max(-padding[-4], 0)\n",
      "  4619|         0|            0|            0|  0.00%|        in_h1 = in_shape[3] - max(-padding[-3], 0)\n",
      "  4620|         0|            0|            0|  0.00%|\n",
      "  4621|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1, out_h0:out_h1] = input[..., in_d0:in_d1, in_h0:in_h1]\n",
      "  4622|         0|            0|            0|  0.00%|    elif ndim == 3:\n",
      "  4623|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4624|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4625|         0|            0|            0|  0.00%|\n",
      "  4626|         0|            0|            0|  0.00%|        out_h0 = max(padding[-4], 0)\n",
      "  4627|         0|            0|            0|  0.00%|        out_h1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4628|         0|            0|            0|  0.00%|\n",
      "  4629|         0|            0|            0|  0.00%|        out_w0 = max(padding[-6], 0)\n",
      "  4630|         0|            0|            0|  0.00%|        out_w1 = out_shape[4] - max(padding[-5], 0)\n",
      "  4631|         0|            0|            0|  0.00%|\n",
      "  4632|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4633|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4634|         0|            0|            0|  0.00%|\n",
      "  4635|         0|            0|            0|  0.00%|        in_h0 = max(-padding[-4], 0)\n",
      "  4636|         0|            0|            0|  0.00%|        in_h1 = in_shape[3] - max(-padding[-3], 0)\n",
      "  4637|         0|            0|            0|  0.00%|\n",
      "  4638|         0|            0|            0|  0.00%|        in_w0 = max(-padding[-6], 0)\n",
      "  4639|         0|            0|            0|  0.00%|        in_w1 = in_shape[4] - max(-padding[-5], 0)\n",
      "  4640|         0|            0|            0|  0.00%|\n",
      "  4641|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1, out_h0:out_h1, out_w0:out_w1] = input[..., in_d0:in_d1, in_h0:in_h1, in_w0:in_w1]\n",
      "  4642|         0|            0|            0|  0.00%|\n",
      "  4643|         0|            0|            0|  0.00%|    # The following steps first pad the beginning of the tensor (left side),\n",
      "  4644|         0|            0|            0|  0.00%|    # and then pad the end of the tensor (right side).\n",
      "  4645|         0|            0|            0|  0.00%|    # Note: Corners will be written more than once when ndim > 1.\n",
      "  4646|         0|            0|            0|  0.00%|\n",
      "  4647|         0|            0|            0|  0.00%|    # Only in cases where padding values are > 0 are when additional copying\n",
      "  4648|         0|            0|            0|  0.00%|    # is required.\n",
      "  4649|         0|            0|            0|  0.00%|\n",
      "  4650|         0|            0|            0|  0.00%|    # Pad first dimension (depth)\n",
      "  4651|         0|            0|            0|  0.00%|    if padding[-2] > 0:\n",
      "  4652|         0|            0|            0|  0.00%|        i0 = out_shape[2] - padding[-2] - max(padding[-1], 0)\n",
      "  4653|         0|            0|            0|  0.00%|        i1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4654|         0|            0|            0|  0.00%|        o0 = 0\n",
      "  4655|         0|            0|            0|  0.00%|        o1 = padding[-2]\n",
      "  4656|         0|            0|            0|  0.00%|        out[:, :, o0:o1] = out[:, :, i0:i1]\n",
      "  4657|         0|            0|            0|  0.00%|    if padding[-1] > 0:\n",
      "  4658|         0|            0|            0|  0.00%|        i0 = max(padding[-2], 0)\n",
      "  4659|         0|            0|            0|  0.00%|        i1 = max(padding[-2], 0) + padding[-1]\n",
      "  4660|         0|            0|            0|  0.00%|        o0 = out_shape[2] - padding[-1]\n",
      "  4661|         0|            0|            0|  0.00%|        o1 = out_shape[2]\n",
      "  4662|         0|            0|            0|  0.00%|        out[:, :, o0:o1] = out[:, :, i0:i1]\n",
      "  4663|         0|            0|            0|  0.00%|\n",
      "  4664|         0|            0|            0|  0.00%|    # Pad second dimension (height)\n",
      "  4665|         0|            0|            0|  0.00%|    if len(padding) > 2:\n",
      "  4666|         0|            0|            0|  0.00%|        if padding[-4] > 0:\n",
      "  4667|         0|            0|            0|  0.00%|            i0 = out_shape[3] - padding[-4] - max(padding[-3], 0)\n",
      "  4668|         0|            0|            0|  0.00%|            i1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4669|         0|            0|            0|  0.00%|            o0 = 0\n",
      "  4670|         0|            0|            0|  0.00%|            o1 = padding[-4]\n",
      "  4671|         0|            0|            0|  0.00%|            out[:, :, :, o0:o1] = out[:, :, :, i0:i1]\n",
      "  4672|         0|            0|            0|  0.00%|        if padding[-3] > 0:\n",
      "  4673|         0|            0|            0|  0.00%|            i0 = max(padding[-4], 0)\n",
      "  4674|         0|            0|            0|  0.00%|            i1 = max(padding[-4], 0) + padding[-3]\n",
      "  4675|         0|            0|            0|  0.00%|            o0 = out_shape[3] - padding[-3]\n",
      "  4676|         0|            0|            0|  0.00%|            o1 = out_shape[3]\n",
      "  4677|         0|            0|            0|  0.00%|            out[:, :, :, o0:o1] = out[:, :, :, i0:i1]\n",
      "  4678|         0|            0|            0|  0.00%|\n",
      "  4679|         0|            0|            0|  0.00%|    # Pad third dimension (width)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4680|         0|            0|            0|  0.00%|    if len(padding) > 4:\n",
      "  4681|         0|            0|            0|  0.00%|        if padding[-6] > 0:\n",
      "  4682|         0|            0|            0|  0.00%|            i0 = out_shape[4] - padding[-6] - max(padding[-5], 0)\n",
      "  4683|         0|            0|            0|  0.00%|            i1 = out_shape[4] - max(padding[-5], 0)\n",
      "  4684|         0|            0|            0|  0.00%|            o0 = 0\n",
      "  4685|         0|            0|            0|  0.00%|            o1 = padding[-6]\n",
      "  4686|         0|            0|            0|  0.00%|            out[:, :, :, :, o0:o1] = out[:, :, :, :, i0:i1]\n",
      "  4687|         0|            0|            0|  0.00%|        if padding[-5] > 0:\n",
      "  4688|         0|            0|            0|  0.00%|            i0 = max(padding[-6], 0)\n",
      "  4689|         0|            0|            0|  0.00%|            i1 = max(padding[-6], 0) + padding[-5]\n",
      "  4690|         0|            0|            0|  0.00%|            o0 = out_shape[4] - padding[-5]\n",
      "  4691|         0|            0|            0|  0.00%|            o1 = out_shape[4]\n",
      "  4692|         0|            0|            0|  0.00%|            out[:, :, :, :, o0:o1] = out[:, :, :, :, i0:i1]\n",
      "  4693|         0|            0|            0|  0.00%|\n",
      "  4694|         0|            0|            0|  0.00%|    return out\n",
      "  4695|         0|            0|            0|  0.00%|\n",
      "  4696|         0|            0|            0|  0.00%|#\n",
      "  4697|         0|            0|            0|  0.00%|# multihead attention\n",
      "  4698|         0|            0|            0|  0.00%|#\n",
      "  4699|         0|            0|            0|  0.00%|\n",
      "  4700|         0|            0|            0|  0.00%|def _in_projection_packed(\n",
      "  4701|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4702|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4703|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4704|         0|            0|            0|  0.00%|    w: Tensor,\n",
      "  4705|         0|            0|            0|  0.00%|    b: Optional[Tensor] = None,\n",
      "  4706|         0|            0|            0|  0.00%|) -> List[Tensor]:\n",
      "  4707|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4708|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation, using packed weights.\n",
      "  4709|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.\n",
      "  4710|         0|            0|            0|  0.00%|\n",
      "  4711|         0|            0|            0|  0.00%|    Args:\n",
      "  4712|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected. For self-attention,\n",
      "  4713|         0|            0|            0|  0.00%|            these are typically the same tensor; for encoder-decoder attention,\n",
      "  4714|         0|            0|            0|  0.00%|            k and v are typically the same tensor. (We take advantage of these\n",
      "  4715|         0|            0|            0|  0.00%|            identities for performance if they are present.) Regardless, q, k and v\n",
      "  4716|         0|            0|            0|  0.00%|            must share a common embedding dimension; otherwise their shapes may vary.\n",
      "  4717|         0|            0|            0|  0.00%|        w: projection weights for q, k and v, packed into a single tensor. Weights\n",
      "  4718|         0|            0|            0|  0.00%|            are packed along dimension 0, in q, k, v order.\n",
      "  4719|         0|            0|            0|  0.00%|        b: optional projection biases for q, k and v, packed into a single tensor\n",
      "  4720|         0|            0|            0|  0.00%|            in q, k, v order.\n",
      "  4721|         0|            0|            0|  0.00%|\n",
      "  4722|         0|            0|            0|  0.00%|    Shape:\n",
      "  4723|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4724|         0|            0|            0|  0.00%|        - q: :math:`(..., E)` where E is the embedding dimension\n",
      "  4725|         0|            0|            0|  0.00%|        - k: :math:`(..., E)` where E is the embedding dimension\n",
      "  4726|         0|            0|            0|  0.00%|        - v: :math:`(..., E)` where E is the embedding dimension\n",
      "  4727|         0|            0|            0|  0.00%|        - w: :math:`(E * 3, E)` where E is the embedding dimension\n",
      "  4728|         0|            0|            0|  0.00%|        - b: :math:`E * 3` where E is the embedding dimension\n",
      "  4729|         0|            0|            0|  0.00%|\n",
      "  4730|         0|            0|            0|  0.00%|        Output:\n",
      "  4731|         0|            0|            0|  0.00%|        - in output list :math:`[q', k', v']`, each output tensor will have the\n",
      "  4732|         0|            0|            0|  0.00%|            same shape as the corresponding input tensor.\n",
      "  4733|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4734|         0|            0|            0|  0.00%|    E = q.size(-1)\n",
      "  4735|         0|            0|            0|  0.00%|    if k is v:\n",
      "  4736|         0|            0|            0|  0.00%|        if q is k:\n",
      "  4737|         0|            0|            0|  0.00%|            # self-attention\n",
      "  4738|         0|            0|            0|  0.00%|            return linear(q, w, b).chunk(3, dim=-1)\n",
      "  4739|         0|            0|            0|  0.00%|        else:\n",
      "  4740|         0|            0|            0|  0.00%|            # encoder-decoder attention\n",
      "  4741|         0|            0|            0|  0.00%|            w_q, w_kv = w.split([E, E * 2])\n",
      "  4742|         0|            0|            0|  0.00%|            if b is None:\n",
      "  4743|         0|            0|            0|  0.00%|                b_q = b_kv = None\n",
      "  4744|         0|            0|            0|  0.00%|            else:\n",
      "  4745|         0|            0|            0|  0.00%|                b_q, b_kv = b.split([E, E * 2])\n",
      "  4746|         0|            0|            0|  0.00%|            return (linear(q, w_q, b_q),) + linear(k, w_kv, b_kv).chunk(2, dim=-1)\n",
      "  4747|         0|            0|            0|  0.00%|    else:\n",
      "  4748|         0|            0|            0|  0.00%|        w_q, w_k, w_v = w.chunk(3)\n",
      "  4749|         0|            0|            0|  0.00%|        if b is None:\n",
      "  4750|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None\n",
      "  4751|         0|            0|            0|  0.00%|        else:\n",
      "  4752|         0|            0|            0|  0.00%|            b_q, b_k, b_v = b.chunk(3)\n",
      "  4753|         0|            0|            0|  0.00%|        return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "  4754|         0|            0|            0|  0.00%|\n",
      "  4755|         0|            0|            0|  0.00%|\n",
      "  4756|         0|            0|            0|  0.00%|def _in_projection(\n",
      "  4757|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4758|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4759|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4760|         0|            0|            0|  0.00%|    w_q: Tensor,\n",
      "  4761|         0|            0|            0|  0.00%|    w_k: Tensor,\n",
      "  4762|         0|            0|            0|  0.00%|    w_v: Tensor,\n",
      "  4763|         0|            0|            0|  0.00%|    b_q: Optional[Tensor] = None,\n",
      "  4764|         0|            0|            0|  0.00%|    b_k: Optional[Tensor] = None,\n",
      "  4765|         0|            0|            0|  0.00%|    b_v: Optional[Tensor] = None,\n",
      "  4766|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  4767|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4768|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation. This is simply\n",
      "  4769|         0|            0|            0|  0.00%|    a triple of linear projections, with shape constraints on the weights which\n",
      "  4770|         0|            0|            0|  0.00%|    ensure embedding dimension uniformity in the projected outputs.\n",
      "  4771|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.\n",
      "  4772|         0|            0|            0|  0.00%|\n",
      "  4773|         0|            0|            0|  0.00%|    Args:\n",
      "  4774|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected.\n",
      "  4775|         0|            0|            0|  0.00%|        w_q, w_k, w_v: weights for q, k and v, respectively.\n",
      "  4776|         0|            0|            0|  0.00%|        b_q, b_k, b_v: optional biases for q, k and v, respectively.\n",
      "  4777|         0|            0|            0|  0.00%|\n",
      "  4778|         0|            0|            0|  0.00%|    Shape:\n",
      "  4779|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4780|         0|            0|            0|  0.00%|        - q: :math:`(Qdims..., Eq)` where Eq is the query embedding dimension and Qdims are any\n",
      "  4781|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4782|         0|            0|            0|  0.00%|        - k: :math:`(Kdims..., Ek)` where Ek is the key embedding dimension and Kdims are any\n",
      "  4783|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4784|         0|            0|            0|  0.00%|        - v: :math:`(Vdims..., Ev)` where Ev is the value embedding dimension and Vdims are any\n",
      "  4785|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4786|         0|            0|            0|  0.00%|        - w_q: :math:`(Eq, Eq)`\n",
      "  4787|         0|            0|            0|  0.00%|        - w_k: :math:`(Eq, Ek)`\n",
      "  4788|         0|            0|            0|  0.00%|        - w_v: :math:`(Eq, Ev)`\n",
      "  4789|         0|            0|            0|  0.00%|        - b_q: :math:`(Eq)`\n",
      "  4790|         0|            0|            0|  0.00%|        - b_k: :math:`(Eq)`\n",
      "  4791|         0|            0|            0|  0.00%|        - b_v: :math:`(Eq)`\n",
      "  4792|         0|            0|            0|  0.00%|\n",
      "  4793|         0|            0|            0|  0.00%|        Output: in output triple :math:`(q', k', v')`,\n",
      "  4794|         0|            0|            0|  0.00%|         - q': :math:`[Qdims..., Eq]`\n",
      "  4795|         0|            0|            0|  0.00%|         - k': :math:`[Kdims..., Eq]`\n",
      "  4796|         0|            0|            0|  0.00%|         - v': :math:`[Vdims..., Eq]`\n",
      "  4797|         0|            0|            0|  0.00%|\n",
      "  4798|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4799|         0|            0|            0|  0.00%|    Eq, Ek, Ev = q.size(-1), k.size(-1), v.size(-1)\n",
      "  4800|         0|            0|            0|  0.00%|    assert w_q.shape == (Eq, Eq), f\"expecting query weights shape of {(Eq, Eq)}, but got {w_q.shape}\"\n",
      "  4801|         0|            0|            0|  0.00%|    assert w_k.shape == (Eq, Ek), f\"expecting key weights shape of {(Eq, Ek)}, but got {w_k.shape}\"\n",
      "  4802|         0|            0|            0|  0.00%|    assert w_v.shape == (Eq, Ev), f\"expecting value weights shape of {(Eq, Ev)}, but got {w_v.shape}\"\n",
      "  4803|         0|            0|            0|  0.00%|    assert b_q is None or b_q.shape == (Eq,), f\"expecting query bias shape of {(Eq,)}, but got {b_q.shape}\"\n",
      "  4804|         0|            0|            0|  0.00%|    assert b_k is None or b_k.shape == (Eq,), f\"expecting key bias shape of {(Eq,)}, but got {b_k.shape}\"\n",
      "  4805|         0|            0|            0|  0.00%|    assert b_v is None or b_v.shape == (Eq,), f\"expecting value bias shape of {(Eq,)}, but got {b_v.shape}\"\n",
      "  4806|         0|            0|            0|  0.00%|    return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "  4807|         0|            0|            0|  0.00%|\n",
      "  4808|         0|            0|            0|  0.00%|\n",
      "  4809|         0|            0|            0|  0.00%|def _scaled_dot_product_attention(\n",
      "  4810|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4811|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4812|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4813|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,\n",
      "  4814|         0|            0|            0|  0.00%|    dropout_p: float = 0.0,\n",
      "  4815|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  4816|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4817|         0|            0|            0|  0.00%|    Computes scaled dot product attention on query, key and value tensors, using\n",
      "  4818|         0|            0|            0|  0.00%|    an optional attention mask if passed, and applying dropout if a probability\n",
      "  4819|         0|            0|            0|  0.00%|    greater than 0.0 is specified.\n",
      "  4820|         0|            0|            0|  0.00%|    Returns a tensor pair containing attended values and attention weights.\n",
      "  4821|         0|            0|            0|  0.00%|\n",
      "  4822|         0|            0|            0|  0.00%|    Args:\n",
      "  4823|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors. See Shape section for shape details.\n",
      "  4824|         0|            0|            0|  0.00%|        attn_mask: optional tensor containing mask values to be added to calculated\n",
      "  4825|         0|            0|            0|  0.00%|            attention. May be 2D or 3D; see Shape section for details.\n",
      "  4826|         0|            0|            0|  0.00%|        dropout_p: dropout probability. If greater than 0.0, dropout is applied.\n",
      "  4827|         0|            0|            0|  0.00%|\n",
      "  4828|         0|            0|            0|  0.00%|    Shape:\n",
      "  4829|         0|            0|            0|  0.00%|        - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,\n",
      "  4830|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4831|         0|            0|            0|  0.00%|        - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,\n",
      "  4832|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4833|         0|            0|            0|  0.00%|        - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,\n",
      "  4834|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4835|         0|            0|            0|  0.00%|        - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of\n",
      "  4836|         0|            0|            0|  0.00%|            shape :math:`(Nt, Ns)`.\n",
      "  4837|         0|            0|            0|  0.00%|\n",
      "  4838|         0|            0|            0|  0.00%|        - Output: attention values have shape :math:`(B, Nt, E)`; attention weights\n",
      "  4839|         0|            0|            0|  0.00%|            have shape :math:`(B, Nt, Ns)`\n",
      "  4840|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4841|         0|            0|            0|  0.00%|    B, Nt, E = q.shape\n",
      "  4842|         0|            0|            0|  0.00%|    q = q / math.sqrt(E)\n",
      "  4843|         0|            0|            0|  0.00%|    # (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)\n",
      "  4844|         0|            0|            0|  0.00%|    attn = torch.bmm(q, k.transpose(-2, -1))\n",
      "  4845|         0|            0|            0|  0.00%|    if attn_mask is not None:\n",
      "  4846|         0|            0|            0|  0.00%|        attn += attn_mask\n",
      "  4847|         0|            0|            0|  0.00%|    attn = softmax(attn, dim=-1)\n",
      "  4848|         0|            0|            0|  0.00%|    if dropout_p > 0.0:\n",
      "  4849|         0|            0|            0|  0.00%|        attn = dropout(attn, p=dropout_p)\n",
      "  4850|         0|            0|            0|  0.00%|    # (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\n",
      "  4851|         0|            0|            0|  0.00%|    output = torch.bmm(attn, v)\n",
      "  4852|         0|            0|            0|  0.00%|    return output, attn\n",
      "  4853|         0|            0|            0|  0.00%|\n",
      "  4854|         0|            0|            0|  0.00%|\n",
      "  4855|         0|            0|            0|  0.00%|def multi_head_attention_forward(\n",
      "  4856|         0|            0|            0|  0.00%|    query: Tensor,\n",
      "  4857|         0|            0|            0|  0.00%|    key: Tensor,\n",
      "  4858|         0|            0|            0|  0.00%|    value: Tensor,\n",
      "  4859|         0|            0|            0|  0.00%|    embed_dim_to_check: int,\n",
      "  4860|         0|            0|            0|  0.00%|    num_heads: int,\n",
      "  4861|         0|            0|            0|  0.00%|    in_proj_weight: Tensor,\n",
      "  4862|         0|            0|            0|  0.00%|    in_proj_bias: Optional[Tensor],\n",
      "  4863|         0|            0|            0|  0.00%|    bias_k: Optional[Tensor],\n",
      "  4864|         0|            0|            0|  0.00%|    bias_v: Optional[Tensor],\n",
      "  4865|         0|            0|            0|  0.00%|    add_zero_attn: bool,\n",
      "  4866|         0|            0|            0|  0.00%|    dropout_p: float,\n",
      "  4867|         0|            0|            0|  0.00%|    out_proj_weight: Tensor,\n",
      "  4868|         0|            0|            0|  0.00%|    out_proj_bias: Optional[Tensor],\n",
      "  4869|         0|            0|            0|  0.00%|    training: bool = True,\n",
      "  4870|         0|            0|            0|  0.00%|    key_padding_mask: Optional[Tensor] = None,\n",
      "  4871|         0|            0|            0|  0.00%|    need_weights: bool = True,\n",
      "  4872|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,\n",
      "  4873|         0|            0|            0|  0.00%|    use_separate_proj_weight: bool = False,\n",
      "  4874|         0|            0|            0|  0.00%|    q_proj_weight: Optional[Tensor] = None,\n",
      "  4875|         0|            0|            0|  0.00%|    k_proj_weight: Optional[Tensor] = None,\n",
      "  4876|         0|            0|            0|  0.00%|    v_proj_weight: Optional[Tensor] = None,\n",
      "  4877|         0|            0|            0|  0.00%|    static_k: Optional[Tensor] = None,\n",
      "  4878|         0|            0|            0|  0.00%|    static_v: Optional[Tensor] = None,\n",
      "  4879|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Optional[Tensor]]:\n",
      "  4880|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4881|         0|            0|            0|  0.00%|    Args:\n",
      "  4882|         0|            0|            0|  0.00%|        query, key, value: map a query and a set of key-value pairs to an output.\n",
      "  4883|         0|            0|            0|  0.00%|            See \"Attention Is All You Need\" for more details.\n",
      "  4884|         0|            0|            0|  0.00%|        embed_dim_to_check: total dimension of the model.\n",
      "  4885|         0|            0|            0|  0.00%|        num_heads: parallel attention heads.\n",
      "  4886|         0|            0|            0|  0.00%|        in_proj_weight, in_proj_bias: input projection weight and bias.\n",
      "  4887|         0|            0|            0|  0.00%|        bias_k, bias_v: bias of the key and value sequences to be added at dim=0.\n",
      "  4888|         0|            0|            0|  0.00%|        add_zero_attn: add a new batch of zeros to the key and\n",
      "  4889|         0|            0|            0|  0.00%|                       value sequences at dim=1.\n",
      "  4890|         0|            0|            0|  0.00%|        dropout_p: probability of an element to be zeroed.\n",
      "  4891|         0|            0|            0|  0.00%|        out_proj_weight, out_proj_bias: the output projection weight and bias.\n",
      "  4892|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``.\n",
      "  4893|         0|            0|            0|  0.00%|        key_padding_mask: if provided, specified padding elements in the key will\n",
      "  4894|         0|            0|            0|  0.00%|            be ignored by the attention. This is an binary mask. When the value is True,\n",
      "  4895|         0|            0|            0|  0.00%|            the corresponding value on the attention layer will be filled with -inf.\n",
      "  4896|         0|            0|            0|  0.00%|        need_weights: output attn_output_weights.\n",
      "  4897|         0|            0|            0|  0.00%|        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all\n",
      "  4898|         0|            0|            0|  0.00%|            the batches while a 3D mask allows to specify a different mask for the entries of each batch.\n",
      "  4899|         0|            0|            0|  0.00%|        use_separate_proj_weight: the function accept the proj. weights for query, key,\n",
      "  4900|         0|            0|            0|  0.00%|            and value in different forms. If false, in_proj_weight will be used, which is\n",
      "  4901|         0|            0|            0|  0.00%|            a combination of q_proj_weight, k_proj_weight, v_proj_weight.\n",
      "  4902|         0|            0|            0|  0.00%|        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.\n",
      "  4903|         0|            0|            0|  0.00%|        static_k, static_v: static key and value used for attention operators.\n",
      "  4904|         0|            0|            0|  0.00%|\n",
      "  4905|         0|            0|            0|  0.00%|\n",
      "  4906|         0|            0|            0|  0.00%|    Shape:\n",
      "  4907|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4908|         0|            0|            0|  0.00%|        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
      "  4909|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4910|         0|            0|            0|  0.00%|        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
      "  4911|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4912|         0|            0|            0|  0.00%|        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
      "  4913|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4914|         0|            0|            0|  0.00%|        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.\n",
      "  4915|         0|            0|            0|  0.00%|          If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions\n",
      "  4916|         0|            0|            0|  0.00%|          will be unchanged. If a BoolTensor is provided, the positions with the\n",
      "  4917|         0|            0|            0|  0.00%|          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n",
      "  4918|         0|            0|            0|  0.00%|        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
      "  4919|         0|            0|            0|  0.00%|          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,\n",
      "  4920|         0|            0|            0|  0.00%|          S is the source sequence length. attn_mask ensures that position i is allowed to attend the unmasked\n",
      "  4921|         0|            0|            0|  0.00%|          positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend\n",
      "  4922|         0|            0|            0|  0.00%|          while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``\n",
      "  4923|         0|            0|            0|  0.00%|          are not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n",
      "  4924|         0|            0|            0|  0.00%|          is provided, it will be added to the attention weight.\n",
      "  4925|         0|            0|            0|  0.00%|        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n",
      "  4926|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n",
      "  4927|         0|            0|            0|  0.00%|        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n",
      "  4928|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n",
      "  4929|         0|            0|            0|  0.00%|\n",
      "  4930|         0|            0|            0|  0.00%|        Outputs:\n",
      "  4931|         0|            0|            0|  0.00%|        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
      "  4932|         0|            0|            0|  0.00%|          E is the embedding dimension.\n",
      "  4933|         0|            0|            0|  0.00%|        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n",
      "  4934|         0|            0|            0|  0.00%|          L is the target sequence length, S is the source sequence length.\n",
      "  4935|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4936|         0|            0|            0|  0.00%|    tens_ops = (query, key, value, in_proj_weight, in_proj_bias, bias_k, bias_v, out_proj_weight, out_proj_bias)\n",
      "  4937|         0|            0|            0|  0.00%|    if has_torch_function(tens_ops):\n",
      "  4938|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4939|         0|            0|            0|  0.00%|            multi_head_attention_forward,\n",
      "  4940|         0|            0|            0|  0.00%|            tens_ops,\n",
      "  4941|         0|            0|            0|  0.00%|            query,\n",
      "  4942|         0|            0|            0|  0.00%|            key,\n",
      "  4943|         0|            0|            0|  0.00%|            value,\n",
      "  4944|         0|            0|            0|  0.00%|            embed_dim_to_check,\n",
      "  4945|         0|            0|            0|  0.00%|            num_heads,\n",
      "  4946|         0|            0|            0|  0.00%|            in_proj_weight,\n",
      "  4947|         0|            0|            0|  0.00%|            in_proj_bias,\n",
      "  4948|         0|            0|            0|  0.00%|            bias_k,\n",
      "  4949|         0|            0|            0|  0.00%|            bias_v,\n",
      "  4950|         0|            0|            0|  0.00%|            add_zero_attn,\n",
      "  4951|         0|            0|            0|  0.00%|            dropout_p,\n",
      "  4952|         0|            0|            0|  0.00%|            out_proj_weight,\n",
      "  4953|         0|            0|            0|  0.00%|            out_proj_bias,\n",
      "  4954|         0|            0|            0|  0.00%|            training=training,\n",
      "  4955|         0|            0|            0|  0.00%|            key_padding_mask=key_padding_mask,\n",
      "  4956|         0|            0|            0|  0.00%|            need_weights=need_weights,\n",
      "  4957|         0|            0|            0|  0.00%|            attn_mask=attn_mask,\n",
      "  4958|         0|            0|            0|  0.00%|            use_separate_proj_weight=use_separate_proj_weight,\n",
      "  4959|         0|            0|            0|  0.00%|            q_proj_weight=q_proj_weight,\n",
      "  4960|         0|            0|            0|  0.00%|            k_proj_weight=k_proj_weight,\n",
      "  4961|         0|            0|            0|  0.00%|            v_proj_weight=v_proj_weight,\n",
      "  4962|         0|            0|            0|  0.00%|            static_k=static_k,\n",
      "  4963|         0|            0|            0|  0.00%|            static_v=static_v,\n",
      "  4964|         0|            0|            0|  0.00%|        )\n",
      "  4965|         0|            0|            0|  0.00%|\n",
      "  4966|         0|            0|            0|  0.00%|    # set up shape vars\n",
      "  4967|         0|            0|            0|  0.00%|    tgt_len, bsz, embed_dim = query.shape\n",
      "  4968|         0|            0|            0|  0.00%|    src_len, _, _ = key.shape\n",
      "  4969|         0|            0|            0|  0.00%|    assert embed_dim == embed_dim_to_check, \\\n",
      "  4970|         0|            0|            0|  0.00%|        f\"was expecting embedding dimension of {embed_dim_to_check}, but got {embed_dim}\"\n",
      "  4971|         0|            0|            0|  0.00%|    if isinstance(embed_dim, torch.Tensor):\n",
      "  4972|         0|            0|            0|  0.00%|        # embed_dim can be a tensor when JIT tracing\n",
      "  4973|         0|            0|            0|  0.00%|        head_dim = embed_dim.div(num_heads, rounding_mode='trunc')\n",
      "  4974|         0|            0|            0|  0.00%|    else:\n",
      "  4975|         0|            0|            0|  0.00%|        head_dim = embed_dim // num_heads\n",
      "  4976|         0|            0|            0|  0.00%|    assert head_dim * num_heads == embed_dim, f\"embed_dim {embed_dim} not divisible by num_heads {num_heads}\"\n",
      "  4977|         0|            0|            0|  0.00%|    if use_separate_proj_weight:\n",
      "  4978|         0|            0|            0|  0.00%|        # allow MHA to have different embedding dimensions when separate projection weights are used\n",
      "  4979|         0|            0|            0|  0.00%|        assert key.shape[:2] == value.shape[:2], \\\n",
      "  4980|         0|            0|            0|  0.00%|            f\"key's sequence and batch dims {key.shape[:2]} do not match value's {value.shape[:2]}\"\n",
      "  4981|         0|            0|            0|  0.00%|    else:\n",
      "  4982|         0|            0|            0|  0.00%|        assert key.shape == value.shape, f\"key shape {key.shape} does not match value shape {value.shape}\"\n",
      "  4983|         0|            0|            0|  0.00%|\n",
      "  4984|         0|            0|            0|  0.00%|    #\n",
      "  4985|         0|            0|            0|  0.00%|    # compute in-projection\n",
      "  4986|         0|            0|            0|  0.00%|    #\n",
      "  4987|         0|            0|            0|  0.00%|    if not use_separate_proj_weight:\n",
      "  4988|         0|            0|            0|  0.00%|        q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n",
      "  4989|         0|            0|            0|  0.00%|    else:\n",
      "  4990|         0|            0|            0|  0.00%|        assert q_proj_weight is not None, \"use_separate_proj_weight is True but q_proj_weight is None\"\n",
      "  4991|         0|            0|            0|  0.00%|        assert k_proj_weight is not None, \"use_separate_proj_weight is True but k_proj_weight is None\"\n",
      "  4992|         0|            0|            0|  0.00%|        assert v_proj_weight is not None, \"use_separate_proj_weight is True but v_proj_weight is None\"\n",
      "  4993|         0|            0|            0|  0.00%|        if in_proj_bias is None:\n",
      "  4994|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None\n",
      "  4995|         0|            0|            0|  0.00%|        else:\n",
      "  4996|         0|            0|            0|  0.00%|            b_q, b_k, b_v = in_proj_bias.chunk(3)\n",
      "  4997|         0|            0|            0|  0.00%|        q, k, v = _in_projection(query, key, value, q_proj_weight, k_proj_weight, v_proj_weight, b_q, b_k, b_v)\n",
      "  4998|         0|            0|            0|  0.00%|\n",
      "  4999|         0|            0|            0|  0.00%|    # prep attention mask\n",
      "  5000|         0|            0|            0|  0.00%|    if attn_mask is not None:\n",
      "  5001|         0|            0|            0|  0.00%|        if attn_mask.dtype == torch.uint8:\n",
      "  5002|         0|            0|            0|  0.00%|            warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
      "  5003|         0|            0|            0|  0.00%|            attn_mask = attn_mask.to(torch.bool)\n",
      "  5004|         0|            0|            0|  0.00%|        else:\n",
      "  5005|         0|            0|            0|  0.00%|            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
      "  5006|         0|            0|            0|  0.00%|                f\"Only float, byte, and bool types are supported for attn_mask, not {attn_mask.dtype}\"\n",
      "  5007|         0|            0|            0|  0.00%|        # ensure attn_mask's dim is 3\n",
      "  5008|         0|            0|            0|  0.00%|        if attn_mask.dim() == 2:\n",
      "  5009|         0|            0|            0|  0.00%|            correct_2d_size = (tgt_len, src_len)\n",
      "  5010|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_2d_size:\n",
      "  5011|         0|            0|            0|  0.00%|                raise RuntimeError(f\"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.\")\n",
      "  5012|         0|            0|            0|  0.00%|            attn_mask = attn_mask.unsqueeze(0)\n",
      "  5013|         0|            0|            0|  0.00%|        elif attn_mask.dim() == 3:\n",
      "  5014|         0|            0|            0|  0.00%|            correct_3d_size = (bsz * num_heads, tgt_len, src_len)\n",
      "  5015|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_3d_size:\n",
      "  5016|         0|            0|            0|  0.00%|                raise RuntimeError(f\"The shape of the 3D attn_mask is {attn_mask.shape}, but should be {correct_3d_size}.\")\n",
      "  5017|         0|            0|            0|  0.00%|        else:\n",
      "  5018|         0|            0|            0|  0.00%|            raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
      "  5019|         0|            0|            0|  0.00%|\n",
      "  5020|         0|            0|            0|  0.00%|    # prep key padding mask\n",
      "  5021|         0|            0|            0|  0.00%|    if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:\n",
      "  5022|         0|            0|            0|  0.00%|        warnings.warn(\"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
      "  5023|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.to(torch.bool)\n",
      "  5024|         0|            0|            0|  0.00%|\n",
      "  5025|         0|            0|            0|  0.00%|    # add bias along batch dimension (currently second)\n",
      "  5026|         0|            0|            0|  0.00%|    if bias_k is not None and bias_v is not None:\n",
      "  5027|         0|            0|            0|  0.00%|        assert static_k is None, \"bias cannot be added to static key.\"\n",
      "  5028|         0|            0|            0|  0.00%|        assert static_v is None, \"bias cannot be added to static value.\"\n",
      "  5029|         0|            0|            0|  0.00%|        k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
      "  5030|         0|            0|            0|  0.00%|        v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
      "  5031|         0|            0|            0|  0.00%|        if attn_mask is not None:\n",
      "  5032|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))\n",
      "  5033|         0|            0|            0|  0.00%|        if key_padding_mask is not None:\n",
      "  5034|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))\n",
      "  5035|         0|            0|            0|  0.00%|    else:\n",
      "  5036|         0|            0|            0|  0.00%|        assert bias_k is None\n",
      "  5037|         0|            0|            0|  0.00%|        assert bias_v is None\n",
      "  5038|         0|            0|            0|  0.00%|\n",
      "  5039|         0|            0|            0|  0.00%|    #\n",
      "  5040|         0|            0|            0|  0.00%|    # reshape q, k, v for multihead attention and make em batch first\n",
      "  5041|         0|            0|            0|  0.00%|    #\n",
      "  5042|         0|            0|            0|  0.00%|    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5043|         0|            0|            0|  0.00%|    if static_k is None:\n",
      "  5044|         0|            0|            0|  0.00%|        k = k.contiguous().view(k.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5045|         0|            0|            0|  0.00%|    else:\n",
      "  5046|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
      "  5047|         0|            0|            0|  0.00%|        assert static_k.size(0) == bsz * num_heads, \\\n",
      "  5048|         0|            0|            0|  0.00%|            f\"expecting static_k.size(0) of {bsz * num_heads}, but got {static_k.size(0)}\"\n",
      "  5049|         0|            0|            0|  0.00%|        assert static_k.size(2) == head_dim, \\\n",
      "  5050|         0|            0|            0|  0.00%|            f\"expecting static_k.size(2) of {head_dim}, but got {static_k.size(2)}\"\n",
      "  5051|         0|            0|            0|  0.00%|        k = static_k\n",
      "  5052|         0|            0|            0|  0.00%|    if static_v is None:\n",
      "  5053|         0|            0|            0|  0.00%|        v = v.contiguous().view(v.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5054|         0|            0|            0|  0.00%|    else:\n",
      "  5055|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
      "  5056|         0|            0|            0|  0.00%|        assert static_v.size(0) == bsz * num_heads, \\\n",
      "  5057|         0|            0|            0|  0.00%|            f\"expecting static_v.size(0) of {bsz * num_heads}, but got {static_v.size(0)}\"\n",
      "  5058|         0|            0|            0|  0.00%|        assert static_v.size(2) == head_dim, \\\n",
      "  5059|         0|            0|            0|  0.00%|            f\"expecting static_v.size(2) of {head_dim}, but got {static_v.size(2)}\"\n",
      "  5060|         0|            0|            0|  0.00%|        v = static_v\n",
      "  5061|         0|            0|            0|  0.00%|\n",
      "  5062|         0|            0|            0|  0.00%|    # add zero attention along batch dimension (now first)\n",
      "  5063|         0|            0|            0|  0.00%|    if add_zero_attn:\n",
      "  5064|         0|            0|            0|  0.00%|        zero_attn_shape = (bsz * num_heads, 1, head_dim)\n",
      "  5065|         0|            0|            0|  0.00%|        k = torch.cat([k, torch.zeros(zero_attn_shape, dtype=k.dtype, device=k.device)], dim=1)\n",
      "  5066|         0|            0|            0|  0.00%|        v = torch.cat([v, torch.zeros(zero_attn_shape, dtype=v.dtype, device=v.device)], dim=1)\n",
      "  5067|         0|            0|            0|  0.00%|        if attn_mask is not None:\n",
      "  5068|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))\n",
      "  5069|         0|            0|            0|  0.00%|        if key_padding_mask is not None:\n",
      "  5070|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))\n",
      "  5071|         0|            0|            0|  0.00%|\n",
      "  5072|         0|            0|            0|  0.00%|    # update source sequence length after adjustments\n",
      "  5073|         0|            0|            0|  0.00%|    src_len = k.size(1)\n",
      "  5074|         0|            0|            0|  0.00%|\n",
      "  5075|         0|            0|            0|  0.00%|    # merge key padding and attention masks\n",
      "  5076|         0|            0|            0|  0.00%|    if key_padding_mask is not None:\n",
      "  5077|         0|            0|            0|  0.00%|        assert key_padding_mask.shape == (bsz, src_len), \\\n",
      "  5078|         0|            0|            0|  0.00%|            f\"expecting key_padding_mask shape of {(bsz, src_len)}, but got {key_padding_mask.shape}\"\n",
      "  5079|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.view(bsz, 1, 1, src_len).   \\\n",
      "  5080|         0|            0|            0|  0.00%|            expand(-1, num_heads, -1, -1).reshape(bsz * num_heads, 1, src_len)\n",
      "  5081|         0|            0|            0|  0.00%|        if attn_mask is None:\n",
      "  5082|         0|            0|            0|  0.00%|            attn_mask = key_padding_mask\n",
      "  5083|         0|            0|            0|  0.00%|        elif attn_mask.dtype == torch.bool:\n",
      "  5084|         0|            0|            0|  0.00%|            attn_mask = attn_mask.logical_or(key_padding_mask)\n",
      "  5085|         0|            0|            0|  0.00%|        else:\n",
      "  5086|         0|            0|            0|  0.00%|            attn_mask = attn_mask.masked_fill(key_padding_mask, float(\"-inf\"))\n",
      "  5087|         0|            0|            0|  0.00%|\n",
      "  5088|         0|            0|            0|  0.00%|    # convert mask to float\n",
      "  5089|         0|            0|            0|  0.00%|    if attn_mask is not None and attn_mask.dtype == torch.bool:\n",
      "  5090|         0|            0|            0|  0.00%|        new_attn_mask = torch.zeros_like(attn_mask, dtype=torch.float)\n",
      "  5091|         0|            0|            0|  0.00%|        new_attn_mask.masked_fill_(attn_mask, float(\"-inf\"))\n",
      "  5092|         0|            0|            0|  0.00%|        attn_mask = new_attn_mask\n",
      "  5093|         0|            0|            0|  0.00%|\n",
      "  5094|         0|            0|            0|  0.00%|    # adjust dropout probability\n",
      "  5095|         0|            0|            0|  0.00%|    if not training:\n",
      "  5096|         0|            0|            0|  0.00%|        dropout_p = 0.0\n",
      "  5097|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5098|         0|            0|            0|  0.00%|    #\n",
      "  5099|         0|            0|            0|  0.00%|    # (deep breath) calculate attention and out projection\n",
      "  5100|         0|            0|            0|  0.00%|    #\n",
      "  5101|         0|            0|            0|  0.00%|    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
      "  5102|         0|            0|            0|  0.00%|    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
      "  5103|         0|            0|            0|  0.00%|    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "  5104|         0|            0|            0|  0.00%|\n",
      "  5105|         0|            0|            0|  0.00%|    if need_weights:\n",
      "  5106|         0|            0|            0|  0.00%|        # average attention weights over heads\n",
      "  5107|         0|            0|            0|  0.00%|        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
      "  5108|         0|            0|            0|  0.00%|        return attn_output, attn_output_weights.sum(dim=1) / num_heads\n",
      "  5109|         0|            0|            0|  0.00%|    else:\n",
      "  5110|         0|            0|            0|  0.00%|        return attn_output, None\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py\n",
      "File duration: 0.00421929s (1.87%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import OrderedDict, namedtuple\n",
      "     2|         0|            0|            0|  0.00%|import itertools\n",
      "     3|         0|            0|            0|  0.00%|import warnings\n",
      "     4|         0|            0|            0|  0.00%|import functools\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|import torch\n",
      "     7|         0|            0|            0|  0.00%|from ..parameter import Parameter\n",
      "     8|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|from torch import Tensor, device, dtype\n",
      "    11|         0|            0|            0|  0.00%|from typing import Union, Tuple, Any, Callable, Iterator, Set, Optional, overload, TypeVar, Mapping, Dict, List\n",
      "    12|         0|            0|            0|  0.00%|from ...utils.hooks import RemovableHandle\n",
      "    13|         0|            0|            0|  0.00%|\n",
      "    14|         0|            0|            0|  0.00%|_grad_t = Union[Tuple[Tensor, ...], Tensor]\n",
      "    15|         0|            0|            0|  0.00%|# See https://mypy.readthedocs.io/en/latest/generics.html#generic-methods-and-generic-self for the use\n",
      "    16|         0|            0|            0|  0.00%|# of `T` to annotate `self`. Many methods of `Module` return `self` and we want those return values to be\n",
      "    17|         0|            0|            0|  0.00%|# the type of the subclass, not the looser type of `Module`.\n",
      "    18|         0|            0|            0|  0.00%|T = TypeVar('T', bound='Module')\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         0|            0|            0|  0.00%|class _IncompatibleKeys(namedtuple('IncompatibleKeys', ['missing_keys', 'unexpected_keys'])):\n",
      "    21|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "    22|         0|            0|            0|  0.00%|        if not self.missing_keys and not self.unexpected_keys:\n",
      "    23|         0|            0|            0|  0.00%|            return '<All keys matched successfully>'\n",
      "    24|         0|            0|            0|  0.00%|        return super(_IncompatibleKeys, self).__repr__()\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|    __str__ = __repr__\n",
      "    27|         0|            0|            0|  0.00%|\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|def _addindent(s_, numSpaces):\n",
      "    30|         0|            0|            0|  0.00%|    s = s_.split('\\n')\n",
      "    31|         0|            0|            0|  0.00%|    # don't do anything for single-line stuff\n",
      "    32|         0|            0|            0|  0.00%|    if len(s) == 1:\n",
      "    33|         0|            0|            0|  0.00%|        return s_\n",
      "    34|         0|            0|            0|  0.00%|    first = s.pop(0)\n",
      "    35|         0|            0|            0|  0.00%|    s = [(numSpaces * ' ') + line for line in s]\n",
      "    36|         0|            0|            0|  0.00%|    s = '\\n'.join(s)\n",
      "    37|         0|            0|            0|  0.00%|    s = first + '\\n' + s\n",
      "    38|         0|            0|            0|  0.00%|    return s\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|\n",
      "    41|         0|            0|            0|  0.00%|r\"\"\"This tracks hooks common to all modules that are executed before/after\n",
      "    42|         0|            0|            0|  0.00%|calling forward and backward. This is global state used for debugging/profiling\n",
      "    43|         0|            0|            0|  0.00%|purposes\"\"\"\n",
      "    44|         0|            0|            0|  0.00%|_global_backward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    45|         0|            0|            0|  0.00%|_global_is_full_backward_hook: Optional[bool] = None\n",
      "    46|         0|            0|            0|  0.00%|_global_forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    47|         0|            0|            0|  0.00%|_global_forward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    48|         0|            0|            0|  0.00%|\n",
      "    49|         0|            0|            0|  0.00%|_EXTRA_STATE_KEY_SUFFIX = '_extra_state'\n",
      "    50|         0|            0|            0|  0.00%|\n",
      "    51|         0|            0|            0|  0.00%|\n",
      "    52|         0|            0|            0|  0.00%|def register_module_forward_pre_hook(hook: Callable[..., None]) -> RemovableHandle:\n",
      "    53|         0|            0|            0|  0.00%|    r\"\"\"Registers a forward pre-hook common to all modules.\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|    .. warning ::\n",
      "    56|         0|            0|            0|  0.00%|\n",
      "    57|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "    58|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "    59|         0|            0|            0|  0.00%|\n",
      "    60|         0|            0|            0|  0.00%|    The hook will be called every time before :func:`forward` is invoked.\n",
      "    61|         0|            0|            0|  0.00%|    It should have the following signature::\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|        hook(module, input) -> None or modified input\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.\n",
      "    66|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "    67|         0|            0|            0|  0.00%|    The hook can modify the input. User can either return a tuple or a\n",
      "    68|         0|            0|            0|  0.00%|    single modified value in the hook. We will wrap the value into a tuple\n",
      "    69|         0|            0|            0|  0.00%|    if a single value is returned(unless that value is already a tuple).\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|    This hook has precedence over the specific module hooks registered with\n",
      "    72|         0|            0|            0|  0.00%|    ``register_forward_pre_hook``.\n",
      "    73|         0|            0|            0|  0.00%|\n",
      "    74|         0|            0|            0|  0.00%|    Returns:\n",
      "    75|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "    76|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "    77|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "    78|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    79|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_pre_hooks)\n",
      "    80|         0|            0|            0|  0.00%|    _global_forward_pre_hooks[handle.id] = hook\n",
      "    81|         0|            0|            0|  0.00%|    return handle\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|def register_module_forward_hook(hook: Callable[..., None]) -> RemovableHandle:\n",
      "    85|         0|            0|            0|  0.00%|    r\"\"\"Registers a global forward hook for all the modules\n",
      "    86|         0|            0|            0|  0.00%|\n",
      "    87|         0|            0|            0|  0.00%|    .. warning ::\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "    90|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    The hook will be called every time after :func:`forward` has computed an output.\n",
      "    93|         0|            0|            0|  0.00%|    It should have the following signature::\n",
      "    94|         0|            0|            0|  0.00%|\n",
      "    95|         0|            0|            0|  0.00%|        hook(module, input, output) -> None or modified output\n",
      "    96|         0|            0|            0|  0.00%|\n",
      "    97|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.\n",
      "    98|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "    99|         0|            0|            0|  0.00%|    The hook can modify the output. It can modify the input inplace but\n",
      "   100|         0|            0|            0|  0.00%|    it will not have effect on forward since this is called after\n",
      "   101|         0|            0|            0|  0.00%|    :func:`forward` is called.\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    Returns:\n",
      "   104|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   105|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   106|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   107|         0|            0|            0|  0.00%|\n",
      "   108|         0|            0|            0|  0.00%|    This hook will be executed before specific module hooks registered with\n",
      "   109|         0|            0|            0|  0.00%|    ``register_forward_hook``.\n",
      "   110|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   111|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_hooks)\n",
      "   112|         0|            0|            0|  0.00%|    _global_forward_hooks[handle.id] = hook\n",
      "   113|         0|            0|            0|  0.00%|    return handle\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|def register_module_backward_hook(\n",
      "   116|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   117|         0|            0|            0|  0.00%|) -> RemovableHandle:\n",
      "   118|         0|            0|            0|  0.00%|    r\"\"\"Registers a backward hook common to all the modules.\n",
      "   119|         0|            0|            0|  0.00%|\n",
      "   120|         0|            0|            0|  0.00%|    This function is deprecated in favor of\n",
      "   121|         0|            0|            0|  0.00%|    :func:`torch.nn.modules.module.register_module_full_backward_hook`\n",
      "   122|         0|            0|            0|  0.00%|    and the behavior of this function will change in future versions.\n",
      "   123|         0|            0|            0|  0.00%|\n",
      "   124|         0|            0|            0|  0.00%|    Returns:\n",
      "   125|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   126|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   127|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   130|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook\n",
      "   131|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is True:\n",
      "   132|         0|            0|            0|  0.00%|        raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks as a \"\n",
      "   133|         0|            0|            0|  0.00%|                           \"global Module hook. Please use only one of them.\")\n",
      "   134|         0|            0|            0|  0.00%|\n",
      "   135|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = False\n",
      "   136|         0|            0|            0|  0.00%|\n",
      "   137|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)\n",
      "   138|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook\n",
      "   139|         0|            0|            0|  0.00%|    return handle\n",
      "   140|         0|            0|            0|  0.00%|\n",
      "   141|         0|            0|            0|  0.00%|def register_module_full_backward_hook(\n",
      "   142|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   143|         0|            0|            0|  0.00%|) -> RemovableHandle:\n",
      "   144|         0|            0|            0|  0.00%|    r\"\"\"Registers a backward hook common to all the modules.\n",
      "   145|         0|            0|            0|  0.00%|\n",
      "   146|         0|            0|            0|  0.00%|    .. warning ::\n",
      "   147|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "   148|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "   149|         0|            0|            0|  0.00%|\n",
      "   150|         0|            0|            0|  0.00%|    The hook will be called every time the gradients with respect to module\n",
      "   151|         0|            0|            0|  0.00%|    inputs are computed. The hook should have the following signature::\n",
      "   152|         0|            0|            0|  0.00%|\n",
      "   153|         0|            0|            0|  0.00%|        hook(module, grad_input, grad_output) -> Tensor or None\n",
      "   154|         0|            0|            0|  0.00%|\n",
      "   155|         0|            0|            0|  0.00%|    The :attr:`grad_input` and :attr:`grad_output` are tuples. The hook should\n",
      "   156|         0|            0|            0|  0.00%|    not modify its arguments, but it can optionally return a new gradient with\n",
      "   157|         0|            0|            0|  0.00%|    respect to the input that will be used in place of :attr:`grad_input` in\n",
      "   158|         0|            0|            0|  0.00%|    subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      "   159|         0|            0|            0|  0.00%|    as positional arguments and all kwarg arguments will not appear in the hook. Entries\n",
      "   160|         0|            0|            0|  0.00%|    in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      "   161|         0|            0|            0|  0.00%|    arguments.\n",
      "   162|         0|            0|            0|  0.00%|\n",
      "   163|         0|            0|            0|  0.00%|    For technical reasons, when this hook is applied to a Module, its forward function will\n",
      "   164|         0|            0|            0|  0.00%|    receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      "   165|         0|            0|            0|  0.00%|    of each Tensor returned by the Module's forward function.\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|    Global hooks are called before hooks registered with `register_backward_hook`\n",
      "   168|         0|            0|            0|  0.00%|\n",
      "   169|         0|            0|            0|  0.00%|    Returns:\n",
      "   170|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   171|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   172|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   173|         0|            0|            0|  0.00%|\n",
      "   174|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   175|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook\n",
      "   176|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is False:\n",
      "   177|         0|            0|            0|  0.00%|        raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks as a \"\n",
      "   178|         0|            0|            0|  0.00%|                           \"global Module hook. Please use only one of them.\")\n",
      "   179|         0|            0|            0|  0.00%|\n",
      "   180|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = True\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)\n",
      "   183|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook\n",
      "   184|         0|            0|            0|  0.00%|    return handle\n",
      "   185|         0|            0|            0|  0.00%|\n",
      "   186|         0|            0|            0|  0.00%|\n",
      "   187|         0|            0|            0|  0.00%|# Trick mypy into not applying contravariance rules to inputs by defining\n",
      "   188|         0|            0|            0|  0.00%|# forward as a value, rather than a function.  See also\n",
      "   189|         0|            0|            0|  0.00%|# https://github.com/python/mypy/issues/8795\n",
      "   190|         0|            0|            0|  0.00%|def _forward_unimplemented(self, *input: Any) -> None:\n",
      "   191|         0|            0|            0|  0.00%|    r\"\"\"Defines the computation performed at every call.\n",
      "   192|         0|            0|            0|  0.00%|\n",
      "   193|         0|            0|            0|  0.00%|    Should be overridden by all subclasses.\n",
      "   194|         0|            0|            0|  0.00%|\n",
      "   195|         0|            0|            0|  0.00%|    .. note::\n",
      "   196|         0|            0|            0|  0.00%|        Although the recipe for forward pass needs to be defined within\n",
      "   197|         0|            0|            0|  0.00%|        this function, one should call the :class:`Module` instance afterwards\n",
      "   198|         0|            0|            0|  0.00%|        instead of this since the former takes care of running the\n",
      "   199|         0|            0|            0|  0.00%|        registered hooks while the latter silently ignores them.\n",
      "   200|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   201|         0|            0|            0|  0.00%|    raise NotImplementedError\n",
      "   202|         0|            0|            0|  0.00%|\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|class Module:\n",
      "   205|         0|            0|            0|  0.00%|    r\"\"\"Base class for all neural network modules.\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|    Your models should also subclass this class.\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|    Modules can also contain other Modules, allowing to nest them in\n",
      "   210|         0|            0|            0|  0.00%|    a tree structure. You can assign the submodules as regular attributes::\n",
      "   211|         0|            0|            0|  0.00%|\n",
      "   212|         0|            0|            0|  0.00%|        import torch.nn as nn\n",
      "   213|         0|            0|            0|  0.00%|        import torch.nn.functional as F\n",
      "   214|         0|            0|            0|  0.00%|\n",
      "   215|         0|            0|            0|  0.00%|        class Model(nn.Module):\n",
      "   216|         0|            0|            0|  0.00%|            def __init__(self):\n",
      "   217|         0|            0|            0|  0.00%|                super(Model, self).__init__()\n",
      "   218|         0|            0|            0|  0.00%|                self.conv1 = nn.Conv2d(1, 20, 5)\n",
      "   219|         0|            0|            0|  0.00%|                self.conv2 = nn.Conv2d(20, 20, 5)\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|            def forward(self, x):\n",
      "   222|         0|            0|            0|  0.00%|                x = F.relu(self.conv1(x))\n",
      "   223|         0|            0|            0|  0.00%|                return F.relu(self.conv2(x))\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|    Submodules assigned in this way will be registered, and will have their\n",
      "   226|         0|            0|            0|  0.00%|    parameters converted too when you call :meth:`to`, etc.\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    :ivar training: Boolean represents whether this module is in training or\n",
      "   229|         0|            0|            0|  0.00%|                    evaluation mode.\n",
      "   230|         0|            0|            0|  0.00%|    :vartype training: bool\n",
      "   231|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   232|         0|            0|            0|  0.00%|\n",
      "   233|         0|            0|            0|  0.00%|    dump_patches: bool = False\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    r\"\"\"This allows better BC support for :meth:`load_state_dict`. In\n",
      "   236|         0|            0|            0|  0.00%|    :meth:`state_dict`, the version number will be saved as in the attribute\n",
      "   237|         0|            0|            0|  0.00%|    `_metadata` of the returned state dict, and thus pickled. `_metadata` is a\n",
      "   238|         0|            0|            0|  0.00%|    dictionary with keys that follow the naming convention of state dict. See\n",
      "   239|         0|            0|            0|  0.00%|    ``_load_from_state_dict`` on how to use this information in loading.\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    If new parameters/buffers are added/removed from a module, this number shall\n",
      "   242|         0|            0|            0|  0.00%|    be bumped, and the module's `_load_from_state_dict` method can compare the\n",
      "   243|         0|            0|            0|  0.00%|    version number and do appropriate changes if the state dict is from before\n",
      "   244|         0|            0|            0|  0.00%|    the change.\"\"\"\n",
      "   245|         0|            0|            0|  0.00%|    _version: int = 1\n",
      "   246|         0|            0|            0|  0.00%|\n",
      "   247|         0|            0|            0|  0.00%|    training: bool\n",
      "   248|         0|            0|            0|  0.00%|    _is_full_backward_hook: Optional[bool]\n",
      "   249|         0|            0|            0|  0.00%|\n",
      "   250|         1|  3.09944e-06|  3.09944e-06|  0.00%|    def __init__(self) -> None:\n",
      "   251|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   252|         0|            0|            0|  0.00%|        Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "   253|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   254|         1|  1.09673e-05|  1.09673e-05|  0.00%|        torch._C._log_api_usage_once(\"python.nn_module\")\n",
      "   255|         0|            0|            0|  0.00%|\n",
      "   256|         1|  1.66893e-05|  1.66893e-05|  0.01%|        self.training = True\n",
      "(call)|         1|  6.31809e-05|  6.31809e-05|  0.03%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   257|         1|  1.28746e-05|  1.28746e-05|  0.01%|        self._parameters: Dict[str, Optional[Parameter]] = OrderedDict()\n",
      "(call)|         1|  3.40939e-05|  3.40939e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   258|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._buffers: Dict[str, Optional[Tensor]] = OrderedDict()\n",
      "(call)|         1|  3.29018e-05|  3.29018e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   259|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._non_persistent_buffers_set: Set[str] = set()\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   260|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._backward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   261|         1|  1.19209e-05|  1.19209e-05|  0.01%|        self._is_full_backward_hook = None\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   262|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._forward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   263|         1|  1.12057e-05|  1.12057e-05|  0.00%|        self._forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   264|         1|  1.19209e-05|  1.19209e-05|  0.01%|        self._state_dict_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.09944e-05|  3.09944e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   265|         1|  1.21593e-05|  1.21593e-05|  0.01%|        self._load_state_dict_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   266|         1|   1.4782e-05|   1.4782e-05|  0.01%|        self._modules: Dict[str, Optional['Module']] = OrderedDict()\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|    forward: Callable[..., Any] = _forward_unimplemented\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         1|  8.82149e-06|  8.82149e-06|  0.00%|    def register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True) -> None:\n",
      "   271|         0|            0|            0|  0.00%|        r\"\"\"Adds a buffer to the module.\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|        This is typically used to register a buffer that should not to be\n",
      "   274|         0|            0|            0|  0.00%|        considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      "   275|         0|            0|            0|  0.00%|        is not a parameter, but is part of the module's state. Buffers, by\n",
      "   276|         0|            0|            0|  0.00%|        default, are persistent and will be saved alongside parameters. This\n",
      "   277|         0|            0|            0|  0.00%|        behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      "   278|         0|            0|            0|  0.00%|        only difference between a persistent buffer and a non-persistent buffer\n",
      "   279|         0|            0|            0|  0.00%|        is that the latter will not be a part of this module's\n",
      "   280|         0|            0|            0|  0.00%|        :attr:`state_dict`.\n",
      "   281|         0|            0|            0|  0.00%|\n",
      "   282|         0|            0|            0|  0.00%|        Buffers can be accessed as attributes using given names.\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|        Args:\n",
      "   285|         0|            0|            0|  0.00%|            name (string): name of the buffer. The buffer can be accessed\n",
      "   286|         0|            0|            0|  0.00%|                from this module using the given name\n",
      "   287|         0|            0|            0|  0.00%|            tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      "   288|         0|            0|            0|  0.00%|                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      "   289|         0|            0|            0|  0.00%|                the buffer is **not** included in the module's :attr:`state_dict`.\n",
      "   290|         0|            0|            0|  0.00%|            persistent (bool): whether the buffer is part of this module's\n",
      "   291|         0|            0|            0|  0.00%|                :attr:`state_dict`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   292|         0|            0|            0|  0.00%|\n",
      "   293|         0|            0|            0|  0.00%|        Example::\n",
      "   294|         0|            0|            0|  0.00%|\n",
      "   295|         0|            0|            0|  0.00%|            >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      "   296|         0|            0|            0|  0.00%|\n",
      "   297|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   298|         1|  4.05312e-06|  4.05312e-06|  0.00%|        if persistent is False and isinstance(self, torch.jit.ScriptModule):\n",
      "   299|         0|            0|            0|  0.00%|            raise RuntimeError(\"ScriptModule does not support non-persistent buffers\")\n",
      "   300|         0|            0|            0|  0.00%|\n",
      "   301|         1|  5.00679e-06|  5.00679e-06|  0.00%|        if '_buffers' not in self.__dict__:\n",
      "   302|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   303|         0|            0|            0|  0.00%|                \"cannot assign buffer before Module.__init__() call\")\n",
      "   304|         1|  4.05312e-06|  4.05312e-06|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   305|         0|            0|            0|  0.00%|            raise TypeError(\"buffer name should be a string. \"\n",
      "   306|         0|            0|            0|  0.00%|                            \"Got {}\".format(torch.typename(name)))\n",
      "   307|         1|   3.8147e-06|   3.8147e-06|  0.00%|        elif '.' in name:\n",
      "   308|         0|            0|            0|  0.00%|            raise KeyError(\"buffer name can't contain \\\".\\\"\")\n",
      "   309|         1|  4.05312e-06|  4.05312e-06|  0.00%|        elif name == '':\n",
      "   310|         0|            0|            0|  0.00%|            raise KeyError(\"buffer name can't be empty string \\\"\\\"\")\n",
      "   311|         1|  1.40667e-05|  1.40667e-05|  0.01%|        elif hasattr(self, name) and name not in self._buffers:\n",
      "(call)|         1|  5.19753e-05|  5.19753e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "   312|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   313|         1|  5.00679e-06|  5.00679e-06|  0.00%|        elif tensor is not None and not isinstance(tensor, torch.Tensor):\n",
      "   314|         0|            0|            0|  0.00%|            raise TypeError(\"cannot assign '{}' object to buffer '{}' \"\n",
      "   315|         0|            0|            0|  0.00%|                            \"(torch Tensor or None required)\"\n",
      "   316|         0|            0|            0|  0.00%|                            .format(torch.typename(tensor), name))\n",
      "   317|         0|            0|            0|  0.00%|        else:\n",
      "   318|         1|  4.05312e-06|  4.05312e-06|  0.00%|            self._buffers[name] = tensor\n",
      "   319|         1|  4.05312e-06|  4.05312e-06|  0.00%|            if persistent:\n",
      "   320|         1|   3.8147e-06|   3.8147e-06|  0.00%|                self._non_persistent_buffers_set.discard(name)\n",
      "   321|         0|            0|            0|  0.00%|            else:\n",
      "   322|         0|            0|            0|  0.00%|                self._non_persistent_buffers_set.add(name)\n",
      "   323|         0|            0|            0|  0.00%|\n",
      "   324|         0|            0|            0|  0.00%|    def register_parameter(self, name: str, param: Optional[Parameter]) -> None:\n",
      "   325|         0|            0|            0|  0.00%|        r\"\"\"Adds a parameter to the module.\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|        The parameter can be accessed as an attribute using given name.\n",
      "   328|         0|            0|            0|  0.00%|\n",
      "   329|         0|            0|            0|  0.00%|        Args:\n",
      "   330|         0|            0|            0|  0.00%|            name (string): name of the parameter. The parameter can be accessed\n",
      "   331|         0|            0|            0|  0.00%|                from this module using the given name\n",
      "   332|         0|            0|            0|  0.00%|            param (Parameter or None): parameter to be added to the module. If\n",
      "   333|         0|            0|            0|  0.00%|                ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      "   334|         0|            0|            0|  0.00%|                are ignored. If ``None``, the parameter is **not** included in the\n",
      "   335|         0|            0|            0|  0.00%|                module's :attr:`state_dict`.\n",
      "   336|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   337|         0|            0|            0|  0.00%|        if '_parameters' not in self.__dict__:\n",
      "   338|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   339|         0|            0|            0|  0.00%|                \"cannot assign parameter before Module.__init__() call\")\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   342|         0|            0|            0|  0.00%|            raise TypeError(\"parameter name should be a string. \"\n",
      "   343|         0|            0|            0|  0.00%|                            \"Got {}\".format(torch.typename(name)))\n",
      "   344|         0|            0|            0|  0.00%|        elif '.' in name:\n",
      "   345|         0|            0|            0|  0.00%|            raise KeyError(\"parameter name can't contain \\\".\\\"\")\n",
      "   346|         0|            0|            0|  0.00%|        elif name == '':\n",
      "   347|         0|            0|            0|  0.00%|            raise KeyError(\"parameter name can't be empty string \\\"\\\"\")\n",
      "   348|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._parameters:\n",
      "   349|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|        if param is None:\n",
      "   352|         0|            0|            0|  0.00%|            self._parameters[name] = None\n",
      "   353|         0|            0|            0|  0.00%|        elif not isinstance(param, Parameter):\n",
      "   354|         0|            0|            0|  0.00%|            raise TypeError(\"cannot assign '{}' object to parameter '{}' \"\n",
      "   355|         0|            0|            0|  0.00%|                            \"(torch.nn.Parameter or None required)\"\n",
      "   356|         0|            0|            0|  0.00%|                            .format(torch.typename(param), name))\n",
      "   357|         0|            0|            0|  0.00%|        elif param.grad_fn:\n",
      "   358|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   359|         0|            0|            0|  0.00%|                \"Cannot assign non-leaf Tensor to parameter '{0}'. Model \"\n",
      "   360|         0|            0|            0|  0.00%|                \"parameters must be created explicitly. To express '{0}' \"\n",
      "   361|         0|            0|            0|  0.00%|                \"as a function of another Tensor, compute the value in \"\n",
      "   362|         0|            0|            0|  0.00%|                \"the forward() method.\".format(name))\n",
      "   363|         0|            0|            0|  0.00%|        else:\n",
      "   364|         0|            0|            0|  0.00%|            self._parameters[name] = param\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    def add_module(self, name: str, module: Optional['Module']) -> None:\n",
      "   367|         0|            0|            0|  0.00%|        r\"\"\"Adds a child module to the current module.\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|        The module can be accessed as an attribute using the given name.\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|        Args:\n",
      "   372|         0|            0|            0|  0.00%|            name (string): name of the child module. The child module can be\n",
      "   373|         0|            0|            0|  0.00%|                accessed from this module using the given name\n",
      "   374|         0|            0|            0|  0.00%|            module (Module): child module to be added to the module.\n",
      "   375|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   376|         0|            0|            0|  0.00%|        if not isinstance(module, Module) and module is not None:\n",
      "   377|         0|            0|            0|  0.00%|            raise TypeError(\"{} is not a Module subclass\".format(\n",
      "   378|         0|            0|            0|  0.00%|                torch.typename(module)))\n",
      "   379|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   380|         0|            0|            0|  0.00%|            raise TypeError(\"module name should be a string. Got {}\".format(\n",
      "   381|         0|            0|            0|  0.00%|                torch.typename(name)))\n",
      "   382|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._modules:\n",
      "   383|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   384|         0|            0|            0|  0.00%|        elif '.' in name:\n",
      "   385|         0|            0|            0|  0.00%|            raise KeyError(\"module name can't contain \\\".\\\", got: {}\".format(name))\n",
      "   386|         0|            0|            0|  0.00%|        elif name == '':\n",
      "   387|         0|            0|            0|  0.00%|            raise KeyError(\"module name can't be empty string \\\"\\\"\")\n",
      "   388|         0|            0|            0|  0.00%|        self._modules[name] = module\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    def get_submodule(self, target: str) -> \"Module\":\n",
      "   391|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   392|         0|            0|            0|  0.00%|        Returns the submodule given by ``target`` if it exists,\n",
      "   393|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   394|         0|            0|            0|  0.00%|\n",
      "   395|         0|            0|            0|  0.00%|        For example, let's say you have an ``nn.Module`` ``A`` that\n",
      "   396|         0|            0|            0|  0.00%|        looks like this:\n",
      "   397|         0|            0|            0|  0.00%|\n",
      "   398|         0|            0|            0|  0.00%|        .. code-block::text\n",
      "   399|         0|            0|            0|  0.00%|\n",
      "   400|         0|            0|            0|  0.00%|            A(\n",
      "   401|         0|            0|            0|  0.00%|                (net_b): Module(\n",
      "   402|         0|            0|            0|  0.00%|                    (net_c): Module(\n",
      "   403|         0|            0|            0|  0.00%|                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      "   404|         0|            0|            0|  0.00%|                    )\n",
      "   405|         0|            0|            0|  0.00%|                    (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      "   406|         0|            0|            0|  0.00%|                )\n",
      "   407|         0|            0|            0|  0.00%|            )\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      "   410|         0|            0|            0|  0.00%|        submodule ``net_b``, which itself has two submodules ``net_c``\n",
      "   411|         0|            0|            0|  0.00%|        and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      "   412|         0|            0|            0|  0.00%|\n",
      "   413|         0|            0|            0|  0.00%|        To check whether or not we have the ``linear`` submodule, we\n",
      "   414|         0|            0|            0|  0.00%|        would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      "   415|         0|            0|            0|  0.00%|        we have the ``conv`` submodule, we would call\n",
      "   416|         0|            0|            0|  0.00%|        ``get_submodule(\"net_b.net_c.conv\")``.\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|        The runtime of ``get_submodule`` is bounded by the degree\n",
      "   419|         0|            0|            0|  0.00%|        of module nesting in ``target``. A query against\n",
      "   420|         0|            0|            0|  0.00%|        ``named_modules`` achieves the same result, but it is O(N) in\n",
      "   421|         0|            0|            0|  0.00%|        the number of transitive modules. So, for a simple check to see\n",
      "   422|         0|            0|            0|  0.00%|        if some submodule exists, ``get_submodule`` should always be\n",
      "   423|         0|            0|            0|  0.00%|        used.\n",
      "   424|         0|            0|            0|  0.00%|\n",
      "   425|         0|            0|            0|  0.00%|        Args:\n",
      "   426|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the submodule\n",
      "   427|         0|            0|            0|  0.00%|                to look for. (See above example for how to specify a\n",
      "   428|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   429|         0|            0|            0|  0.00%|\n",
      "   430|         0|            0|            0|  0.00%|        Returns:\n",
      "   431|         0|            0|            0|  0.00%|            torch.nn.Module: The submodule referenced by ``target``\n",
      "   432|         0|            0|            0|  0.00%|\n",
      "   433|         0|            0|            0|  0.00%|        Raises:\n",
      "   434|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   435|         0|            0|            0|  0.00%|                path or resolves to something that is not an\n",
      "   436|         0|            0|            0|  0.00%|                ``nn.Module``\n",
      "   437|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   438|         0|            0|            0|  0.00%|        if target == \"\":\n",
      "   439|         0|            0|            0|  0.00%|            return self\n",
      "   440|         0|            0|            0|  0.00%|\n",
      "   441|         0|            0|            0|  0.00%|        atoms: List[str] = target.split(\".\")\n",
      "   442|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|        for item in atoms:\n",
      "   445|         0|            0|            0|  0.00%|\n",
      "   446|         0|            0|            0|  0.00%|            if not hasattr(mod, item):\n",
      "   447|         0|            0|            0|  0.00%|                raise AttributeError(mod._get_name() + \" has no \"\n",
      "   448|         0|            0|            0|  0.00%|                                     \"attribute `\" + item + \"`\")\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|            mod = getattr(mod, item)\n",
      "   451|         0|            0|            0|  0.00%|\n",
      "   452|         0|            0|            0|  0.00%|            if not isinstance(mod, torch.nn.Module):\n",
      "   453|         0|            0|            0|  0.00%|                raise AttributeError(\"`\" + item + \"` is not \"\n",
      "   454|         0|            0|            0|  0.00%|                                     \"an nn.Module\")\n",
      "   455|         0|            0|            0|  0.00%|\n",
      "   456|         0|            0|            0|  0.00%|        return mod\n",
      "   457|         0|            0|            0|  0.00%|\n",
      "   458|         0|            0|            0|  0.00%|    def get_parameter(self, target: str) -> \"Parameter\":\n",
      "   459|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   460|         0|            0|            0|  0.00%|        Returns the parameter given by ``target`` if it exists,\n",
      "   461|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   462|         0|            0|            0|  0.00%|\n",
      "   463|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed\n",
      "   464|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to\n",
      "   465|         0|            0|            0|  0.00%|        correctly specify ``target``.\n",
      "   466|         0|            0|            0|  0.00%|\n",
      "   467|         0|            0|            0|  0.00%|        Args:\n",
      "   468|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the Parameter\n",
      "   469|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a\n",
      "   470|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   471|         0|            0|            0|  0.00%|\n",
      "   472|         0|            0|            0|  0.00%|        Returns:\n",
      "   473|         0|            0|            0|  0.00%|            torch.nn.Parameter: The Parameter referenced by ``target``\n",
      "   474|         0|            0|            0|  0.00%|\n",
      "   475|         0|            0|            0|  0.00%|        Raises:\n",
      "   476|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   477|         0|            0|            0|  0.00%|                path or resolves to something that is not an\n",
      "   478|         0|            0|            0|  0.00%|                ``nn.Parameter``\n",
      "   479|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   480|         0|            0|            0|  0.00%|        module_path, _, param_name = target.rpartition(\".\")\n",
      "   481|         0|            0|            0|  0.00%|\n",
      "   482|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)\n",
      "   483|         0|            0|            0|  0.00%|\n",
      "   484|         0|            0|            0|  0.00%|        if not hasattr(mod, param_name):\n",
      "   485|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + \" has no attribute `\"\n",
      "   486|         0|            0|            0|  0.00%|                                 + param_name + \"`\")\n",
      "   487|         0|            0|            0|  0.00%|\n",
      "   488|         0|            0|            0|  0.00%|        param: torch.nn.Parameter = getattr(mod, param_name)\n",
      "   489|         0|            0|            0|  0.00%|\n",
      "   490|         0|            0|            0|  0.00%|        if not isinstance(param, torch.nn.Parameter):\n",
      "   491|         0|            0|            0|  0.00%|            raise AttributeError(\"`\" + param_name + \"` is not an \"\n",
      "   492|         0|            0|            0|  0.00%|                                 \"nn.Parameter\")\n",
      "   493|         0|            0|            0|  0.00%|\n",
      "   494|         0|            0|            0|  0.00%|        return param\n",
      "   495|         0|            0|            0|  0.00%|\n",
      "   496|         0|            0|            0|  0.00%|    def get_buffer(self, target: str) -> \"Tensor\":\n",
      "   497|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   498|         0|            0|            0|  0.00%|        Returns the buffer given by ``target`` if it exists,\n",
      "   499|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   500|         0|            0|            0|  0.00%|\n",
      "   501|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed\n",
      "   502|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to\n",
      "   503|         0|            0|            0|  0.00%|        correctly specify ``target``.\n",
      "   504|         0|            0|            0|  0.00%|\n",
      "   505|         0|            0|            0|  0.00%|        Args:\n",
      "   506|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the buffer\n",
      "   507|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a\n",
      "   508|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   509|         0|            0|            0|  0.00%|\n",
      "   510|         0|            0|            0|  0.00%|        Returns:\n",
      "   511|         0|            0|            0|  0.00%|            torch.Tensor: The buffer referenced by ``target``\n",
      "   512|         0|            0|            0|  0.00%|\n",
      "   513|         0|            0|            0|  0.00%|        Raises:\n",
      "   514|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   515|         0|            0|            0|  0.00%|                path or resolves to something that is not a\n",
      "   516|         0|            0|            0|  0.00%|                buffer\n",
      "   517|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   518|         0|            0|            0|  0.00%|        module_path, _, buffer_name = target.rpartition(\".\")\n",
      "   519|         0|            0|            0|  0.00%|\n",
      "   520|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)\n",
      "   521|         0|            0|            0|  0.00%|\n",
      "   522|         0|            0|            0|  0.00%|        if not hasattr(mod, buffer_name):\n",
      "   523|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + \" has no attribute `\"\n",
      "   524|         0|            0|            0|  0.00%|                                 + buffer_name + \"`\")\n",
      "   525|         0|            0|            0|  0.00%|\n",
      "   526|         0|            0|            0|  0.00%|        buffer: torch.Tensor = getattr(mod, buffer_name)\n",
      "   527|         0|            0|            0|  0.00%|\n",
      "   528|         0|            0|            0|  0.00%|        if buffer_name not in mod._buffers:\n",
      "   529|         0|            0|            0|  0.00%|            raise AttributeError(\"`\" + buffer_name + \"` is not a buffer\")\n",
      "   530|         0|            0|            0|  0.00%|\n",
      "   531|         0|            0|            0|  0.00%|        return buffer\n",
      "   532|         0|            0|            0|  0.00%|\n",
      "   533|         0|            0|            0|  0.00%|    def get_extra_state(self) -> Any:\n",
      "   534|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   535|         0|            0|            0|  0.00%|        Returns any extra state to include in the module's state_dict.\n",
      "   536|         0|            0|            0|  0.00%|        Implement this and a corresponding :func:`set_extra_state` for your module\n",
      "   537|         0|            0|            0|  0.00%|        if you need to store extra state. This function is called when building the\n",
      "   538|         0|            0|            0|  0.00%|        module's `state_dict()`.\n",
      "   539|         0|            0|            0|  0.00%|\n",
      "   540|         0|            0|            0|  0.00%|        Note that extra state should be pickleable to ensure working serialization\n",
      "   541|         0|            0|            0|  0.00%|        of the state_dict. We only provide provide backwards compatibility guarantees\n",
      "   542|         0|            0|            0|  0.00%|        for serializing Tensors; other objects may break backwards compatibility if\n",
      "   543|         0|            0|            0|  0.00%|        their serialized pickled form changes.\n",
      "   544|         0|            0|            0|  0.00%|\n",
      "   545|         0|            0|            0|  0.00%|        Returns:\n",
      "   546|         0|            0|            0|  0.00%|            object: Any extra state to store in the module's state_dict\n",
      "   547|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   548|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   549|         0|            0|            0|  0.00%|            \"Reached a code path in Module.get_extra_state() that should never be called. \"\n",
      "   550|         0|            0|            0|  0.00%|            \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   551|         0|            0|            0|  0.00%|            \"to report this bug.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   552|         0|            0|            0|  0.00%|\n",
      "   553|         0|            0|            0|  0.00%|    def set_extra_state(self, state: Any):\n",
      "   554|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   555|         0|            0|            0|  0.00%|        This function is called from :func:`load_state_dict` to handle any extra state\n",
      "   556|         0|            0|            0|  0.00%|        found within the `state_dict`. Implement this function and a corresponding\n",
      "   557|         0|            0|            0|  0.00%|        :func:`get_extra_state` for your module if you need to store extra state within its\n",
      "   558|         0|            0|            0|  0.00%|        `state_dict`.\n",
      "   559|         0|            0|            0|  0.00%|\n",
      "   560|         0|            0|            0|  0.00%|        Args:\n",
      "   561|         0|            0|            0|  0.00%|            state (dict): Extra state from the `state_dict`\n",
      "   562|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   563|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   564|         0|            0|            0|  0.00%|            \"Reached a code path in Module.set_extra_state() that should never be called. \"\n",
      "   565|         0|            0|            0|  0.00%|            \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   566|         0|            0|            0|  0.00%|            \"to report this bug.\")\n",
      "   567|         0|            0|            0|  0.00%|\n",
      "   568|         0|            0|            0|  0.00%|    def _apply(self, fn):\n",
      "   569|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "   570|         0|            0|            0|  0.00%|            module._apply(fn)\n",
      "   571|         0|            0|            0|  0.00%|\n",
      "   572|         0|            0|            0|  0.00%|        def compute_should_use_set_data(tensor, tensor_applied):\n",
      "   573|         0|            0|            0|  0.00%|            if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
      "   574|         0|            0|            0|  0.00%|                # If the new tensor has compatible tensor type as the existing tensor,\n",
      "   575|         0|            0|            0|  0.00%|                # the current behavior is to change the tensor in-place using `.data =`,\n",
      "   576|         0|            0|            0|  0.00%|                # and the future behavior is to overwrite the existing tensor. However,\n",
      "   577|         0|            0|            0|  0.00%|                # changing the current behavior is a BC-breaking change, and we want it\n",
      "   578|         0|            0|            0|  0.00%|                # to happen in future releases. So for now we introduce the\n",
      "   579|         0|            0|            0|  0.00%|                # `torch.__future__.get_overwrite_module_params_on_conversion()`\n",
      "   580|         0|            0|            0|  0.00%|                # global flag to let the user control whether they want the future\n",
      "   581|         0|            0|            0|  0.00%|                # behavior of overwriting the existing tensor or not.\n",
      "   582|         0|            0|            0|  0.00%|                return not torch.__future__.get_overwrite_module_params_on_conversion()\n",
      "   583|         0|            0|            0|  0.00%|            else:\n",
      "   584|         0|            0|            0|  0.00%|                return False\n",
      "   585|         0|            0|            0|  0.00%|\n",
      "   586|         0|            0|            0|  0.00%|        for key, param in self._parameters.items():\n",
      "   587|         0|            0|            0|  0.00%|            if param is None:\n",
      "   588|         0|            0|            0|  0.00%|                continue\n",
      "   589|         0|            0|            0|  0.00%|            # Tensors stored in modules are graph leaves, and we don't want to\n",
      "   590|         0|            0|            0|  0.00%|            # track autograd history of `param_applied`, so we have to use\n",
      "   591|         0|            0|            0|  0.00%|            # `with torch.no_grad():`\n",
      "   592|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   593|         0|            0|            0|  0.00%|                param_applied = fn(param)\n",
      "   594|         0|            0|            0|  0.00%|            should_use_set_data = compute_should_use_set_data(param, param_applied)\n",
      "   595|         0|            0|            0|  0.00%|            if should_use_set_data:\n",
      "   596|         0|            0|            0|  0.00%|                param.data = param_applied\n",
      "   597|         0|            0|            0|  0.00%|                out_param = param\n",
      "   598|         0|            0|            0|  0.00%|            else:\n",
      "   599|         0|            0|            0|  0.00%|                assert isinstance(param, Parameter)\n",
      "   600|         0|            0|            0|  0.00%|                assert param.is_leaf\n",
      "   601|         0|            0|            0|  0.00%|                out_param = Parameter(param_applied, param.requires_grad)\n",
      "   602|         0|            0|            0|  0.00%|                self._parameters[key] = out_param\n",
      "   603|         0|            0|            0|  0.00%|\n",
      "   604|         0|            0|            0|  0.00%|            if param.grad is not None:\n",
      "   605|         0|            0|            0|  0.00%|                with torch.no_grad():\n",
      "   606|         0|            0|            0|  0.00%|                    grad_applied = fn(param.grad)\n",
      "   607|         0|            0|            0|  0.00%|                should_use_set_data = compute_should_use_set_data(param.grad, grad_applied)\n",
      "   608|         0|            0|            0|  0.00%|                if should_use_set_data:\n",
      "   609|         0|            0|            0|  0.00%|                    out_param.grad.data = grad_applied\n",
      "   610|         0|            0|            0|  0.00%|                else:\n",
      "   611|         0|            0|            0|  0.00%|                    assert param.grad.is_leaf\n",
      "   612|         0|            0|            0|  0.00%|                    out_param.grad = grad_applied.requires_grad_(param.grad.requires_grad)\n",
      "   613|         0|            0|            0|  0.00%|\n",
      "   614|         0|            0|            0|  0.00%|        for key, buf in self._buffers.items():\n",
      "   615|         0|            0|            0|  0.00%|            if buf is not None:\n",
      "   616|         0|            0|            0|  0.00%|                self._buffers[key] = fn(buf)\n",
      "   617|         0|            0|            0|  0.00%|\n",
      "   618|         0|            0|            0|  0.00%|        return self\n",
      "   619|         0|            0|            0|  0.00%|\n",
      "   620|         0|            0|            0|  0.00%|    def apply(self: T, fn: Callable[['Module'], None]) -> T:\n",
      "   621|         0|            0|            0|  0.00%|        r\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      "   622|         0|            0|            0|  0.00%|        as well as self. Typical use includes initializing the parameters of a model\n",
      "   623|         0|            0|            0|  0.00%|        (see also :ref:`nn-init-doc`).\n",
      "   624|         0|            0|            0|  0.00%|\n",
      "   625|         0|            0|            0|  0.00%|        Args:\n",
      "   626|         0|            0|            0|  0.00%|            fn (:class:`Module` -> None): function to be applied to each submodule\n",
      "   627|         0|            0|            0|  0.00%|\n",
      "   628|         0|            0|            0|  0.00%|        Returns:\n",
      "   629|         0|            0|            0|  0.00%|            Module: self\n",
      "   630|         0|            0|            0|  0.00%|\n",
      "   631|         0|            0|            0|  0.00%|        Example::\n",
      "   632|         0|            0|            0|  0.00%|\n",
      "   633|         0|            0|            0|  0.00%|            >>> @torch.no_grad()\n",
      "   634|         0|            0|            0|  0.00%|            >>> def init_weights(m):\n",
      "   635|         0|            0|            0|  0.00%|            >>>     print(m)\n",
      "   636|         0|            0|            0|  0.00%|            >>>     if type(m) == nn.Linear:\n",
      "   637|         0|            0|            0|  0.00%|            >>>         m.weight.fill_(1.0)\n",
      "   638|         0|            0|            0|  0.00%|            >>>         print(m.weight)\n",
      "   639|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      "   640|         0|            0|            0|  0.00%|            >>> net.apply(init_weights)\n",
      "   641|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   642|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   643|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],\n",
      "   644|         0|            0|            0|  0.00%|                    [ 1.,  1.]])\n",
      "   645|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   646|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   647|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],\n",
      "   648|         0|            0|            0|  0.00%|                    [ 1.,  1.]])\n",
      "   649|         0|            0|            0|  0.00%|            Sequential(\n",
      "   650|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "   651|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "   652|         0|            0|            0|  0.00%|            )\n",
      "   653|         0|            0|            0|  0.00%|            Sequential(\n",
      "   654|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "   655|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "   656|         0|            0|            0|  0.00%|            )\n",
      "   657|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   658|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "   659|         0|            0|            0|  0.00%|            module.apply(fn)\n",
      "   660|         0|            0|            0|  0.00%|        fn(self)\n",
      "   661|         0|            0|            0|  0.00%|        return self\n",
      "   662|         0|            0|            0|  0.00%|\n",
      "   663|         0|            0|            0|  0.00%|    def cuda(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
      "   664|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the GPU.\n",
      "   665|         0|            0|            0|  0.00%|\n",
      "   666|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So\n",
      "   667|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will\n",
      "   668|         0|            0|            0|  0.00%|        live on GPU while being optimized.\n",
      "   669|         0|            0|            0|  0.00%|\n",
      "   670|         0|            0|            0|  0.00%|        .. note::\n",
      "   671|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   672|         0|            0|            0|  0.00%|\n",
      "   673|         0|            0|            0|  0.00%|        Args:\n",
      "   674|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be\n",
      "   675|         0|            0|            0|  0.00%|                copied to that device\n",
      "   676|         0|            0|            0|  0.00%|\n",
      "   677|         0|            0|            0|  0.00%|        Returns:\n",
      "   678|         0|            0|            0|  0.00%|            Module: self\n",
      "   679|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   680|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cuda(device))\n",
      "   681|         0|            0|            0|  0.00%|\n",
      "   682|         0|            0|            0|  0.00%|    def xpu(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
      "   683|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the XPU.\n",
      "   684|         0|            0|            0|  0.00%|\n",
      "   685|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So\n",
      "   686|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will\n",
      "   687|         0|            0|            0|  0.00%|        live on XPU while being optimized.\n",
      "   688|         0|            0|            0|  0.00%|\n",
      "   689|         0|            0|            0|  0.00%|        .. note::\n",
      "   690|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   691|         0|            0|            0|  0.00%|\n",
      "   692|         0|            0|            0|  0.00%|        Arguments:\n",
      "   693|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be\n",
      "   694|         0|            0|            0|  0.00%|                copied to that device\n",
      "   695|         0|            0|            0|  0.00%|\n",
      "   696|         0|            0|            0|  0.00%|        Returns:\n",
      "   697|         0|            0|            0|  0.00%|            Module: self\n",
      "   698|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   699|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.xpu(device))\n",
      "   700|         0|            0|            0|  0.00%|\n",
      "   701|         0|            0|            0|  0.00%|    def cpu(self: T) -> T:\n",
      "   702|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the CPU.\n",
      "   703|         0|            0|            0|  0.00%|\n",
      "   704|         0|            0|            0|  0.00%|        .. note::\n",
      "   705|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   706|         0|            0|            0|  0.00%|\n",
      "   707|         0|            0|            0|  0.00%|        Returns:\n",
      "   708|         0|            0|            0|  0.00%|            Module: self\n",
      "   709|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   710|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cpu())\n",
      "   711|         0|            0|            0|  0.00%|\n",
      "   712|         0|            0|            0|  0.00%|    def type(self: T, dst_type: Union[dtype, str]) -> T:\n",
      "   713|         0|            0|            0|  0.00%|        r\"\"\"Casts all parameters and buffers to :attr:`dst_type`.\n",
      "   714|         0|            0|            0|  0.00%|\n",
      "   715|         0|            0|            0|  0.00%|        .. note::\n",
      "   716|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   717|         0|            0|            0|  0.00%|\n",
      "   718|         0|            0|            0|  0.00%|        Args:\n",
      "   719|         0|            0|            0|  0.00%|            dst_type (type or string): the desired type\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|        Returns:\n",
      "   722|         0|            0|            0|  0.00%|            Module: self\n",
      "   723|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   724|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.type(dst_type))\n",
      "   725|         0|            0|            0|  0.00%|\n",
      "   726|         0|            0|            0|  0.00%|    def float(self: T) -> T:\n",
      "   727|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``float`` datatype.\n",
      "   728|         0|            0|            0|  0.00%|\n",
      "   729|         0|            0|            0|  0.00%|        .. note::\n",
      "   730|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   731|         0|            0|            0|  0.00%|\n",
      "   732|         0|            0|            0|  0.00%|        Returns:\n",
      "   733|         0|            0|            0|  0.00%|            Module: self\n",
      "   734|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   735|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.float() if t.is_floating_point() else t)\n",
      "   736|         0|            0|            0|  0.00%|\n",
      "   737|         0|            0|            0|  0.00%|    def double(self: T) -> T:\n",
      "   738|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``double`` datatype.\n",
      "   739|         0|            0|            0|  0.00%|\n",
      "   740|         0|            0|            0|  0.00%|        .. note::\n",
      "   741|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   742|         0|            0|            0|  0.00%|\n",
      "   743|         0|            0|            0|  0.00%|        Returns:\n",
      "   744|         0|            0|            0|  0.00%|            Module: self\n",
      "   745|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   746|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.double() if t.is_floating_point() else t)\n",
      "   747|         0|            0|            0|  0.00%|\n",
      "   748|         0|            0|            0|  0.00%|    def half(self: T) -> T:\n",
      "   749|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``half`` datatype.\n",
      "   750|         0|            0|            0|  0.00%|\n",
      "   751|         0|            0|            0|  0.00%|        .. note::\n",
      "   752|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   753|         0|            0|            0|  0.00%|\n",
      "   754|         0|            0|            0|  0.00%|        Returns:\n",
      "   755|         0|            0|            0|  0.00%|            Module: self\n",
      "   756|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   757|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.half() if t.is_floating_point() else t)\n",
      "   758|         0|            0|            0|  0.00%|\n",
      "   759|         0|            0|            0|  0.00%|    def bfloat16(self: T) -> T:\n",
      "   760|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|        .. note::\n",
      "   763|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   764|         0|            0|            0|  0.00%|\n",
      "   765|         0|            0|            0|  0.00%|        Returns:\n",
      "   766|         0|            0|            0|  0.00%|            Module: self\n",
      "   767|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   768|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.bfloat16() if t.is_floating_point() else t)\n",
      "   769|         0|            0|            0|  0.00%|\n",
      "   770|         0|            0|            0|  0.00%|    def to_empty(self: T, *, device: Union[str, device]) -> T:\n",
      "   771|         0|            0|            0|  0.00%|        r\"\"\"Moves the parameters and buffers to the specified device without copying storage.\n",
      "   772|         0|            0|            0|  0.00%|\n",
      "   773|         0|            0|            0|  0.00%|        Args:\n",
      "   774|         0|            0|            0|  0.00%|            device (:class:`torch.device`): The desired device of the parameters\n",
      "   775|         0|            0|            0|  0.00%|                and buffers in this module.\n",
      "   776|         0|            0|            0|  0.00%|\n",
      "   777|         0|            0|            0|  0.00%|        Returns:\n",
      "   778|         0|            0|            0|  0.00%|            Module: self\n",
      "   779|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   780|         0|            0|            0|  0.00%|        return self._apply(lambda t: torch.empty_like(t, device=device))\n",
      "   781|         0|            0|            0|  0.00%|\n",
      "   782|         0|            0|            0|  0.00%|    @overload\n",
      "   783|         0|            0|            0|  0.00%|    def to(self: T, device: Optional[Union[int, device]] = ..., dtype: Optional[Union[dtype, str]] = ...,\n",
      "   784|         0|            0|            0|  0.00%|           non_blocking: bool = ...) -> T:\n",
      "   785|         0|            0|            0|  0.00%|        ...\n",
      "   786|         0|            0|            0|  0.00%|\n",
      "   787|         0|            0|            0|  0.00%|    @overload\n",
      "   788|         0|            0|            0|  0.00%|    def to(self: T, dtype: Union[dtype, str], non_blocking: bool = ...) -> T:\n",
      "   789|         0|            0|            0|  0.00%|        ...\n",
      "   790|         0|            0|            0|  0.00%|\n",
      "   791|         0|            0|            0|  0.00%|    @overload\n",
      "   792|         0|            0|            0|  0.00%|    def to(self: T, tensor: Tensor, non_blocking: bool = ...) -> T:\n",
      "   793|         0|            0|            0|  0.00%|        ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   794|         0|            0|            0|  0.00%|\n",
      "   795|         0|            0|            0|  0.00%|    def to(self, *args, **kwargs):\n",
      "   796|         0|            0|            0|  0.00%|        r\"\"\"Moves and/or casts the parameters and buffers.\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|        This can be called as\n",
      "   799|         0|            0|            0|  0.00%|\n",
      "   800|         0|            0|            0|  0.00%|        .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      "   801|         0|            0|            0|  0.00%|           :noindex:\n",
      "   802|         0|            0|            0|  0.00%|\n",
      "   803|         0|            0|            0|  0.00%|        .. function:: to(dtype, non_blocking=False)\n",
      "   804|         0|            0|            0|  0.00%|           :noindex:\n",
      "   805|         0|            0|            0|  0.00%|\n",
      "   806|         0|            0|            0|  0.00%|        .. function:: to(tensor, non_blocking=False)\n",
      "   807|         0|            0|            0|  0.00%|           :noindex:\n",
      "   808|         0|            0|            0|  0.00%|\n",
      "   809|         0|            0|            0|  0.00%|        .. function:: to(memory_format=torch.channels_last)\n",
      "   810|         0|            0|            0|  0.00%|           :noindex:\n",
      "   811|         0|            0|            0|  0.00%|\n",
      "   812|         0|            0|            0|  0.00%|        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      "   813|         0|            0|            0|  0.00%|        floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      "   814|         0|            0|            0|  0.00%|        only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      "   815|         0|            0|            0|  0.00%|        (if given). The integral parameters and buffers will be moved\n",
      "   816|         0|            0|            0|  0.00%|        :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      "   817|         0|            0|            0|  0.00%|        :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      "   818|         0|            0|            0|  0.00%|        with respect to the host if possible, e.g., moving CPU Tensors with\n",
      "   819|         0|            0|            0|  0.00%|        pinned memory to CUDA devices.\n",
      "   820|         0|            0|            0|  0.00%|\n",
      "   821|         0|            0|            0|  0.00%|        See below for examples.\n",
      "   822|         0|            0|            0|  0.00%|\n",
      "   823|         0|            0|            0|  0.00%|        .. note::\n",
      "   824|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   825|         0|            0|            0|  0.00%|\n",
      "   826|         0|            0|            0|  0.00%|        Args:\n",
      "   827|         0|            0|            0|  0.00%|            device (:class:`torch.device`): the desired device of the parameters\n",
      "   828|         0|            0|            0|  0.00%|                and buffers in this module\n",
      "   829|         0|            0|            0|  0.00%|            dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      "   830|         0|            0|            0|  0.00%|                the parameters and buffers in this module\n",
      "   831|         0|            0|            0|  0.00%|            tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      "   832|         0|            0|            0|  0.00%|                dtype and device for all parameters and buffers in this module\n",
      "   833|         0|            0|            0|  0.00%|            memory_format (:class:`torch.memory_format`): the desired memory\n",
      "   834|         0|            0|            0|  0.00%|                format for 4D parameters and buffers in this module (keyword\n",
      "   835|         0|            0|            0|  0.00%|                only argument)\n",
      "   836|         0|            0|            0|  0.00%|\n",
      "   837|         0|            0|            0|  0.00%|        Returns:\n",
      "   838|         0|            0|            0|  0.00%|            Module: self\n",
      "   839|         0|            0|            0|  0.00%|\n",
      "   840|         0|            0|            0|  0.00%|        Examples::\n",
      "   841|         0|            0|            0|  0.00%|\n",
      "   842|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2)\n",
      "   843|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   844|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   845|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],\n",
      "   846|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]])\n",
      "   847|         0|            0|            0|  0.00%|            >>> linear.to(torch.double)\n",
      "   848|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   849|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   850|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   851|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],\n",
      "   852|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]], dtype=torch.float64)\n",
      "   853|         0|            0|            0|  0.00%|            >>> gpu1 = torch.device(\"cuda:1\")\n",
      "   854|         0|            0|            0|  0.00%|            >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      "   855|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   856|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   857|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   858|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],\n",
      "   859|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      "   860|         0|            0|            0|  0.00%|            >>> cpu = torch.device(\"cpu\")\n",
      "   861|         0|            0|            0|  0.00%|            >>> linear.to(cpu)\n",
      "   862|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   863|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   864|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   865|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],\n",
      "   866|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16)\n",
      "   867|         0|            0|            0|  0.00%|\n",
      "   868|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      "   869|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   870|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   871|         0|            0|            0|  0.00%|            tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      "   872|         0|            0|            0|  0.00%|                    [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      "   873|         0|            0|            0|  0.00%|            >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      "   874|         0|            0|            0|  0.00%|            tensor([[0.6122+0.j, 0.1150+0.j],\n",
      "   875|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j],\n",
      "   876|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      "   877|         0|            0|            0|  0.00%|\n",
      "   878|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   879|         0|            0|            0|  0.00%|\n",
      "   880|         0|            0|            0|  0.00%|        device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n",
      "   881|         0|            0|            0|  0.00%|\n",
      "   882|         0|            0|            0|  0.00%|        if dtype is not None:\n",
      "   883|         0|            0|            0|  0.00%|            if not (dtype.is_floating_point or dtype.is_complex):\n",
      "   884|         0|            0|            0|  0.00%|                raise TypeError('nn.Module.to only accepts floating point or complex '\n",
      "   885|         0|            0|            0|  0.00%|                                'dtypes, but got desired dtype={}'.format(dtype))\n",
      "   886|         0|            0|            0|  0.00%|            if dtype.is_complex:\n",
      "   887|         0|            0|            0|  0.00%|                warnings.warn(\n",
      "   888|         0|            0|            0|  0.00%|                    \"Complex modules are a new feature under active development whose design may change, \"\n",
      "   889|         0|            0|            0|  0.00%|                    \"and some modules might not work as expected when using complex tensors as parameters or buffers. \"\n",
      "   890|         0|            0|            0|  0.00%|                    \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   891|         0|            0|            0|  0.00%|                    \"if a complex module does not work as expected.\")\n",
      "   892|         0|            0|            0|  0.00%|\n",
      "   893|         0|            0|            0|  0.00%|        def convert(t):\n",
      "   894|         0|            0|            0|  0.00%|            if convert_to_format is not None and t.dim() in (4, 5):\n",
      "   895|         0|            0|            0|  0.00%|                return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n",
      "   896|         0|            0|            0|  0.00%|                            non_blocking, memory_format=convert_to_format)\n",
      "   897|         0|            0|            0|  0.00%|            return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|        return self._apply(convert)\n",
      "   900|         0|            0|            0|  0.00%|\n",
      "   901|         0|            0|            0|  0.00%|    def register_backward_hook(\n",
      "   902|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   903|         0|            0|            0|  0.00%|    ) -> RemovableHandle:\n",
      "   904|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook on the module.\n",
      "   905|         0|            0|            0|  0.00%|\n",
      "   906|         0|            0|            0|  0.00%|        This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      "   907|         0|            0|            0|  0.00%|        the behavior of this function will change in future versions.\n",
      "   908|         0|            0|            0|  0.00%|\n",
      "   909|         0|            0|            0|  0.00%|        Returns:\n",
      "   910|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   911|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "   912|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "   913|         0|            0|            0|  0.00%|\n",
      "   914|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   915|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is True:\n",
      "   916|         0|            0|            0|  0.00%|            raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n",
      "   917|         0|            0|            0|  0.00%|                               \"single Module. Please use only one of them.\")\n",
      "   918|         0|            0|            0|  0.00%|\n",
      "   919|         0|            0|            0|  0.00%|        self._is_full_backward_hook = False\n",
      "   920|         0|            0|            0|  0.00%|\n",
      "   921|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   922|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   923|         0|            0|            0|  0.00%|        return handle\n",
      "   924|         0|            0|            0|  0.00%|\n",
      "   925|         0|            0|            0|  0.00%|    def register_full_backward_hook(\n",
      "   926|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   927|         0|            0|            0|  0.00%|    ) -> RemovableHandle:\n",
      "   928|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook on the module.\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|        The hook will be called every time the gradients with respect to module\n",
      "   931|         0|            0|            0|  0.00%|        inputs are computed. The hook should have the following signature::\n",
      "   932|         0|            0|            0|  0.00%|\n",
      "   933|         0|            0|            0|  0.00%|            hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      "   934|         0|            0|            0|  0.00%|\n",
      "   935|         0|            0|            0|  0.00%|        The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      "   936|         0|            0|            0|  0.00%|        with respect to the inputs and outputs respectively. The hook should\n",
      "   937|         0|            0|            0|  0.00%|        not modify its arguments, but it can optionally return a new gradient with\n",
      "   938|         0|            0|            0|  0.00%|        respect to the input that will be used in place of :attr:`grad_input` in\n",
      "   939|         0|            0|            0|  0.00%|        subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      "   940|         0|            0|            0|  0.00%|        as positional arguments and all kwarg arguments are ignored. Entries\n",
      "   941|         0|            0|            0|  0.00%|        in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      "   942|         0|            0|            0|  0.00%|        arguments.\n",
      "   943|         0|            0|            0|  0.00%|\n",
      "   944|         0|            0|            0|  0.00%|        For technical reasons, when this hook is applied to a Module, its forward function will\n",
      "   945|         0|            0|            0|  0.00%|        receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      "   946|         0|            0|            0|  0.00%|        of each Tensor returned by the Module's forward function.\n",
      "   947|         0|            0|            0|  0.00%|\n",
      "   948|         0|            0|            0|  0.00%|        .. warning ::\n",
      "   949|         0|            0|            0|  0.00%|            Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      "   950|         0|            0|            0|  0.00%|            will raise an error.\n",
      "   951|         0|            0|            0|  0.00%|\n",
      "   952|         0|            0|            0|  0.00%|        Returns:\n",
      "   953|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   954|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "   955|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "   956|         0|            0|            0|  0.00%|\n",
      "   957|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   958|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is False:\n",
      "   959|         0|            0|            0|  0.00%|            raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n",
      "   960|         0|            0|            0|  0.00%|                               \"single Module. Please use only one of them.\")\n",
      "   961|         0|            0|            0|  0.00%|\n",
      "   962|         0|            0|            0|  0.00%|        self._is_full_backward_hook = True\n",
      "   963|         0|            0|            0|  0.00%|\n",
      "   964|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   965|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   966|         0|            0|            0|  0.00%|        return handle\n",
      "   967|         0|            0|            0|  0.00%|\n",
      "   968|         0|            0|            0|  0.00%|    def _get_backward_hooks(self):\n",
      "   969|         0|            0|            0|  0.00%|        r\"\"\"Returns the backward hooks for use in the call function.\n",
      "   970|         0|            0|            0|  0.00%|        It returns two lists, one with the full backward hooks and one with the non-full\n",
      "   971|         0|            0|            0|  0.00%|        backward hooks.\n",
      "   972|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   973|         0|            0|            0|  0.00%|        full_backward_hooks: List[Callable] = []\n",
      "   974|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is True):\n",
      "   975|         0|            0|            0|  0.00%|            full_backward_hooks += _global_backward_hooks.values()\n",
      "   976|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is True):\n",
      "   977|         0|            0|            0|  0.00%|            full_backward_hooks += self._backward_hooks.values()\n",
      "   978|         0|            0|            0|  0.00%|\n",
      "   979|         0|            0|            0|  0.00%|        non_full_backward_hooks: List[Callable] = []\n",
      "   980|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is False):\n",
      "   981|         0|            0|            0|  0.00%|            non_full_backward_hooks += _global_backward_hooks.values()\n",
      "   982|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is False):\n",
      "   983|         0|            0|            0|  0.00%|            non_full_backward_hooks += self._backward_hooks.values()\n",
      "   984|         0|            0|            0|  0.00%|\n",
      "   985|         0|            0|            0|  0.00%|        return full_backward_hooks, non_full_backward_hooks\n",
      "   986|         0|            0|            0|  0.00%|\n",
      "   987|         0|            0|            0|  0.00%|    def _maybe_warn_non_full_backward_hook(self, inputs, result, grad_fn):\n",
      "   988|         0|            0|            0|  0.00%|        if not isinstance(result, torch.Tensor):\n",
      "   989|         0|            0|            0|  0.00%|            if not (isinstance(result, tuple) and all([isinstance(r, torch.Tensor) for r in result])):\n",
      "   990|         0|            0|            0|  0.00%|                warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "   991|         0|            0|            0|  0.00%|                              \"single Tensor or a tuple of Tensors is deprecated and will be removed \"\n",
      "   992|         0|            0|            0|  0.00%|                              \"in future versions. This hook will be missing some of the grad_output. \"\n",
      "   993|         0|            0|            0|  0.00%|                              \"Please use register_full_backward_hook to get the documented behavior.\")\n",
      "   994|         0|            0|            0|  0.00%|                return\n",
      "   995|         0|            0|            0|  0.00%|        else:\n",
      "   996|         0|            0|            0|  0.00%|            result = (result,)\n",
      "   997|         0|            0|            0|  0.00%|\n",
      "   998|         0|            0|            0|  0.00%|        if not isinstance(inputs, torch.Tensor):\n",
      "   999|         0|            0|            0|  0.00%|            if not (isinstance(inputs, tuple) and all([isinstance(i, torch.Tensor) for i in inputs])):\n",
      "  1000|         0|            0|            0|  0.00%|                warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "  1001|         0|            0|            0|  0.00%|                              \"single Tensor or a tuple of Tensors is deprecated and will be removed \"\n",
      "  1002|         0|            0|            0|  0.00%|                              \"in future versions. This hook will be missing some of the grad_input. \"\n",
      "  1003|         0|            0|            0|  0.00%|                              \"Please use register_full_backward_hook to get the documented behavior.\")\n",
      "  1004|         0|            0|            0|  0.00%|                return\n",
      "  1005|         0|            0|            0|  0.00%|        else:\n",
      "  1006|         0|            0|            0|  0.00%|            inputs = (inputs,)\n",
      "  1007|         0|            0|            0|  0.00%|\n",
      "  1008|         0|            0|            0|  0.00%|        # At this point we are sure that inputs and result are tuple of Tensors\n",
      "  1009|         0|            0|            0|  0.00%|        out_grad_fn = {r.grad_fn for r in result if r.grad_fn is not None}\n",
      "  1010|         0|            0|            0|  0.00%|        if len(out_grad_fn) == 0 or (len(out_grad_fn) == 1 and grad_fn not in out_grad_fn):\n",
      "  1011|         0|            0|            0|  0.00%|            warnings.warn(\"Using a non-full backward hook when outputs are nested in python data structure \"\n",
      "  1012|         0|            0|            0|  0.00%|                          \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1013|         0|            0|            0|  0.00%|                          \"some grad_output.\")\n",
      "  1014|         0|            0|            0|  0.00%|        elif len(out_grad_fn) > 1:\n",
      "  1015|         0|            0|            0|  0.00%|            warnings.warn(\"Using a non-full backward hook when outputs are generated by different autograd Nodes \"\n",
      "  1016|         0|            0|            0|  0.00%|                          \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1017|         0|            0|            0|  0.00%|                          \"some grad_output. Please use register_full_backward_hook to get the documented behavior.\")\n",
      "  1018|         0|            0|            0|  0.00%|        else:\n",
      "  1019|         0|            0|            0|  0.00%|            # At this point the grad_ouput part of the hook will most likely be correct\n",
      "  1020|         0|            0|            0|  0.00%|            inputs_grad_fn = {i.grad_fn for i in inputs if i.grad_fn is not None}\n",
      "  1021|         0|            0|            0|  0.00%|\n",
      "  1022|         0|            0|            0|  0.00%|            next_functions = {n[0] for n in grad_fn.next_functions}\n",
      "  1023|         0|            0|            0|  0.00%|\n",
      "  1024|         0|            0|            0|  0.00%|            if inputs_grad_fn != next_functions:\n",
      "  1025|         0|            0|            0|  0.00%|                warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "  1026|         0|            0|            0|  0.00%|                              \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1027|         0|            0|            0|  0.00%|                              \"some grad_input. Please use register_full_backward_hook to get the documented \"\n",
      "  1028|         0|            0|            0|  0.00%|                              \"behavior.\")\n",
      "  1029|         0|            0|            0|  0.00%|\n",
      "  1030|         0|            0|            0|  0.00%|    def register_forward_pre_hook(self, hook: Callable[..., None]) -> RemovableHandle:\n",
      "  1031|         0|            0|            0|  0.00%|        r\"\"\"Registers a forward pre-hook on the module.\n",
      "  1032|         0|            0|            0|  0.00%|\n",
      "  1033|         0|            0|            0|  0.00%|        The hook will be called every time before :func:`forward` is invoked.\n",
      "  1034|         0|            0|            0|  0.00%|        It should have the following signature::\n",
      "  1035|         0|            0|            0|  0.00%|\n",
      "  1036|         0|            0|            0|  0.00%|            hook(module, input) -> None or modified input\n",
      "  1037|         0|            0|            0|  0.00%|\n",
      "  1038|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.\n",
      "  1039|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "  1040|         0|            0|            0|  0.00%|        The hook can modify the input. User can either return a tuple or a\n",
      "  1041|         0|            0|            0|  0.00%|        single modified value in the hook. We will wrap the value into a tuple\n",
      "  1042|         0|            0|            0|  0.00%|        if a single value is returned(unless that value is already a tuple).\n",
      "  1043|         0|            0|            0|  0.00%|\n",
      "  1044|         0|            0|            0|  0.00%|        Returns:\n",
      "  1045|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "  1046|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "  1047|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "  1048|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1049|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_pre_hooks)\n",
      "  1050|         0|            0|            0|  0.00%|        self._forward_pre_hooks[handle.id] = hook\n",
      "  1051|         0|            0|            0|  0.00%|        return handle\n",
      "  1052|         0|            0|            0|  0.00%|\n",
      "  1053|         0|            0|            0|  0.00%|    def register_forward_hook(self, hook: Callable[..., None]) -> RemovableHandle:\n",
      "  1054|         0|            0|            0|  0.00%|        r\"\"\"Registers a forward hook on the module.\n",
      "  1055|         0|            0|            0|  0.00%|\n",
      "  1056|         0|            0|            0|  0.00%|        The hook will be called every time after :func:`forward` has computed an output.\n",
      "  1057|         0|            0|            0|  0.00%|        It should have the following signature::\n",
      "  1058|         0|            0|            0|  0.00%|\n",
      "  1059|         0|            0|            0|  0.00%|            hook(module, input, output) -> None or modified output\n",
      "  1060|         0|            0|            0|  0.00%|\n",
      "  1061|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.\n",
      "  1062|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "  1063|         0|            0|            0|  0.00%|        The hook can modify the output. It can modify the input inplace but\n",
      "  1064|         0|            0|            0|  0.00%|        it will not have effect on forward since this is called after\n",
      "  1065|         0|            0|            0|  0.00%|        :func:`forward` is called.\n",
      "  1066|         0|            0|            0|  0.00%|\n",
      "  1067|         0|            0|            0|  0.00%|        Returns:\n",
      "  1068|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "  1069|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "  1070|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "  1071|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1072|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_hooks)\n",
      "  1073|         0|            0|            0|  0.00%|        self._forward_hooks[handle.id] = hook\n",
      "  1074|         0|            0|            0|  0.00%|        return handle\n",
      "  1075|         0|            0|            0|  0.00%|\n",
      "  1076|         0|            0|            0|  0.00%|    def _slow_forward(self, *input, **kwargs):\n",
      "  1077|         0|            0|            0|  0.00%|        tracing_state = torch._C._get_tracing_state()\n",
      "  1078|         0|            0|            0|  0.00%|        if not tracing_state or isinstance(self.forward, torch._C.ScriptMethod):\n",
      "  1079|         0|            0|            0|  0.00%|            return self.forward(*input, **kwargs)\n",
      "  1080|         0|            0|            0|  0.00%|        recording_scopes = torch.jit._trace._trace_module_map is not None\n",
      "  1081|         0|            0|            0|  0.00%|        if recording_scopes:\n",
      "  1082|         0|            0|            0|  0.00%|            # type ignore was added because at this point one knows that\n",
      "  1083|         0|            0|            0|  0.00%|            # torch.jit._trace._trace_module_map is not Optional and has type Dict[Any, Any]\n",
      "  1084|         0|            0|            0|  0.00%|            name = torch.jit._trace._trace_module_map[self] if self in torch.jit._trace._trace_module_map else None  # type: ignore[index, operator] # noqa: B950\n",
      "  1085|         0|            0|            0|  0.00%|            if name:\n",
      "  1086|         0|            0|            0|  0.00%|                tracing_state.push_scope(name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1087|         0|            0|            0|  0.00%|            else:\n",
      "  1088|         0|            0|            0|  0.00%|                recording_scopes = False\n",
      "  1089|         0|            0|            0|  0.00%|        try:\n",
      "  1090|         0|            0|            0|  0.00%|            result = self.forward(*input, **kwargs)\n",
      "  1091|         0|            0|            0|  0.00%|        finally:\n",
      "  1092|         0|            0|            0|  0.00%|            if recording_scopes:\n",
      "  1093|         0|            0|            0|  0.00%|                tracing_state.pop_scope()\n",
      "  1094|         0|            0|            0|  0.00%|        return result\n",
      "  1095|         0|            0|            0|  0.00%|\n",
      "  1096|        53|  0.000202179|   3.8147e-06|  0.09%|    def _call_impl(self, *input, **kwargs):\n",
      "  1097|        53|  0.000305414|  5.76253e-06|  0.14%|        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "  1098|         0|            0|            0|  0.00%|        # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "  1099|         0|            0|            0|  0.00%|        # this function, and just call forward.\n",
      "  1100|        53|  0.000225782|  4.26005e-06|  0.10%|        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "  1101|        53|  0.000186443|   3.5178e-06|  0.08%|                or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "  1102|        53|  0.000654221|  1.23438e-05|  0.29%|            return forward_call(*input, **kwargs)\n",
      "(call)|         9|   0.00129366|   0.00014374|  0.57%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/sparse.py:157 forward\n",
      "(call)|         9|    0.0180247|   0.00200274|  7.98%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:824 forward\n",
      "(call)|         1|     0.014082|     0.014082|  6.24%|# <ipython-input-176-5d68b8565542>:22 forward\n",
      "(call)|         8|    0.0517087|   0.00646359| 22.91%|# <ipython-input-176-5d68b8565542>:39 forward\n",
      "(call)|        16|   0.00264001|  0.000165001|  1.17%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/linear.py:102 forward\n",
      "(call)|         8|    0.0668242|   0.00835302| 29.60%|# <ipython-input-176-5d68b8565542>:25 forward\n",
      "(call)|         1|    0.0828261|    0.0828261| 36.69%|# <ipython-input-176-5d68b8565542>:19 forward\n",
      "(call)|         1|   0.00437307|   0.00437307|  1.94%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:1149 forward\n",
      "  1103|         0|            0|            0|  0.00%|        # Do not call functions when jit is used\n",
      "  1104|         0|            0|            0|  0.00%|        full_backward_hooks, non_full_backward_hooks = [], []\n",
      "  1105|         0|            0|            0|  0.00%|        if self._backward_hooks or _global_backward_hooks:\n",
      "  1106|         0|            0|            0|  0.00%|            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()\n",
      "  1107|         0|            0|            0|  0.00%|        if _global_forward_pre_hooks or self._forward_pre_hooks:\n",
      "  1108|         0|            0|            0|  0.00%|            for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()):\n",
      "  1109|         0|            0|            0|  0.00%|                result = hook(self, input)\n",
      "  1110|         0|            0|            0|  0.00%|                if result is not None:\n",
      "  1111|         0|            0|            0|  0.00%|                    if not isinstance(result, tuple):\n",
      "  1112|         0|            0|            0|  0.00%|                        result = (result,)\n",
      "  1113|         0|            0|            0|  0.00%|                    input = result\n",
      "  1114|         0|            0|            0|  0.00%|\n",
      "  1115|         0|            0|            0|  0.00%|        bw_hook = None\n",
      "  1116|         0|            0|            0|  0.00%|        if full_backward_hooks:\n",
      "  1117|         0|            0|            0|  0.00%|            bw_hook = hooks.BackwardHook(self, full_backward_hooks)\n",
      "  1118|         0|            0|            0|  0.00%|            input = bw_hook.setup_input_hook(input)\n",
      "  1119|         0|            0|            0|  0.00%|\n",
      "  1120|         0|            0|            0|  0.00%|        result = forward_call(*input, **kwargs)\n",
      "  1121|         0|            0|            0|  0.00%|        if _global_forward_hooks or self._forward_hooks:\n",
      "  1122|         0|            0|            0|  0.00%|            for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):\n",
      "  1123|         0|            0|            0|  0.00%|                hook_result = hook(self, input, result)\n",
      "  1124|         0|            0|            0|  0.00%|                if hook_result is not None:\n",
      "  1125|         0|            0|            0|  0.00%|                    result = hook_result\n",
      "  1126|         0|            0|            0|  0.00%|\n",
      "  1127|         0|            0|            0|  0.00%|        if bw_hook:\n",
      "  1128|         0|            0|            0|  0.00%|            result = bw_hook.setup_output_hook(result)\n",
      "  1129|         0|            0|            0|  0.00%|\n",
      "  1130|         0|            0|            0|  0.00%|        # Handle the non-full backward hooks\n",
      "  1131|         0|            0|            0|  0.00%|        if non_full_backward_hooks:\n",
      "  1132|         0|            0|            0|  0.00%|            var = result\n",
      "  1133|         0|            0|            0|  0.00%|            while not isinstance(var, torch.Tensor):\n",
      "  1134|         0|            0|            0|  0.00%|                if isinstance(var, dict):\n",
      "  1135|         0|            0|            0|  0.00%|                    var = next((v for v in var.values() if isinstance(v, torch.Tensor)))\n",
      "  1136|         0|            0|            0|  0.00%|                else:\n",
      "  1137|         0|            0|            0|  0.00%|                    var = var[0]\n",
      "  1138|         0|            0|            0|  0.00%|            grad_fn = var.grad_fn\n",
      "  1139|         0|            0|            0|  0.00%|            if grad_fn is not None:\n",
      "  1140|         0|            0|            0|  0.00%|                for hook in non_full_backward_hooks:\n",
      "  1141|         0|            0|            0|  0.00%|                    wrapper = functools.partial(hook, self)\n",
      "  1142|         0|            0|            0|  0.00%|                    functools.update_wrapper(wrapper, hook)\n",
      "  1143|         0|            0|            0|  0.00%|                    grad_fn.register_hook(wrapper)\n",
      "  1144|         0|            0|            0|  0.00%|                self._maybe_warn_non_full_backward_hook(input, result, grad_fn)\n",
      "  1145|         0|            0|            0|  0.00%|\n",
      "  1146|         0|            0|            0|  0.00%|        return result\n",
      "  1147|         0|            0|            0|  0.00%|\n",
      "  1148|         0|            0|            0|  0.00%|    __call__ : Callable[..., Any] = _call_impl\n",
      "  1149|         0|            0|            0|  0.00%|\n",
      "  1150|         0|            0|            0|  0.00%|    def __setstate__(self, state):\n",
      "  1151|         0|            0|            0|  0.00%|        self.__dict__.update(state)\n",
      "  1152|         0|            0|            0|  0.00%|        # Support loading old checkpoints that don't have the following attrs:\n",
      "  1153|         0|            0|            0|  0.00%|        if '_forward_pre_hooks' not in self.__dict__:\n",
      "  1154|         0|            0|            0|  0.00%|            self._forward_pre_hooks = OrderedDict()\n",
      "  1155|         0|            0|            0|  0.00%|        if '_state_dict_hooks' not in self.__dict__:\n",
      "  1156|         0|            0|            0|  0.00%|            self._state_dict_hooks = OrderedDict()\n",
      "  1157|         0|            0|            0|  0.00%|        if '_load_state_dict_pre_hooks' not in self.__dict__:\n",
      "  1158|         0|            0|            0|  0.00%|            self._load_state_dict_pre_hooks = OrderedDict()\n",
      "  1159|         0|            0|            0|  0.00%|        if '_non_persistent_buffers_set' not in self.__dict__:\n",
      "  1160|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set = set()\n",
      "  1161|         0|            0|            0|  0.00%|        if '_is_full_backward_hook' not in self.__dict__:\n",
      "  1162|         0|            0|            0|  0.00%|            self._is_full_backward_hook = None\n",
      "  1163|         0|            0|            0|  0.00%|\n",
      "  1164|        94|  0.000243902|   2.5947e-06|  0.11%|    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:\n",
      "  1165|        94|  0.000275373|   2.9295e-06|  0.12%|        if '_parameters' in self.__dict__:\n",
      "  1166|        94|  0.000237703|  2.52876e-06|  0.11%|            _parameters = self.__dict__['_parameters']\n",
      "  1167|        94|  0.000222921|   2.3715e-06|  0.10%|            if name in _parameters:\n",
      "  1168|        41|  0.000100374|  2.44815e-06|  0.04%|                return _parameters[name]\n",
      "  1169|        53|   0.00013113|  2.47416e-06|  0.06%|        if '_buffers' in self.__dict__:\n",
      "  1170|        53|  0.000124454|   2.3482e-06|  0.06%|            _buffers = self.__dict__['_buffers']\n",
      "  1171|        53|  0.000126123|  2.37969e-06|  0.06%|            if name in _buffers:\n",
      "  1172|         1|  1.90735e-06|  1.90735e-06|  0.00%|                return _buffers[name]\n",
      "  1173|        52|  0.000118971|   2.2879e-06|  0.05%|        if '_modules' in self.__dict__:\n",
      "  1174|        52|  0.000120163|  2.31083e-06|  0.05%|            modules = self.__dict__['_modules']\n",
      "  1175|        52|  0.000111103|   2.1366e-06|  0.05%|            if name in modules:\n",
      "  1176|        51|  0.000119448|  2.34211e-06|  0.05%|                return modules[name]\n",
      "  1177|         1|   3.8147e-06|   3.8147e-06|  0.00%|        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "  1178|         1|  7.15256e-06|  7.15256e-06|  0.00%|            type(self).__name__, name))\n",
      "  1179|         0|            0|            0|  0.00%|\n",
      "  1180|        14|  5.00679e-05|  3.57628e-06|  0.02%|    def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -> None:\n",
      "  1181|        14|    4.673e-05|  3.33786e-06|  0.02%|        def remove_from(*dicts_or_sets):\n",
      "  1182|         0|            0|            0|  0.00%|            for d in dicts_or_sets:\n",
      "  1183|         0|            0|            0|  0.00%|                if name in d:\n",
      "  1184|         0|            0|            0|  0.00%|                    if isinstance(d, dict):\n",
      "  1185|         0|            0|            0|  0.00%|                        del d[name]\n",
      "  1186|         0|            0|            0|  0.00%|                    else:\n",
      "  1187|         0|            0|            0|  0.00%|                        d.discard(name)\n",
      "  1188|         0|            0|            0|  0.00%|\n",
      "  1189|        14|  4.74453e-05|  3.38895e-06|  0.02%|        params = self.__dict__.get('_parameters')\n",
      "  1190|        14|  4.52995e-05|  3.23568e-06|  0.02%|        if isinstance(value, Parameter):\n",
      "  1191|         0|            0|            0|  0.00%|            if params is None:\n",
      "  1192|         0|            0|            0|  0.00%|                raise AttributeError(\n",
      "  1193|         0|            0|            0|  0.00%|                    \"cannot assign parameters before Module.__init__() call\")\n",
      "  1194|         0|            0|            0|  0.00%|            remove_from(self.__dict__, self._buffers, self._modules, self._non_persistent_buffers_set)\n",
      "  1195|         0|            0|            0|  0.00%|            self.register_parameter(name, value)\n",
      "  1196|        14|  4.31538e-05|  3.08241e-06|  0.02%|        elif params is not None and name in params:\n",
      "  1197|         0|            0|            0|  0.00%|            if value is not None:\n",
      "  1198|         0|            0|            0|  0.00%|                raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n",
      "  1199|         0|            0|            0|  0.00%|                                \"(torch.nn.Parameter or None expected)\"\n",
      "  1200|         0|            0|            0|  0.00%|                                .format(torch.typename(value), name))\n",
      "  1201|         0|            0|            0|  0.00%|            self.register_parameter(name, value)\n",
      "  1202|         0|            0|            0|  0.00%|        else:\n",
      "  1203|        14|  4.45843e-05|  3.18459e-06|  0.02%|            modules = self.__dict__.get('_modules')\n",
      "  1204|        14|  4.33922e-05|  3.09944e-06|  0.02%|            if isinstance(value, Module):\n",
      "  1205|         0|            0|            0|  0.00%|                if modules is None:\n",
      "  1206|         0|            0|            0|  0.00%|                    raise AttributeError(\n",
      "  1207|         0|            0|            0|  0.00%|                        \"cannot assign module before Module.__init__() call\")\n",
      "  1208|         0|            0|            0|  0.00%|                remove_from(self.__dict__, self._parameters, self._buffers, self._non_persistent_buffers_set)\n",
      "  1209|         0|            0|            0|  0.00%|                modules[name] = value\n",
      "  1210|        14|  3.71933e-05|  2.65666e-06|  0.02%|            elif modules is not None and name in modules:\n",
      "  1211|         0|            0|            0|  0.00%|                if value is not None:\n",
      "  1212|         0|            0|            0|  0.00%|                    raise TypeError(\"cannot assign '{}' as child module '{}' \"\n",
      "  1213|         0|            0|            0|  0.00%|                                    \"(torch.nn.Module or None expected)\"\n",
      "  1214|         0|            0|            0|  0.00%|                                    .format(torch.typename(value), name))\n",
      "  1215|         0|            0|            0|  0.00%|                modules[name] = value\n",
      "  1216|         0|            0|            0|  0.00%|            else:\n",
      "  1217|        14|   4.1008e-05|  2.92914e-06|  0.02%|                buffers = self.__dict__.get('_buffers')\n",
      "  1218|        14|  3.93391e-05|  2.80993e-06|  0.02%|                if buffers is not None and name in buffers:\n",
      "  1219|         0|            0|            0|  0.00%|                    if value is not None and not isinstance(value, torch.Tensor):\n",
      "  1220|         0|            0|            0|  0.00%|                        raise TypeError(\"cannot assign '{}' as buffer '{}' \"\n",
      "  1221|         0|            0|            0|  0.00%|                                        \"(torch.Tensor or None expected)\"\n",
      "  1222|         0|            0|            0|  0.00%|                                        .format(torch.typename(value), name))\n",
      "  1223|         0|            0|            0|  0.00%|                    buffers[name] = value\n",
      "  1224|         0|            0|            0|  0.00%|                else:\n",
      "  1225|        14|  5.22137e-05|  3.72955e-06|  0.02%|                    object.__setattr__(self, name, value)\n",
      "  1226|         0|            0|            0|  0.00%|\n",
      "  1227|         0|            0|            0|  0.00%|    def __delattr__(self, name):\n",
      "  1228|         0|            0|            0|  0.00%|        if name in self._parameters:\n",
      "  1229|         0|            0|            0|  0.00%|            del self._parameters[name]\n",
      "  1230|         0|            0|            0|  0.00%|        elif name in self._buffers:\n",
      "  1231|         0|            0|            0|  0.00%|            del self._buffers[name]\n",
      "  1232|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set.discard(name)\n",
      "  1233|         0|            0|            0|  0.00%|        elif name in self._modules:\n",
      "  1234|         0|            0|            0|  0.00%|            del self._modules[name]\n",
      "  1235|         0|            0|            0|  0.00%|        else:\n",
      "  1236|         0|            0|            0|  0.00%|            object.__delattr__(self, name)\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    def _register_state_dict_hook(self, hook):\n",
      "  1239|         0|            0|            0|  0.00%|        r\"\"\"These hooks will be called with arguments: `self`, `state_dict`,\n",
      "  1240|         0|            0|            0|  0.00%|        `prefix`, `local_metadata`, after the `state_dict` of `self` is set.\n",
      "  1241|         0|            0|            0|  0.00%|        Note that only parameters and buffers of `self` or its children are\n",
      "  1242|         0|            0|            0|  0.00%|        guaranteed to exist in `state_dict`. The hooks may modify `state_dict`\n",
      "  1243|         0|            0|            0|  0.00%|        inplace or return a new one.\n",
      "  1244|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1245|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._state_dict_hooks)\n",
      "  1246|         0|            0|            0|  0.00%|        self._state_dict_hooks[handle.id] = hook\n",
      "  1247|         0|            0|            0|  0.00%|        return handle\n",
      "  1248|         0|            0|            0|  0.00%|\n",
      "  1249|         0|            0|            0|  0.00%|    def _save_to_state_dict(self, destination, prefix, keep_vars):\n",
      "  1250|         0|            0|            0|  0.00%|        r\"\"\"Saves module state to `destination` dictionary, containing a state\n",
      "  1251|         0|            0|            0|  0.00%|        of the module, but not its descendants. This is called on every\n",
      "  1252|         0|            0|            0|  0.00%|        submodule in :meth:`~torch.nn.Module.state_dict`.\n",
      "  1253|         0|            0|            0|  0.00%|\n",
      "  1254|         0|            0|            0|  0.00%|        In rare cases, subclasses can achieve class-specific behavior by\n",
      "  1255|         0|            0|            0|  0.00%|        overriding this method with custom logic.\n",
      "  1256|         0|            0|            0|  0.00%|\n",
      "  1257|         0|            0|            0|  0.00%|        Args:\n",
      "  1258|         0|            0|            0|  0.00%|            destination (dict): a dict where state will be stored\n",
      "  1259|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this\n",
      "  1260|         0|            0|            0|  0.00%|                module\n",
      "  1261|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1262|         0|            0|            0|  0.00%|        for name, param in self._parameters.items():\n",
      "  1263|         0|            0|            0|  0.00%|            if param is not None:\n",
      "  1264|         0|            0|            0|  0.00%|                destination[prefix + name] = param if keep_vars else param.detach()\n",
      "  1265|         0|            0|            0|  0.00%|        for name, buf in self._buffers.items():\n",
      "  1266|         0|            0|            0|  0.00%|            if buf is not None and name not in self._non_persistent_buffers_set:\n",
      "  1267|         0|            0|            0|  0.00%|                destination[prefix + name] = buf if keep_vars else buf.detach()\n",
      "  1268|         0|            0|            0|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
      "  1269|         0|            0|            0|  0.00%|        if getattr(self.__class__, \"get_extra_state\", Module.get_extra_state) is not Module.get_extra_state:\n",
      "  1270|         0|            0|            0|  0.00%|            destination[extra_state_key] = self.get_extra_state()\n",
      "  1271|         0|            0|            0|  0.00%|\n",
      "  1272|         0|            0|            0|  0.00%|    # The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns\n",
      "  1273|         0|            0|            0|  0.00%|    # back that same object. But if they pass nothing, an `OrederedDict` is created and returned.\n",
      "  1274|         0|            0|            0|  0.00%|    T_destination = TypeVar('T_destination', bound=Mapping[str, Tensor])\n",
      "  1275|         0|            0|            0|  0.00%|\n",
      "  1276|         0|            0|            0|  0.00%|    @overload\n",
      "  1277|         0|            0|            0|  0.00%|    def state_dict(self, destination: T_destination, prefix: str = ..., keep_vars: bool = ...) -> T_destination:\n",
      "  1278|         0|            0|            0|  0.00%|        ...\n",
      "  1279|         0|            0|            0|  0.00%|\n",
      "  1280|         0|            0|            0|  0.00%|    # TODO: Remove string escape once Python-3.6 no longer supported\n",
      "  1281|         0|            0|            0|  0.00%|    # See https://github.com/python/mypy/issues/6904#issuecomment-496207426\n",
      "  1282|         0|            0|            0|  0.00%|    @overload\n",
      "  1283|         0|            0|            0|  0.00%|    def state_dict(self, prefix: str = ..., keep_vars: bool = ...) -> 'OrderedDict[str, Tensor]':\n",
      "  1284|         0|            0|            0|  0.00%|        ...\n",
      "  1285|         0|            0|            0|  0.00%|\n",
      "  1286|         0|            0|            0|  0.00%|    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
      "  1287|         0|            0|            0|  0.00%|        r\"\"\"Returns a dictionary containing a whole state of the module.\n",
      "  1288|         0|            0|            0|  0.00%|\n",
      "  1289|         0|            0|            0|  0.00%|        Both parameters and persistent buffers (e.g. running averages) are\n",
      "  1290|         0|            0|            0|  0.00%|        included. Keys are corresponding parameter and buffer names.\n",
      "  1291|         0|            0|            0|  0.00%|        Parameters and buffers set to ``None`` are not included.\n",
      "  1292|         0|            0|            0|  0.00%|\n",
      "  1293|         0|            0|            0|  0.00%|        Returns:\n",
      "  1294|         0|            0|            0|  0.00%|            dict:\n",
      "  1295|         0|            0|            0|  0.00%|                a dictionary containing a whole state of the module\n",
      "  1296|         0|            0|            0|  0.00%|\n",
      "  1297|         0|            0|            0|  0.00%|        Example::\n",
      "  1298|         0|            0|            0|  0.00%|\n",
      "  1299|         0|            0|            0|  0.00%|            >>> module.state_dict().keys()\n",
      "  1300|         0|            0|            0|  0.00%|            ['bias', 'weight']\n",
      "  1301|         0|            0|            0|  0.00%|\n",
      "  1302|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1303|         0|            0|            0|  0.00%|        if destination is None:\n",
      "  1304|         0|            0|            0|  0.00%|            destination = OrderedDict()\n",
      "  1305|         0|            0|            0|  0.00%|            destination._metadata = OrderedDict()\n",
      "  1306|         0|            0|            0|  0.00%|        destination._metadata[prefix[:-1]] = local_metadata = dict(version=self._version)\n",
      "  1307|         0|            0|            0|  0.00%|        self._save_to_state_dict(destination, prefix, keep_vars)\n",
      "  1308|         0|            0|            0|  0.00%|        for name, module in self._modules.items():\n",
      "  1309|         0|            0|            0|  0.00%|            if module is not None:\n",
      "  1310|         0|            0|            0|  0.00%|                module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)\n",
      "  1311|         0|            0|            0|  0.00%|        for hook in self._state_dict_hooks.values():\n",
      "  1312|         0|            0|            0|  0.00%|            hook_result = hook(self, destination, prefix, local_metadata)\n",
      "  1313|         0|            0|            0|  0.00%|            if hook_result is not None:\n",
      "  1314|         0|            0|            0|  0.00%|                destination = hook_result\n",
      "  1315|         0|            0|            0|  0.00%|        return destination\n",
      "  1316|         0|            0|            0|  0.00%|\n",
      "  1317|         0|            0|            0|  0.00%|    def _register_load_state_dict_pre_hook(self, hook, with_module=False):\n",
      "  1318|         0|            0|            0|  0.00%|        r\"\"\"These hooks will be called with arguments: `state_dict`, `prefix`,\n",
      "  1319|         0|            0|            0|  0.00%|        `local_metadata`, `strict`, `missing_keys`, `unexpected_keys`,\n",
      "  1320|         0|            0|            0|  0.00%|        `error_msgs`, before loading `state_dict` into `self`. These arguments\n",
      "  1321|         0|            0|            0|  0.00%|        are exactly the same as those of `_load_from_state_dict`.\n",
      "  1322|         0|            0|            0|  0.00%|\n",
      "  1323|         0|            0|            0|  0.00%|        If ``with_module`` is ``True``, then the first argument to the hook is\n",
      "  1324|         0|            0|            0|  0.00%|        an instance of the module.\n",
      "  1325|         0|            0|            0|  0.00%|\n",
      "  1326|         0|            0|            0|  0.00%|        Arguments:\n",
      "  1327|         0|            0|            0|  0.00%|            hook (Callable): Callable hook that will be invoked before\n",
      "  1328|         0|            0|            0|  0.00%|                loading the state dict.\n",
      "  1329|         0|            0|            0|  0.00%|            with_module (bool, optional): Whether or not to pass the module\n",
      "  1330|         0|            0|            0|  0.00%|                instance to the hook as the first parameter.\n",
      "  1331|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1332|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._load_state_dict_pre_hooks)\n",
      "  1333|         0|            0|            0|  0.00%|        if with_module:\n",
      "  1334|         0|            0|            0|  0.00%|            hook = functools.partial(hook, self)\n",
      "  1335|         0|            0|            0|  0.00%|        self._load_state_dict_pre_hooks[handle.id] = hook\n",
      "  1336|         0|            0|            0|  0.00%|        return handle\n",
      "  1337|         0|            0|            0|  0.00%|\n",
      "  1338|         0|            0|            0|  0.00%|    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n",
      "  1339|         0|            0|            0|  0.00%|                              missing_keys, unexpected_keys, error_msgs):\n",
      "  1340|         0|            0|            0|  0.00%|        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\n",
      "  1341|         0|            0|            0|  0.00%|        this module, but not its descendants. This is called on every submodule\n",
      "  1342|         0|            0|            0|  0.00%|        in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\n",
      "  1343|         0|            0|            0|  0.00%|        module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\n",
      "  1344|         0|            0|            0|  0.00%|        For state dicts without metadata, :attr:`local_metadata` is empty.\n",
      "  1345|         0|            0|            0|  0.00%|        Subclasses can achieve class-specific backward compatible loading using\n",
      "  1346|         0|            0|            0|  0.00%|        the version number at `local_metadata.get(\"version\", None)`.\n",
      "  1347|         0|            0|            0|  0.00%|\n",
      "  1348|         0|            0|            0|  0.00%|        .. note::\n",
      "  1349|         0|            0|            0|  0.00%|            :attr:`state_dict` is not the same object as the input\n",
      "  1350|         0|            0|            0|  0.00%|            :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\n",
      "  1351|         0|            0|            0|  0.00%|            it can be modified.\n",
      "  1352|         0|            0|            0|  0.00%|\n",
      "  1353|         0|            0|            0|  0.00%|        Args:\n",
      "  1354|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and\n",
      "  1355|         0|            0|            0|  0.00%|                persistent buffers.\n",
      "  1356|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this\n",
      "  1357|         0|            0|            0|  0.00%|                module\n",
      "  1358|         0|            0|            0|  0.00%|            local_metadata (dict): a dict containing the metadata for this module.\n",
      "  1359|         0|            0|            0|  0.00%|                See\n",
      "  1360|         0|            0|            0|  0.00%|            strict (bool): whether to strictly enforce that the keys in\n",
      "  1361|         0|            0|            0|  0.00%|                :attr:`state_dict` with :attr:`prefix` match the names of\n",
      "  1362|         0|            0|            0|  0.00%|                parameters and buffers in this module\n",
      "  1363|         0|            0|            0|  0.00%|            missing_keys (list of str): if ``strict=True``, add missing keys to\n",
      "  1364|         0|            0|            0|  0.00%|                this list\n",
      "  1365|         0|            0|            0|  0.00%|            unexpected_keys (list of str): if ``strict=True``, add unexpected\n",
      "  1366|         0|            0|            0|  0.00%|                keys to this list\n",
      "  1367|         0|            0|            0|  0.00%|            error_msgs (list of str): error messages should be added to this\n",
      "  1368|         0|            0|            0|  0.00%|                list, and will be reported together in\n",
      "  1369|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.load_state_dict`\n",
      "  1370|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1371|         0|            0|            0|  0.00%|        for hook in self._load_state_dict_pre_hooks.values():\n",
      "  1372|         0|            0|            0|  0.00%|            hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "  1373|         0|            0|            0|  0.00%|\n",
      "  1374|         0|            0|            0|  0.00%|        persistent_buffers = {k: v for k, v in self._buffers.items() if k not in self._non_persistent_buffers_set}\n",
      "  1375|         0|            0|            0|  0.00%|        local_name_params = itertools.chain(self._parameters.items(), persistent_buffers.items())\n",
      "  1376|         0|            0|            0|  0.00%|        local_state = {k: v for k, v in local_name_params if v is not None}\n",
      "  1377|         0|            0|            0|  0.00%|\n",
      "  1378|         0|            0|            0|  0.00%|        for name, param in local_state.items():\n",
      "  1379|         0|            0|            0|  0.00%|            key = prefix + name\n",
      "  1380|         0|            0|            0|  0.00%|            if key in state_dict:\n",
      "  1381|         0|            0|            0|  0.00%|                input_param = state_dict[key]\n",
      "  1382|         0|            0|            0|  0.00%|                # This is used to avoid copying uninitialized parameters into\n",
      "  1383|         0|            0|            0|  0.00%|                # non-lazy modules, since they dont have the hook to do the checks\n",
      "  1384|         0|            0|            0|  0.00%|                # in such case, it will error when accessing the .shape attribute.\n",
      "  1385|         0|            0|            0|  0.00%|                is_param_lazy = torch.nn.parameter.is_lazy(param)\n",
      "  1386|         0|            0|            0|  0.00%|                # Backward compatibility: loading 1-dim tensor from 0.3.* to version 0.4+\n",
      "  1387|         0|            0|            0|  0.00%|                if not is_param_lazy and len(param.shape) == 0 and len(input_param.shape) == 1:\n",
      "  1388|         0|            0|            0|  0.00%|                    input_param = input_param[0]\n",
      "  1389|         0|            0|            0|  0.00%|\n",
      "  1390|         0|            0|            0|  0.00%|                if not is_param_lazy and input_param.shape != param.shape:\n",
      "  1391|         0|            0|            0|  0.00%|                    # local shape should match the one in checkpoint\n",
      "  1392|         0|            0|            0|  0.00%|                    error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '\n",
      "  1393|         0|            0|            0|  0.00%|                                      'the shape in current model is {}.'\n",
      "  1394|         0|            0|            0|  0.00%|                                      .format(key, input_param.shape, param.shape))\n",
      "  1395|         0|            0|            0|  0.00%|                    continue\n",
      "  1396|         0|            0|            0|  0.00%|                try:\n",
      "  1397|         0|            0|            0|  0.00%|                    with torch.no_grad():\n",
      "  1398|         0|            0|            0|  0.00%|                        param.copy_(input_param)\n",
      "  1399|         0|            0|            0|  0.00%|                except Exception as ex:\n",
      "  1400|         0|            0|            0|  0.00%|                    error_msgs.append('While copying the parameter named \"{}\", '\n",
      "  1401|         0|            0|            0|  0.00%|                                      'whose dimensions in the model are {} and '\n",
      "  1402|         0|            0|            0|  0.00%|                                      'whose dimensions in the checkpoint are {}, '\n",
      "  1403|         0|            0|            0|  0.00%|                                      'an exception occurred : {}.'\n",
      "  1404|         0|            0|            0|  0.00%|                                      .format(key, param.size(), input_param.size(), ex.args))\n",
      "  1405|         0|            0|            0|  0.00%|            elif strict:\n",
      "  1406|         0|            0|            0|  0.00%|                missing_keys.append(key)\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
      "  1409|         0|            0|            0|  0.00%|        if getattr(self.__class__, \"set_extra_state\", Module.set_extra_state) is not Module.set_extra_state:\n",
      "  1410|         0|            0|            0|  0.00%|            if extra_state_key in state_dict:\n",
      "  1411|         0|            0|            0|  0.00%|                self.set_extra_state(state_dict[extra_state_key])\n",
      "  1412|         0|            0|            0|  0.00%|            elif strict:\n",
      "  1413|         0|            0|            0|  0.00%|                missing_keys.append(extra_state_key)\n",
      "  1414|         0|            0|            0|  0.00%|        elif strict and (extra_state_key in state_dict):\n",
      "  1415|         0|            0|            0|  0.00%|            unexpected_keys.append(extra_state_key)\n",
      "  1416|         0|            0|            0|  0.00%|\n",
      "  1417|         0|            0|            0|  0.00%|        if strict:\n",
      "  1418|         0|            0|            0|  0.00%|            for key in state_dict.keys():\n",
      "  1419|         0|            0|            0|  0.00%|                if key.startswith(prefix) and key != extra_state_key:\n",
      "  1420|         0|            0|            0|  0.00%|                    input_name = key[len(prefix):]\n",
      "  1421|         0|            0|            0|  0.00%|                    input_name = input_name.split('.', 1)[0]  # get the name of param/buffer/child\n",
      "  1422|         0|            0|            0|  0.00%|                    if input_name not in self._modules and input_name not in local_state:\n",
      "  1423|         0|            0|            0|  0.00%|                        unexpected_keys.append(key)\n",
      "  1424|         0|            0|            0|  0.00%|\n",
      "  1425|         0|            0|            0|  0.00%|    def load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]',\n",
      "  1426|         0|            0|            0|  0.00%|                        strict: bool = True):\n",
      "  1427|         0|            0|            0|  0.00%|        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into\n",
      "  1428|         0|            0|            0|  0.00%|        this module and its descendants. If :attr:`strict` is ``True``, then\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1429|         0|            0|            0|  0.00%|        the keys of :attr:`state_dict` must exactly match the keys returned\n",
      "  1430|         0|            0|            0|  0.00%|        by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      "  1431|         0|            0|            0|  0.00%|\n",
      "  1432|         0|            0|            0|  0.00%|        Args:\n",
      "  1433|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and\n",
      "  1434|         0|            0|            0|  0.00%|                persistent buffers.\n",
      "  1435|         0|            0|            0|  0.00%|            strict (bool, optional): whether to strictly enforce that the keys\n",
      "  1436|         0|            0|            0|  0.00%|                in :attr:`state_dict` match the keys returned by this module's\n",
      "  1437|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      "  1438|         0|            0|            0|  0.00%|\n",
      "  1439|         0|            0|            0|  0.00%|        Returns:\n",
      "  1440|         0|            0|            0|  0.00%|            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      "  1441|         0|            0|            0|  0.00%|                * **missing_keys** is a list of str containing the missing keys\n",
      "  1442|         0|            0|            0|  0.00%|                * **unexpected_keys** is a list of str containing the unexpected keys\n",
      "  1443|         0|            0|            0|  0.00%|\n",
      "  1444|         0|            0|            0|  0.00%|        Note:\n",
      "  1445|         0|            0|            0|  0.00%|            If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      "  1446|         0|            0|            0|  0.00%|            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      "  1447|         0|            0|            0|  0.00%|            ``RuntimeError``.\n",
      "  1448|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1449|         0|            0|            0|  0.00%|        missing_keys: List[str] = []\n",
      "  1450|         0|            0|            0|  0.00%|        unexpected_keys: List[str] = []\n",
      "  1451|         0|            0|            0|  0.00%|        error_msgs: List[str] = []\n",
      "  1452|         0|            0|            0|  0.00%|\n",
      "  1453|         0|            0|            0|  0.00%|        # copy state_dict so _load_from_state_dict can modify it\n",
      "  1454|         0|            0|            0|  0.00%|        metadata = getattr(state_dict, '_metadata', None)\n",
      "  1455|         0|            0|            0|  0.00%|        state_dict = state_dict.copy()\n",
      "  1456|         0|            0|            0|  0.00%|        if metadata is not None:\n",
      "  1457|         0|            0|            0|  0.00%|            # mypy isn't aware that \"_metadata\" exists in state_dict\n",
      "  1458|         0|            0|            0|  0.00%|            state_dict._metadata = metadata  # type: ignore[attr-defined]\n",
      "  1459|         0|            0|            0|  0.00%|\n",
      "  1460|         0|            0|            0|  0.00%|        def load(module, prefix=''):\n",
      "  1461|         0|            0|            0|  0.00%|            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
      "  1462|         0|            0|            0|  0.00%|            module._load_from_state_dict(\n",
      "  1463|         0|            0|            0|  0.00%|                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
      "  1464|         0|            0|            0|  0.00%|            for name, child in module._modules.items():\n",
      "  1465|         0|            0|            0|  0.00%|                if child is not None:\n",
      "  1466|         0|            0|            0|  0.00%|                    load(child, prefix + name + '.')\n",
      "  1467|         0|            0|            0|  0.00%|\n",
      "  1468|         0|            0|            0|  0.00%|        load(self)\n",
      "  1469|         0|            0|            0|  0.00%|        del load\n",
      "  1470|         0|            0|            0|  0.00%|\n",
      "  1471|         0|            0|            0|  0.00%|        if strict:\n",
      "  1472|         0|            0|            0|  0.00%|            if len(unexpected_keys) > 0:\n",
      "  1473|         0|            0|            0|  0.00%|                error_msgs.insert(\n",
      "  1474|         0|            0|            0|  0.00%|                    0, 'Unexpected key(s) in state_dict: {}. '.format(\n",
      "  1475|         0|            0|            0|  0.00%|                        ', '.join('\"{}\"'.format(k) for k in unexpected_keys)))\n",
      "  1476|         0|            0|            0|  0.00%|            if len(missing_keys) > 0:\n",
      "  1477|         0|            0|            0|  0.00%|                error_msgs.insert(\n",
      "  1478|         0|            0|            0|  0.00%|                    0, 'Missing key(s) in state_dict: {}. '.format(\n",
      "  1479|         0|            0|            0|  0.00%|                        ', '.join('\"{}\"'.format(k) for k in missing_keys)))\n",
      "  1480|         0|            0|            0|  0.00%|\n",
      "  1481|         0|            0|            0|  0.00%|        if len(error_msgs) > 0:\n",
      "  1482|         0|            0|            0|  0.00%|            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "  1483|         0|            0|            0|  0.00%|                               self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "  1484|         0|            0|            0|  0.00%|        return _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "  1485|         0|            0|            0|  0.00%|\n",
      "  1486|         0|            0|            0|  0.00%|    def _named_members(self, get_members_fn, prefix='', recurse=True):\n",
      "  1487|         0|            0|            0|  0.00%|        r\"\"\"Helper method for yielding various names + members of modules.\"\"\"\n",
      "  1488|         0|            0|            0|  0.00%|        memo = set()\n",
      "  1489|         0|            0|            0|  0.00%|        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)]\n",
      "  1490|         0|            0|            0|  0.00%|        for module_prefix, module in modules:\n",
      "  1491|         0|            0|            0|  0.00%|            members = get_members_fn(module)\n",
      "  1492|         0|            0|            0|  0.00%|            for k, v in members:\n",
      "  1493|         0|            0|            0|  0.00%|                if v is None or v in memo:\n",
      "  1494|         0|            0|            0|  0.00%|                    continue\n",
      "  1495|         0|            0|            0|  0.00%|                memo.add(v)\n",
      "  1496|         0|            0|            0|  0.00%|                name = module_prefix + ('.' if module_prefix else '') + k\n",
      "  1497|         0|            0|            0|  0.00%|                yield name, v\n",
      "  1498|         0|            0|            0|  0.00%|\n",
      "  1499|         0|            0|            0|  0.00%|    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
      "  1500|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module parameters.\n",
      "  1501|         0|            0|            0|  0.00%|\n",
      "  1502|         0|            0|            0|  0.00%|        This is typically passed to an optimizer.\n",
      "  1503|         0|            0|            0|  0.00%|\n",
      "  1504|         0|            0|            0|  0.00%|        Args:\n",
      "  1505|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module\n",
      "  1506|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that\n",
      "  1507|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1508|         0|            0|            0|  0.00%|\n",
      "  1509|         0|            0|            0|  0.00%|        Yields:\n",
      "  1510|         0|            0|            0|  0.00%|            Parameter: module parameter\n",
      "  1511|         0|            0|            0|  0.00%|\n",
      "  1512|         0|            0|            0|  0.00%|        Example::\n",
      "  1513|         0|            0|            0|  0.00%|\n",
      "  1514|         0|            0|            0|  0.00%|            >>> for param in model.parameters():\n",
      "  1515|         0|            0|            0|  0.00%|            >>>     print(type(param), param.size())\n",
      "  1516|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)\n",
      "  1517|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      "  1518|         0|            0|            0|  0.00%|\n",
      "  1519|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1520|         0|            0|            0|  0.00%|        for name, param in self.named_parameters(recurse=recurse):\n",
      "  1521|         0|            0|            0|  0.00%|            yield param\n",
      "  1522|         0|            0|            0|  0.00%|\n",
      "  1523|         0|            0|            0|  0.00%|    def named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Parameter]]:\n",
      "  1524|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module parameters, yielding both the\n",
      "  1525|         0|            0|            0|  0.00%|        name of the parameter as well as the parameter itself.\n",
      "  1526|         0|            0|            0|  0.00%|\n",
      "  1527|         0|            0|            0|  0.00%|        Args:\n",
      "  1528|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all parameter names.\n",
      "  1529|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module\n",
      "  1530|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that\n",
      "  1531|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1532|         0|            0|            0|  0.00%|\n",
      "  1533|         0|            0|            0|  0.00%|        Yields:\n",
      "  1534|         0|            0|            0|  0.00%|            (string, Parameter): Tuple containing the name and parameter\n",
      "  1535|         0|            0|            0|  0.00%|\n",
      "  1536|         0|            0|            0|  0.00%|        Example::\n",
      "  1537|         0|            0|            0|  0.00%|\n",
      "  1538|         0|            0|            0|  0.00%|            >>> for name, param in self.named_parameters():\n",
      "  1539|         0|            0|            0|  0.00%|            >>>    if name in ['bias']:\n",
      "  1540|         0|            0|            0|  0.00%|            >>>        print(param.size())\n",
      "  1541|         0|            0|            0|  0.00%|\n",
      "  1542|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1543|         0|            0|            0|  0.00%|        gen = self._named_members(\n",
      "  1544|         0|            0|            0|  0.00%|            lambda module: module._parameters.items(),\n",
      "  1545|         0|            0|            0|  0.00%|            prefix=prefix, recurse=recurse)\n",
      "  1546|         0|            0|            0|  0.00%|        for elem in gen:\n",
      "  1547|         0|            0|            0|  0.00%|            yield elem\n",
      "  1548|         0|            0|            0|  0.00%|\n",
      "  1549|         0|            0|            0|  0.00%|    def buffers(self, recurse: bool = True) -> Iterator[Tensor]:\n",
      "  1550|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module buffers.\n",
      "  1551|         0|            0|            0|  0.00%|\n",
      "  1552|         0|            0|            0|  0.00%|        Args:\n",
      "  1553|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module\n",
      "  1554|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that\n",
      "  1555|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1556|         0|            0|            0|  0.00%|\n",
      "  1557|         0|            0|            0|  0.00%|        Yields:\n",
      "  1558|         0|            0|            0|  0.00%|            torch.Tensor: module buffer\n",
      "  1559|         0|            0|            0|  0.00%|\n",
      "  1560|         0|            0|            0|  0.00%|        Example::\n",
      "  1561|         0|            0|            0|  0.00%|\n",
      "  1562|         0|            0|            0|  0.00%|            >>> for buf in model.buffers():\n",
      "  1563|         0|            0|            0|  0.00%|            >>>     print(type(buf), buf.size())\n",
      "  1564|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)\n",
      "  1565|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      "  1566|         0|            0|            0|  0.00%|\n",
      "  1567|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1568|         0|            0|            0|  0.00%|        for _, buf in self.named_buffers(recurse=recurse):\n",
      "  1569|         0|            0|            0|  0.00%|            yield buf\n",
      "  1570|         0|            0|            0|  0.00%|\n",
      "  1571|         0|            0|            0|  0.00%|    def named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Tensor]]:\n",
      "  1572|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module buffers, yielding both the\n",
      "  1573|         0|            0|            0|  0.00%|        name of the buffer as well as the buffer itself.\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|        Args:\n",
      "  1576|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all buffer names.\n",
      "  1577|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module\n",
      "  1578|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that\n",
      "  1579|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1580|         0|            0|            0|  0.00%|\n",
      "  1581|         0|            0|            0|  0.00%|        Yields:\n",
      "  1582|         0|            0|            0|  0.00%|            (string, torch.Tensor): Tuple containing the name and buffer\n",
      "  1583|         0|            0|            0|  0.00%|\n",
      "  1584|         0|            0|            0|  0.00%|        Example::\n",
      "  1585|         0|            0|            0|  0.00%|\n",
      "  1586|         0|            0|            0|  0.00%|            >>> for name, buf in self.named_buffers():\n",
      "  1587|         0|            0|            0|  0.00%|            >>>    if name in ['running_var']:\n",
      "  1588|         0|            0|            0|  0.00%|            >>>        print(buf.size())\n",
      "  1589|         0|            0|            0|  0.00%|\n",
      "  1590|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1591|         0|            0|            0|  0.00%|        gen = self._named_members(\n",
      "  1592|         0|            0|            0|  0.00%|            lambda module: module._buffers.items(),\n",
      "  1593|         0|            0|            0|  0.00%|            prefix=prefix, recurse=recurse)\n",
      "  1594|         0|            0|            0|  0.00%|        for elem in gen:\n",
      "  1595|         0|            0|            0|  0.00%|            yield elem\n",
      "  1596|         0|            0|            0|  0.00%|\n",
      "  1597|         0|            0|            0|  0.00%|    def children(self) -> Iterator['Module']:\n",
      "  1598|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over immediate children modules.\n",
      "  1599|         0|            0|            0|  0.00%|\n",
      "  1600|         0|            0|            0|  0.00%|        Yields:\n",
      "  1601|         0|            0|            0|  0.00%|            Module: a child module\n",
      "  1602|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1603|         0|            0|            0|  0.00%|        for name, module in self.named_children():\n",
      "  1604|         0|            0|            0|  0.00%|            yield module\n",
      "  1605|         0|            0|            0|  0.00%|\n",
      "  1606|         0|            0|            0|  0.00%|    def named_children(self) -> Iterator[Tuple[str, 'Module']]:\n",
      "  1607|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over immediate children modules, yielding both\n",
      "  1608|         0|            0|            0|  0.00%|        the name of the module as well as the module itself.\n",
      "  1609|         0|            0|            0|  0.00%|\n",
      "  1610|         0|            0|            0|  0.00%|        Yields:\n",
      "  1611|         0|            0|            0|  0.00%|            (string, Module): Tuple containing a name and child module\n",
      "  1612|         0|            0|            0|  0.00%|\n",
      "  1613|         0|            0|            0|  0.00%|        Example::\n",
      "  1614|         0|            0|            0|  0.00%|\n",
      "  1615|         0|            0|            0|  0.00%|            >>> for name, module in model.named_children():\n",
      "  1616|         0|            0|            0|  0.00%|            >>>     if name in ['conv4', 'conv5']:\n",
      "  1617|         0|            0|            0|  0.00%|            >>>         print(module)\n",
      "  1618|         0|            0|            0|  0.00%|\n",
      "  1619|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1620|         0|            0|            0|  0.00%|        memo = set()\n",
      "  1621|         0|            0|            0|  0.00%|        for name, module in self._modules.items():\n",
      "  1622|         0|            0|            0|  0.00%|            if module is not None and module not in memo:\n",
      "  1623|         0|            0|            0|  0.00%|                memo.add(module)\n",
      "  1624|         0|            0|            0|  0.00%|                yield name, module\n",
      "  1625|         0|            0|            0|  0.00%|\n",
      "  1626|         0|            0|            0|  0.00%|    def modules(self) -> Iterator['Module']:\n",
      "  1627|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over all modules in the network.\n",
      "  1628|         0|            0|            0|  0.00%|\n",
      "  1629|         0|            0|            0|  0.00%|        Yields:\n",
      "  1630|         0|            0|            0|  0.00%|            Module: a module in the network\n",
      "  1631|         0|            0|            0|  0.00%|\n",
      "  1632|         0|            0|            0|  0.00%|        Note:\n",
      "  1633|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following\n",
      "  1634|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.\n",
      "  1635|         0|            0|            0|  0.00%|\n",
      "  1636|         0|            0|            0|  0.00%|        Example::\n",
      "  1637|         0|            0|            0|  0.00%|\n",
      "  1638|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)\n",
      "  1639|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)\n",
      "  1640|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.modules()):\n",
      "  1641|         0|            0|            0|  0.00%|                    print(idx, '->', m)\n",
      "  1642|         0|            0|            0|  0.00%|\n",
      "  1643|         0|            0|            0|  0.00%|            0 -> Sequential(\n",
      "  1644|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1645|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1646|         0|            0|            0|  0.00%|            )\n",
      "  1647|         0|            0|            0|  0.00%|            1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      "  1648|         0|            0|            0|  0.00%|\n",
      "  1649|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1650|         0|            0|            0|  0.00%|        for _, module in self.named_modules():\n",
      "  1651|         0|            0|            0|  0.00%|            yield module\n",
      "  1652|         0|            0|            0|  0.00%|\n",
      "  1653|         0|            0|            0|  0.00%|    def named_modules(self, memo: Optional[Set['Module']] = None, prefix: str = '', remove_duplicate: bool = True):\n",
      "  1654|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over all modules in the network, yielding\n",
      "  1655|         0|            0|            0|  0.00%|        both the name of the module as well as the module itself.\n",
      "  1656|         0|            0|            0|  0.00%|\n",
      "  1657|         0|            0|            0|  0.00%|        Args:\n",
      "  1658|         0|            0|            0|  0.00%|            memo: a memo to store the set of modules already added to the result\n",
      "  1659|         0|            0|            0|  0.00%|            prefix: a prefix that will be added to the name of the module\n",
      "  1660|         0|            0|            0|  0.00%|            remove_duplicate: whether to remove the duplicated module instances in the result\n",
      "  1661|         0|            0|            0|  0.00%|            or not\n",
      "  1662|         0|            0|            0|  0.00%|\n",
      "  1663|         0|            0|            0|  0.00%|        Yields:\n",
      "  1664|         0|            0|            0|  0.00%|            (string, Module): Tuple of name and module\n",
      "  1665|         0|            0|            0|  0.00%|\n",
      "  1666|         0|            0|            0|  0.00%|        Note:\n",
      "  1667|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following\n",
      "  1668|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.\n",
      "  1669|         0|            0|            0|  0.00%|\n",
      "  1670|         0|            0|            0|  0.00%|        Example::\n",
      "  1671|         0|            0|            0|  0.00%|\n",
      "  1672|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)\n",
      "  1673|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)\n",
      "  1674|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.named_modules()):\n",
      "  1675|         0|            0|            0|  0.00%|                    print(idx, '->', m)\n",
      "  1676|         0|            0|            0|  0.00%|\n",
      "  1677|         0|            0|            0|  0.00%|            0 -> ('', Sequential(\n",
      "  1678|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1679|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1680|         0|            0|            0|  0.00%|            ))\n",
      "  1681|         0|            0|            0|  0.00%|            1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      "  1682|         0|            0|            0|  0.00%|\n",
      "  1683|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1684|         0|            0|            0|  0.00%|\n",
      "  1685|         0|            0|            0|  0.00%|        if memo is None:\n",
      "  1686|         0|            0|            0|  0.00%|            memo = set()\n",
      "  1687|         0|            0|            0|  0.00%|        if self not in memo:\n",
      "  1688|         0|            0|            0|  0.00%|            if remove_duplicate:\n",
      "  1689|         0|            0|            0|  0.00%|                memo.add(self)\n",
      "  1690|         0|            0|            0|  0.00%|            yield prefix, self\n",
      "  1691|         0|            0|            0|  0.00%|            for name, module in self._modules.items():\n",
      "  1692|         0|            0|            0|  0.00%|                if module is None:\n",
      "  1693|         0|            0|            0|  0.00%|                    continue\n",
      "  1694|         0|            0|            0|  0.00%|                submodule_prefix = prefix + ('.' if prefix else '') + name\n",
      "  1695|         0|            0|            0|  0.00%|                for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n",
      "  1696|         0|            0|            0|  0.00%|                    yield m\n",
      "  1697|         0|            0|            0|  0.00%|\n",
      "  1698|         0|            0|            0|  0.00%|    def train(self: T, mode: bool = True) -> T:\n",
      "  1699|         0|            0|            0|  0.00%|        r\"\"\"Sets the module in training mode.\n",
      "  1700|         0|            0|            0|  0.00%|\n",
      "  1701|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of\n",
      "  1702|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation\n",
      "  1703|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "  1704|         0|            0|            0|  0.00%|        etc.\n",
      "  1705|         0|            0|            0|  0.00%|\n",
      "  1706|         0|            0|            0|  0.00%|        Args:\n",
      "  1707|         0|            0|            0|  0.00%|            mode (bool): whether to set training mode (``True``) or evaluation\n",
      "  1708|         0|            0|            0|  0.00%|                         mode (``False``). Default: ``True``.\n",
      "  1709|         0|            0|            0|  0.00%|\n",
      "  1710|         0|            0|            0|  0.00%|        Returns:\n",
      "  1711|         0|            0|            0|  0.00%|            Module: self\n",
      "  1712|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1713|         0|            0|            0|  0.00%|        if not isinstance(mode, bool):\n",
      "  1714|         0|            0|            0|  0.00%|            raise ValueError(\"training mode is expected to be boolean\")\n",
      "  1715|         0|            0|            0|  0.00%|        self.training = mode\n",
      "  1716|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "  1717|         0|            0|            0|  0.00%|            module.train(mode)\n",
      "  1718|         0|            0|            0|  0.00%|        return self\n",
      "  1719|         0|            0|            0|  0.00%|\n",
      "  1720|         0|            0|            0|  0.00%|    def eval(self: T) -> T:\n",
      "  1721|         0|            0|            0|  0.00%|        r\"\"\"Sets the module in evaluation mode.\n",
      "  1722|         0|            0|            0|  0.00%|\n",
      "  1723|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of\n",
      "  1724|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation\n",
      "  1725|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "  1726|         0|            0|            0|  0.00%|        etc.\n",
      "  1727|         0|            0|            0|  0.00%|\n",
      "  1728|         0|            0|            0|  0.00%|        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      "  1729|         0|            0|            0|  0.00%|\n",
      "  1730|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between\n",
      "  1731|         0|            0|            0|  0.00%|        `.eval()` and several similar mechanisms that may be confused with it.\n",
      "  1732|         0|            0|            0|  0.00%|\n",
      "  1733|         0|            0|            0|  0.00%|        Returns:\n",
      "  1734|         0|            0|            0|  0.00%|            Module: self\n",
      "  1735|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1736|         0|            0|            0|  0.00%|        return self.train(False)\n",
      "  1737|         0|            0|            0|  0.00%|\n",
      "  1738|         0|            0|            0|  0.00%|    def requires_grad_(self: T, requires_grad: bool = True) -> T:\n",
      "  1739|         0|            0|            0|  0.00%|        r\"\"\"Change if autograd should record operations on parameters in this\n",
      "  1740|         0|            0|            0|  0.00%|        module.\n",
      "  1741|         0|            0|            0|  0.00%|\n",
      "  1742|         0|            0|            0|  0.00%|        This method sets the parameters' :attr:`requires_grad` attributes\n",
      "  1743|         0|            0|            0|  0.00%|        in-place.\n",
      "  1744|         0|            0|            0|  0.00%|\n",
      "  1745|         0|            0|            0|  0.00%|        This method is helpful for freezing part of the module for finetuning\n",
      "  1746|         0|            0|            0|  0.00%|        or training parts of a model individually (e.g., GAN training).\n",
      "  1747|         0|            0|            0|  0.00%|\n",
      "  1748|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between\n",
      "  1749|         0|            0|            0|  0.00%|        `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      "  1750|         0|            0|            0|  0.00%|\n",
      "  1751|         0|            0|            0|  0.00%|        Args:\n",
      "  1752|         0|            0|            0|  0.00%|            requires_grad (bool): whether autograd should record operations on\n",
      "  1753|         0|            0|            0|  0.00%|                                  parameters in this module. Default: ``True``.\n",
      "  1754|         0|            0|            0|  0.00%|\n",
      "  1755|         0|            0|            0|  0.00%|        Returns:\n",
      "  1756|         0|            0|            0|  0.00%|            Module: self\n",
      "  1757|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1758|         0|            0|            0|  0.00%|        for p in self.parameters():\n",
      "  1759|         0|            0|            0|  0.00%|            p.requires_grad_(requires_grad)\n",
      "  1760|         0|            0|            0|  0.00%|        return self\n",
      "  1761|         0|            0|            0|  0.00%|\n",
      "  1762|         0|            0|            0|  0.00%|    def zero_grad(self, set_to_none: bool = False) -> None:\n",
      "  1763|         0|            0|            0|  0.00%|        r\"\"\"Sets gradients of all model parameters to zero. See similar function\n",
      "  1764|         0|            0|            0|  0.00%|        under :class:`torch.optim.Optimizer` for more context.\n",
      "  1765|         0|            0|            0|  0.00%|\n",
      "  1766|         0|            0|            0|  0.00%|        Args:\n",
      "  1767|         0|            0|            0|  0.00%|            set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      "  1768|         0|            0|            0|  0.00%|                See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      "  1769|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1770|         0|            0|            0|  0.00%|        if getattr(self, '_is_replica', False):\n",
      "  1771|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  1772|         0|            0|            0|  0.00%|                \"Calling .zero_grad() from a module created with nn.DataParallel() has no effect. \"\n",
      "  1773|         0|            0|            0|  0.00%|                \"The parameters are copied (in a differentiable manner) from the original module. \"\n",
      "  1774|         0|            0|            0|  0.00%|                \"This means they are not leaf nodes in autograd and so don't accumulate gradients. \"\n",
      "  1775|         0|            0|            0|  0.00%|                \"If you need gradients in your forward method, consider using autograd.grad instead.\")\n",
      "  1776|         0|            0|            0|  0.00%|\n",
      "  1777|         0|            0|            0|  0.00%|        for p in self.parameters():\n",
      "  1778|         0|            0|            0|  0.00%|            if p.grad is not None:\n",
      "  1779|         0|            0|            0|  0.00%|                if set_to_none:\n",
      "  1780|         0|            0|            0|  0.00%|                    p.grad = None\n",
      "  1781|         0|            0|            0|  0.00%|                else:\n",
      "  1782|         0|            0|            0|  0.00%|                    if p.grad.grad_fn is not None:\n",
      "  1783|         0|            0|            0|  0.00%|                        p.grad.detach_()\n",
      "  1784|         0|            0|            0|  0.00%|                    else:\n",
      "  1785|         0|            0|            0|  0.00%|                        p.grad.requires_grad_(False)\n",
      "  1786|         0|            0|            0|  0.00%|                    p.grad.zero_()\n",
      "  1787|         0|            0|            0|  0.00%|\n",
      "  1788|         0|            0|            0|  0.00%|    def share_memory(self: T) -> T:\n",
      "  1789|         0|            0|            0|  0.00%|        r\"\"\"See :meth:`torch.Tensor.share_memory_`\"\"\"\n",
      "  1790|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.share_memory_())\n",
      "  1791|         0|            0|            0|  0.00%|\n",
      "  1792|         0|            0|            0|  0.00%|    def _get_name(self):\n",
      "  1793|         0|            0|            0|  0.00%|        return self.__class__.__name__\n",
      "  1794|         0|            0|            0|  0.00%|\n",
      "  1795|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "  1796|         0|            0|            0|  0.00%|        r\"\"\"Set the extra representation of the module\n",
      "  1797|         0|            0|            0|  0.00%|\n",
      "  1798|         0|            0|            0|  0.00%|        To print customized extra information, you should re-implement\n",
      "  1799|         0|            0|            0|  0.00%|        this method in your own modules. Both single-line and multi-line\n",
      "  1800|         0|            0|            0|  0.00%|        strings are acceptable.\n",
      "  1801|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1802|         0|            0|            0|  0.00%|        return ''\n",
      "  1803|         0|            0|            0|  0.00%|\n",
      "  1804|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "  1805|         0|            0|            0|  0.00%|        # We treat the extra repr like the sub-module, one item per line\n",
      "  1806|         0|            0|            0|  0.00%|        extra_lines = []\n",
      "  1807|         0|            0|            0|  0.00%|        extra_repr = self.extra_repr()\n",
      "  1808|         0|            0|            0|  0.00%|        # empty string will be split into list ['']\n",
      "  1809|         0|            0|            0|  0.00%|        if extra_repr:\n",
      "  1810|         0|            0|            0|  0.00%|            extra_lines = extra_repr.split('\\n')\n",
      "  1811|         0|            0|            0|  0.00%|        child_lines = []\n",
      "  1812|         0|            0|            0|  0.00%|        for key, module in self._modules.items():\n",
      "  1813|         0|            0|            0|  0.00%|            mod_str = repr(module)\n",
      "  1814|         0|            0|            0|  0.00%|            mod_str = _addindent(mod_str, 2)\n",
      "  1815|         0|            0|            0|  0.00%|            child_lines.append('(' + key + '): ' + mod_str)\n",
      "  1816|         0|            0|            0|  0.00%|        lines = extra_lines + child_lines\n",
      "  1817|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1818|         0|            0|            0|  0.00%|        main_str = self._get_name() + '('\n",
      "  1819|         0|            0|            0|  0.00%|        if lines:\n",
      "  1820|         0|            0|            0|  0.00%|            # simple one-liner info, which most builtin Modules will use\n",
      "  1821|         0|            0|            0|  0.00%|            if len(extra_lines) == 1 and not child_lines:\n",
      "  1822|         0|            0|            0|  0.00%|                main_str += extra_lines[0]\n",
      "  1823|         0|            0|            0|  0.00%|            else:\n",
      "  1824|         0|            0|            0|  0.00%|                main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
      "  1825|         0|            0|            0|  0.00%|\n",
      "  1826|         0|            0|            0|  0.00%|        main_str += ')'\n",
      "  1827|         0|            0|            0|  0.00%|        return main_str\n",
      "  1828|         0|            0|            0|  0.00%|\n",
      "  1829|         0|            0|            0|  0.00%|    def __dir__(self):\n",
      "  1830|         0|            0|            0|  0.00%|        module_attrs = dir(self.__class__)\n",
      "  1831|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())\n",
      "  1832|         0|            0|            0|  0.00%|        parameters = list(self._parameters.keys())\n",
      "  1833|         0|            0|            0|  0.00%|        modules = list(self._modules.keys())\n",
      "  1834|         0|            0|            0|  0.00%|        buffers = list(self._buffers.keys())\n",
      "  1835|         0|            0|            0|  0.00%|        keys = module_attrs + attrs + parameters + modules + buffers\n",
      "  1836|         0|            0|            0|  0.00%|\n",
      "  1837|         0|            0|            0|  0.00%|        # Eliminate attrs that are not legal Python variable names\n",
      "  1838|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key[0].isdigit()]\n",
      "  1839|         0|            0|            0|  0.00%|\n",
      "  1840|         0|            0|            0|  0.00%|        return sorted(keys)\n",
      "  1841|         0|            0|            0|  0.00%|\n",
      "  1842|         0|            0|            0|  0.00%|    def _replicate_for_data_parallel(self):\n",
      "  1843|         0|            0|            0|  0.00%|        replica = self.__new__(type(self))\n",
      "  1844|         0|            0|            0|  0.00%|        replica.__dict__ = self.__dict__.copy()\n",
      "  1845|         0|            0|            0|  0.00%|\n",
      "  1846|         0|            0|            0|  0.00%|        # replicas do not have parameters themselves, the replicas reference the original\n",
      "  1847|         0|            0|            0|  0.00%|        # module.\n",
      "  1848|         0|            0|            0|  0.00%|        replica._parameters = OrderedDict()\n",
      "  1849|         0|            0|            0|  0.00%|        replica._buffers = replica._buffers.copy()\n",
      "  1850|         0|            0|            0|  0.00%|        replica._modules = replica._modules.copy()\n",
      "  1851|         0|            0|            0|  0.00%|        replica._is_replica = True\n",
      "  1852|         0|            0|            0|  0.00%|\n",
      "  1853|         0|            0|            0|  0.00%|        return replica\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py\n",
      "File duration: 0.00078249s (0.35%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import namedtuple\n",
      "     2|         0|            0|            0|  0.00%|import warnings\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|import torch\n",
      "     5|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     6|         0|            0|            0|  0.00%|from ... import _VF\n",
      "     7|         0|            0|            0|  0.00%|from ..._jit_internal import Optional\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|from typing import List, Tuple\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|\n",
      "    13|         0|            0|            0|  0.00%|PackedSequence_ = namedtuple('PackedSequence_',\n",
      "    14|         0|            0|            0|  0.00%|                             ['data', 'batch_sizes', 'sorted_indices', 'unsorted_indices'])\n",
      "    15|         0|            0|            0|  0.00%|\n",
      "    16|         0|            0|            0|  0.00%|# type annotation for PackedSequence_ to make it compatible with TorchScript\n",
      "    17|         0|            0|            0|  0.00%|PackedSequence_.__annotations__ = {'data': torch.Tensor, 'batch_sizes': torch.Tensor,\n",
      "    18|         0|            0|            0|  0.00%|                                   'sorted_indices': Optional[torch.Tensor],\n",
      "    19|         0|            0|            0|  0.00%|                                   'unsorted_indices': Optional[torch.Tensor]}\n",
      "    20|         0|            0|            0|  0.00%|\n",
      "    21|         0|            0|            0|  0.00%|def bind(optional, fn):\n",
      "    22|         0|            0|            0|  0.00%|    if optional is None:\n",
      "    23|         0|            0|            0|  0.00%|        return None\n",
      "    24|         0|            0|            0|  0.00%|    return fn(optional)\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|\n",
      "    27|         0|            0|            0|  0.00%|class PackedSequence(PackedSequence_):\n",
      "    28|         0|            0|            0|  0.00%|    r\"\"\"Holds the data and list of :attr:`batch_sizes` of a packed sequence.\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|    All RNN modules accept packed sequences as inputs.\n",
      "    31|         0|            0|            0|  0.00%|\n",
      "    32|         0|            0|            0|  0.00%|    Note:\n",
      "    33|         0|            0|            0|  0.00%|        Instances of this class should never be created manually. They are meant\n",
      "    34|         0|            0|            0|  0.00%|        to be instantiated by functions like :func:`pack_padded_sequence`.\n",
      "    35|         0|            0|            0|  0.00%|\n",
      "    36|         0|            0|            0|  0.00%|        Batch sizes represent the number elements at each sequence step in\n",
      "    37|         0|            0|            0|  0.00%|        the batch, not the varying sequence lengths passed to\n",
      "    38|         0|            0|            0|  0.00%|        :func:`pack_padded_sequence`.  For instance, given data ``abc`` and ``x``\n",
      "    39|         0|            0|            0|  0.00%|        the :class:`PackedSequence` would contain data ``axbc`` with\n",
      "    40|         0|            0|            0|  0.00%|        ``batch_sizes=[2,1,1]``.\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|    Attributes:\n",
      "    43|         0|            0|            0|  0.00%|        data (Tensor): Tensor containing packed sequence\n",
      "    44|         0|            0|            0|  0.00%|        batch_sizes (Tensor): Tensor of integers holding\n",
      "    45|         0|            0|            0|  0.00%|            information about the batch size at each sequence step\n",
      "    46|         0|            0|            0|  0.00%|        sorted_indices (Tensor, optional): Tensor of integers holding how this\n",
      "    47|         0|            0|            0|  0.00%|            :class:`PackedSequence` is constructed from sequences.\n",
      "    48|         0|            0|            0|  0.00%|        unsorted_indices (Tensor, optional): Tensor of integers holding how this\n",
      "    49|         0|            0|            0|  0.00%|            to recover the original sequences with correct order.\n",
      "    50|         0|            0|            0|  0.00%|\n",
      "    51|         0|            0|            0|  0.00%|    .. note::\n",
      "    52|         0|            0|            0|  0.00%|        :attr:`data` can be on arbitrary device and of arbitrary dtype.\n",
      "    53|         0|            0|            0|  0.00%|        :attr:`sorted_indices` and :attr:`unsorted_indices` must be ``torch.int64``\n",
      "    54|         0|            0|            0|  0.00%|        tensors on the same device as :attr:`data`.\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|        However, :attr:`batch_sizes` should always be a CPU ``torch.int64`` tensor.\n",
      "    57|         0|            0|            0|  0.00%|\n",
      "    58|         0|            0|            0|  0.00%|        This invariant is maintained throughout :class:`PackedSequence` class,\n",
      "    59|         0|            0|            0|  0.00%|        and all functions that construct a `:class:PackedSequence` in PyTorch\n",
      "    60|         0|            0|            0|  0.00%|        (i.e., they only pass in tensors conforming to this constraint).\n",
      "    61|         0|            0|            0|  0.00%|\n",
      "    62|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    63|         2|  0.000118017|  5.90086e-05|  0.05%|    def __new__(cls, data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "    64|         2|  1.38283e-05|  6.91414e-06|  0.01%|        return super(PackedSequence, cls).__new__(\n",
      "    65|         2|  7.15256e-06|  3.57628e-06|  0.00%|            cls,\n",
      "    66|         2|  5.24521e-06|   2.6226e-06|  0.00%|            *_packed_sequence_init_args(data, batch_sizes, sorted_indices,\n",
      "    67|         2|   3.6478e-05|   1.8239e-05|  0.02%|                                        unsorted_indices))\n",
      "(call)|         2|  3.40939e-05|  1.70469e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:156 _packed_sequence_init_args\n",
      "(call)|         2|  2.02656e-05|  1.01328e-05|  0.01%|# <string>:12 __new__\n",
      "    68|         0|            0|            0|  0.00%|\n",
      "    69|         0|            0|            0|  0.00%|    # NOTE [ device and dtype of a PackedSequence ]\n",
      "    70|         0|            0|            0|  0.00%|    #\n",
      "    71|         0|            0|            0|  0.00%|    # See the note above in doc string (starting with \":attr:`data` can be on\n",
      "    72|         0|            0|            0|  0.00%|    # arbitrary device...\").\n",
      "    73|         0|            0|            0|  0.00%|    def pin_memory(self):\n",
      "    74|         0|            0|            0|  0.00%|        # Why not convert `batch_sizes`?\n",
      "    75|         0|            0|            0|  0.00%|        # See NOTE [ device and dtype of a PackedSequence ]\n",
      "    76|         0|            0|            0|  0.00%|        return type(self)(self.data.pin_memory(), self.batch_sizes,\n",
      "    77|         0|            0|            0|  0.00%|                          bind(self.sorted_indices, lambda t: t.pin_memory()),\n",
      "    78|         0|            0|            0|  0.00%|                          bind(self.unsorted_indices, lambda t: t.pin_memory()))\n",
      "    79|         0|            0|            0|  0.00%|\n",
      "    80|         0|            0|            0|  0.00%|    def cuda(self, *args, **kwargs):\n",
      "    81|         0|            0|            0|  0.00%|        # Tests to see if 'cuda' should be added to kwargs\n",
      "    82|         0|            0|            0|  0.00%|        ex = torch.tensor((), dtype=self.data.dtype, device=self.data.device).to(*args, **kwargs)\n",
      "    83|         0|            0|            0|  0.00%|        if ex.is_cuda:\n",
      "    84|         0|            0|            0|  0.00%|            return self.to(*args, **kwargs)\n",
      "    85|         0|            0|            0|  0.00%|        return self.to(*args, device='cuda', **kwargs)\n",
      "    86|         0|            0|            0|  0.00%|\n",
      "    87|         0|            0|            0|  0.00%|    def cpu(self, *args, **kwargs):\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|        ex = torch.tensor((), dtype=self.data.dtype, device=self.data.device).to(*args, **kwargs)\n",
      "    90|         0|            0|            0|  0.00%|        if ex.device.type == 'cpu':\n",
      "    91|         0|            0|            0|  0.00%|            return self.to(*args, **kwargs)\n",
      "    92|         0|            0|            0|  0.00%|        return self.to(*args, device='cpu', **kwargs)\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|    def double(self):\n",
      "    95|         0|            0|            0|  0.00%|        return self.to(dtype=torch.double)\n",
      "    96|         0|            0|            0|  0.00%|\n",
      "    97|         0|            0|            0|  0.00%|    def float(self):\n",
      "    98|         0|            0|            0|  0.00%|        return self.to(dtype=torch.float)\n",
      "    99|         0|            0|            0|  0.00%|\n",
      "   100|         0|            0|            0|  0.00%|    def half(self):\n",
      "   101|         0|            0|            0|  0.00%|        return self.to(dtype=torch.half)\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    def long(self):\n",
      "   104|         0|            0|            0|  0.00%|        return self.to(dtype=torch.long)\n",
      "   105|         0|            0|            0|  0.00%|\n",
      "   106|         0|            0|            0|  0.00%|    def int(self):\n",
      "   107|         0|            0|            0|  0.00%|        return self.to(dtype=torch.int)\n",
      "   108|         0|            0|            0|  0.00%|\n",
      "   109|         0|            0|            0|  0.00%|    def short(self):\n",
      "   110|         0|            0|            0|  0.00%|        return self.to(dtype=torch.short)\n",
      "   111|         0|            0|            0|  0.00%|\n",
      "   112|         0|            0|            0|  0.00%|    def char(self):\n",
      "   113|         0|            0|            0|  0.00%|        return self.to(dtype=torch.int8)\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|    def byte(self):\n",
      "   116|         0|            0|            0|  0.00%|        return self.to(dtype=torch.uint8)\n",
      "   117|         0|            0|            0|  0.00%|\n",
      "   118|         0|            0|            0|  0.00%|    def to(self, *args, **kwargs):\n",
      "   119|         0|            0|            0|  0.00%|        r\"\"\"Performs dtype and/or device conversion on `self.data`.\n",
      "   120|         0|            0|            0|  0.00%|\n",
      "   121|         0|            0|            0|  0.00%|        It has similar signature as :meth:`torch.Tensor.to`, except optional\n",
      "   122|         0|            0|            0|  0.00%|        arguments like `non_blocking` and `copy` should be passed as kwargs,\n",
      "   123|         0|            0|            0|  0.00%|        not args, or they will not apply to the index tensors.\n",
      "   124|         0|            0|            0|  0.00%|\n",
      "   125|         0|            0|            0|  0.00%|        .. note::\n",
      "   126|         0|            0|            0|  0.00%|\n",
      "   127|         0|            0|            0|  0.00%|            If the ``self.data`` Tensor already has the correct :class:`torch.dtype`\n",
      "   128|         0|            0|            0|  0.00%|            and :class:`torch.device`, then ``self`` is returned.\n",
      "   129|         0|            0|            0|  0.00%|            Otherwise, returns a copy with the desired configuration.\n",
      "   130|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   131|         0|            0|            0|  0.00%|\n",
      "   132|         0|            0|            0|  0.00%|        # Why not convert `batch_sizes`?\n",
      "   133|         0|            0|            0|  0.00%|        # See NOTE [ device and dtype of a PackedSequence ]\n",
      "   134|         0|            0|            0|  0.00%|        data = self.data.to(*args, **kwargs)\n",
      "   135|         0|            0|            0|  0.00%|        if data is self.data:\n",
      "   136|         0|            0|            0|  0.00%|            return self\n",
      "   137|         0|            0|            0|  0.00%|        else:\n",
      "   138|         0|            0|            0|  0.00%|            # Does not forward device or dtype arg/kwargs, device is set from data.device\n",
      "   139|         0|            0|            0|  0.00%|            kwargs = {k : v for k, v in filter(lambda t: t[0] != 'device' and t[0] != 'dtype', kwargs.items())}\n",
      "   140|         0|            0|            0|  0.00%|            sorted_indices = bind(self.sorted_indices, lambda t: t.to(data.device, **kwargs))\n",
      "   141|         0|            0|            0|  0.00%|            unsorted_indices = bind(self.unsorted_indices, lambda t: t.to(data.device, **kwargs))\n",
      "   142|         0|            0|            0|  0.00%|            return type(self)(data, self.batch_sizes, sorted_indices, unsorted_indices)\n",
      "   143|         0|            0|            0|  0.00%|\n",
      "   144|         0|            0|            0|  0.00%|    @property\n",
      "   145|         0|            0|            0|  0.00%|    def is_cuda(self):\n",
      "   146|         0|            0|            0|  0.00%|        r\"\"\"Returns true if `self.data` stored on a gpu\"\"\"\n",
      "   147|         0|            0|            0|  0.00%|        return self.data.is_cuda\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         0|            0|            0|  0.00%|    def is_pinned(self):\n",
      "   150|         0|            0|            0|  0.00%|        r\"\"\"Returns true if `self.data` stored on in pinned memory\"\"\"\n",
      "   151|         0|            0|            0|  0.00%|        return self.data.is_pinned()\n",
      "   152|         0|            0|            0|  0.00%|\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|# TorchScript doesn't support constructors on named tuples, so we use this helper\n",
      "   155|         0|            0|            0|  0.00%|# method to construct PackedSequence\n",
      "   156|         3|  1.23978e-05|  4.13259e-06|  0.01%|def _packed_sequence_init_args(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "   157|         0|            0|            0|  0.00%|    # type: (Tensor, Optional[Tensor], Optional[Tensor], Optional[Tensor]) -> Tuple[Tensor, Tensor, Optional[Tensor], Optional[Tensor]]  # noqa: B950\n",
      "   158|         0|            0|            0|  0.00%|    # NB: if unsorted_indices is provided, it should be the inverse permutation\n",
      "   159|         0|            0|            0|  0.00%|    # to sorted_indices. Don't assert it here because the PackedSequence ctor\n",
      "   160|         0|            0|            0|  0.00%|    # should only be used internally.\n",
      "   161|         0|            0|            0|  0.00%|\n",
      "   162|         3|  9.05991e-06|  3.01997e-06|  0.00%|    if unsorted_indices is None:\n",
      "   163|         1|  1.28746e-05|  1.28746e-05|  0.01%|        unsorted_indices = invert_permutation(sorted_indices)\n",
      "(call)|         1|  5.10216e-05|  5.10216e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:190 invert_permutation\n",
      "   164|         0|            0|            0|  0.00%|\n",
      "   165|         0|            0|            0|  0.00%|    # support being called as `PackedSequence(data, batch_sizes, sorted_indices)`\n",
      "   166|         3|  8.34465e-06|  2.78155e-06|  0.00%|    if batch_sizes is not None:\n",
      "   167|         0|            0|            0|  0.00%|        # TODO: Re-enable this check (.type isn't supported in TorchScript)\n",
      "   168|         3|  2.16961e-05|  7.23203e-06|  0.01%|        if batch_sizes.device.type != 'cpu':\n",
      "   169|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   170|         0|            0|            0|  0.00%|                \"batch_sizes should always be on CPU. \"\n",
      "   171|         0|            0|            0|  0.00%|                \"Instances of PackedSequence should never be created manually. \"\n",
      "   172|         0|            0|            0|  0.00%|                \"They should be instantiated by functions like pack_sequence \"\n",
      "   173|         0|            0|            0|  0.00%|                \"and pack_padded_sequences in nn.utils.rnn. \"\n",
      "   174|         0|            0|            0|  0.00%|                \"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence\")\n",
      "   175|         3|  1.07288e-05|  3.57628e-06|  0.00%|        return data, batch_sizes, sorted_indices, unsorted_indices\n",
      "   176|         0|            0|            0|  0.00%|\n",
      "   177|         0|            0|            0|  0.00%|    # support being called as `PackedSequence((data, batch_sizes), *, sorted_indices)`\n",
      "   178|         0|            0|            0|  0.00%|    else:\n",
      "   179|         0|            0|            0|  0.00%|        assert isinstance(data, (list, tuple)) and len(data) == 2\n",
      "   180|         0|            0|            0|  0.00%|        return data[0], data[1], sorted_indices, unsorted_indices\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|\n",
      "   183|         1|  3.09944e-06|  3.09944e-06|  0.00%|def _packed_sequence_init(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "   184|         0|            0|            0|  0.00%|    # type: (Tensor, Optional[Tensor], Optional[Tensor], Optional[Tensor]) -> PackedSequence\n",
      "   185|         1|  4.05312e-06|  4.05312e-06|  0.00%|    data, batch_sizes, sorted_indices, unsorted_indices = _packed_sequence_init_args(\n",
      "   186|         1|  1.07288e-05|  1.07288e-05|  0.00%|        data, batch_sizes, sorted_indices, unsorted_indices)\n",
      "(call)|         1|  9.20296e-05|  9.20296e-05|  0.04%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:156 _packed_sequence_init_args\n",
      "   187|         1|  1.28746e-05|  1.28746e-05|  0.01%|    return PackedSequence(data, batch_sizes, sorted_indices, unsorted_indices)\n",
      "(call)|         1|  6.22272e-05|  6.22272e-05|  0.03%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:63 __new__\n",
      "   188|         0|            0|            0|  0.00%|\n",
      "   189|         0|            0|            0|  0.00%|\n",
      "   190|         1|  4.76837e-06|  4.76837e-06|  0.00%|def invert_permutation(permutation):\n",
      "   191|         0|            0|            0|  0.00%|    # type: (Optional[Tensor]) -> Optional[Tensor]\n",
      "   192|         1|  4.29153e-06|  4.29153e-06|  0.00%|    if permutation is None:\n",
      "   193|         0|            0|            0|  0.00%|        return None\n",
      "   194|         1|  8.82149e-06|  8.82149e-06|  0.00%|    output = torch.empty_like(permutation, memory_format=torch.legacy_contiguous_format)\n",
      "   195|         1|  5.24521e-06|  5.24521e-06|  0.00%|    output.scatter_(0, permutation,\n",
      "   196|         1|  2.28882e-05|  2.28882e-05|  0.01%|                    torch.arange(0, permutation.numel(), device=permutation.device))\n",
      "   197|         1|  5.00679e-06|  5.00679e-06|  0.00%|    return output\n",
      "   198|         0|            0|            0|  0.00%|\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         1|  1.57356e-05|  1.57356e-05|  0.01%|def pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True):\n",
      "   201|         0|            0|            0|  0.00%|    # type: (Tensor, Tensor, bool, bool) -> PackedSequence\n",
      "   202|         0|            0|            0|  0.00%|    r\"\"\"Packs a Tensor containing padded sequences of variable length.\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|    :attr:`input` can be of size ``T x B x *`` where `T` is the length of the\n",
      "   205|         0|            0|            0|  0.00%|    longest sequence (equal to ``lengths[0]``), ``B`` is the batch size, and\n",
      "   206|         0|            0|            0|  0.00%|    ``*`` is any number of dimensions (including 0). If ``batch_first`` is\n",
      "   207|         0|            0|            0|  0.00%|    ``True``, ``B x T x *`` :attr:`input` is expected.\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|    For unsorted sequences, use `enforce_sorted = False`. If :attr:`enforce_sorted` is\n",
      "   210|         0|            0|            0|  0.00%|    ``True``, the sequences should be sorted by length in a decreasing order, i.e.\n",
      "   211|         0|            0|            0|  0.00%|    ``input[:,0]`` should be the longest sequence, and ``input[:,B-1]`` the shortest\n",
      "   212|         0|            0|            0|  0.00%|    one. `enforce_sorted = True` is only necessary for ONNX export.\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|    Note:\n",
      "   215|         0|            0|            0|  0.00%|        This function accepts any input that has at least two dimensions. You\n",
      "   216|         0|            0|            0|  0.00%|        can apply it to pack the labels, and use the output of the RNN with\n",
      "   217|         0|            0|            0|  0.00%|        them to compute the loss directly. A Tensor can be retrieved from\n",
      "   218|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object by accessing its ``.data`` attribute.\n",
      "   219|         0|            0|            0|  0.00%|\n",
      "   220|         0|            0|            0|  0.00%|    Args:\n",
      "   221|         0|            0|            0|  0.00%|        input (Tensor): padded batch of variable length sequences.\n",
      "   222|         0|            0|            0|  0.00%|        lengths (Tensor or list(int)): list of sequence lengths of each batch\n",
      "   223|         0|            0|            0|  0.00%|            element (must be on the CPU if provided as a tensor).\n",
      "   224|         0|            0|            0|  0.00%|        batch_first (bool, optional): if ``True``, the input is expected in ``B x T x *``\n",
      "   225|         0|            0|            0|  0.00%|            format.\n",
      "   226|         0|            0|            0|  0.00%|        enforce_sorted (bool, optional): if ``True``, the input is expected to\n",
      "   227|         0|            0|            0|  0.00%|            contain sequences sorted by length in a decreasing order. If\n",
      "   228|         0|            0|            0|  0.00%|            ``False``, the input will get sorted unconditionally. Default: ``True``.\n",
      "   229|         0|            0|            0|  0.00%|\n",
      "   230|         0|            0|            0|  0.00%|    Returns:\n",
      "   231|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object\n",
      "   232|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   233|         1|  1.43051e-05|  1.43051e-05|  0.01%|    if torch._C._get_tracing_state() and not isinstance(lengths, torch.Tensor):\n",
      "   234|         0|            0|            0|  0.00%|        warnings.warn('pack_padded_sequence has been called with a Python list of '\n",
      "   235|         0|            0|            0|  0.00%|                      'sequence lengths. The tracer cannot track the data flow of Python '\n",
      "   236|         0|            0|            0|  0.00%|                      'values, and it will treat them as constants, likely rendering '\n",
      "   237|         0|            0|            0|  0.00%|                      'the trace incorrect for any other combination of lengths.',\n",
      "   238|         0|            0|            0|  0.00%|                      stacklevel=2)\n",
      "   239|         1|  1.88351e-05|  1.88351e-05|  0.01%|    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
      "   240|         1|  5.00679e-06|  5.00679e-06|  0.00%|    if enforce_sorted:\n",
      "   241|         0|            0|            0|  0.00%|        sorted_indices = None\n",
      "   242|         0|            0|            0|  0.00%|    else:\n",
      "   243|         1|  3.50475e-05|  3.50475e-05|  0.02%|        lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
      "   244|         1|  8.82149e-06|  8.82149e-06|  0.00%|        sorted_indices = sorted_indices.to(input.device)\n",
      "   245|         1|  5.24521e-06|  5.24521e-06|  0.00%|        batch_dim = 0 if batch_first else 1\n",
      "   246|         1|  3.98159e-05|  3.98159e-05|  0.02%|        input = input.index_select(batch_dim, sorted_indices)\n",
      "   247|         0|            0|            0|  0.00%|\n",
      "   248|         0|            0|            0|  0.00%|    data, batch_sizes = \\\n",
      "   249|         1|  6.91414e-05|  6.91414e-05|  0.03%|        _VF._pack_padded_sequence(input, lengths, batch_first)\n",
      "(call)|         1|  1.88351e-05|  1.88351e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   250|         1|   1.5974e-05|   1.5974e-05|  0.01%|    return _packed_sequence_init(data, batch_sizes, sorted_indices, None)\n",
      "(call)|         1|  0.000185013|  0.000185013|  0.08%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:183 _packed_sequence_init\n",
      "   251|         0|            0|            0|  0.00%|\n",
      "   252|         0|            0|            0|  0.00%|\n",
      "   253|         1|  1.09673e-05|  1.09673e-05|  0.00%|def pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None):\n",
      "   254|         0|            0|            0|  0.00%|    # type: (PackedSequence, bool, float, Optional[int]) -> Tuple[Tensor, Tensor]\n",
      "   255|         0|            0|            0|  0.00%|    r\"\"\"Pads a packed batch of variable length sequences.\n",
      "   256|         0|            0|            0|  0.00%|\n",
      "   257|         0|            0|            0|  0.00%|    It is an inverse operation to :func:`pack_padded_sequence`.\n",
      "   258|         0|            0|            0|  0.00%|\n",
      "   259|         0|            0|            0|  0.00%|    The returned Tensor's data will be of size ``T x B x *``, where `T` is the length\n",
      "   260|         0|            0|            0|  0.00%|    of the longest sequence and `B` is the batch size. If ``batch_first`` is True,\n",
      "   261|         0|            0|            0|  0.00%|    the data will be transposed into ``B x T x *`` format.\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|    Example:\n",
      "   264|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
      "   265|         0|            0|            0|  0.00%|        >>> seq = torch.tensor([[1,2,0], [3,0,0], [4,5,6]])\n",
      "   266|         0|            0|            0|  0.00%|        >>> lens = [2, 1, 3]\n",
      "   267|         0|            0|            0|  0.00%|        >>> packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)\n",
      "   268|         0|            0|            0|  0.00%|        >>> packed\n",
      "   269|         0|            0|            0|  0.00%|        PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]),\n",
      "   270|         0|            0|            0|  0.00%|                       sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
      "   271|         0|            0|            0|  0.00%|        >>> seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
      "   272|         0|            0|            0|  0.00%|        >>> seq_unpacked\n",
      "   273|         0|            0|            0|  0.00%|        tensor([[1, 2, 0],\n",
      "   274|         0|            0|            0|  0.00%|                [3, 0, 0],\n",
      "   275|         0|            0|            0|  0.00%|                [4, 5, 6]])\n",
      "   276|         0|            0|            0|  0.00%|        >>> lens_unpacked\n",
      "   277|         0|            0|            0|  0.00%|        tensor([2, 1, 3])\n",
      "   278|         0|            0|            0|  0.00%|\n",
      "   279|         0|            0|            0|  0.00%|    .. note::\n",
      "   280|         0|            0|            0|  0.00%|        :attr:`total_length` is useful to implement the\n",
      "   281|         0|            0|            0|  0.00%|        ``pack sequence -> recurrent network -> unpack sequence`` pattern in a\n",
      "   282|         0|            0|            0|  0.00%|        :class:`~torch.nn.Module` wrapped in :class:`~torch.nn.DataParallel`.\n",
      "   283|         0|            0|            0|  0.00%|        See :ref:`this FAQ section <pack-rnn-unpack-with-data-parallelism>` for\n",
      "   284|         0|            0|            0|  0.00%|        details.\n",
      "   285|         0|            0|            0|  0.00%|\n",
      "   286|         0|            0|            0|  0.00%|    Args:\n",
      "   287|         0|            0|            0|  0.00%|        sequence (PackedSequence): batch to pad\n",
      "   288|         0|            0|            0|  0.00%|        batch_first (bool, optional): if ``True``, the output will be in ``B x T x *``\n",
      "   289|         0|            0|            0|  0.00%|            format.\n",
      "   290|         0|            0|            0|  0.00%|        padding_value (float, optional): values for padded elements.\n",
      "   291|         0|            0|            0|  0.00%|        total_length (int, optional): if not ``None``, the output will be padded to\n",
      "   292|         0|            0|            0|  0.00%|            have length :attr:`total_length`. This method will throw :class:`ValueError`\n",
      "   293|         0|            0|            0|  0.00%|            if :attr:`total_length` is less than the max sequence length in\n",
      "   294|         0|            0|            0|  0.00%|            :attr:`sequence`.\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|    Returns:\n",
      "   297|         0|            0|            0|  0.00%|        Tuple of Tensor containing the padded sequence, and a Tensor\n",
      "   298|         0|            0|            0|  0.00%|        containing the list of lengths of each sequence in the batch.\n",
      "   299|         0|            0|            0|  0.00%|        Batch elements will be re-ordered as they were ordered originally when\n",
      "   300|         0|            0|            0|  0.00%|        the batch was passed to ``pack_padded_sequence`` or ``pack_sequence``.\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|\n",
      "   303|         0|            0|            0|  0.00%|\n",
      "   304|         0|            0|            0|  0.00%|\n",
      "   305|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   306|         1|  7.86781e-06|  7.86781e-06|  0.00%|    max_seq_length = sequence.batch_sizes.size(0)\n",
      "   307|         1|  5.24521e-06|  5.24521e-06|  0.00%|    if total_length is not None:\n",
      "   308|         0|            0|            0|  0.00%|        if total_length < max_seq_length:\n",
      "   309|         0|            0|            0|  0.00%|            raise ValueError(\"Expected total_length to be at least the length \"\n",
      "   310|         0|            0|            0|  0.00%|                             \"of the longest sequence in input, but got \"\n",
      "   311|         0|            0|            0|  0.00%|                             \"total_length={} and max sequence length being {}\"\n",
      "   312|         0|            0|            0|  0.00%|                             .format(total_length, max_seq_length))\n",
      "   313|         0|            0|            0|  0.00%|        max_seq_length = total_length\n",
      "   314|         1|  1.62125e-05|  1.62125e-05|  0.01%|    padded_output, lengths = _VF._pad_packed_sequence(\n",
      "(call)|         1|  6.91414e-06|  6.91414e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   315|         1|  0.000125885|  0.000125885|  0.06%|        sequence.data, sequence.batch_sizes, batch_first, padding_value, max_seq_length)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   316|         1|  7.86781e-06|  7.86781e-06|  0.00%|    unsorted_indices = sequence.unsorted_indices\n",
      "   317|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if unsorted_indices is not None:\n",
      "   318|         1|   3.8147e-06|   3.8147e-06|  0.00%|        batch_dim = 0 if batch_first else 1\n",
      "   319|         1|  3.50475e-05|  3.50475e-05|  0.02%|        return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]\n",
      "   320|         0|            0|            0|  0.00%|    return padded_output, lengths\n",
      "   321|         0|            0|            0|  0.00%|\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|def pad_sequence(sequences, batch_first=False, padding_value=0.0):\n",
      "   324|         0|            0|            0|  0.00%|    # type: (List[Tensor], bool, float) -> Tensor\n",
      "   325|         0|            0|            0|  0.00%|    r\"\"\"Pad a list of variable length Tensors with ``padding_value``\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|    ``pad_sequence`` stacks a list of Tensors along a new dimension,\n",
      "   328|         0|            0|            0|  0.00%|    and pads them to equal length. For example, if the input is list of\n",
      "   329|         0|            0|            0|  0.00%|    sequences with size ``L x *`` and if batch_first is False, and ``T x B x *``\n",
      "   330|         0|            0|            0|  0.00%|    otherwise.\n",
      "   331|         0|            0|            0|  0.00%|\n",
      "   332|         0|            0|            0|  0.00%|    `B` is batch size. It is equal to the number of elements in ``sequences``.\n",
      "   333|         0|            0|            0|  0.00%|    `T` is length of the longest sequence.\n",
      "   334|         0|            0|            0|  0.00%|    `L` is length of the sequence.\n",
      "   335|         0|            0|            0|  0.00%|    `*` is any number of trailing dimensions, including none.\n",
      "   336|         0|            0|            0|  0.00%|\n",
      "   337|         0|            0|            0|  0.00%|    Example:\n",
      "   338|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pad_sequence\n",
      "   339|         0|            0|            0|  0.00%|        >>> a = torch.ones(25, 300)\n",
      "   340|         0|            0|            0|  0.00%|        >>> b = torch.ones(22, 300)\n",
      "   341|         0|            0|            0|  0.00%|        >>> c = torch.ones(15, 300)\n",
      "   342|         0|            0|            0|  0.00%|        >>> pad_sequence([a, b, c]).size()\n",
      "   343|         0|            0|            0|  0.00%|        torch.Size([25, 3, 300])\n",
      "   344|         0|            0|            0|  0.00%|\n",
      "   345|         0|            0|            0|  0.00%|    Note:\n",
      "   346|         0|            0|            0|  0.00%|        This function returns a Tensor of size ``T x B x *`` or ``B x T x *``\n",
      "   347|         0|            0|            0|  0.00%|        where `T` is the length of the longest sequence. This function assumes\n",
      "   348|         0|            0|            0|  0.00%|        trailing dimensions and type of all the Tensors in sequences are same.\n",
      "   349|         0|            0|            0|  0.00%|\n",
      "   350|         0|            0|            0|  0.00%|    Args:\n",
      "   351|         0|            0|            0|  0.00%|        sequences (list[Tensor]): list of variable length sequences.\n",
      "   352|         0|            0|            0|  0.00%|        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
      "   353|         0|            0|            0|  0.00%|            ``T x B x *`` otherwise\n",
      "   354|         0|            0|            0|  0.00%|        padding_value (float, optional): value for padded elements. Default: 0.\n",
      "   355|         0|            0|            0|  0.00%|\n",
      "   356|         0|            0|            0|  0.00%|    Returns:\n",
      "   357|         0|            0|            0|  0.00%|        Tensor of size ``T x B x *`` if :attr:`batch_first` is ``False``.\n",
      "   358|         0|            0|            0|  0.00%|        Tensor of size ``B x T x *`` otherwise\n",
      "   359|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|    # assuming trailing dimensions and type of all the Tensors\n",
      "   362|         0|            0|            0|  0.00%|    # in sequences are same and fetching those from sequences[0]\n",
      "   363|         0|            0|            0|  0.00%|    return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
      "   364|         0|            0|            0|  0.00%|\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|def pack_sequence(sequences, enforce_sorted=True):\n",
      "   367|         0|            0|            0|  0.00%|    # type: (List[Tensor], bool) -> PackedSequence\n",
      "   368|         0|            0|            0|  0.00%|    r\"\"\"Packs a list of variable length Tensors\n",
      "   369|         0|            0|            0|  0.00%|\n",
      "   370|         0|            0|            0|  0.00%|    ``sequences`` should be a list of Tensors of size ``L x *``, where `L` is\n",
      "   371|         0|            0|            0|  0.00%|    the length of a sequence and `*` is any number of trailing dimensions,\n",
      "   372|         0|            0|            0|  0.00%|    including zero.\n",
      "   373|         0|            0|            0|  0.00%|\n",
      "   374|         0|            0|            0|  0.00%|    For unsorted sequences, use `enforce_sorted = False`. If ``enforce_sorted``\n",
      "   375|         0|            0|            0|  0.00%|    is ``True``, the sequences should be sorted in the order of decreasing length.\n",
      "   376|         0|            0|            0|  0.00%|    ``enforce_sorted = True`` is only necessary for ONNX export.\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|\n",
      "   379|         0|            0|            0|  0.00%|    Example:\n",
      "   380|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pack_sequence\n",
      "   381|         0|            0|            0|  0.00%|        >>> a = torch.tensor([1,2,3])\n",
      "   382|         0|            0|            0|  0.00%|        >>> b = torch.tensor([4,5])\n",
      "   383|         0|            0|            0|  0.00%|        >>> c = torch.tensor([6])\n",
      "   384|         0|            0|            0|  0.00%|        >>> pack_sequence([a, b, c])\n",
      "   385|         0|            0|            0|  0.00%|        PackedSequence(data=tensor([ 1,  4,  6,  2,  5,  3]), batch_sizes=tensor([ 3,  2,  1]))\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|\n",
      "   388|         0|            0|            0|  0.00%|    Args:\n",
      "   389|         0|            0|            0|  0.00%|        sequences (list[Tensor]): A list of sequences of decreasing length.\n",
      "   390|         0|            0|            0|  0.00%|        enforce_sorted (bool, optional): if ``True``, checks that the input\n",
      "   391|         0|            0|            0|  0.00%|            contains sequences sorted by length in a decreasing order. If\n",
      "   392|         0|            0|            0|  0.00%|            ``False``, this condition is not checked. Default: ``True``.\n",
      "   393|         0|            0|            0|  0.00%|\n",
      "   394|         0|            0|            0|  0.00%|    Returns:\n",
      "   395|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object\n",
      "   396|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   397|         0|            0|            0|  0.00%|    lengths = torch.as_tensor([v.size(0) for v in sequences])\n",
      "   398|         0|            0|            0|  0.00%|    return pack_padded_sequence(pad_sequence(sequences), lengths, enforce_sorted=enforce_sorted)\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/linear.py\n",
      "File duration: 0.000382662s (0.17%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|import math\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|import torch\n",
      "     4|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     5|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter, UninitializedParameter\n",
      "     6|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     7|         0|            0|            0|  0.00%|from .. import init\n",
      "     8|         0|            0|            0|  0.00%|from .module import Module\n",
      "     9|         0|            0|            0|  0.00%|from .lazy import LazyModuleMixin\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class Identity(Module):\n",
      "    13|         0|            0|            0|  0.00%|    r\"\"\"A placeholder identity operator that is argument-insensitive.\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|    Args:\n",
      "    16|         0|            0|            0|  0.00%|        args: any argument (unused)\n",
      "    17|         0|            0|            0|  0.00%|        kwargs: any keyword argument (unused)\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|    Shape:\n",
      "    20|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "    21|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|    Examples::\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|        >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n",
      "    26|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)\n",
      "    27|         0|            0|            0|  0.00%|        >>> output = m(input)\n",
      "    28|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "    29|         0|            0|            0|  0.00%|        torch.Size([128, 20])\n",
      "    30|         0|            0|            0|  0.00%|\n",
      "    31|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    32|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):\n",
      "    33|         0|            0|            0|  0.00%|        super(Identity, self).__init__()\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:\n",
      "    36|         0|            0|            0|  0.00%|        return input\n",
      "    37|         0|            0|            0|  0.00%|\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|         0|            0|            0|  0.00%|class Linear(Module):\n",
      "    40|         0|            0|            0|  0.00%|    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "    43|         0|            0|            0|  0.00%|\n",
      "    44|         0|            0|            0|  0.00%|    Args:\n",
      "    45|         0|            0|            0|  0.00%|        in_features: size of each input sample\n",
      "    46|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "    47|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "    48|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "    49|         0|            0|            0|  0.00%|\n",
      "    50|         0|            0|            0|  0.00%|    Shape:\n",
      "    51|         0|            0|            0|  0.00%|        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
      "    52|         0|            0|            0|  0.00%|          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
      "    53|         0|            0|            0|  0.00%|        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
      "    54|         0|            0|            0|  0.00%|          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|    Attributes:\n",
      "    57|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "    58|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "    59|         0|            0|            0|  0.00%|            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "    60|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    61|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "    62|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "    63|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "    64|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    65|         0|            0|            0|  0.00%|\n",
      "    66|         0|            0|            0|  0.00%|    Examples::\n",
      "    67|         0|            0|            0|  0.00%|\n",
      "    68|         0|            0|            0|  0.00%|        >>> m = nn.Linear(20, 30)\n",
      "    69|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)\n",
      "    70|         0|            0|            0|  0.00%|        >>> output = m(input)\n",
      "    71|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "    72|         0|            0|            0|  0.00%|        torch.Size([128, 30])\n",
      "    73|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    74|         0|            0|            0|  0.00%|    __constants__ = ['in_features', 'out_features']\n",
      "    75|         0|            0|            0|  0.00%|    in_features: int\n",
      "    76|         0|            0|            0|  0.00%|    out_features: int\n",
      "    77|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "    78|         0|            0|            0|  0.00%|\n",
      "    79|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
      "    80|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "    81|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "    82|         0|            0|            0|  0.00%|        super(Linear, self).__init__()\n",
      "    83|         0|            0|            0|  0.00%|        self.in_features = in_features\n",
      "    84|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "    85|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
      "    86|         0|            0|            0|  0.00%|        if bias:\n",
      "    87|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "    88|         0|            0|            0|  0.00%|        else:\n",
      "    89|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)\n",
      "    90|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "    93|         0|            0|            0|  0.00%|        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
      "    94|         0|            0|            0|  0.00%|        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
      "    95|         0|            0|            0|  0.00%|        # https://github.com/pytorch/pytorch/issues/57109\n",
      "    96|         0|            0|            0|  0.00%|        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "    97|         0|            0|            0|  0.00%|        if self.bias is not None:\n",
      "    98|         0|            0|            0|  0.00%|            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
      "    99|         0|            0|            0|  0.00%|            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
      "   100|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)\n",
      "   101|         0|            0|            0|  0.00%|\n",
      "   102|        16|  3.29018e-05|  2.05636e-06|  0.01%|    def forward(self, input: Tensor) -> Tensor:\n",
      "   103|        16|   0.00034976|    2.186e-05|  0.15%|        return F.linear(input, self.weight, self.bias)\n",
      "(call)|        32|  0.000377893|  1.18092e-05|  0.17%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|        16|   0.00187945|  0.000117466|  0.83%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:1832 linear\n",
      "   104|         0|            0|            0|  0.00%|\n",
      "   105|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   106|         0|            0|            0|  0.00%|        return 'in_features={}, out_features={}, bias={}'.format(\n",
      "   107|         0|            0|            0|  0.00%|            self.in_features, self.out_features, self.bias is not None\n",
      "   108|         0|            0|            0|  0.00%|        )\n",
      "   109|         0|            0|            0|  0.00%|\n",
      "   110|         0|            0|            0|  0.00%|\n",
      "   111|         0|            0|            0|  0.00%|# This class exists solely to avoid triggering an obscure error when scripting\n",
      "   112|         0|            0|            0|  0.00%|# an improperly quantized attention layer. See this issue for details:\n",
      "   113|         0|            0|            0|  0.00%|# https://github.com/pytorch/pytorch/issues/58969\n",
      "   114|         0|            0|            0|  0.00%|# TODO: fail fast on quantization API usage error, then remove this class\n",
      "   115|         0|            0|            0|  0.00%|# and replace uses of it with plain Linear\n",
      "   116|         0|            0|            0|  0.00%|class NonDynamicallyQuantizableLinear(Linear):\n",
      "   117|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
      "   118|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   119|         0|            0|            0|  0.00%|        super().__init__(in_features, out_features, bias=bias,\n",
      "   120|         0|            0|            0|  0.00%|                         device=device, dtype=dtype)\n",
      "   121|         0|            0|            0|  0.00%|\n",
      "   122|         0|            0|            0|  0.00%|\n",
      "   123|         0|            0|            0|  0.00%|class Bilinear(Module):\n",
      "   124|         0|            0|            0|  0.00%|    r\"\"\"Applies a bilinear transformation to the incoming data:\n",
      "   125|         0|            0|            0|  0.00%|    :math:`y = x_1^T A x_2 + b`\n",
      "   126|         0|            0|            0|  0.00%|\n",
      "   127|         0|            0|            0|  0.00%|    Args:\n",
      "   128|         0|            0|            0|  0.00%|        in1_features: size of each first input sample\n",
      "   129|         0|            0|            0|  0.00%|        in2_features: size of each second input sample\n",
      "   130|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "   131|         0|            0|            0|  0.00%|        bias: If set to False, the layer will not learn an additive bias.\n",
      "   132|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   133|         0|            0|            0|  0.00%|\n",
      "   134|         0|            0|            0|  0.00%|    Shape:\n",
      "   135|         0|            0|            0|  0.00%|        - Input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\\text{in1\\_features}` and\n",
      "   136|         0|            0|            0|  0.00%|          :math:`*` means any number of additional dimensions. All but the last dimension\n",
      "   137|         0|            0|            0|  0.00%|          of the inputs should be the same.\n",
      "   138|         0|            0|            0|  0.00%|        - Input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\\text{in2\\_features}`.\n",
      "   139|         0|            0|            0|  0.00%|        - Output: :math:`(N, *, H_{out})` where :math:`H_{out}=\\text{out\\_features}`\n",
      "   140|         0|            0|            0|  0.00%|          and all but the last dimension are the same shape as the input.\n",
      "   141|         0|            0|            0|  0.00%|\n",
      "   142|         0|            0|            0|  0.00%|    Attributes:\n",
      "   143|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "   144|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in1\\_features}, \\text{in2\\_features})`.\n",
      "   145|         0|            0|            0|  0.00%|            The values are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   146|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in1\\_features}}`\n",
      "   147|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "   148|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "   149|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   150|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in1\\_features}}`\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    Examples::\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|        >>> m = nn.Bilinear(20, 30, 40)\n",
      "   155|         0|            0|            0|  0.00%|        >>> input1 = torch.randn(128, 20)\n",
      "   156|         0|            0|            0|  0.00%|        >>> input2 = torch.randn(128, 30)\n",
      "   157|         0|            0|            0|  0.00%|        >>> output = m(input1, input2)\n",
      "   158|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "   159|         0|            0|            0|  0.00%|        torch.Size([128, 40])\n",
      "   160|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   161|         0|            0|            0|  0.00%|    __constants__ = ['in1_features', 'in2_features', 'out_features']\n",
      "   162|         0|            0|            0|  0.00%|    in1_features: int\n",
      "   163|         0|            0|            0|  0.00%|    in2_features: int\n",
      "   164|         0|            0|            0|  0.00%|    out_features: int\n",
      "   165|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|    def __init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True,\n",
      "   168|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   169|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   170|         0|            0|            0|  0.00%|        super(Bilinear, self).__init__()\n",
      "   171|         0|            0|            0|  0.00%|        self.in1_features = in1_features\n",
      "   172|         0|            0|            0|  0.00%|        self.in2_features = in2_features\n",
      "   173|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "   174|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in1_features, in2_features), **factory_kwargs))\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|        if bias:\n",
      "   177|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "   178|         0|            0|            0|  0.00%|        else:\n",
      "   179|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)\n",
      "   180|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   183|         0|            0|            0|  0.00%|        bound = 1 / math.sqrt(self.weight.size(1))\n",
      "   184|         0|            0|            0|  0.00%|        init.uniform_(self.weight, -bound, bound)\n",
      "   185|         0|            0|            0|  0.00%|        if self.bias is not None:\n",
      "   186|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)\n",
      "   187|         0|            0|            0|  0.00%|\n",
      "   188|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor) -> Tensor:\n",
      "   189|         0|            0|            0|  0.00%|        return F.bilinear(input1, input2, self.weight, self.bias)\n",
      "   190|         0|            0|            0|  0.00%|\n",
      "   191|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   192|         0|            0|            0|  0.00%|        return 'in1_features={}, in2_features={}, out_features={}, bias={}'.format(\n",
      "   193|         0|            0|            0|  0.00%|            self.in1_features, self.in2_features, self.out_features, self.bias is not None\n",
      "   194|         0|            0|            0|  0.00%|        )\n",
      "   195|         0|            0|            0|  0.00%|\n",
      "   196|         0|            0|            0|  0.00%|\n",
      "   197|         0|            0|            0|  0.00%|class LazyLinear(LazyModuleMixin, Linear):\n",
      "   198|         0|            0|            0|  0.00%|    r\"\"\"A :class:`torch.nn.Linear` module where `in_features` is inferred.\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         0|            0|            0|  0.00%|    In this module, the `weight` and `bias` are of :class:`torch.nn.UninitializedParameter`\n",
      "   201|         0|            0|            0|  0.00%|    class. They will be initialized after the first call to ``forward`` is done and the\n",
      "   202|         0|            0|            0|  0.00%|    module will become a regular :class:`torch.nn.Linear` module. The ``in_features`` argument\n",
      "   203|         0|            0|            0|  0.00%|    of the :class:`Linear` is inferred from the ``input.shape[-1]``.\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|    Check the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\n",
      "   206|         0|            0|            0|  0.00%|    on lazy modules and their limitations.\n",
      "   207|         0|            0|            0|  0.00%|\n",
      "   208|         0|            0|            0|  0.00%|    Args:\n",
      "   209|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "   210|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "   211|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|    Attributes:\n",
      "   214|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "   215|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "   216|         0|            0|            0|  0.00%|            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   217|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "   218|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "   219|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "   220|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "   221|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|\n",
      "   224|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    cls_to_become = Linear  # type: ignore[assignment]\n",
      "   227|         0|            0|            0|  0.00%|    weight: UninitializedParameter\n",
      "   228|         0|            0|            0|  0.00%|    bias: UninitializedParameter  # type: ignore[assignment]\n",
      "   229|         0|            0|            0|  0.00%|\n",
      "   230|         0|            0|            0|  0.00%|    def __init__(self, out_features: int, bias: bool = True,\n",
      "   231|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   232|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   233|         0|            0|            0|  0.00%|        # bias is hardcoded to False to avoid creating tensor\n",
      "   234|         0|            0|            0|  0.00%|        # that will soon be overwritten.\n",
      "   235|         0|            0|            0|  0.00%|        super().__init__(0, 0, False)\n",
      "   236|         0|            0|            0|  0.00%|        self.weight = UninitializedParameter(**factory_kwargs)\n",
      "   237|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "   238|         0|            0|            0|  0.00%|        if bias:\n",
      "   239|         0|            0|            0|  0.00%|            self.bias = UninitializedParameter(**factory_kwargs)\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   242|         0|            0|            0|  0.00%|        if not self.has_uninitialized_params() and self.in_features != 0:\n",
      "   243|         0|            0|            0|  0.00%|            super().reset_parameters()\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    def initialize_parameters(self, input) -> None:  # type: ignore[override]\n",
      "   246|         0|            0|            0|  0.00%|        if self.has_uninitialized_params():\n",
      "   247|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   248|         0|            0|            0|  0.00%|                self.in_features = input.shape[-1]\n",
      "   249|         0|            0|            0|  0.00%|                self.weight.materialize((self.out_features, self.in_features))\n",
      "   250|         0|            0|            0|  0.00%|                if self.bias is not None:\n",
      "   251|         0|            0|            0|  0.00%|                    self.bias.materialize((self.out_features,))\n",
      "   252|         0|            0|            0|  0.00%|                self.reset_parameters()\n",
      "   253|         0|            0|            0|  0.00%|# TODO: PartialLinear - maybe in sparse?\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/sparse.py\n",
      "File duration: 0.000254869s (0.11%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from typing import Optional\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|import torch\n",
      "     4|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     5|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|from .module import Module\n",
      "     8|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     9|         0|            0|            0|  0.00%|from .. import init\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class Embedding(Module):\n",
      "    13|         0|            0|            0|  0.00%|    r\"\"\"A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|    This module is often used to store word embeddings and retrieve them using indices.\n",
      "    16|         0|            0|            0|  0.00%|    The input to the module is a list of indices, and the output is the corresponding\n",
      "    17|         0|            0|            0|  0.00%|    word embeddings.\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|    Args:\n",
      "    20|         0|            0|            0|  0.00%|        num_embeddings (int): size of the dictionary of embeddings\n",
      "    21|         0|            0|            0|  0.00%|        embedding_dim (int): the size of each embedding vector\n",
      "    22|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "    23|         0|            0|            0|  0.00%|                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "    24|         0|            0|            0|  0.00%|                                     i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\n",
      "    25|         0|            0|            0|  0.00%|                                     the embedding vector at :attr:`padding_idx` will default to all zeros,\n",
      "    26|         0|            0|            0|  0.00%|                                     but can be updated to another value to be used as the padding vector.\n",
      "    27|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "    28|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "    29|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "    30|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      "    31|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "    32|         0|            0|            0|  0.00%|        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
      "    33|         0|            0|            0|  0.00%|                                 See Notes for more details regarding sparse gradients.\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    Attributes:\n",
      "    36|         0|            0|            0|  0.00%|        weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      "    37|         0|            0|            0|  0.00%|                         initialized from :math:`\\mathcal{N}(0, 1)`\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|         0|            0|            0|  0.00%|    Shape:\n",
      "    40|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n",
      "    41|         0|            0|            0|  0.00%|        - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n",
      "    42|         0|            0|            0|  0.00%|\n",
      "    43|         0|            0|            0|  0.00%|    .. note::\n",
      "    44|         0|            0|            0|  0.00%|        Keep in mind that only a limited number of optimizers support\n",
      "    45|         0|            0|            0|  0.00%|        sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
      "    46|         0|            0|            0|  0.00%|        :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
      "    47|         0|            0|            0|  0.00%|\n",
      "    48|         0|            0|            0|  0.00%|    .. note::\n",
      "    49|         0|            0|            0|  0.00%|        When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\n",
      "    50|         0|            0|            0|  0.00%|        :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n",
      "    51|         0|            0|            0|  0.00%|        modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n",
      "    52|         0|            0|            0|  0.00%|        calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    53|         0|            0|            0|  0.00%|        :attr:`max_norm` is not ``None``. For example::\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|            n, d, m = 3, 5, 7\n",
      "    56|         0|            0|            0|  0.00%|            embedding = nn.Embedding(n, d, max_norm=True)\n",
      "    57|         0|            0|            0|  0.00%|            W = torch.randn((m, d), requires_grad=True)\n",
      "    58|         0|            0|            0|  0.00%|            idx = torch.tensor([1, 2])\n",
      "    59|         0|            0|            0|  0.00%|            a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
      "    60|         0|            0|            0|  0.00%|            b = embedding(idx) @ W.t()  # modifies weight in-place\n",
      "    61|         0|            0|            0|  0.00%|            out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
      "    62|         0|            0|            0|  0.00%|            loss = out.sigmoid().prod()\n",
      "    63|         0|            0|            0|  0.00%|            loss.backward()\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|    Examples::\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|        >>> # an Embedding module containing 10 tensors of size 3\n",
      "    68|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3)\n",
      "    69|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "    70|         0|            0|            0|  0.00%|        >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
      "    71|         0|            0|            0|  0.00%|        >>> embedding(input)\n",
      "    72|         0|            0|            0|  0.00%|        tensor([[[-0.0251, -1.6902,  0.7172],\n",
      "    73|         0|            0|            0|  0.00%|                 [-0.6431,  0.0748,  0.6969],\n",
      "    74|         0|            0|            0|  0.00%|                 [ 1.4970,  1.3448, -0.9685],\n",
      "    75|         0|            0|            0|  0.00%|                 [-0.3677, -2.7265, -0.1685]],\n",
      "    76|         0|            0|            0|  0.00%|\n",
      "    77|         0|            0|            0|  0.00%|                [[ 1.4970,  1.3448, -0.9685],\n",
      "    78|         0|            0|            0|  0.00%|                 [ 0.4362, -0.4004,  0.9400],\n",
      "    79|         0|            0|            0|  0.00%|                 [-0.6431,  0.0748,  0.6969],\n",
      "    80|         0|            0|            0|  0.00%|                 [ 0.9124, -2.3616,  1.1151]]])\n",
      "    81|         0|            0|            0|  0.00%|\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "    84|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      "    85|         0|            0|            0|  0.00%|        >>> input = torch.LongTensor([[0,2,0,5]])\n",
      "    86|         0|            0|            0|  0.00%|        >>> embedding(input)\n",
      "    87|         0|            0|            0|  0.00%|        tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "    88|         0|            0|            0|  0.00%|                 [ 0.1535, -2.0309,  0.9315],\n",
      "    89|         0|            0|            0|  0.00%|                 [ 0.0000,  0.0000,  0.0000],\n",
      "    90|         0|            0|            0|  0.00%|                 [-0.1655,  0.9897,  0.0635]]])\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|        >>> # example of changing `pad` vector\n",
      "    93|         0|            0|            0|  0.00%|        >>> padding_idx = 0\n",
      "    94|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
      "    95|         0|            0|            0|  0.00%|        >>> embedding.weight\n",
      "    96|         0|            0|            0|  0.00%|        Parameter containing:\n",
      "    97|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "    98|         0|            0|            0|  0.00%|                [-0.7895, -0.7089, -0.0364],\n",
      "    99|         0|            0|            0|  0.00%|                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      "   100|         0|            0|            0|  0.00%|        >>> with torch.no_grad():\n",
      "   101|         0|            0|            0|  0.00%|        ...     embedding.weight[padding_idx] = torch.ones(3)\n",
      "   102|         0|            0|            0|  0.00%|        >>> embedding.weight\n",
      "   103|         0|            0|            0|  0.00%|        Parameter containing:\n",
      "   104|         0|            0|            0|  0.00%|        tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "   105|         0|            0|            0|  0.00%|                [-0.7895, -0.7089, -0.0364],\n",
      "   106|         0|            0|            0|  0.00%|                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      "   107|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   108|         0|            0|            0|  0.00%|    __constants__ = ['num_embeddings', 'embedding_dim', 'padding_idx', 'max_norm',\n",
      "   109|         0|            0|            0|  0.00%|                     'norm_type', 'scale_grad_by_freq', 'sparse']\n",
      "   110|         0|            0|            0|  0.00%|\n",
      "   111|         0|            0|            0|  0.00%|    num_embeddings: int\n",
      "   112|         0|            0|            0|  0.00%|    embedding_dim: int\n",
      "   113|         0|            0|            0|  0.00%|    padding_idx: Optional[int]\n",
      "   114|         0|            0|            0|  0.00%|    max_norm: Optional[float]\n",
      "   115|         0|            0|            0|  0.00%|    norm_type: float\n",
      "   116|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool\n",
      "   117|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   118|         0|            0|            0|  0.00%|    sparse: bool\n",
      "   119|         0|            0|            0|  0.00%|\n",
      "   120|         0|            0|            0|  0.00%|    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None,\n",
      "   121|         0|            0|            0|  0.00%|                 max_norm: Optional[float] = None, norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   122|         0|            0|            0|  0.00%|                 sparse: bool = False, _weight: Optional[Tensor] = None,\n",
      "   123|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   124|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   125|         0|            0|            0|  0.00%|        super(Embedding, self).__init__()\n",
      "   126|         0|            0|            0|  0.00%|        self.num_embeddings = num_embeddings\n",
      "   127|         0|            0|            0|  0.00%|        self.embedding_dim = embedding_dim\n",
      "   128|         0|            0|            0|  0.00%|        if padding_idx is not None:\n",
      "   129|         0|            0|            0|  0.00%|            if padding_idx > 0:\n",
      "   130|         0|            0|            0|  0.00%|                assert padding_idx < self.num_embeddings, 'Padding_idx must be within num_embeddings'\n",
      "   131|         0|            0|            0|  0.00%|            elif padding_idx < 0:\n",
      "   132|         0|            0|            0|  0.00%|                assert padding_idx >= -self.num_embeddings, 'Padding_idx must be within num_embeddings'\n",
      "   133|         0|            0|            0|  0.00%|                padding_idx = self.num_embeddings + padding_idx\n",
      "   134|         0|            0|            0|  0.00%|        self.padding_idx = padding_idx\n",
      "   135|         0|            0|            0|  0.00%|        self.max_norm = max_norm\n",
      "   136|         0|            0|            0|  0.00%|        self.norm_type = norm_type\n",
      "   137|         0|            0|            0|  0.00%|        self.scale_grad_by_freq = scale_grad_by_freq\n",
      "   138|         0|            0|            0|  0.00%|        if _weight is None:\n",
      "   139|         0|            0|            0|  0.00%|            self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs))\n",
      "   140|         0|            0|            0|  0.00%|            self.reset_parameters()\n",
      "   141|         0|            0|            0|  0.00%|        else:\n",
      "   142|         0|            0|            0|  0.00%|            assert list(_weight.shape) == [num_embeddings, embedding_dim], \\\n",
      "   143|         0|            0|            0|  0.00%|                'Shape of weight does not match num_embeddings and embedding_dim'\n",
      "   144|         0|            0|            0|  0.00%|            self.weight = Parameter(_weight)\n",
      "   145|         0|            0|            0|  0.00%|\n",
      "   146|         0|            0|            0|  0.00%|        self.sparse = sparse\n",
      "   147|         0|            0|            0|  0.00%|\n",
      "   148|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   149|         0|            0|            0|  0.00%|        init.normal_(self.weight)\n",
      "   150|         0|            0|            0|  0.00%|        self._fill_padding_idx_with_zero()\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    def _fill_padding_idx_with_zero(self) -> None:\n",
      "   153|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   154|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   155|         0|            0|            0|  0.00%|                self.weight[self.padding_idx].fill_(0)\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         9|  2.28882e-05|  2.54313e-06|  0.01%|    def forward(self, input: Tensor) -> Tensor:\n",
      "   158|         9|  3.21865e-05|  3.57628e-06|  0.01%|        return F.embedding(\n",
      "   159|         9|   7.7486e-05|  8.60956e-06|  0.03%|            input, self.weight, self.padding_idx, self.max_norm,\n",
      "(call)|         9|  0.000108004|  1.20004e-05|  0.05%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "   160|         9|  0.000122309|  1.35899e-05|  0.05%|            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "(call)|         9|  0.000930786|  0.000103421|  0.41%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:1950 embedding\n",
      "   161|         0|            0|            0|  0.00%|\n",
      "   162|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   163|         0|            0|            0|  0.00%|        s = '{num_embeddings}, {embedding_dim}'\n",
      "   164|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   165|         0|            0|            0|  0.00%|            s += ', padding_idx={padding_idx}'\n",
      "   166|         0|            0|            0|  0.00%|        if self.max_norm is not None:\n",
      "   167|         0|            0|            0|  0.00%|            s += ', max_norm={max_norm}'\n",
      "   168|         0|            0|            0|  0.00%|        if self.norm_type != 2:\n",
      "   169|         0|            0|            0|  0.00%|            s += ', norm_type={norm_type}'\n",
      "   170|         0|            0|            0|  0.00%|        if self.scale_grad_by_freq is not False:\n",
      "   171|         0|            0|            0|  0.00%|            s += ', scale_grad_by_freq={scale_grad_by_freq}'\n",
      "   172|         0|            0|            0|  0.00%|        if self.sparse is not False:\n",
      "   173|         0|            0|            0|  0.00%|            s += ', sparse=True'\n",
      "   174|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|    @classmethod\n",
      "   177|         0|            0|            0|  0.00%|    def from_pretrained(cls, embeddings, freeze=True, padding_idx=None,\n",
      "   178|         0|            0|            0|  0.00%|                        max_norm=None, norm_type=2., scale_grad_by_freq=False,\n",
      "   179|         0|            0|            0|  0.00%|                        sparse=False):\n",
      "   180|         0|            0|            0|  0.00%|        r\"\"\"Creates Embedding instance from given 2-dimensional FloatTensor.\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|        Args:\n",
      "   183|         0|            0|            0|  0.00%|            embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
      "   184|         0|            0|            0|  0.00%|                First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\n",
      "   185|         0|            0|            0|  0.00%|            freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      "   186|         0|            0|            0|  0.00%|                Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
      "   187|         0|            0|            0|  0.00%|            padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "   188|         0|            0|            0|  0.00%|                                         therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "   189|         0|            0|            0|  0.00%|                                         i.e. it remains as a fixed \"pad\".\n",
      "   190|         0|            0|            0|  0.00%|            max_norm (float, optional): See module initialization documentation.\n",
      "   191|         0|            0|            0|  0.00%|            norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      "   192|         0|            0|            0|  0.00%|            scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\n",
      "   193|         0|            0|            0|  0.00%|            sparse (bool, optional): See module initialization documentation.\n",
      "   194|         0|            0|            0|  0.00%|\n",
      "   195|         0|            0|            0|  0.00%|        Examples::\n",
      "   196|         0|            0|            0|  0.00%|\n",
      "   197|         0|            0|            0|  0.00%|            >>> # FloatTensor containing pretrained weights\n",
      "   198|         0|            0|            0|  0.00%|            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      "   199|         0|            0|            0|  0.00%|            >>> embedding = nn.Embedding.from_pretrained(weight)\n",
      "   200|         0|            0|            0|  0.00%|            >>> # Get embeddings for index 1\n",
      "   201|         0|            0|            0|  0.00%|            >>> input = torch.LongTensor([1])\n",
      "   202|         0|            0|            0|  0.00%|            >>> embedding(input)\n",
      "   203|         0|            0|            0|  0.00%|            tensor([[ 4.0000,  5.1000,  6.3000]])\n",
      "   204|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   205|         0|            0|            0|  0.00%|        assert embeddings.dim() == 2, \\\n",
      "   206|         0|            0|            0|  0.00%|            'Embeddings parameter is expected to be 2-dimensional'\n",
      "   207|         0|            0|            0|  0.00%|        rows, cols = embeddings.shape\n",
      "   208|         0|            0|            0|  0.00%|        embedding = cls(\n",
      "   209|         0|            0|            0|  0.00%|            num_embeddings=rows,\n",
      "   210|         0|            0|            0|  0.00%|            embedding_dim=cols,\n",
      "   211|         0|            0|            0|  0.00%|            _weight=embeddings,\n",
      "   212|         0|            0|            0|  0.00%|            padding_idx=padding_idx,\n",
      "   213|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "   214|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "   215|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "   216|         0|            0|            0|  0.00%|            sparse=sparse)\n",
      "   217|         0|            0|            0|  0.00%|        embedding.weight.requires_grad = not freeze\n",
      "   218|         0|            0|            0|  0.00%|        return embedding\n",
      "   219|         0|            0|            0|  0.00%|\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|class EmbeddingBag(Module):\n",
      "   222|         0|            0|            0|  0.00%|    r\"\"\"Computes sums or means of 'bags' of embeddings, without instantiating the\n",
      "   223|         0|            0|            0|  0.00%|    intermediate embeddings.\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|    For bags of constant length, no :attr:`per_sample_weights`, no indices equal to :attr:`padding_idx`,\n",
      "   226|         0|            0|            0|  0.00%|    and with 2D inputs, this class\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|        * with ``mode=\"sum\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=1)``,\n",
      "   229|         0|            0|            0|  0.00%|        * with ``mode=\"mean\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.mean(dim=1)``,\n",
      "   230|         0|            0|            0|  0.00%|        * with ``mode=\"max\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.max(dim=1)``.\n",
      "   231|         0|            0|            0|  0.00%|\n",
      "   232|         0|            0|            0|  0.00%|    However, :class:`~torch.nn.EmbeddingBag` is much more time and memory efficient than using a chain of these\n",
      "   233|         0|            0|            0|  0.00%|    operations.\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    EmbeddingBag also supports per-sample weights as an argument to the forward\n",
      "   236|         0|            0|            0|  0.00%|    pass. This scales the output of the Embedding before performing a weighted\n",
      "   237|         0|            0|            0|  0.00%|    reduction as specified by ``mode``. If :attr:`per_sample_weights` is passed, the\n",
      "   238|         0|            0|            0|  0.00%|    only supported ``mode`` is ``\"sum\"``, which computes a weighted sum according to\n",
      "   239|         0|            0|            0|  0.00%|    :attr:`per_sample_weights`.\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    Args:\n",
      "   242|         0|            0|            0|  0.00%|        num_embeddings (int): size of the dictionary of embeddings\n",
      "   243|         0|            0|            0|  0.00%|        embedding_dim (int): the size of each embedding vector\n",
      "   244|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "   245|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "   246|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "   247|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
      "   248|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "   249|         0|            0|            0|  0.00%|                                                Note: this option is not supported when ``mode=\"max\"``.\n",
      "   250|         0|            0|            0|  0.00%|        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
      "   251|         0|            0|            0|  0.00%|                                 ``\"sum\"`` computes the weighted sum, taking :attr:`per_sample_weights`\n",
      "   252|         0|            0|            0|  0.00%|                                 into consideration. ``\"mean\"`` computes the average of the values\n",
      "   253|         0|            0|            0|  0.00%|                                 in the bag, ``\"max\"`` computes the max value over each bag.\n",
      "   254|         0|            0|            0|  0.00%|                                 Default: ``\"mean\"``\n",
      "   255|         0|            0|            0|  0.00%|        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See\n",
      "   256|         0|            0|            0|  0.00%|                                 Notes for more details regarding sparse gradients. Note: this option is not\n",
      "   257|         0|            0|            0|  0.00%|                                 supported when ``mode=\"max\"``.\n",
      "   258|         0|            0|            0|  0.00%|        include_last_offset (bool, optional): if ``True``, :attr:`offsets` has one additional element, where the last element\n",
      "   259|         0|            0|            0|  0.00%|                                      is equivalent to the size of `indices`. This matches the CSR format.\n",
      "   260|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the\n",
      "   261|         0|            0|            0|  0.00%|                                     gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated\n",
      "   262|         0|            0|            0|  0.00%|                                     during training, i.e. it remains as a fixed \"pad\". For a newly constructed\n",
      "   263|         0|            0|            0|  0.00%|                                     EmbeddingBag, the embedding vector at :attr:`padding_idx` will default to all\n",
      "   264|         0|            0|            0|  0.00%|                                     zeros, but can be updated to another value to be used as the padding vector.\n",
      "   265|         0|            0|            0|  0.00%|                                     Note that the embedding vector at :attr:`padding_idx` is excluded from the\n",
      "   266|         0|            0|            0|  0.00%|                                     reduction.\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|    Attributes:\n",
      "   269|         0|            0|            0|  0.00%|        weight (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`\n",
      "   270|         0|            0|            0|  0.00%|                         initialized from :math:`\\mathcal{N}(0, 1)`.\n",
      "   271|         0|            0|            0|  0.00%|\n",
      "   272|         0|            0|            0|  0.00%|    Examples::\n",
      "   273|         0|            0|            0|  0.00%|\n",
      "   274|         0|            0|            0|  0.00%|        >>> # an EmbeddingBag module containing 10 tensors of size 3\n",
      "   275|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum')\n",
      "   276|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "   277|         0|            0|            0|  0.00%|        >>> input = torch.tensor([1,2,4,5,4,3,2,9], dtype=torch.long)\n",
      "   278|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4], dtype=torch.long)\n",
      "   279|         0|            0|            0|  0.00%|        >>> embedding_sum(input, offsets)\n",
      "   280|         0|            0|            0|  0.00%|        tensor([[-0.8861, -5.4350, -0.0523],\n",
      "   281|         0|            0|            0|  0.00%|                [ 1.1306, -2.5798, -1.0044]])\n",
      "   282|         0|            0|            0|  0.00%|\n",
      "   283|         0|            0|            0|  0.00%|        >>> # Example with padding_idx\n",
      "   284|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum', padding_idx=2)\n",
      "   285|         0|            0|            0|  0.00%|        >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9], dtype=torch.long)\n",
      "   286|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4], dtype=torch.long)\n",
      "   287|         0|            0|            0|  0.00%|        >>> embedding_sum(input, offsets)\n",
      "   288|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "   289|         0|            0|            0|  0.00%|                [-0.7082,  3.2145, -2.6251]])\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|        >>> # An EmbeddingBag can be loaded from an Embedding like so\n",
      "   292|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3, padding_idx=2)\n",
      "   293|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag.from_pretrained(\n",
      "   294|         0|            0|            0|  0.00%|                embedding.weight,\n",
      "   295|         0|            0|            0|  0.00%|                padding_idx=embedding.padding_idx,\n",
      "   296|         0|            0|            0|  0.00%|                mode='sum')\n",
      "   297|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   298|         0|            0|            0|  0.00%|    __constants__ = ['num_embeddings', 'embedding_dim', 'max_norm', 'norm_type',\n",
      "   299|         0|            0|            0|  0.00%|                     'scale_grad_by_freq', 'mode', 'sparse', 'include_last_offset',\n",
      "   300|         0|            0|            0|  0.00%|                     'padding_idx']\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|    num_embeddings: int\n",
      "   303|         0|            0|            0|  0.00%|    embedding_dim: int\n",
      "   304|         0|            0|            0|  0.00%|    max_norm: Optional[float]\n",
      "   305|         0|            0|            0|  0.00%|    norm_type: float\n",
      "   306|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool\n",
      "   307|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   308|         0|            0|            0|  0.00%|    mode: str\n",
      "   309|         0|            0|            0|  0.00%|    sparse: bool\n",
      "   310|         0|            0|            0|  0.00%|    include_last_offset: bool\n",
      "   311|         0|            0|            0|  0.00%|    padding_idx: Optional[int]\n",
      "   312|         0|            0|            0|  0.00%|\n",
      "   313|         0|            0|            0|  0.00%|    def __init__(self, num_embeddings: int, embedding_dim: int,\n",
      "   314|         0|            0|            0|  0.00%|                 max_norm: Optional[float] = None, norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   315|         0|            0|            0|  0.00%|                 mode: str = 'mean', sparse: bool = False, _weight: Optional[Tensor] = None,\n",
      "   316|         0|            0|            0|  0.00%|                 include_last_offset: bool = False, padding_idx: Optional[int] = None,\n",
      "   317|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   318|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   319|         0|            0|            0|  0.00%|        super(EmbeddingBag, self).__init__()\n",
      "   320|         0|            0|            0|  0.00%|        self.num_embeddings = num_embeddings\n",
      "   321|         0|            0|            0|  0.00%|        self.embedding_dim = embedding_dim\n",
      "   322|         0|            0|            0|  0.00%|        self.max_norm = max_norm\n",
      "   323|         0|            0|            0|  0.00%|        self.norm_type = norm_type\n",
      "   324|         0|            0|            0|  0.00%|        self.scale_grad_by_freq = scale_grad_by_freq\n",
      "   325|         0|            0|            0|  0.00%|        if padding_idx is not None:\n",
      "   326|         0|            0|            0|  0.00%|            if padding_idx > 0:\n",
      "   327|         0|            0|            0|  0.00%|                assert padding_idx < self.num_embeddings, 'padding_idx must be within num_embeddings'\n",
      "   328|         0|            0|            0|  0.00%|            elif padding_idx < 0:\n",
      "   329|         0|            0|            0|  0.00%|                assert padding_idx >= -self.num_embeddings, 'padding_idx must be within num_embeddings'\n",
      "   330|         0|            0|            0|  0.00%|                padding_idx = self.num_embeddings + padding_idx\n",
      "   331|         0|            0|            0|  0.00%|        self.padding_idx = padding_idx\n",
      "   332|         0|            0|            0|  0.00%|        if _weight is None:\n",
      "   333|         0|            0|            0|  0.00%|            self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs))\n",
      "   334|         0|            0|            0|  0.00%|            self.reset_parameters()\n",
      "   335|         0|            0|            0|  0.00%|        else:\n",
      "   336|         0|            0|            0|  0.00%|            assert list(_weight.shape) == [num_embeddings, embedding_dim], \\\n",
      "   337|         0|            0|            0|  0.00%|                'Shape of weight does not match num_embeddings and embedding_dim'\n",
      "   338|         0|            0|            0|  0.00%|            self.weight = Parameter(_weight)\n",
      "   339|         0|            0|            0|  0.00%|        self.mode = mode\n",
      "   340|         0|            0|            0|  0.00%|        self.sparse = sparse\n",
      "   341|         0|            0|            0|  0.00%|        self.include_last_offset = include_last_offset\n",
      "   342|         0|            0|            0|  0.00%|\n",
      "   343|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   344|         0|            0|            0|  0.00%|        init.normal_(self.weight)\n",
      "   345|         0|            0|            0|  0.00%|        self._fill_padding_idx_with_zero()\n",
      "   346|         0|            0|            0|  0.00%|\n",
      "   347|         0|            0|            0|  0.00%|    def _fill_padding_idx_with_zero(self) -> None:\n",
      "   348|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   349|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   350|         0|            0|            0|  0.00%|                self.weight[self.padding_idx].fill_(0)\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, offsets: Optional[Tensor] = None, per_sample_weights: Optional[Tensor] = None) -> Tensor:\n",
      "   353|         0|            0|            0|  0.00%|        \"\"\"Forward pass of EmbeddingBag.\n",
      "   354|         0|            0|            0|  0.00%|\n",
      "   355|         0|            0|            0|  0.00%|        Args:\n",
      "   356|         0|            0|            0|  0.00%|            input (Tensor): Tensor containing bags of indices into the embedding matrix.\n",
      "   357|         0|            0|            0|  0.00%|            offsets (Tensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines\n",
      "   358|         0|            0|            0|  0.00%|                the starting index position of each bag (sequence) in :attr:`input`.\n",
      "   359|         0|            0|            0|  0.00%|            per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
      "   360|         0|            0|            0|  0.00%|                to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`\n",
      "   361|         0|            0|            0|  0.00%|                must have exactly the same shape as input and is treated as having the same\n",
      "   362|         0|            0|            0|  0.00%|                :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.\n",
      "   363|         0|            0|            0|  0.00%|\n",
      "   364|         0|            0|            0|  0.00%|        Returns:\n",
      "   365|         0|            0|            0|  0.00%|            Tensor output shape of `(B, embedding_dim)`.\n",
      "   366|         0|            0|            0|  0.00%|\n",
      "   367|         0|            0|            0|  0.00%|        .. note::\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|            A few notes about ``input`` and ``offsets``:\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|            - :attr:`input` and :attr:`offsets` have to be of the same type, either int or long\n",
      "   372|         0|            0|            0|  0.00%|\n",
      "   373|         0|            0|            0|  0.00%|            - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)\n",
      "   374|         0|            0|            0|  0.00%|              each of fixed length ``N``, and this will return ``B`` values aggregated in a way\n",
      "   375|         0|            0|            0|  0.00%|              depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
      "   376|         0|            0|            0|  0.00%|\n",
      "   377|         0|            0|            0|  0.00%|            - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of\n",
      "   378|         0|            0|            0|  0.00%|              multiple bags (sequences).  :attr:`offsets` is required to be a 1D tensor containing the\n",
      "   379|         0|            0|            0|  0.00%|              starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets` of shape `(B)`,\n",
      "   380|         0|            0|            0|  0.00%|              :attr:`input` will be viewed as having ``B`` bags. Empty bags (i.e., having 0-length) will have\n",
      "   381|         0|            0|            0|  0.00%|              returned vectors filled by zeros.\n",
      "   382|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   383|         0|            0|            0|  0.00%|        return F.embedding_bag(input, self.weight, offsets,\n",
      "   384|         0|            0|            0|  0.00%|                               self.max_norm, self.norm_type,\n",
      "   385|         0|            0|            0|  0.00%|                               self.scale_grad_by_freq, self.mode, self.sparse,\n",
      "   386|         0|            0|            0|  0.00%|                               per_sample_weights, self.include_last_offset,\n",
      "   387|         0|            0|            0|  0.00%|                               self.padding_idx)\n",
      "   388|         0|            0|            0|  0.00%|\n",
      "   389|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   390|         0|            0|            0|  0.00%|        s = '{num_embeddings}, {embedding_dim}'\n",
      "   391|         0|            0|            0|  0.00%|        if self.max_norm is not None:\n",
      "   392|         0|            0|            0|  0.00%|            s += ', max_norm={max_norm}'\n",
      "   393|         0|            0|            0|  0.00%|        if self.norm_type != 2:\n",
      "   394|         0|            0|            0|  0.00%|            s += ', norm_type={norm_type}'\n",
      "   395|         0|            0|            0|  0.00%|        if self.scale_grad_by_freq is not False:\n",
      "   396|         0|            0|            0|  0.00%|            s += ', scale_grad_by_freq={scale_grad_by_freq}'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   397|         0|            0|            0|  0.00%|        s += ', mode={mode}'\n",
      "   398|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   399|         0|            0|            0|  0.00%|            s += ', padding_idx={padding_idx}'\n",
      "   400|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   401|         0|            0|            0|  0.00%|\n",
      "   402|         0|            0|            0|  0.00%|    @classmethod\n",
      "   403|         0|            0|            0|  0.00%|    def from_pretrained(cls, embeddings: Tensor, freeze: bool = True, max_norm: Optional[float] = None,\n",
      "   404|         0|            0|            0|  0.00%|                        norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   405|         0|            0|            0|  0.00%|                        mode: str = 'mean', sparse: bool = False, include_last_offset: bool = False,\n",
      "   406|         0|            0|            0|  0.00%|                        padding_idx: Optional[int] = None) -> 'EmbeddingBag':\n",
      "   407|         0|            0|            0|  0.00%|        r\"\"\"Creates EmbeddingBag instance from given 2-dimensional FloatTensor.\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|        Args:\n",
      "   410|         0|            0|            0|  0.00%|            embeddings (Tensor): FloatTensor containing weights for the EmbeddingBag.\n",
      "   411|         0|            0|            0|  0.00%|                First dimension is being passed to EmbeddingBag as 'num_embeddings', second as 'embedding_dim'.\n",
      "   412|         0|            0|            0|  0.00%|            freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      "   413|         0|            0|            0|  0.00%|                Equivalent to ``embeddingbag.weight.requires_grad = False``. Default: ``True``\n",
      "   414|         0|            0|            0|  0.00%|            max_norm (float, optional): See module initialization documentation. Default: ``None``\n",
      "   415|         0|            0|            0|  0.00%|            norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      "   416|         0|            0|            0|  0.00%|            scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\n",
      "   417|         0|            0|            0|  0.00%|            mode (string, optional): See module initialization documentation. Default: ``\"mean\"``\n",
      "   418|         0|            0|            0|  0.00%|            sparse (bool, optional): See module initialization documentation. Default: ``False``.\n",
      "   419|         0|            0|            0|  0.00%|            include_last_offset (bool, optional): See module initialization documentation. Default: ``False``.\n",
      "   420|         0|            0|            0|  0.00%|            padding_idx (int, optional): See module initialization documentation. Default: ``None``.\n",
      "   421|         0|            0|            0|  0.00%|\n",
      "   422|         0|            0|            0|  0.00%|        Examples::\n",
      "   423|         0|            0|            0|  0.00%|\n",
      "   424|         0|            0|            0|  0.00%|            >>> # FloatTensor containing pretrained weights\n",
      "   425|         0|            0|            0|  0.00%|            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      "   426|         0|            0|            0|  0.00%|            >>> embeddingbag = nn.EmbeddingBag.from_pretrained(weight)\n",
      "   427|         0|            0|            0|  0.00%|            >>> # Get embeddings for index 1\n",
      "   428|         0|            0|            0|  0.00%|            >>> input = torch.LongTensor([[1, 0]])\n",
      "   429|         0|            0|            0|  0.00%|            >>> embeddingbag(input)\n",
      "   430|         0|            0|            0|  0.00%|            tensor([[ 2.5000,  3.7000,  4.6500]])\n",
      "   431|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   432|         0|            0|            0|  0.00%|        assert embeddings.dim() == 2, \\\n",
      "   433|         0|            0|            0|  0.00%|            'Embeddings parameter is expected to be 2-dimensional'\n",
      "   434|         0|            0|            0|  0.00%|        rows, cols = embeddings.shape\n",
      "   435|         0|            0|            0|  0.00%|        embeddingbag = cls(\n",
      "   436|         0|            0|            0|  0.00%|            num_embeddings=rows,\n",
      "   437|         0|            0|            0|  0.00%|            embedding_dim=cols,\n",
      "   438|         0|            0|            0|  0.00%|            _weight=embeddings,\n",
      "   439|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "   440|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "   441|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "   442|         0|            0|            0|  0.00%|            mode=mode,\n",
      "   443|         0|            0|            0|  0.00%|            sparse=sparse,\n",
      "   444|         0|            0|            0|  0.00%|            include_last_offset=include_last_offset,\n",
      "   445|         0|            0|            0|  0.00%|            padding_idx=padding_idx)\n",
      "   446|         0|            0|            0|  0.00%|        embeddingbag.weight.requires_grad = not freeze\n",
      "   447|         0|            0|            0|  0.00%|        return embeddingbag\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py\n",
      "File duration: 0.00017643s (0.08%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|import warnings\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|from .distance import PairwiseDistance\n",
      "     4|         0|            0|            0|  0.00%|from .module import Module\n",
      "     5|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     6|         0|            0|            0|  0.00%|from .. import _reduction as _Reduction\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     9|         0|            0|            0|  0.00%|from typing import Callable, Optional\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class _Loss(Module):\n",
      "    13|         0|            0|            0|  0.00%|    reduction: str\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         1|  2.86102e-06|  2.86102e-06|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    16|         1|  1.33514e-05|  1.33514e-05|  0.01%|        super(_Loss, self).__init__()\n",
      "(call)|         1|  0.000537872|  0.000537872|  0.24%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:250 __init__\n",
      "    17|         1|   3.8147e-06|   3.8147e-06|  0.00%|        if size_average is not None or reduce is not None:\n",
      "    18|         0|            0|            0|  0.00%|            self.reduction: str = _Reduction.legacy_get_string(size_average, reduce)\n",
      "    19|         0|            0|            0|  0.00%|        else:\n",
      "    20|         1|  1.00136e-05|  1.00136e-05|  0.00%|            self.reduction = reduction\n",
      "(call)|         1|  3.40939e-05|  3.40939e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|class _WeightedLoss(_Loss):\n",
      "    24|         1|   3.8147e-06|   3.8147e-06|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    25|         1|  1.38283e-05|  1.38283e-05|  0.01%|        super(_WeightedLoss, self).__init__(size_average, reduce, reduction)\n",
      "(call)|         1|  0.000602007|  0.000602007|  0.27%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:15 __init__\n",
      "    26|         1|  1.33514e-05|  1.33514e-05|  0.01%|        self.register_buffer('weight', weight)\n",
      "(call)|         1|  0.000112772|  0.000112772|  0.05%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:270 register_buffer\n",
      "    27|         1|  2.86102e-06|  2.86102e-06|  0.00%|        self.weight: Optional[Tensor]\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|class L1Loss(_Loss):\n",
      "    31|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the mean absolute error (MAE) between each element in\n",
      "    32|         0|            0|            0|  0.00%|    the input :math:`x` and target :math:`y`.\n",
      "    33|         0|            0|            0|  0.00%|\n",
      "    34|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "    35|         0|            0|            0|  0.00%|\n",
      "    36|         0|            0|            0|  0.00%|    .. math::\n",
      "    37|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "    38|         0|            0|            0|  0.00%|        l_n = \\left| x_n - y_n \\right|,\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "    41|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "    42|         0|            0|            0|  0.00%|\n",
      "    43|         0|            0|            0|  0.00%|    .. math::\n",
      "    44|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "    45|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "    46|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "    47|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "    48|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "    49|         0|            0|            0|  0.00%|\n",
      "    50|         0|            0|            0|  0.00%|    :math:`x` and :math:`y` are tensors of arbitrary shapes with a total\n",
      "    51|         0|            0|            0|  0.00%|    of :math:`n` elements each.\n",
      "    52|         0|            0|            0|  0.00%|\n",
      "    53|         0|            0|            0|  0.00%|    The sum operation still operates over all the elements, and divides by :math:`n`.\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|    The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.\n",
      "    56|         0|            0|            0|  0.00%|\n",
      "    57|         0|            0|            0|  0.00%|    Supports real-valued and complex-valued inputs.\n",
      "    58|         0|            0|            0|  0.00%|\n",
      "    59|         0|            0|            0|  0.00%|    Args:\n",
      "    60|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "    61|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "    62|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "    63|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "    64|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "    65|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "    66|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "    67|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "    68|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    69|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "    70|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "    71|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "    72|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "    73|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "    74|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    75|         0|            0|            0|  0.00%|\n",
      "    76|         0|            0|            0|  0.00%|    Shape:\n",
      "    77|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "    78|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "    79|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then\n",
      "    80|         0|            0|            0|  0.00%|          :math:`(*)`, same shape as the input.\n",
      "    81|         0|            0|            0|  0.00%|\n",
      "    82|         0|            0|            0|  0.00%|    Examples::\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|        >>> loss = nn.L1Loss()\n",
      "    85|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    86|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5)\n",
      "    87|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "    88|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "    89|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    90|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    93|         0|            0|            0|  0.00%|        super(L1Loss, self).__init__(size_average, reduce, reduction)\n",
      "    94|         0|            0|            0|  0.00%|\n",
      "    95|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "    96|         0|            0|            0|  0.00%|        return F.l1_loss(input, target, reduction=self.reduction)\n",
      "    97|         0|            0|            0|  0.00%|\n",
      "    98|         0|            0|            0|  0.00%|\n",
      "    99|         0|            0|            0|  0.00%|class NLLLoss(_WeightedLoss):\n",
      "   100|         0|            0|            0|  0.00%|    r\"\"\"The negative log likelihood loss. It is useful to train a classification\n",
      "   101|         0|            0|            0|  0.00%|    problem with `C` classes.\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning\n",
      "   104|         0|            0|            0|  0.00%|    weight to each of the classes. This is particularly useful when you have an\n",
      "   105|         0|            0|            0|  0.00%|    unbalanced training set.\n",
      "   106|         0|            0|            0|  0.00%|\n",
      "   107|         0|            0|            0|  0.00%|    The `input` given through a forward call is expected to contain\n",
      "   108|         0|            0|            0|  0.00%|    log-probabilities of each class. `input` has to be a Tensor of size either\n",
      "   109|         0|            0|            0|  0.00%|    :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`\n",
      "   110|         0|            0|            0|  0.00%|    with :math:`K \\geq 1` for the `K`-dimensional case. The latter is useful for\n",
      "   111|         0|            0|            0|  0.00%|    higher dimension inputs, such as computing NLL loss per-pixel for 2D images.\n",
      "   112|         0|            0|            0|  0.00%|\n",
      "   113|         0|            0|            0|  0.00%|    Obtaining log-probabilities in a neural network is easily achieved by\n",
      "   114|         0|            0|            0|  0.00%|    adding a  `LogSoftmax`  layer in the last layer of your network.\n",
      "   115|         0|            0|            0|  0.00%|    You may use `CrossEntropyLoss` instead, if you prefer not to add an extra\n",
      "   116|         0|            0|            0|  0.00%|    layer.\n",
      "   117|         0|            0|            0|  0.00%|\n",
      "   118|         0|            0|            0|  0.00%|    The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`\n",
      "   119|         0|            0|            0|  0.00%|    where `C = number of classes`; if `ignore_index` is specified, this loss also accepts\n",
      "   120|         0|            0|            0|  0.00%|    this class index (this index may not necessarily be in the class range).\n",
      "   121|         0|            0|            0|  0.00%|\n",
      "   122|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   123|         0|            0|            0|  0.00%|\n",
      "   124|         0|            0|            0|  0.00%|    .. math::\n",
      "   125|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   126|         0|            0|            0|  0.00%|        l_n = - w_{y_n} x_{n,y_n}, \\quad\n",
      "   127|         0|            0|            0|  0.00%|        w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|    where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and\n",
      "   130|         0|            0|            0|  0.00%|    :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   131|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   132|         0|            0|            0|  0.00%|\n",
      "   133|         0|            0|            0|  0.00%|    .. math::\n",
      "   134|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   135|         0|            0|            0|  0.00%|            \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &\n",
      "   136|         0|            0|            0|  0.00%|            \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   137|         0|            0|            0|  0.00%|            \\sum_{n=1}^N l_n,  &\n",
      "   138|         0|            0|            0|  0.00%|            \\text{if reduction} = \\text{`sum'.}\n",
      "   139|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   140|         0|            0|            0|  0.00%|\n",
      "   141|         0|            0|            0|  0.00%|    Args:\n",
      "   142|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "   143|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "   144|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "   145|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   146|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   147|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   148|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   149|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   150|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "   151|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When\n",
      "   152|         0|            0|            0|  0.00%|            :attr:`size_average` is ``True``, the loss is averaged over\n",
      "   153|         0|            0|            0|  0.00%|            non-ignored targets.\n",
      "   154|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   155|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   156|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   157|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   158|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   159|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "   160|         0|            0|            0|  0.00%|            be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "   161|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   162|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in\n",
      "   163|         0|            0|            0|  0.00%|            the meantime, specifying either of those two args will override\n",
      "   164|         0|            0|            0|  0.00%|            :attr:`reduction`. Default: ``'mean'``\n",
      "   165|         0|            0|            0|  0.00%|\n",
      "   166|         0|            0|            0|  0.00%|    Shape:\n",
      "   167|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, or\n",
      "   168|         0|            0|            0|  0.00%|          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "   169|         0|            0|            0|  0.00%|          in the case of `K`-dimensional loss.\n",
      "   170|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`, where each value is\n",
      "   171|         0|            0|            0|  0.00%|          :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n",
      "   172|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of\n",
      "   173|         0|            0|            0|  0.00%|          K-dimensional loss.\n",
      "   174|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n",
      "   175|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n",
      "   176|         0|            0|            0|  0.00%|          Otherwise, scalar.\n",
      "   177|         0|            0|            0|  0.00%|\n",
      "   178|         0|            0|            0|  0.00%|    Examples::\n",
      "   179|         0|            0|            0|  0.00%|\n",
      "   180|         0|            0|            0|  0.00%|        >>> m = nn.LogSoftmax(dim=1)\n",
      "   181|         0|            0|            0|  0.00%|        >>> loss = nn.NLLLoss()\n",
      "   182|         0|            0|            0|  0.00%|        >>> # input is of size N x C = 3 x 5\n",
      "   183|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "   184|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "   185|         0|            0|            0|  0.00%|        >>> target = torch.tensor([1, 0, 4])\n",
      "   186|         0|            0|            0|  0.00%|        >>> output = loss(m(input), target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   187|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   188|         0|            0|            0|  0.00%|        >>>\n",
      "   189|         0|            0|            0|  0.00%|        >>>\n",
      "   190|         0|            0|            0|  0.00%|        >>> # 2D loss example (used, for example, with image inputs)\n",
      "   191|         0|            0|            0|  0.00%|        >>> N, C = 5, 4\n",
      "   192|         0|            0|            0|  0.00%|        >>> loss = nn.NLLLoss()\n",
      "   193|         0|            0|            0|  0.00%|        >>> # input is of size N x C x height x width\n",
      "   194|         0|            0|            0|  0.00%|        >>> data = torch.randn(N, 16, 10, 10)\n",
      "   195|         0|            0|            0|  0.00%|        >>> conv = nn.Conv2d(16, C, (3, 3))\n",
      "   196|         0|            0|            0|  0.00%|        >>> m = nn.LogSoftmax(dim=1)\n",
      "   197|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "   198|         0|            0|            0|  0.00%|        >>> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
      "   199|         0|            0|            0|  0.00%|        >>> output = loss(m(conv(data)), target)\n",
      "   200|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   201|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   202|         0|            0|            0|  0.00%|    __constants__ = ['ignore_index', 'reduction']\n",
      "   203|         0|            0|            0|  0.00%|    ignore_index: int\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "   206|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "   207|         0|            0|            0|  0.00%|        super(NLLLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "   208|         0|            0|            0|  0.00%|        self.ignore_index = ignore_index\n",
      "   209|         0|            0|            0|  0.00%|\n",
      "   210|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   211|         0|            0|            0|  0.00%|        return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|class NLLLoss2d(NLLLoss):\n",
      "   215|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "   216|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "   217|         0|            0|            0|  0.00%|        warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "   218|         0|            0|            0|  0.00%|                      \"Please use NLLLoss instead as a drop-in replacement and see \"\n",
      "   219|         0|            0|            0|  0.00%|                      \"https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\")\n",
      "   220|         0|            0|            0|  0.00%|        super(NLLLoss2d, self).__init__(weight, size_average, ignore_index, reduce, reduction)\n",
      "   221|         0|            0|            0|  0.00%|\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|class PoissonNLLLoss(_Loss):\n",
      "   224|         0|            0|            0|  0.00%|    r\"\"\"Negative log likelihood loss with Poisson distribution of target.\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    The loss can be described as:\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    .. math::\n",
      "   229|         0|            0|            0|  0.00%|        \\text{target} \\sim \\mathrm{Poisson}(\\text{input})\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|        \\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input})\n",
      "   232|         0|            0|            0|  0.00%|                                    + \\log(\\text{target!})\n",
      "   233|         0|            0|            0|  0.00%|\n",
      "   234|         0|            0|            0|  0.00%|    The last term can be omitted or approximated with Stirling formula. The\n",
      "   235|         0|            0|            0|  0.00%|    approximation is used for target values more than 1. For targets less or\n",
      "   236|         0|            0|            0|  0.00%|    equal to 1 zeros are added to the loss.\n",
      "   237|         0|            0|            0|  0.00%|\n",
      "   238|         0|            0|            0|  0.00%|    Args:\n",
      "   239|         0|            0|            0|  0.00%|        log_input (bool, optional): if ``True`` the loss is computed as\n",
      "   240|         0|            0|            0|  0.00%|            :math:`\\exp(\\text{input}) - \\text{target}*\\text{input}`, if ``False`` the loss is\n",
      "   241|         0|            0|            0|  0.00%|            :math:`\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})`.\n",
      "   242|         0|            0|            0|  0.00%|        full (bool, optional): whether to compute full loss, i. e. to add the\n",
      "   243|         0|            0|            0|  0.00%|            Stirling approximation term\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|            .. math::\n",
      "   246|         0|            0|            0|  0.00%|                \\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\n",
      "   247|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   248|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   249|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   250|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   251|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   252|         0|            0|            0|  0.00%|        eps (float, optional): Small value to avoid evaluation of :math:`\\log(0)` when\n",
      "   253|         0|            0|            0|  0.00%|            :attr:`log_input = False`. Default: 1e-8\n",
      "   254|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   255|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   256|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   257|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   258|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   259|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   260|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   261|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   262|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   263|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   264|         0|            0|            0|  0.00%|\n",
      "   265|         0|            0|            0|  0.00%|    Examples::\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|        >>> loss = nn.PoissonNLLLoss()\n",
      "   268|         0|            0|            0|  0.00%|        >>> log_input = torch.randn(5, 2, requires_grad=True)\n",
      "   269|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   270|         0|            0|            0|  0.00%|        >>> output = loss(log_input, target)\n",
      "   271|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|    Shape:\n",
      "   274|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   275|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   276|         0|            0|            0|  0.00%|        - Output: scalar by default. If :attr:`reduction` is ``'none'``, then :math:`(*)`,\n",
      "   277|         0|            0|            0|  0.00%|          the same shape as the input.\n",
      "   278|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   279|         0|            0|            0|  0.00%|    __constants__ = ['log_input', 'full', 'eps', 'reduction']\n",
      "   280|         0|            0|            0|  0.00%|    log_input: bool\n",
      "   281|         0|            0|            0|  0.00%|    full: bool\n",
      "   282|         0|            0|            0|  0.00%|    eps: float\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|    def __init__(self, log_input: bool = True, full: bool = False, size_average=None,\n",
      "   285|         0|            0|            0|  0.00%|                 eps: float = 1e-8, reduce=None, reduction: str = 'mean') -> None:\n",
      "   286|         0|            0|            0|  0.00%|        super(PoissonNLLLoss, self).__init__(size_average, reduce, reduction)\n",
      "   287|         0|            0|            0|  0.00%|        self.log_input = log_input\n",
      "   288|         0|            0|            0|  0.00%|        self.full = full\n",
      "   289|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|    def forward(self, log_input: Tensor, target: Tensor) -> Tensor:\n",
      "   292|         0|            0|            0|  0.00%|        return F.poisson_nll_loss(log_input, target, log_input=self.log_input, full=self.full,\n",
      "   293|         0|            0|            0|  0.00%|                                  eps=self.eps, reduction=self.reduction)\n",
      "   294|         0|            0|            0|  0.00%|\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|class GaussianNLLLoss(_Loss):\n",
      "   297|         0|            0|            0|  0.00%|    r\"\"\"Gaussian negative log likelihood loss.\n",
      "   298|         0|            0|            0|  0.00%|\n",
      "   299|         0|            0|            0|  0.00%|    The targets are treated as samples from Gaussian distributions with\n",
      "   300|         0|            0|            0|  0.00%|    expectations and variances predicted by the neural network. For a\n",
      "   301|         0|            0|            0|  0.00%|    ``target`` tensor modelled as having Gaussian distribution with a tensor\n",
      "   302|         0|            0|            0|  0.00%|    of expectations ``input`` and a tensor of positive variances ``var`` the loss is:\n",
      "   303|         0|            0|            0|  0.00%|\n",
      "   304|         0|            0|            0|  0.00%|    .. math::\n",
      "   305|         0|            0|            0|  0.00%|        \\text{loss} = \\frac{1}{2}\\left(\\log\\left(\\text{max}\\left(\\text{var},\n",
      "   306|         0|            0|            0|  0.00%|        \\ \\text{eps}\\right)\\right) + \\frac{\\left(\\text{input} - \\text{target}\\right)^2}\n",
      "   307|         0|            0|            0|  0.00%|        {\\text{max}\\left(\\text{var}, \\ \\text{eps}\\right)}\\right) + \\text{const.}\n",
      "   308|         0|            0|            0|  0.00%|\n",
      "   309|         0|            0|            0|  0.00%|    where :attr:`eps` is used for stability. By default, the constant term of\n",
      "   310|         0|            0|            0|  0.00%|    the loss function is omitted unless :attr:`full` is ``True``. If ``var`` is not the same\n",
      "   311|         0|            0|            0|  0.00%|    size as ``input`` (due to a homoscedastic assumption), it must either have a final dimension\n",
      "   312|         0|            0|            0|  0.00%|    of 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting.\n",
      "   313|         0|            0|            0|  0.00%|\n",
      "   314|         0|            0|            0|  0.00%|    Args:\n",
      "   315|         0|            0|            0|  0.00%|        full (bool, optional): include the constant term in the loss\n",
      "   316|         0|            0|            0|  0.00%|            calculation. Default: ``False``.\n",
      "   317|         0|            0|            0|  0.00%|        eps (float, optional): value used to clamp ``var`` (see note below), for\n",
      "   318|         0|            0|            0|  0.00%|            stability. Default: 1e-6.\n",
      "   319|         0|            0|            0|  0.00%|        reduction (string, optional): specifies the reduction to apply to the\n",
      "   320|         0|            0|            0|  0.00%|            output:``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n",
      "   321|         0|            0|            0|  0.00%|            will be applied, ``'mean'``: the output is the average of all batch\n",
      "   322|         0|            0|            0|  0.00%|            member losses, ``'sum'``: the output is the sum of all batch member\n",
      "   323|         0|            0|            0|  0.00%|            losses. Default: ``'mean'``.\n",
      "   324|         0|            0|            0|  0.00%|\n",
      "   325|         0|            0|            0|  0.00%|    Shape:\n",
      "   326|         0|            0|            0|  0.00%|        - Input: :math:`(N, *)` where :math:`*` means any number of additional\n",
      "   327|         0|            0|            0|  0.00%|          dimensions\n",
      "   328|         0|            0|            0|  0.00%|        - Target: :math:`(N, *)`, same shape as the input, or same shape as the input\n",
      "   329|         0|            0|            0|  0.00%|          but with one dimension equal to 1 (to allow for broadcasting)\n",
      "   330|         0|            0|            0|  0.00%|        - Var: :math:`(N, *)`, same shape as the input, or same shape as the input but\n",
      "   331|         0|            0|            0|  0.00%|          with one dimension equal to 1, or same shape as the input but with one fewer\n",
      "   332|         0|            0|            0|  0.00%|          dimension (to allow for broadcasting)\n",
      "   333|         0|            0|            0|  0.00%|        - Output: scalar if :attr:`reduction` is ``'mean'`` (default) or\n",
      "   334|         0|            0|            0|  0.00%|          ``'sum'``. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n",
      "   335|         0|            0|            0|  0.00%|          shape as the input\n",
      "   336|         0|            0|            0|  0.00%|\n",
      "   337|         0|            0|            0|  0.00%|    Examples::\n",
      "   338|         0|            0|            0|  0.00%|        >>> loss = nn.GaussianNLLLoss()\n",
      "   339|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 2, requires_grad=True)\n",
      "   340|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   341|         0|            0|            0|  0.00%|        >>> var = torch.ones(5, 2, requires_grad=True) #heteroscedastic\n",
      "   342|         0|            0|            0|  0.00%|        >>> output = loss(input, target, var)\n",
      "   343|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   344|         0|            0|            0|  0.00%|\n",
      "   345|         0|            0|            0|  0.00%|        >>> loss = nn.GaussianNLLLoss()\n",
      "   346|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 2, requires_grad=True)\n",
      "   347|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   348|         0|            0|            0|  0.00%|        >>> var = torch.ones(5, 1, requires_grad=True) #homoscedastic\n",
      "   349|         0|            0|            0|  0.00%|        >>> output = loss(input, target, var)\n",
      "   350|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|    Note:\n",
      "   353|         0|            0|            0|  0.00%|        The clamping of ``var`` is ignored with respect to autograd, and so the\n",
      "   354|         0|            0|            0|  0.00%|        gradients are unaffected by it.\n",
      "   355|         0|            0|            0|  0.00%|\n",
      "   356|         0|            0|            0|  0.00%|    Reference:\n",
      "   357|         0|            0|            0|  0.00%|        Nix, D. A. and Weigend, A. S., \"Estimating the mean and variance of the\n",
      "   358|         0|            0|            0|  0.00%|        target probability distribution\", Proceedings of 1994 IEEE International\n",
      "   359|         0|            0|            0|  0.00%|        Conference on Neural Networks (ICNN'94), Orlando, FL, USA, 1994, pp. 55-60\n",
      "   360|         0|            0|            0|  0.00%|        vol.1, doi: 10.1109/ICNN.1994.374138.\n",
      "   361|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   362|         0|            0|            0|  0.00%|    __constants__ = ['full', 'eps', 'reduction']\n",
      "   363|         0|            0|            0|  0.00%|    full: bool\n",
      "   364|         0|            0|            0|  0.00%|    eps: float\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    def __init__(self, *, full: bool = False, eps: float = 1e-6, reduction: str = 'mean') -> None:\n",
      "   367|         0|            0|            0|  0.00%|        super(GaussianNLLLoss, self).__init__(None, None, reduction)\n",
      "   368|         0|            0|            0|  0.00%|        self.full = full\n",
      "   369|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor, var: Tensor) -> Tensor:\n",
      "   372|         0|            0|            0|  0.00%|        return F.gaussian_nll_loss(input, target, var, full=self.full, eps=self.eps, reduction=self.reduction)\n",
      "   373|         0|            0|            0|  0.00%|\n",
      "   374|         0|            0|            0|  0.00%|\n",
      "   375|         0|            0|            0|  0.00%|class KLDivLoss(_Loss):\n",
      "   376|         0|            0|            0|  0.00%|    r\"\"\"The Kullback-Leibler divergence loss measure\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|    `Kullback-Leibler divergence`_ is a useful distance measure for continuous\n",
      "   379|         0|            0|            0|  0.00%|    distributions and is often useful when performing direct regression over\n",
      "   380|         0|            0|            0|  0.00%|    the space of (discretely sampled) continuous output distributions.\n",
      "   381|         0|            0|            0|  0.00%|\n",
      "   382|         0|            0|            0|  0.00%|    As with :class:`~torch.nn.NLLLoss`, the `input` given is expected to contain\n",
      "   383|         0|            0|            0|  0.00%|    *log-probabilities* and is not restricted to a 2D Tensor.\n",
      "   384|         0|            0|            0|  0.00%|    The targets are interpreted as *probabilities* by default, but could be considered\n",
      "   385|         0|            0|            0|  0.00%|    as *log-probabilities* with :attr:`log_target` set to ``True``.\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|    This criterion expects a `target` `Tensor` of the same size as the\n",
      "   388|         0|            0|            0|  0.00%|    `input` `Tensor`.\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   391|         0|            0|            0|  0.00%|\n",
      "   392|         0|            0|            0|  0.00%|    .. math::\n",
      "   393|         0|            0|            0|  0.00%|        l(x,y) = L = \\{ l_1,\\dots,l_N \\}, \\quad\n",
      "   394|         0|            0|            0|  0.00%|        l_n = y_n \\cdot \\left( \\log y_n - x_n \\right)\n",
      "   395|         0|            0|            0|  0.00%|\n",
      "   396|         0|            0|            0|  0.00%|    where the index :math:`N` spans all dimensions of ``input`` and :math:`L` has the same\n",
      "   397|         0|            0|            0|  0.00%|    shape as ``input``. If :attr:`reduction` is not ``'none'`` (default ``'mean'``), then:\n",
      "   398|         0|            0|            0|  0.00%|\n",
      "   399|         0|            0|            0|  0.00%|    .. math::\n",
      "   400|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   401|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';} \\\\\n",
      "   402|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   403|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   404|         0|            0|            0|  0.00%|\n",
      "   405|         0|            0|            0|  0.00%|    In default :attr:`reduction` mode ``'mean'``, the losses are averaged for each minibatch over observations\n",
      "   406|         0|            0|            0|  0.00%|    **as well as** over dimensions. ``'batchmean'`` mode gives the correct KL divergence where losses\n",
      "   407|         0|            0|            0|  0.00%|    are averaged over batch dimension only. ``'mean'`` mode's behavior will be changed to the same as\n",
      "   408|         0|            0|            0|  0.00%|    ``'batchmean'`` in the next major release.\n",
      "   409|         0|            0|            0|  0.00%|\n",
      "   410|         0|            0|            0|  0.00%|    .. _`kullback-leibler divergence`: https://en.wikipedia.org/wiki/Kullback-Leibler_divergence\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|    Args:\n",
      "   413|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   414|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   415|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   416|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   417|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   418|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   419|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   420|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   421|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   422|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   423|         0|            0|            0|  0.00%|            ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.\n",
      "   424|         0|            0|            0|  0.00%|            ``'none'``: no reduction will be applied.\n",
      "   425|         0|            0|            0|  0.00%|            ``'batchmean'``: the sum of the output will be divided by batchsize.\n",
      "   426|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed.\n",
      "   427|         0|            0|            0|  0.00%|            ``'mean'``: the output will be divided by the number of elements in the output.\n",
      "   428|         0|            0|            0|  0.00%|            Default: ``'mean'``\n",
      "   429|         0|            0|            0|  0.00%|        log_target (bool, optional): Specifies whether `target` is passed in the log space.\n",
      "   430|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "   431|         0|            0|            0|  0.00%|\n",
      "   432|         0|            0|            0|  0.00%|    .. note::\n",
      "   433|         0|            0|            0|  0.00%|        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,\n",
      "   434|         0|            0|            0|  0.00%|        and in the meantime, specifying either of those two args will override :attr:`reduction`.\n",
      "   435|         0|            0|            0|  0.00%|\n",
      "   436|         0|            0|            0|  0.00%|    .. note::\n",
      "   437|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use\n",
      "   438|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.\n",
      "   439|         0|            0|            0|  0.00%|        In the next major release, ``'mean'`` will be changed to be the same as ``'batchmean'``.\n",
      "   440|         0|            0|            0|  0.00%|\n",
      "   441|         0|            0|            0|  0.00%|    Shape:\n",
      "   442|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   443|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   444|         0|            0|            0|  0.00%|        - Output: scalar by default. If :attr:``reduction`` is ``'none'``, then :math:`(*)`,\n",
      "   445|         0|            0|            0|  0.00%|          same shape as the input.\n",
      "   446|         0|            0|            0|  0.00%|\n",
      "   447|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   448|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False) -> None:\n",
      "   451|         0|            0|            0|  0.00%|        super(KLDivLoss, self).__init__(size_average, reduce, reduction)\n",
      "   452|         0|            0|            0|  0.00%|        self.log_target = log_target\n",
      "   453|         0|            0|            0|  0.00%|\n",
      "   454|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   455|         0|            0|            0|  0.00%|        return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)\n",
      "   456|         0|            0|            0|  0.00%|\n",
      "   457|         0|            0|            0|  0.00%|\n",
      "   458|         0|            0|            0|  0.00%|class MSELoss(_Loss):\n",
      "   459|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the mean squared error (squared L2 norm) between\n",
      "   460|         0|            0|            0|  0.00%|    each element in the input :math:`x` and target :math:`y`.\n",
      "   461|         0|            0|            0|  0.00%|\n",
      "   462|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   463|         0|            0|            0|  0.00%|\n",
      "   464|         0|            0|            0|  0.00%|    .. math::\n",
      "   465|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   466|         0|            0|            0|  0.00%|        l_n = \\left( x_n - y_n \\right)^2,\n",
      "   467|         0|            0|            0|  0.00%|\n",
      "   468|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   469|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "   470|         0|            0|            0|  0.00%|\n",
      "   471|         0|            0|            0|  0.00%|    .. math::\n",
      "   472|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   473|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   474|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   475|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   476|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   477|         0|            0|            0|  0.00%|\n",
      "   478|         0|            0|            0|  0.00%|    :math:`x` and :math:`y` are tensors of arbitrary shapes with a total\n",
      "   479|         0|            0|            0|  0.00%|    of :math:`n` elements each.\n",
      "   480|         0|            0|            0|  0.00%|\n",
      "   481|         0|            0|            0|  0.00%|    The mean operation still operates over all the elements, and divides by :math:`n`.\n",
      "   482|         0|            0|            0|  0.00%|\n",
      "   483|         0|            0|            0|  0.00%|    The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.\n",
      "   484|         0|            0|            0|  0.00%|\n",
      "   485|         0|            0|            0|  0.00%|    Args:\n",
      "   486|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   487|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   488|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   489|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   490|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   491|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   492|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   493|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   494|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   495|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   496|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   497|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   498|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   499|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   500|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   501|         0|            0|            0|  0.00%|\n",
      "   502|         0|            0|            0|  0.00%|    Shape:\n",
      "   503|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   504|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   505|         0|            0|            0|  0.00%|\n",
      "   506|         0|            0|            0|  0.00%|    Examples::\n",
      "   507|         0|            0|            0|  0.00%|\n",
      "   508|         0|            0|            0|  0.00%|        >>> loss = nn.MSELoss()\n",
      "   509|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "   510|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5)\n",
      "   511|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "   512|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   513|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   514|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   515|         0|            0|            0|  0.00%|\n",
      "   516|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   517|         0|            0|            0|  0.00%|        super(MSELoss, self).__init__(size_average, reduce, reduction)\n",
      "   518|         0|            0|            0|  0.00%|\n",
      "   519|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   520|         0|            0|            0|  0.00%|        return F.mse_loss(input, target, reduction=self.reduction)\n",
      "   521|         0|            0|            0|  0.00%|\n",
      "   522|         0|            0|            0|  0.00%|\n",
      "   523|         0|            0|            0|  0.00%|class BCELoss(_WeightedLoss):\n",
      "   524|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the Binary Cross Entropy between the target and\n",
      "   525|         0|            0|            0|  0.00%|    the input probabilities:\n",
      "   526|         0|            0|            0|  0.00%|\n",
      "   527|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   528|         0|            0|            0|  0.00%|\n",
      "   529|         0|            0|            0|  0.00%|    .. math::\n",
      "   530|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   531|         0|            0|            0|  0.00%|        l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
      "   532|         0|            0|            0|  0.00%|\n",
      "   533|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   534|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   535|         0|            0|            0|  0.00%|\n",
      "   536|         0|            0|            0|  0.00%|    .. math::\n",
      "   537|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   538|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   539|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   540|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   541|         0|            0|            0|  0.00%|\n",
      "   542|         0|            0|            0|  0.00%|    This is used for measuring the error of a reconstruction in for example\n",
      "   543|         0|            0|            0|  0.00%|    an auto-encoder. Note that the targets :math:`y` should be numbers\n",
      "   544|         0|            0|            0|  0.00%|    between 0 and 1.\n",
      "   545|         0|            0|            0|  0.00%|\n",
      "   546|         0|            0|            0|  0.00%|    Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be\n",
      "   547|         0|            0|            0|  0.00%|    mathematically undefined in the above loss equation. PyTorch chooses to set\n",
      "   548|         0|            0|            0|  0.00%|    :math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\n",
      "   549|         0|            0|            0|  0.00%|    However, an infinite term in the loss equation is not desirable for several reasons.\n",
      "   550|         0|            0|            0|  0.00%|\n",
      "   551|         0|            0|            0|  0.00%|    For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\n",
      "   552|         0|            0|            0|  0.00%|    multiplying 0 with infinity. Secondly, if we have an infinite loss value, then\n",
      "   553|         0|            0|            0|  0.00%|    we would also have an infinite term in our gradient, since\n",
      "   554|         0|            0|            0|  0.00%|    :math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\n",
      "   555|         0|            0|            0|  0.00%|    This would make BCELoss's backward method nonlinear with respect to :math:`x_n`,\n",
      "   556|         0|            0|            0|  0.00%|    and using it for things like linear regression would not be straight-forward.\n",
      "   557|         0|            0|            0|  0.00%|\n",
      "   558|         0|            0|            0|  0.00%|    Our solution is that BCELoss clamps its log function outputs to be greater than\n",
      "   559|         0|            0|            0|  0.00%|    or equal to -100. This way, we can always have a finite loss value and a linear\n",
      "   560|         0|            0|            0|  0.00%|    backward method.\n",
      "   561|         0|            0|            0|  0.00%|\n",
      "   562|         0|            0|            0|  0.00%|\n",
      "   563|         0|            0|            0|  0.00%|    Args:\n",
      "   564|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to the loss\n",
      "   565|         0|            0|            0|  0.00%|            of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
      "   566|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   567|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   568|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   569|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   570|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   571|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   572|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   573|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   574|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   575|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   576|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   577|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   578|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   579|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   580|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   581|         0|            0|            0|  0.00%|\n",
      "   582|         0|            0|            0|  0.00%|    Shape:\n",
      "   583|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   584|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   585|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "   586|         0|            0|            0|  0.00%|          shape as input.\n",
      "   587|         0|            0|            0|  0.00%|\n",
      "   588|         0|            0|            0|  0.00%|    Examples::\n",
      "   589|         0|            0|            0|  0.00%|\n",
      "   590|         0|            0|            0|  0.00%|        >>> m = nn.Sigmoid()\n",
      "   591|         0|            0|            0|  0.00%|        >>> loss = nn.BCELoss()\n",
      "   592|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, requires_grad=True)\n",
      "   593|         0|            0|            0|  0.00%|        >>> target = torch.empty(3).random_(2)\n",
      "   594|         0|            0|            0|  0.00%|        >>> output = loss(m(input), target)\n",
      "   595|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   596|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   597|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   598|         0|            0|            0|  0.00%|\n",
      "   599|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   600|         0|            0|            0|  0.00%|        super(BCELoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "   601|         0|            0|            0|  0.00%|\n",
      "   602|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   603|         0|            0|            0|  0.00%|        return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "   604|         0|            0|            0|  0.00%|\n",
      "   605|         0|            0|            0|  0.00%|\n",
      "   606|         0|            0|            0|  0.00%|class BCEWithLogitsLoss(_Loss):\n",
      "   607|         0|            0|            0|  0.00%|    r\"\"\"This loss combines a `Sigmoid` layer and the `BCELoss` in one single\n",
      "   608|         0|            0|            0|  0.00%|    class. This version is more numerically stable than using a plain `Sigmoid`\n",
      "   609|         0|            0|            0|  0.00%|    followed by a `BCELoss` as, by combining the operations into one layer,\n",
      "   610|         0|            0|            0|  0.00%|    we take advantage of the log-sum-exp trick for numerical stability.\n",
      "   611|         0|            0|            0|  0.00%|\n",
      "   612|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   613|         0|            0|            0|  0.00%|\n",
      "   614|         0|            0|            0|  0.00%|    .. math::\n",
      "   615|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   616|         0|            0|            0|  0.00%|        l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\n",
      "   617|         0|            0|            0|  0.00%|        + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\n",
      "   618|         0|            0|            0|  0.00%|\n",
      "   619|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   620|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   621|         0|            0|            0|  0.00%|\n",
      "   622|         0|            0|            0|  0.00%|    .. math::\n",
      "   623|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   624|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   625|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   626|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   627|         0|            0|            0|  0.00%|\n",
      "   628|         0|            0|            0|  0.00%|    This is used for measuring the error of a reconstruction in for example\n",
      "   629|         0|            0|            0|  0.00%|    an auto-encoder. Note that the targets `t[i]` should be numbers\n",
      "   630|         0|            0|            0|  0.00%|    between 0 and 1.\n",
      "   631|         0|            0|            0|  0.00%|\n",
      "   632|         0|            0|            0|  0.00%|    It's possible to trade off recall and precision by adding weights to positive examples.\n",
      "   633|         0|            0|            0|  0.00%|    In the case of multi-label classification the loss can be described as:\n",
      "   634|         0|            0|            0|  0.00%|\n",
      "   635|         0|            0|            0|  0.00%|    .. math::\n",
      "   636|         0|            0|            0|  0.00%|        \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\n",
      "   637|         0|            0|            0|  0.00%|        l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\n",
      "   638|         0|            0|            0|  0.00%|        + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\n",
      "   639|         0|            0|            0|  0.00%|\n",
      "   640|         0|            0|            0|  0.00%|    where :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,\n",
      "   641|         0|            0|            0|  0.00%|    :math:`c = 1` for single-label binary classification),\n",
      "   642|         0|            0|            0|  0.00%|    :math:`n` is the number of the sample in the batch and\n",
      "   643|         0|            0|            0|  0.00%|    :math:`p_c` is the weight of the positive answer for the class :math:`c`.\n",
      "   644|         0|            0|            0|  0.00%|\n",
      "   645|         0|            0|            0|  0.00%|    :math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.\n",
      "   646|         0|            0|            0|  0.00%|\n",
      "   647|         0|            0|            0|  0.00%|    For example, if a dataset contains 100 positive and 300 negative examples of a single class,\n",
      "   648|         0|            0|            0|  0.00%|    then `pos_weight` for the class should be equal to :math:`\\frac{300}{100}=3`.\n",
      "   649|         0|            0|            0|  0.00%|    The loss would act as if the dataset contains :math:`3\\times 100=300` positive examples.\n",
      "   650|         0|            0|            0|  0.00%|\n",
      "   651|         0|            0|            0|  0.00%|    Examples::\n",
      "   652|         0|            0|            0|  0.00%|\n",
      "   653|         0|            0|            0|  0.00%|        >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n",
      "   654|         0|            0|            0|  0.00%|        >>> output = torch.full([10, 64], 1.5)  # A prediction (logit)\n",
      "   655|         0|            0|            0|  0.00%|        >>> pos_weight = torch.ones([64])  # All weights are equal to 1\n",
      "   656|         0|            0|            0|  0.00%|        >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
      "   657|         0|            0|            0|  0.00%|        >>> criterion(output, target)  # -log(sigmoid(1.5))\n",
      "   658|         0|            0|            0|  0.00%|        tensor(0.2014)\n",
      "   659|         0|            0|            0|  0.00%|\n",
      "   660|         0|            0|            0|  0.00%|    Args:\n",
      "   661|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to the loss\n",
      "   662|         0|            0|            0|  0.00%|            of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
      "   663|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   664|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   665|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   666|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   667|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   668|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   669|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   670|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   671|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   672|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   673|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   674|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   675|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   676|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   677|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   678|         0|            0|            0|  0.00%|        pos_weight (Tensor, optional): a weight of positive examples.\n",
      "   679|         0|            0|            0|  0.00%|                Must be a vector with length equal to the number of classes.\n",
      "   680|         0|            0|            0|  0.00%|\n",
      "   681|         0|            0|            0|  0.00%|    Shape:\n",
      "   682|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   683|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   684|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "   685|         0|            0|            0|  0.00%|          shape as input.\n",
      "   686|         0|            0|            0|  0.00%|\n",
      "   687|         0|            0|            0|  0.00%|     Examples::\n",
      "   688|         0|            0|            0|  0.00%|\n",
      "   689|         0|            0|            0|  0.00%|        >>> loss = nn.BCEWithLogitsLoss()\n",
      "   690|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, requires_grad=True)\n",
      "   691|         0|            0|            0|  0.00%|        >>> target = torch.empty(3).random_(2)\n",
      "   692|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "   693|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   694|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   695|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean',\n",
      "   696|         0|            0|            0|  0.00%|                 pos_weight: Optional[Tensor] = None) -> None:\n",
      "   697|         0|            0|            0|  0.00%|        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
      "   698|         0|            0|            0|  0.00%|        self.register_buffer('weight', weight)\n",
      "   699|         0|            0|            0|  0.00%|        self.register_buffer('pos_weight', pos_weight)\n",
      "   700|         0|            0|            0|  0.00%|        self.weight: Optional[Tensor]\n",
      "   701|         0|            0|            0|  0.00%|        self.pos_weight: Optional[Tensor]\n",
      "   702|         0|            0|            0|  0.00%|\n",
      "   703|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   704|         0|            0|            0|  0.00%|        return F.binary_cross_entropy_with_logits(input, target,\n",
      "   705|         0|            0|            0|  0.00%|                                                  self.weight,\n",
      "   706|         0|            0|            0|  0.00%|                                                  pos_weight=self.pos_weight,\n",
      "   707|         0|            0|            0|  0.00%|                                                  reduction=self.reduction)\n",
      "   708|         0|            0|            0|  0.00%|\n",
      "   709|         0|            0|            0|  0.00%|\n",
      "   710|         0|            0|            0|  0.00%|class HingeEmbeddingLoss(_Loss):\n",
      "   711|         0|            0|            0|  0.00%|    r\"\"\"Measures the loss given an input tensor :math:`x` and a labels tensor :math:`y`\n",
      "   712|         0|            0|            0|  0.00%|    (containing 1 or -1).\n",
      "   713|         0|            0|            0|  0.00%|    This is usually used for measuring whether two inputs are similar or\n",
      "   714|         0|            0|            0|  0.00%|    dissimilar, e.g. using the L1 pairwise distance as :math:`x`, and is typically\n",
      "   715|         0|            0|            0|  0.00%|    used for learning nonlinear embeddings or semi-supervised learning.\n",
      "   716|         0|            0|            0|  0.00%|\n",
      "   717|         0|            0|            0|  0.00%|    The loss function for :math:`n`-th sample in the mini-batch is\n",
      "   718|         0|            0|            0|  0.00%|\n",
      "   719|         0|            0|            0|  0.00%|    .. math::\n",
      "   720|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   721|         0|            0|            0|  0.00%|            x_n, & \\text{if}\\; y_n = 1,\\\\\n",
      "   722|         0|            0|            0|  0.00%|            \\max \\{0, \\Delta - x_n\\}, & \\text{if}\\; y_n = -1,\n",
      "   723|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   724|         0|            0|            0|  0.00%|\n",
      "   725|         0|            0|            0|  0.00%|    and the total loss functions is\n",
      "   726|         0|            0|            0|  0.00%|\n",
      "   727|         0|            0|            0|  0.00%|    .. math::\n",
      "   728|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   729|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   730|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   731|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   732|         0|            0|            0|  0.00%|\n",
      "   733|         0|            0|            0|  0.00%|    where :math:`L = \\{l_1,\\dots,l_N\\}^\\top`.\n",
      "   734|         0|            0|            0|  0.00%|\n",
      "   735|         0|            0|            0|  0.00%|    Args:\n",
      "   736|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of `1`.\n",
      "   737|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   738|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   739|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   740|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   741|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   742|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   743|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   744|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   745|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   746|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   747|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   748|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   749|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   750|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   751|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   752|         0|            0|            0|  0.00%|\n",
      "   753|         0|            0|            0|  0.00%|    Shape:\n",
      "   754|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where :math:`*` means, any number of dimensions. The sum operation\n",
      "   755|         0|            0|            0|  0.00%|          operates over all the elements.\n",
      "   756|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input\n",
      "   757|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the input\n",
      "   758|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   759|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "   760|         0|            0|            0|  0.00%|    margin: float\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   763|         0|            0|            0|  0.00%|        super(HingeEmbeddingLoss, self).__init__(size_average, reduce, reduction)\n",
      "   764|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "   765|         0|            0|            0|  0.00%|\n",
      "   766|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   767|         0|            0|            0|  0.00%|        return F.hinge_embedding_loss(input, target, margin=self.margin, reduction=self.reduction)\n",
      "   768|         0|            0|            0|  0.00%|\n",
      "   769|         0|            0|            0|  0.00%|\n",
      "   770|         0|            0|            0|  0.00%|class MultiLabelMarginLoss(_Loss):\n",
      "   771|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-class multi-classification\n",
      "   772|         0|            0|            0|  0.00%|    hinge loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`)\n",
      "   773|         0|            0|            0|  0.00%|    and output :math:`y` (which is a 2D `Tensor` of target class indices).\n",
      "   774|         0|            0|            0|  0.00%|    For each sample in the mini-batch:\n",
      "   775|         0|            0|            0|  0.00%|\n",
      "   776|         0|            0|            0|  0.00%|    .. math::\n",
      "   777|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)}\n",
      "   778|         0|            0|            0|  0.00%|\n",
      "   779|         0|            0|            0|  0.00%|    where :math:`x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`, \\\n",
      "   780|         0|            0|            0|  0.00%|    :math:`y \\in \\left\\{0, \\; \\cdots , \\; \\text{y.size}(0) - 1\\right\\}`, \\\n",
      "   781|         0|            0|            0|  0.00%|    :math:`0 \\leq y[j] \\leq \\text{x.size}(0)-1`, \\\n",
      "   782|         0|            0|            0|  0.00%|    and :math:`i \\neq y[j]` for all :math:`i` and :math:`j`.\n",
      "   783|         0|            0|            0|  0.00%|\n",
      "   784|         0|            0|            0|  0.00%|    :math:`y` and :math:`x` must have the same size.\n",
      "   785|         0|            0|            0|  0.00%|\n",
      "   786|         0|            0|            0|  0.00%|    The criterion only considers a contiguous block of non-negative targets that\n",
      "   787|         0|            0|            0|  0.00%|    starts at the front.\n",
      "   788|         0|            0|            0|  0.00%|\n",
      "   789|         0|            0|            0|  0.00%|    This allows for different samples to have variable amounts of target classes.\n",
      "   790|         0|            0|            0|  0.00%|\n",
      "   791|         0|            0|            0|  0.00%|    Args:\n",
      "   792|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   793|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   794|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   795|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   796|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   797|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   798|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   799|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   800|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   801|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   802|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   803|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   804|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   805|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   806|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   807|         0|            0|            0|  0.00%|\n",
      "   808|         0|            0|            0|  0.00%|    Shape:\n",
      "   809|         0|            0|            0|  0.00%|        - Input: :math:`(C)` or :math:`(N, C)` where `N` is the batch size and `C`\n",
      "   810|         0|            0|            0|  0.00%|          is the number of classes.\n",
      "   811|         0|            0|            0|  0.00%|        - Target: :math:`(C)` or :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.\n",
      "   812|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "   813|         0|            0|            0|  0.00%|\n",
      "   814|         0|            0|            0|  0.00%|    Examples::\n",
      "   815|         0|            0|            0|  0.00%|\n",
      "   816|         0|            0|            0|  0.00%|        >>> loss = nn.MultiLabelMarginLoss()\n",
      "   817|         0|            0|            0|  0.00%|        >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n",
      "   818|         0|            0|            0|  0.00%|        >>> # for target y, only consider labels 3 and 0, not after label -1\n",
      "   819|         0|            0|            0|  0.00%|        >>> y = torch.LongTensor([[3, 0, -1, 1]])\n",
      "   820|         0|            0|            0|  0.00%|        >>> loss(x, y)\n",
      "   821|         0|            0|            0|  0.00%|        >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n",
      "   822|         0|            0|            0|  0.00%|        tensor(0.8500)\n",
      "   823|         0|            0|            0|  0.00%|\n",
      "   824|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   825|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   826|         0|            0|            0|  0.00%|\n",
      "   827|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   828|         0|            0|            0|  0.00%|        super(MultiLabelMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "   829|         0|            0|            0|  0.00%|\n",
      "   830|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   831|         0|            0|            0|  0.00%|        return F.multilabel_margin_loss(input, target, reduction=self.reduction)\n",
      "   832|         0|            0|            0|  0.00%|\n",
      "   833|         0|            0|            0|  0.00%|\n",
      "   834|         0|            0|            0|  0.00%|class SmoothL1Loss(_Loss):\n",
      "   835|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that uses a squared term if the absolute\n",
      "   836|         0|            0|            0|  0.00%|    element-wise error falls below beta and an L1 term otherwise.\n",
      "   837|         0|            0|            0|  0.00%|    It is less sensitive to outliers than :class:`torch.nn.MSELoss` and in some cases\n",
      "   838|         0|            0|            0|  0.00%|    prevents exploding gradients (e.g. see the paper `Fast R-CNN`_ by Ross Girshick).\n",
      "   839|         0|            0|            0|  0.00%|\n",
      "   840|         0|            0|            0|  0.00%|    For a batch of size :math:`N`, the unreduced loss can be described as:\n",
      "   841|         0|            0|            0|  0.00%|\n",
      "   842|         0|            0|            0|  0.00%|    .. math::\n",
      "   843|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n",
      "   844|         0|            0|            0|  0.00%|\n",
      "   845|         0|            0|            0|  0.00%|    with\n",
      "   846|         0|            0|            0|  0.00%|\n",
      "   847|         0|            0|            0|  0.00%|    .. math::\n",
      "   848|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   849|         0|            0|            0|  0.00%|        0.5 (x_n - y_n)^2 / beta, & \\text{if } |x_n - y_n| < beta \\\\\n",
      "   850|         0|            0|            0|  0.00%|        |x_n - y_n| - 0.5 * beta, & \\text{otherwise }\n",
      "   851|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   852|         0|            0|            0|  0.00%|\n",
      "   853|         0|            0|            0|  0.00%|    If `reduction` is not `none`, then:\n",
      "   854|         0|            0|            0|  0.00%|\n",
      "   855|         0|            0|            0|  0.00%|    .. math::\n",
      "   856|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   857|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   858|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   859|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   860|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   861|         0|            0|            0|  0.00%|\n",
      "   862|         0|            0|            0|  0.00%|    .. note::\n",
      "   863|         0|            0|            0|  0.00%|        Smooth L1 loss can be seen as exactly :class:`L1Loss`, but with the :math:`|x - y| < beta`\n",
      "   864|         0|            0|            0|  0.00%|        portion replaced with a quadratic function such that its slope is 1 at :math:`|x - y| = beta`.\n",
      "   865|         0|            0|            0|  0.00%|        The quadratic segment smooths the L1 loss near :math:`|x - y| = 0`.\n",
      "   866|         0|            0|            0|  0.00%|\n",
      "   867|         0|            0|            0|  0.00%|    .. note::\n",
      "   868|         0|            0|            0|  0.00%|        Smooth L1 loss is closely related to :class:`HuberLoss`, being\n",
      "   869|         0|            0|            0|  0.00%|        equivalent to :math:`huber(x, y) / beta` (note that Smooth L1's beta hyper-parameter is\n",
      "   870|         0|            0|            0|  0.00%|        also known as delta for Huber). This leads to the following differences:\n",
      "   871|         0|            0|            0|  0.00%|\n",
      "   872|         0|            0|            0|  0.00%|        * As beta -> 0, Smooth L1 loss converges to :class:`L1Loss`, while :class:`HuberLoss`\n",
      "   873|         0|            0|            0|  0.00%|          converges to a constant 0 loss.\n",
      "   874|         0|            0|            0|  0.00%|        * As beta -> :math:`+\\infty`, Smooth L1 loss converges to a constant 0 loss, while\n",
      "   875|         0|            0|            0|  0.00%|          :class:`HuberLoss` converges to :class:`MSELoss`.\n",
      "   876|         0|            0|            0|  0.00%|        * For Smooth L1 loss, as beta varies, the L1 segment of the loss has a constant slope of 1.\n",
      "   877|         0|            0|            0|  0.00%|          For :class:`HuberLoss`, the slope of the L1 segment is beta.\n",
      "   878|         0|            0|            0|  0.00%|\n",
      "   879|         0|            0|            0|  0.00%|    .. _`Fast R-CNN`: https://arxiv.org/abs/1504.08083\n",
      "   880|         0|            0|            0|  0.00%|\n",
      "   881|         0|            0|            0|  0.00%|    Args:\n",
      "   882|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   883|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   884|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   885|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   886|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   887|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   888|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   889|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   890|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   891|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   892|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   893|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   894|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   895|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   896|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   897|         0|            0|            0|  0.00%|        beta (float, optional): Specifies the threshold at which to change between L1 and L2 loss.\n",
      "   898|         0|            0|            0|  0.00%|            The value must be non-negative. Default: 1.0\n",
      "   899|         0|            0|            0|  0.00%|\n",
      "   900|         0|            0|            0|  0.00%|    Shape:\n",
      "   901|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   902|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   903|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.\n",
      "   904|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   905|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   906|         0|            0|            0|  0.00%|\n",
      "   907|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0) -> None:\n",
      "   908|         0|            0|            0|  0.00%|        super(SmoothL1Loss, self).__init__(size_average, reduce, reduction)\n",
      "   909|         0|            0|            0|  0.00%|        self.beta = beta\n",
      "   910|         0|            0|            0|  0.00%|\n",
      "   911|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   912|         0|            0|            0|  0.00%|        return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "   913|         0|            0|            0|  0.00%|\n",
      "   914|         0|            0|            0|  0.00%|\n",
      "   915|         0|            0|            0|  0.00%|class HuberLoss(_Loss):\n",
      "   916|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that uses a squared term if the absolute\n",
      "   917|         0|            0|            0|  0.00%|    element-wise error falls below delta and a delta-scaled L1 term otherwise.\n",
      "   918|         0|            0|            0|  0.00%|    This loss combines advantages of both :class:`L1Loss` and :class:`MSELoss`; the\n",
      "   919|         0|            0|            0|  0.00%|    delta-scaled L1 region makes the loss less sensitive to outliers than :class:`MSELoss`,\n",
      "   920|         0|            0|            0|  0.00%|    while the L2 region provides smoothness over :class:`L1Loss` near 0. See\n",
      "   921|         0|            0|            0|  0.00%|    `Huber loss <https://en.wikipedia.org/wiki/Huber_loss>`_ for more information.\n",
      "   922|         0|            0|            0|  0.00%|\n",
      "   923|         0|            0|            0|  0.00%|    For a batch of size :math:`N`, the unreduced loss can be described as:\n",
      "   924|         0|            0|            0|  0.00%|\n",
      "   925|         0|            0|            0|  0.00%|    .. math::\n",
      "   926|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n",
      "   927|         0|            0|            0|  0.00%|\n",
      "   928|         0|            0|            0|  0.00%|    with\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|    .. math::\n",
      "   931|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   932|         0|            0|            0|  0.00%|        0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| < delta \\\\\n",
      "   933|         0|            0|            0|  0.00%|        delta * (|x_n - y_n| - 0.5 * delta), & \\text{otherwise }\n",
      "   934|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   935|         0|            0|            0|  0.00%|\n",
      "   936|         0|            0|            0|  0.00%|    If `reduction` is not `none`, then:\n",
      "   937|         0|            0|            0|  0.00%|\n",
      "   938|         0|            0|            0|  0.00%|    .. math::\n",
      "   939|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   940|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   941|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   942|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   943|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   944|         0|            0|            0|  0.00%|\n",
      "   945|         0|            0|            0|  0.00%|    .. note::\n",
      "   946|         0|            0|            0|  0.00%|        When delta is set to 1, this loss is equivalent to :class:`SmoothL1Loss`.\n",
      "   947|         0|            0|            0|  0.00%|        In general, this loss differs from :class:`SmoothL1Loss` by a factor of delta (AKA beta\n",
      "   948|         0|            0|            0|  0.00%|        in Smooth L1).\n",
      "   949|         0|            0|            0|  0.00%|        See :class:`SmoothL1Loss` for additional discussion on the differences in behavior\n",
      "   950|         0|            0|            0|  0.00%|        between the two losses.\n",
      "   951|         0|            0|            0|  0.00%|\n",
      "   952|         0|            0|            0|  0.00%|    Args:\n",
      "   953|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   954|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   955|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   956|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n",
      "   957|         0|            0|            0|  0.00%|        delta (float, optional): Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\n",
      "   958|         0|            0|            0|  0.00%|            The value must be positive.  Default: 1.0\n",
      "   959|         0|            0|            0|  0.00%|\n",
      "   960|         0|            0|            0|  0.00%|    Shape:\n",
      "   961|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where :math:`*` means any number of dimensions.\n",
      "   962|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   963|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.\n",
      "   964|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   965|         0|            0|            0|  0.00%|    __constants__ = ['reduction', 'delta']\n",
      "   966|         0|            0|            0|  0.00%|\n",
      "   967|         0|            0|            0|  0.00%|    def __init__(self, reduction: str = 'mean', delta: float = 1.0) -> None:\n",
      "   968|         0|            0|            0|  0.00%|        super().__init__(reduction=reduction)\n",
      "   969|         0|            0|            0|  0.00%|        self.delta = delta\n",
      "   970|         0|            0|            0|  0.00%|\n",
      "   971|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   972|         0|            0|            0|  0.00%|        return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n",
      "   973|         0|            0|            0|  0.00%|\n",
      "   974|         0|            0|            0|  0.00%|\n",
      "   975|         0|            0|            0|  0.00%|class SoftMarginLoss(_Loss):\n",
      "   976|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a two-class classification\n",
      "   977|         0|            0|            0|  0.00%|    logistic loss between input tensor :math:`x` and target tensor :math:`y`\n",
      "   978|         0|            0|            0|  0.00%|    (containing 1 or -1).\n",
      "   979|         0|            0|            0|  0.00%|\n",
      "   980|         0|            0|            0|  0.00%|    .. math::\n",
      "   981|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()}\n",
      "   982|         0|            0|            0|  0.00%|\n",
      "   983|         0|            0|            0|  0.00%|    Args:\n",
      "   984|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   985|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   986|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   987|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   988|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   989|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   990|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   991|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   992|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   993|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   994|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   995|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   996|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   997|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   998|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   999|         0|            0|            0|  0.00%|\n",
      "  1000|         0|            0|            0|  0.00%|    Shape:\n",
      "  1001|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "  1002|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "  1003|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "  1004|         0|            0|            0|  0.00%|          shape as input.\n",
      "  1005|         0|            0|            0|  0.00%|\n",
      "  1006|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1007|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "  1008|         0|            0|            0|  0.00%|\n",
      "  1009|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1010|         0|            0|            0|  0.00%|        super(SoftMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1011|         0|            0|            0|  0.00%|\n",
      "  1012|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1013|         0|            0|            0|  0.00%|        return F.soft_margin_loss(input, target, reduction=self.reduction)\n",
      "  1014|         0|            0|            0|  0.00%|\n",
      "  1015|         0|            0|            0|  0.00%|\n",
      "  1016|         0|            0|            0|  0.00%|class CrossEntropyLoss(_WeightedLoss):\n",
      "  1017|         0|            0|            0|  0.00%|    r\"\"\"This criterion computes the cross entropy loss between input and target.\n",
      "  1018|         0|            0|            0|  0.00%|\n",
      "  1019|         0|            0|            0|  0.00%|    It is useful when training a classification problem with `C` classes.\n",
      "  1020|         0|            0|            0|  0.00%|    If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
      "  1021|         0|            0|            0|  0.00%|    assigning weight to each of the classes.\n",
      "  1022|         0|            0|            0|  0.00%|    This is particularly useful when you have an unbalanced training set.\n",
      "  1023|         0|            0|            0|  0.00%|\n",
      "  1024|         0|            0|            0|  0.00%|    The `input` is expected to contain raw, unnormalized scores for each class.\n",
      "  1025|         0|            0|            0|  0.00%|    `input` has to be a Tensor of size either :math:`(minibatch, C)` or\n",
      "  1026|         0|            0|            0|  0.00%|    :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n",
      "  1027|         0|            0|            0|  0.00%|    `K`-dimensional case. The latter is useful for higher dimension inputs, such\n",
      "  1028|         0|            0|            0|  0.00%|    as computing cross entropy loss per-pixel for 2D images.\n",
      "  1029|         0|            0|            0|  0.00%|\n",
      "  1030|         0|            0|            0|  0.00%|    The `target` that this criterion expects should contain either:\n",
      "  1031|         0|            0|            0|  0.00%|\n",
      "  1032|         0|            0|            0|  0.00%|    - Class indices in the range :math:`[0, C-1]` where :math:`C` is the number of classes; if\n",
      "  1033|         0|            0|            0|  0.00%|      `ignore_index` is specified, this loss also accepts this class index (this index\n",
      "  1034|         0|            0|            0|  0.00%|      may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n",
      "  1035|         0|            0|            0|  0.00%|      set to ``'none'``) loss for this case can be described as:\n",
      "  1036|         0|            0|            0|  0.00%|\n",
      "  1037|         0|            0|            0|  0.00%|      .. math::\n",
      "  1038|         0|            0|            0|  0.00%|          \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1039|         0|            0|            0|  0.00%|          l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
      "  1040|         0|            0|            0|  0.00%|          \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
      "  1041|         0|            0|            0|  0.00%|\n",
      "  1042|         0|            0|            0|  0.00%|      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  1043|         0|            0|            0|  0.00%|      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  1044|         0|            0|            0|  0.00%|      :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  1045|         0|            0|            0|  0.00%|      :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "  1046|         0|            0|            0|  0.00%|\n",
      "  1047|         0|            0|            0|  0.00%|      .. math::\n",
      "  1048|         0|            0|            0|  0.00%|          \\ell(x, y) = \\begin{cases}\n",
      "  1049|         0|            0|            0|  0.00%|              \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n",
      "  1050|         0|            0|            0|  0.00%|               \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1051|         0|            0|            0|  0.00%|                \\sum_{n=1}^N l_n,  &\n",
      "  1052|         0|            0|            0|  0.00%|                \\text{if reduction} = \\text{`sum'.}\n",
      "  1053|         0|            0|            0|  0.00%|            \\end{cases}\n",
      "  1054|         0|            0|            0|  0.00%|\n",
      "  1055|         0|            0|            0|  0.00%|      Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and\n",
      "  1056|         0|            0|            0|  0.00%|      :class:`~torch.nn.NLLLoss`.\n",
      "  1057|         0|            0|            0|  0.00%|\n",
      "  1058|         0|            0|            0|  0.00%|    - Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
      "  1059|         0|            0|            0|  0.00%|      are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
      "  1060|         0|            0|            0|  0.00%|      :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n",
      "  1061|         0|            0|            0|  0.00%|\n",
      "  1062|         0|            0|            0|  0.00%|      .. math::\n",
      "  1063|         0|            0|            0|  0.00%|          \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1064|         0|            0|            0|  0.00%|          l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\exp(\\sum_{i=1}^C x_{n,i})} y_{n,c}\n",
      "  1065|         0|            0|            0|  0.00%|\n",
      "  1066|         0|            0|            0|  0.00%|      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  1067|         0|            0|            0|  0.00%|      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  1068|         0|            0|            0|  0.00%|      :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  1069|         0|            0|            0|  0.00%|      :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "  1070|         0|            0|            0|  0.00%|\n",
      "  1071|         0|            0|            0|  0.00%|      .. math::\n",
      "  1072|         0|            0|            0|  0.00%|          \\ell(x, y) = \\begin{cases}\n",
      "  1073|         0|            0|            0|  0.00%|              \\frac{\\sum_{n=1}^N l_n}{N}, &\n",
      "  1074|         0|            0|            0|  0.00%|               \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1075|         0|            0|            0|  0.00%|                \\sum_{n=1}^N l_n,  &\n",
      "  1076|         0|            0|            0|  0.00%|                \\text{if reduction} = \\text{`sum'.}\n",
      "  1077|         0|            0|            0|  0.00%|            \\end{cases}\n",
      "  1078|         0|            0|            0|  0.00%|\n",
      "  1079|         0|            0|            0|  0.00%|    .. note::\n",
      "  1080|         0|            0|            0|  0.00%|        The performance of this criterion is generally better when `target` contains class\n",
      "  1081|         0|            0|            0|  0.00%|        indices, as this allows for optimized computation. Consider providing `target` as\n",
      "  1082|         0|            0|            0|  0.00%|        class probabilities only when a single class label per minibatch item is too restrictive.\n",
      "  1083|         0|            0|            0|  0.00%|\n",
      "  1084|         0|            0|            0|  0.00%|    Args:\n",
      "  1085|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each class.\n",
      "  1086|         0|            0|            0|  0.00%|            If given, has to be a Tensor of size `C`\n",
      "  1087|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1088|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1089|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1090|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1091|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1092|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  1093|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  1094|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "  1095|         0|            0|            0|  0.00%|            :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "  1096|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1097|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1098|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1099|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1100|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1101|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "  1102|         0|            0|            0|  0.00%|            be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "  1103|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1104|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in\n",
      "  1105|         0|            0|            0|  0.00%|            the meantime, specifying either of those two args will override\n",
      "  1106|         0|            0|            0|  0.00%|            :attr:`reduction`. Default: ``'mean'``\n",
      "  1107|         0|            0|            0|  0.00%|        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "  1108|         0|            0|            0|  0.00%|            of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "  1109|         0|            0|            0|  0.00%|            become a mixture of the original ground truth and a uniform distribution as described in\n",
      "  1110|         0|            0|            0|  0.00%|            `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "  1111|         0|            0|            0|  0.00%|\n",
      "  1112|         0|            0|            0|  0.00%|    Shape:\n",
      "  1113|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` where `C = number of classes`, or\n",
      "  1114|         0|            0|            0|  0.00%|          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "  1115|         0|            0|            0|  0.00%|          in the case of `K`-dimensional loss.\n",
      "  1116|         0|            0|            0|  0.00%|        - Target: If containing class indices, shape :math:`(N)` where each value is\n",
      "  1117|         0|            0|            0|  0.00%|          :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "  1118|         0|            0|            0|  0.00%|          :math:`K \\geq 1` in the case of K-dimensional loss. If containing class probabilities,\n",
      "  1119|         0|            0|            0|  0.00%|          same shape as the input.\n",
      "  1120|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n",
      "  1121|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n",
      "  1122|         0|            0|            0|  0.00%|          Otherwise, scalar.\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    Examples::\n",
      "  1125|         0|            0|            0|  0.00%|\n",
      "  1126|         0|            0|            0|  0.00%|        >>> # Example of target with class indices\n",
      "  1127|         0|            0|            0|  0.00%|        >>> loss = nn.CrossEntropyLoss()\n",
      "  1128|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  1129|         0|            0|            0|  0.00%|        >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
      "  1130|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "  1131|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1132|         0|            0|            0|  0.00%|        >>>\n",
      "  1133|         0|            0|            0|  0.00%|        >>> # Example of target with class probabilities\n",
      "  1134|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  1135|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "  1136|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "  1137|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1138|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1139|         0|            0|            0|  0.00%|    __constants__ = ['ignore_index', 'reduction', 'label_smoothing']\n",
      "  1140|         0|            0|            0|  0.00%|    ignore_index: int\n",
      "  1141|         0|            0|            0|  0.00%|    label_smoothing: float\n",
      "  1142|         0|            0|            0|  0.00%|\n",
      "  1143|         1|  5.00679e-06|  5.00679e-06|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "  1144|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n",
      "  1145|         1|  1.93119e-05|  1.93119e-05|  0.01%|        super(CrossEntropyLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "(call)|         1|  0.000748634|  0.000748634|  0.33%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:24 __init__\n",
      "  1146|         1|  1.19209e-05|  1.19209e-05|  0.01%|        self.ignore_index = ignore_index\n",
      "(call)|         1|  3.60012e-05|  3.60012e-05|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "  1147|         1|   1.3113e-05|   1.3113e-05|  0.01%|        self.label_smoothing = label_smoothing\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "  1148|         0|            0|            0|  0.00%|\n",
      "  1149|         1|  4.05312e-06|  4.05312e-06|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1150|         1|  1.40667e-05|  1.40667e-05|  0.01%|        return F.cross_entropy(input, target, weight=self.weight,\n",
      "(call)|         1|  1.97887e-05|  1.97887e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "  1151|         1|  3.09944e-06|  3.09944e-06|  0.00%|                               ignore_index=self.ignore_index, reduction=self.reduction,\n",
      "  1152|         1|  4.19617e-05|  4.19617e-05|  0.02%|                               label_smoothing=self.label_smoothing)\n",
      "(call)|         1|    0.0042901|    0.0042901|  1.90%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:2767 cross_entropy\n",
      "  1153|         0|            0|            0|  0.00%|\n",
      "  1154|         0|            0|            0|  0.00%|\n",
      "  1155|         0|            0|            0|  0.00%|class MultiLabelSoftMarginLoss(_WeightedLoss):\n",
      "  1156|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-label one-versus-all\n",
      "  1157|         0|            0|            0|  0.00%|    loss based on max-entropy, between input :math:`x` and target :math:`y` of size\n",
      "  1158|         0|            0|            0|  0.00%|    :math:`(N, C)`.\n",
      "  1159|         0|            0|            0|  0.00%|    For each sample in the minibatch:\n",
      "  1160|         0|            0|            0|  0.00%|\n",
      "  1161|         0|            0|            0|  0.00%|    .. math::\n",
      "  1162|         0|            0|            0|  0.00%|        loss(x, y) = - \\frac{1}{C} * \\sum_i y[i] * \\log((1 + \\exp(-x[i]))^{-1})\n",
      "  1163|         0|            0|            0|  0.00%|                         + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right)\n",
      "  1164|         0|            0|            0|  0.00%|\n",
      "  1165|         0|            0|            0|  0.00%|    where :math:`i \\in \\left\\{0, \\; \\cdots , \\; \\text{x.nElement}() - 1\\right\\}`,\n",
      "  1166|         0|            0|            0|  0.00%|    :math:`y[i] \\in \\left\\{0, \\; 1\\right\\}`.\n",
      "  1167|         0|            0|            0|  0.00%|\n",
      "  1168|         0|            0|            0|  0.00%|    Args:\n",
      "  1169|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  1170|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "  1171|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "  1172|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1173|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1174|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1175|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1176|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1177|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1178|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1179|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1180|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1181|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1182|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1183|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1184|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1185|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1186|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1187|         0|            0|            0|  0.00%|\n",
      "  1188|         0|            0|            0|  0.00%|    Shape:\n",
      "  1189|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` where `N` is the batch size and `C` is the number of classes.\n",
      "  1190|         0|            0|            0|  0.00%|        - Target: :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.\n",
      "  1191|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "  1192|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1193|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "  1194|         0|            0|            0|  0.00%|\n",
      "  1195|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1196|         0|            0|            0|  0.00%|        super(MultiLabelSoftMarginLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "  1197|         0|            0|            0|  0.00%|\n",
      "  1198|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1199|         0|            0|            0|  0.00%|        return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)\n",
      "  1200|         0|            0|            0|  0.00%|\n",
      "  1201|         0|            0|            0|  0.00%|\n",
      "  1202|         0|            0|            0|  0.00%|class CosineEmbeddingLoss(_Loss):\n",
      "  1203|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the loss given input tensors\n",
      "  1204|         0|            0|            0|  0.00%|    :math:`x_1`, :math:`x_2` and a `Tensor` label :math:`y` with values 1 or -1.\n",
      "  1205|         0|            0|            0|  0.00%|    This is used for measuring whether two inputs are similar or dissimilar,\n",
      "  1206|         0|            0|            0|  0.00%|    using the cosine distance, and is typically used for learning nonlinear\n",
      "  1207|         0|            0|            0|  0.00%|    embeddings or semi-supervised learning.\n",
      "  1208|         0|            0|            0|  0.00%|\n",
      "  1209|         0|            0|            0|  0.00%|    The loss function for each sample is:\n",
      "  1210|         0|            0|            0|  0.00%|\n",
      "  1211|         0|            0|            0|  0.00%|    .. math::\n",
      "  1212|         0|            0|            0|  0.00%|        \\text{loss}(x, y) =\n",
      "  1213|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "  1214|         0|            0|            0|  0.00%|        1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\\n",
      "  1215|         0|            0|            0|  0.00%|        \\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1\n",
      "  1216|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1217|         0|            0|            0|  0.00%|\n",
      "  1218|         0|            0|            0|  0.00%|    Args:\n",
      "  1219|         0|            0|            0|  0.00%|        margin (float, optional): Should be a number from :math:`-1` to :math:`1`,\n",
      "  1220|         0|            0|            0|  0.00%|            :math:`0` to :math:`0.5` is suggested. If :attr:`margin` is missing, the\n",
      "  1221|         0|            0|            0|  0.00%|            default value is :math:`0`.\n",
      "  1222|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1223|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1224|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1225|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1226|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1227|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1228|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1229|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1230|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1231|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1232|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1233|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1234|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1235|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1236|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    Shape:\n",
      "  1239|         0|            0|            0|  0.00%|        - Input1: :math:`(N, D)` or :math:`(D)`, where `N` is the batch size and `D` is the embedding dimension.\n",
      "  1240|         0|            0|            0|  0.00%|        - Input2: :math:`(N, D)` or :math:`(D)`, same shape as Input1.\n",
      "  1241|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`.\n",
      "  1242|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, then :math:`(N)`, otherwise scalar.\n",
      "  1243|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1244|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "  1245|         0|            0|            0|  0.00%|    margin: float\n",
      "  1246|         0|            0|            0|  0.00%|\n",
      "  1247|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 0., size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1248|         0|            0|            0|  0.00%|        super(CosineEmbeddingLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1249|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1250|         0|            0|            0|  0.00%|\n",
      "  1251|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n",
      "  1252|         0|            0|            0|  0.00%|        return F.cosine_embedding_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)\n",
      "  1253|         0|            0|            0|  0.00%|\n",
      "  1254|         0|            0|            0|  0.00%|\n",
      "  1255|         0|            0|            0|  0.00%|class MarginRankingLoss(_Loss):\n",
      "  1256|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the loss given\n",
      "  1257|         0|            0|            0|  0.00%|    inputs :math:`x1`, :math:`x2`, two 1D mini-batch `Tensors`,\n",
      "  1258|         0|            0|            0|  0.00%|    and a label 1D mini-batch tensor :math:`y` (containing 1 or -1).\n",
      "  1259|         0|            0|            0|  0.00%|\n",
      "  1260|         0|            0|            0|  0.00%|    If :math:`y = 1` then it assumed the first input should be ranked higher\n",
      "  1261|         0|            0|            0|  0.00%|    (have a larger value) than the second input, and vice-versa for :math:`y = -1`.\n",
      "  1262|         0|            0|            0|  0.00%|\n",
      "  1263|         0|            0|            0|  0.00%|    The loss function for each pair of samples in the mini-batch is:\n",
      "  1264|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1265|         0|            0|            0|  0.00%|    .. math::\n",
      "  1266|         0|            0|            0|  0.00%|        \\text{loss}(x1, x2, y) = \\max(0, -y * (x1 - x2) + \\text{margin})\n",
      "  1267|         0|            0|            0|  0.00%|\n",
      "  1268|         0|            0|            0|  0.00%|    Args:\n",
      "  1269|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of :math:`0`.\n",
      "  1270|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1271|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1272|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1273|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1274|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1275|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1276|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1277|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1278|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1279|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1280|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1281|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1282|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1283|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1284|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1285|         0|            0|            0|  0.00%|\n",
      "  1286|         0|            0|            0|  0.00%|    Shape:\n",
      "  1287|         0|            0|            0|  0.00%|        - Input1: :math:`(N)` where `N` is the batch size.\n",
      "  1288|         0|            0|            0|  0.00%|        - Input2: :math:`(N)`, same shape as the Input1.\n",
      "  1289|         0|            0|            0|  0.00%|        - Target: :math:`(N)`, same shape as the inputs.\n",
      "  1290|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "  1291|         0|            0|            0|  0.00%|\n",
      "  1292|         0|            0|            0|  0.00%|    Examples::\n",
      "  1293|         0|            0|            0|  0.00%|\n",
      "  1294|         0|            0|            0|  0.00%|        >>> loss = nn.MarginRankingLoss()\n",
      "  1295|         0|            0|            0|  0.00%|        >>> input1 = torch.randn(3, requires_grad=True)\n",
      "  1296|         0|            0|            0|  0.00%|        >>> input2 = torch.randn(3, requires_grad=True)\n",
      "  1297|         0|            0|            0|  0.00%|        >>> target = torch.randn(3).sign()\n",
      "  1298|         0|            0|            0|  0.00%|        >>> output = loss(input1, input2, target)\n",
      "  1299|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1300|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1301|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "  1302|         0|            0|            0|  0.00%|    margin: float\n",
      "  1303|         0|            0|            0|  0.00%|\n",
      "  1304|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 0., size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1305|         0|            0|            0|  0.00%|        super(MarginRankingLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1306|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1307|         0|            0|            0|  0.00%|\n",
      "  1308|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n",
      "  1309|         0|            0|            0|  0.00%|        return F.margin_ranking_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)\n",
      "  1310|         0|            0|            0|  0.00%|\n",
      "  1311|         0|            0|            0|  0.00%|\n",
      "  1312|         0|            0|            0|  0.00%|class MultiMarginLoss(_WeightedLoss):\n",
      "  1313|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-class classification hinge\n",
      "  1314|         0|            0|            0|  0.00%|    loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`) and\n",
      "  1315|         0|            0|            0|  0.00%|    output :math:`y` (which is a 1D tensor of target class indices,\n",
      "  1316|         0|            0|            0|  0.00%|    :math:`0 \\leq y \\leq \\text{x.size}(1)-1`):\n",
      "  1317|         0|            0|            0|  0.00%|\n",
      "  1318|         0|            0|            0|  0.00%|    For each mini-batch sample, the loss in terms of the 1D input :math:`x` and scalar\n",
      "  1319|         0|            0|            0|  0.00%|    output :math:`y` is:\n",
      "  1320|         0|            0|            0|  0.00%|\n",
      "  1321|         0|            0|            0|  0.00%|    .. math::\n",
      "  1322|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\n",
      "  1323|         0|            0|            0|  0.00%|\n",
      "  1324|         0|            0|            0|  0.00%|    where :math:`x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`\n",
      "  1325|         0|            0|            0|  0.00%|    and :math:`i \\neq y`.\n",
      "  1326|         0|            0|            0|  0.00%|\n",
      "  1327|         0|            0|            0|  0.00%|    Optionally, you can give non-equal weighting on the classes by passing\n",
      "  1328|         0|            0|            0|  0.00%|    a 1D :attr:`weight` tensor into the constructor.\n",
      "  1329|         0|            0|            0|  0.00%|\n",
      "  1330|         0|            0|            0|  0.00%|    The loss function then becomes:\n",
      "  1331|         0|            0|            0|  0.00%|\n",
      "  1332|         0|            0|            0|  0.00%|    .. math::\n",
      "  1333|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\frac{\\sum_i \\max(0, w[y] * (\\text{margin} - x[y] + x[i]))^p}{\\text{x.size}(0)}\n",
      "  1334|         0|            0|            0|  0.00%|\n",
      "  1335|         0|            0|            0|  0.00%|    Args:\n",
      "  1336|         0|            0|            0|  0.00%|        p (int, optional): Has a default value of :math:`1`. :math:`1` and :math:`2`\n",
      "  1337|         0|            0|            0|  0.00%|            are the only supported values.\n",
      "  1338|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of :math:`1`.\n",
      "  1339|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  1340|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "  1341|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "  1342|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1343|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1344|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1345|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1346|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1347|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1348|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1349|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1350|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1351|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1352|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1353|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1354|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1355|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1356|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1357|         0|            0|            0|  0.00%|\n",
      "  1358|         0|            0|            0|  0.00%|    Shape:\n",
      "  1359|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` or :math:`(C)`, where :math:`N` is the batch size and :math:`C` is the number of classes.\n",
      "  1360|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`, where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`.\n",
      "  1361|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the target.\n",
      "  1362|         0|            0|            0|  0.00%|\n",
      "  1363|         0|            0|            0|  0.00%|    Examples::\n",
      "  1364|         0|            0|            0|  0.00%|\n",
      "  1365|         0|            0|            0|  0.00%|        >>> loss = nn.MultiMarginLoss()\n",
      "  1366|         0|            0|            0|  0.00%|        >>> x = torch.tensor([[0.1, 0.2, 0.4, 0.8]])\n",
      "  1367|         0|            0|            0|  0.00%|        >>> y = torch.tensor([3])\n",
      "  1368|         0|            0|            0|  0.00%|        >>> loss(x, y)\n",
      "  1369|         0|            0|            0|  0.00%|        >>> # 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n",
      "  1370|         0|            0|            0|  0.00%|        tensor(0.3250)\n",
      "  1371|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1372|         0|            0|            0|  0.00%|    __constants__ = ['p', 'margin', 'reduction']\n",
      "  1373|         0|            0|            0|  0.00%|    margin: float\n",
      "  1374|         0|            0|            0|  0.00%|    p: int\n",
      "  1375|         0|            0|            0|  0.00%|\n",
      "  1376|         0|            0|            0|  0.00%|    def __init__(self, p: int = 1, margin: float = 1., weight: Optional[Tensor] = None, size_average=None,\n",
      "  1377|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "  1378|         0|            0|            0|  0.00%|        super(MultiMarginLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "  1379|         0|            0|            0|  0.00%|        if p != 1 and p != 2:\n",
      "  1380|         0|            0|            0|  0.00%|            raise ValueError(\"only p == 1 and p == 2 supported\")\n",
      "  1381|         0|            0|            0|  0.00%|        assert weight is None or weight.dim() == 1\n",
      "  1382|         0|            0|            0|  0.00%|        self.p = p\n",
      "  1383|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1384|         0|            0|            0|  0.00%|\n",
      "  1385|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1386|         0|            0|            0|  0.00%|        return F.multi_margin_loss(input, target, p=self.p, margin=self.margin,\n",
      "  1387|         0|            0|            0|  0.00%|                                   weight=self.weight, reduction=self.reduction)\n",
      "  1388|         0|            0|            0|  0.00%|\n",
      "  1389|         0|            0|            0|  0.00%|\n",
      "  1390|         0|            0|            0|  0.00%|class TripletMarginLoss(_Loss):\n",
      "  1391|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the triplet loss given an input\n",
      "  1392|         0|            0|            0|  0.00%|    tensors :math:`x1`, :math:`x2`, :math:`x3` and a margin with a value greater than :math:`0`.\n",
      "  1393|         0|            0|            0|  0.00%|    This is used for measuring a relative similarity between samples. A triplet\n",
      "  1394|         0|            0|            0|  0.00%|    is composed by `a`, `p` and `n` (i.e., `anchor`, `positive examples` and `negative\n",
      "  1395|         0|            0|            0|  0.00%|    examples` respectively). The shapes of all input tensors should be\n",
      "  1396|         0|            0|            0|  0.00%|    :math:`(N, D)`.\n",
      "  1397|         0|            0|            0|  0.00%|\n",
      "  1398|         0|            0|            0|  0.00%|    The distance swap is described in detail in the paper `Learning shallow\n",
      "  1399|         0|            0|            0|  0.00%|    convolutional feature descriptors with triplet losses`_ by\n",
      "  1400|         0|            0|            0|  0.00%|    V. Balntas, E. Riba et al.\n",
      "  1401|         0|            0|            0|  0.00%|\n",
      "  1402|         0|            0|            0|  0.00%|    The loss function for each sample in the mini-batch is:\n",
      "  1403|         0|            0|            0|  0.00%|\n",
      "  1404|         0|            0|            0|  0.00%|    .. math::\n",
      "  1405|         0|            0|            0|  0.00%|        L(a, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n",
      "  1406|         0|            0|            0|  0.00%|\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|    where\n",
      "  1409|         0|            0|            0|  0.00%|\n",
      "  1410|         0|            0|            0|  0.00%|    .. math::\n",
      "  1411|         0|            0|            0|  0.00%|        d(x_i, y_i) = \\left\\lVert {\\bf x}_i - {\\bf y}_i \\right\\rVert_p\n",
      "  1412|         0|            0|            0|  0.00%|\n",
      "  1413|         0|            0|            0|  0.00%|    See also :class:`~torch.nn.TripletMarginWithDistanceLoss`, which computes the\n",
      "  1414|         0|            0|            0|  0.00%|    triplet margin loss for input tensors using a custom distance function.\n",
      "  1415|         0|            0|            0|  0.00%|\n",
      "  1416|         0|            0|            0|  0.00%|    Args:\n",
      "  1417|         0|            0|            0|  0.00%|        margin (float, optional): Default: :math:`1`.\n",
      "  1418|         0|            0|            0|  0.00%|        p (int, optional): The norm degree for pairwise distance. Default: :math:`2`.\n",
      "  1419|         0|            0|            0|  0.00%|        swap (bool, optional): The distance swap is described in detail in the paper\n",
      "  1420|         0|            0|            0|  0.00%|            `Learning shallow convolutional feature descriptors with triplet losses` by\n",
      "  1421|         0|            0|            0|  0.00%|            V. Balntas, E. Riba et al. Default: ``False``.\n",
      "  1422|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1423|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1424|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1425|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1426|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1427|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1428|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1429|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1430|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1431|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1432|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1433|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1434|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1435|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1436|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1437|         0|            0|            0|  0.00%|\n",
      "  1438|         0|            0|            0|  0.00%|    Shape:\n",
      "  1439|         0|            0|            0|  0.00%|        - Input: :math:`(N, D)` or :math`(D)` where :math:`D` is the vector dimension.\n",
      "  1440|         0|            0|            0|  0.00%|        - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'`` and\n",
      "  1441|         0|            0|            0|  0.00%|                  input shape is :math`(N, D)`; a scalar otherwise.\n",
      "  1442|         0|            0|            0|  0.00%|\n",
      "  1443|         0|            0|            0|  0.00%|    Examples::\n",
      "  1444|         0|            0|            0|  0.00%|\n",
      "  1445|         0|            0|            0|  0.00%|    >>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
      "  1446|         0|            0|            0|  0.00%|    >>> anchor = torch.randn(100, 128, requires_grad=True)\n",
      "  1447|         0|            0|            0|  0.00%|    >>> positive = torch.randn(100, 128, requires_grad=True)\n",
      "  1448|         0|            0|            0|  0.00%|    >>> negative = torch.randn(100, 128, requires_grad=True)\n",
      "  1449|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1450|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1451|         0|            0|            0|  0.00%|\n",
      "  1452|         0|            0|            0|  0.00%|    .. _Learning shallow convolutional feature descriptors with triplet losses:\n",
      "  1453|         0|            0|            0|  0.00%|        http://www.bmva.org/bmvc/2016/papers/paper119/index.html\n",
      "  1454|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1455|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'p', 'eps', 'swap', 'reduction']\n",
      "  1456|         0|            0|            0|  0.00%|    margin: float\n",
      "  1457|         0|            0|            0|  0.00%|    p: float\n",
      "  1458|         0|            0|            0|  0.00%|    eps: float\n",
      "  1459|         0|            0|            0|  0.00%|    swap: bool\n",
      "  1460|         0|            0|            0|  0.00%|\n",
      "  1461|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 1.0, p: float = 2., eps: float = 1e-6, swap: bool = False, size_average=None,\n",
      "  1462|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean'):\n",
      "  1463|         0|            0|            0|  0.00%|        super(TripletMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1464|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1465|         0|            0|            0|  0.00%|        self.p = p\n",
      "  1466|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "  1467|         0|            0|            0|  0.00%|        self.swap = swap\n",
      "  1468|         0|            0|            0|  0.00%|\n",
      "  1469|         0|            0|            0|  0.00%|    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n",
      "  1470|         0|            0|            0|  0.00%|        return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,\n",
      "  1471|         0|            0|            0|  0.00%|                                     eps=self.eps, swap=self.swap, reduction=self.reduction)\n",
      "  1472|         0|            0|            0|  0.00%|\n",
      "  1473|         0|            0|            0|  0.00%|\n",
      "  1474|         0|            0|            0|  0.00%|class TripletMarginWithDistanceLoss(_Loss):\n",
      "  1475|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the triplet loss given input\n",
      "  1476|         0|            0|            0|  0.00%|    tensors :math:`a`, :math:`p`, and :math:`n` (representing anchor,\n",
      "  1477|         0|            0|            0|  0.00%|    positive, and negative examples, respectively), and a nonnegative,\n",
      "  1478|         0|            0|            0|  0.00%|    real-valued function (\"distance function\") used to compute the relationship\n",
      "  1479|         0|            0|            0|  0.00%|    between the anchor and positive example (\"positive distance\") and the\n",
      "  1480|         0|            0|            0|  0.00%|    anchor and negative example (\"negative distance\").\n",
      "  1481|         0|            0|            0|  0.00%|\n",
      "  1482|         0|            0|            0|  0.00%|    The unreduced loss (i.e., with :attr:`reduction` set to ``'none'``)\n",
      "  1483|         0|            0|            0|  0.00%|    can be described as:\n",
      "  1484|         0|            0|            0|  0.00%|\n",
      "  1485|         0|            0|            0|  0.00%|    .. math::\n",
      "  1486|         0|            0|            0|  0.00%|        \\ell(a, p, n) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1487|         0|            0|            0|  0.00%|        l_i = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n",
      "  1488|         0|            0|            0|  0.00%|\n",
      "  1489|         0|            0|            0|  0.00%|    where :math:`N` is the batch size; :math:`d` is a nonnegative, real-valued function\n",
      "  1490|         0|            0|            0|  0.00%|    quantifying the closeness of two tensors, referred to as the :attr:`distance_function`;\n",
      "  1491|         0|            0|            0|  0.00%|    and :math:`margin` is a nonnegative margin representing the minimum difference\n",
      "  1492|         0|            0|            0|  0.00%|    between the positive and negative distances that is required for the loss to\n",
      "  1493|         0|            0|            0|  0.00%|    be 0.  The input tensors have :math:`N` elements each and can be of any shape\n",
      "  1494|         0|            0|            0|  0.00%|    that the distance function can handle.\n",
      "  1495|         0|            0|            0|  0.00%|\n",
      "  1496|         0|            0|            0|  0.00%|    If :attr:`reduction` is not ``'none'``\n",
      "  1497|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "  1498|         0|            0|            0|  0.00%|\n",
      "  1499|         0|            0|            0|  0.00%|    .. math::\n",
      "  1500|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "  1501|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "  1502|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1503|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "  1504|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1505|         0|            0|            0|  0.00%|\n",
      "  1506|         0|            0|            0|  0.00%|    See also :class:`~torch.nn.TripletMarginLoss`, which computes the triplet\n",
      "  1507|         0|            0|            0|  0.00%|    loss for input tensors using the :math:`l_p` distance as the distance function.\n",
      "  1508|         0|            0|            0|  0.00%|\n",
      "  1509|         0|            0|            0|  0.00%|    Args:\n",
      "  1510|         0|            0|            0|  0.00%|        distance_function (callable, optional): A nonnegative, real-valued function that\n",
      "  1511|         0|            0|            0|  0.00%|            quantifies the closeness of two tensors. If not specified,\n",
      "  1512|         0|            0|            0|  0.00%|            `nn.PairwiseDistance` will be used.  Default: ``None``\n",
      "  1513|         0|            0|            0|  0.00%|        margin (float, optional): A nonnegative margin representing the minimum difference\n",
      "  1514|         0|            0|            0|  0.00%|            between the positive and negative distances required for the loss to be 0. Larger\n",
      "  1515|         0|            0|            0|  0.00%|            margins penalize cases where the negative examples are not distant enough from the\n",
      "  1516|         0|            0|            0|  0.00%|            anchors, relative to the positives. Default: :math:`1`.\n",
      "  1517|         0|            0|            0|  0.00%|        swap (bool, optional): Whether to use the distance swap described in the paper\n",
      "  1518|         0|            0|            0|  0.00%|            `Learning shallow convolutional feature descriptors with triplet losses` by\n",
      "  1519|         0|            0|            0|  0.00%|            V. Balntas, E. Riba et al. If True, and if the positive example is closer to the\n",
      "  1520|         0|            0|            0|  0.00%|            negative example than the anchor is, swaps the positive example and the anchor in\n",
      "  1521|         0|            0|            0|  0.00%|            the loss computation. Default: ``False``.\n",
      "  1522|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the (optional) reduction to apply to the output:\n",
      "  1523|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1524|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1525|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n",
      "  1526|         0|            0|            0|  0.00%|\n",
      "  1527|         0|            0|            0|  0.00%|\n",
      "  1528|         0|            0|            0|  0.00%|    Shape:\n",
      "  1529|         0|            0|            0|  0.00%|        - Input: :math:`(N, *)` where :math:`*` represents any number of additional dimensions\n",
      "  1530|         0|            0|            0|  0.00%|          as supported by the distance function.\n",
      "  1531|         0|            0|            0|  0.00%|        - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'``, or a scalar\n",
      "  1532|         0|            0|            0|  0.00%|          otherwise.\n",
      "  1533|         0|            0|            0|  0.00%|\n",
      "  1534|         0|            0|            0|  0.00%|    Examples::\n",
      "  1535|         0|            0|            0|  0.00%|\n",
      "  1536|         0|            0|            0|  0.00%|    >>> # Initialize embeddings\n",
      "  1537|         0|            0|            0|  0.00%|    >>> embedding = nn.Embedding(1000, 128)\n",
      "  1538|         0|            0|            0|  0.00%|    >>> anchor_ids = torch.randint(0, 1000, (1,))\n",
      "  1539|         0|            0|            0|  0.00%|    >>> positive_ids = torch.randint(0, 1000, (1,))\n",
      "  1540|         0|            0|            0|  0.00%|    >>> negative_ids = torch.randint(0, 1000, (1,))\n",
      "  1541|         0|            0|            0|  0.00%|    >>> anchor = embedding(anchor_ids)\n",
      "  1542|         0|            0|            0|  0.00%|    >>> positive = embedding(positive_ids)\n",
      "  1543|         0|            0|            0|  0.00%|    >>> negative = embedding(negative_ids)\n",
      "  1544|         0|            0|            0|  0.00%|    >>>\n",
      "  1545|         0|            0|            0|  0.00%|    >>> # Built-in Distance Function\n",
      "  1546|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1547|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())\n",
      "  1548|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1549|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1550|         0|            0|            0|  0.00%|    >>>\n",
      "  1551|         0|            0|            0|  0.00%|    >>> # Custom Distance Function\n",
      "  1552|         0|            0|            0|  0.00%|    >>> def l_infinity(x1, x2):\n",
      "  1553|         0|            0|            0|  0.00%|    >>>     return torch.max(torch.abs(x1 - x2), dim=1).values\n",
      "  1554|         0|            0|            0|  0.00%|    >>>\n",
      "  1555|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1556|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5)\n",
      "  1557|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1558|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1559|         0|            0|            0|  0.00%|    >>>\n",
      "  1560|         0|            0|            0|  0.00%|    >>> # Custom Distance Function (Lambda)\n",
      "  1561|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1562|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(\n",
      "  1563|         0|            0|            0|  0.00%|    >>>         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
      "  1564|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1565|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1566|         0|            0|            0|  0.00%|\n",
      "  1567|         0|            0|            0|  0.00%|    Reference:\n",
      "  1568|         0|            0|            0|  0.00%|        V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses:\n",
      "  1569|         0|            0|            0|  0.00%|        http://www.bmva.org/bmvc/2016/papers/paper119/index.html\n",
      "  1570|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1571|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'swap', 'reduction']\n",
      "  1572|         0|            0|            0|  0.00%|    margin: float\n",
      "  1573|         0|            0|            0|  0.00%|    swap: bool\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|    def __init__(self, *, distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n",
      "  1576|         0|            0|            0|  0.00%|                 margin: float = 1.0, swap: bool = False, reduction: str = 'mean'):\n",
      "  1577|         0|            0|            0|  0.00%|        super(TripletMarginWithDistanceLoss, self).__init__(size_average=None, reduce=None, reduction=reduction)\n",
      "  1578|         0|            0|            0|  0.00%|        self.distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = \\\n",
      "  1579|         0|            0|            0|  0.00%|            distance_function if distance_function is not None else PairwiseDistance()\n",
      "  1580|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1581|         0|            0|            0|  0.00%|        self.swap = swap\n",
      "  1582|         0|            0|            0|  0.00%|\n",
      "  1583|         0|            0|            0|  0.00%|    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n",
      "  1584|         0|            0|            0|  0.00%|        return F.triplet_margin_with_distance_loss(anchor, positive, negative,\n",
      "  1585|         0|            0|            0|  0.00%|                                                   distance_function=self.distance_function,\n",
      "  1586|         0|            0|            0|  0.00%|                                                   margin=self.margin, swap=self.swap, reduction=self.reduction)\n",
      "  1587|         0|            0|            0|  0.00%|\n",
      "  1588|         0|            0|            0|  0.00%|\n",
      "  1589|         0|            0|            0|  0.00%|class CTCLoss(_Loss):\n",
      "  1590|         0|            0|            0|  0.00%|    r\"\"\"The Connectionist Temporal Classification loss.\n",
      "  1591|         0|            0|            0|  0.00%|\n",
      "  1592|         0|            0|            0|  0.00%|    Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the\n",
      "  1593|         0|            0|            0|  0.00%|    probability of possible alignments of input to target, producing a loss value which is differentiable\n",
      "  1594|         0|            0|            0|  0.00%|    with respect to each input node. The alignment of input to target is assumed to be \"many-to-one\", which\n",
      "  1595|         0|            0|            0|  0.00%|    limits the length of the target sequence such that it must be :math:`\\leq` the input length.\n",
      "  1596|         0|            0|            0|  0.00%|\n",
      "  1597|         0|            0|            0|  0.00%|    Args:\n",
      "  1598|         0|            0|            0|  0.00%|        blank (int, optional): blank label. Default :math:`0`.\n",
      "  1599|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1600|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1601|         0|            0|            0|  0.00%|            ``'mean'``: the output losses will be divided by the target lengths and\n",
      "  1602|         0|            0|            0|  0.00%|            then the mean over the batch is taken. Default: ``'mean'``\n",
      "  1603|         0|            0|            0|  0.00%|        zero_infinity (bool, optional):\n",
      "  1604|         0|            0|            0|  0.00%|            Whether to zero infinite losses and the associated gradients.\n",
      "  1605|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  1606|         0|            0|            0|  0.00%|            Infinite losses mainly occur when the inputs are too short\n",
      "  1607|         0|            0|            0|  0.00%|            to be aligned to the targets.\n",
      "  1608|         0|            0|            0|  0.00%|\n",
      "  1609|         0|            0|            0|  0.00%|    Shape:\n",
      "  1610|         0|            0|            0|  0.00%|        - Log_probs: Tensor of size :math:`(T, N, C)`,\n",
      "  1611|         0|            0|            0|  0.00%|          where :math:`T = \\text{input length}`,\n",
      "  1612|         0|            0|            0|  0.00%|          :math:`N = \\text{batch size}`, and\n",
      "  1613|         0|            0|            0|  0.00%|          :math:`C = \\text{number of classes (including blank)}`.\n",
      "  1614|         0|            0|            0|  0.00%|          The logarithmized probabilities of the outputs (e.g. obtained with\n",
      "  1615|         0|            0|            0|  0.00%|          :func:`torch.nn.functional.log_softmax`).\n",
      "  1616|         0|            0|            0|  0.00%|        - Targets: Tensor of size :math:`(N, S)` or\n",
      "  1617|         0|            0|            0|  0.00%|          :math:`(\\operatorname{sum}(\\text{target\\_lengths}))`,\n",
      "  1618|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}` and\n",
      "  1619|         0|            0|            0|  0.00%|          :math:`S = \\text{max target length, if shape is } (N, S)`.\n",
      "  1620|         0|            0|            0|  0.00%|          It represent the target sequences. Each element in the target\n",
      "  1621|         0|            0|            0|  0.00%|          sequence is a class index. And the target index cannot be blank (default=0).\n",
      "  1622|         0|            0|            0|  0.00%|          In the :math:`(N, S)` form, targets are padded to the\n",
      "  1623|         0|            0|            0|  0.00%|          length of the longest sequence, and stacked.\n",
      "  1624|         0|            0|            0|  0.00%|          In the :math:`(\\operatorname{sum}(\\text{target\\_lengths}))` form,\n",
      "  1625|         0|            0|            0|  0.00%|          the targets are assumed to be un-padded and\n",
      "  1626|         0|            0|            0|  0.00%|          concatenated within 1 dimension.\n",
      "  1627|         0|            0|            0|  0.00%|        - Input_lengths: Tuple or tensor of size :math:`(N)`,\n",
      "  1628|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}`. It represent the lengths of the\n",
      "  1629|         0|            0|            0|  0.00%|          inputs (must each be :math:`\\leq T`). And the lengths are specified\n",
      "  1630|         0|            0|            0|  0.00%|          for each sequence to achieve masking under the assumption that sequences\n",
      "  1631|         0|            0|            0|  0.00%|          are padded to equal lengths.\n",
      "  1632|         0|            0|            0|  0.00%|        - Target_lengths: Tuple or tensor of size :math:`(N)`,\n",
      "  1633|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}`. It represent lengths of the targets.\n",
      "  1634|         0|            0|            0|  0.00%|          Lengths are specified for each sequence to achieve masking under the\n",
      "  1635|         0|            0|            0|  0.00%|          assumption that sequences are padded to equal lengths. If target shape is\n",
      "  1636|         0|            0|            0|  0.00%|          :math:`(N,S)`, target_lengths are effectively the stop index\n",
      "  1637|         0|            0|            0|  0.00%|          :math:`s_n` for each target sequence, such that ``target_n = targets[n,0:s_n]`` for\n",
      "  1638|         0|            0|            0|  0.00%|          each target in a batch. Lengths must each be :math:`\\leq S`\n",
      "  1639|         0|            0|            0|  0.00%|          If the targets are given as a 1d tensor that is the concatenation of individual\n",
      "  1640|         0|            0|            0|  0.00%|          targets, the target_lengths must add up to the total length of the tensor.\n",
      "  1641|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then\n",
      "  1642|         0|            0|            0|  0.00%|          :math:`(N)`, where :math:`N = \\text{batch size}`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1643|         0|            0|            0|  0.00%|\n",
      "  1644|         0|            0|            0|  0.00%|    Examples::\n",
      "  1645|         0|            0|            0|  0.00%|\n",
      "  1646|         0|            0|            0|  0.00%|        >>> # Target are to be padded\n",
      "  1647|         0|            0|            0|  0.00%|        >>> T = 50      # Input sequence length\n",
      "  1648|         0|            0|            0|  0.00%|        >>> C = 20      # Number of classes (including blank)\n",
      "  1649|         0|            0|            0|  0.00%|        >>> N = 16      # Batch size\n",
      "  1650|         0|            0|            0|  0.00%|        >>> S = 30      # Target sequence length of longest target in batch (padding length)\n",
      "  1651|         0|            0|            0|  0.00%|        >>> S_min = 10  # Minimum target length, for demonstration purposes\n",
      "  1652|         0|            0|            0|  0.00%|        >>>\n",
      "  1653|         0|            0|            0|  0.00%|        >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
      "  1654|         0|            0|            0|  0.00%|        >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
      "  1655|         0|            0|            0|  0.00%|        >>>\n",
      "  1656|         0|            0|            0|  0.00%|        >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
      "  1657|         0|            0|            0|  0.00%|        >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
      "  1658|         0|            0|            0|  0.00%|        >>>\n",
      "  1659|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
      "  1660|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
      "  1661|         0|            0|            0|  0.00%|        >>> ctc_loss = nn.CTCLoss()\n",
      "  1662|         0|            0|            0|  0.00%|        >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
      "  1663|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  1664|         0|            0|            0|  0.00%|        >>>\n",
      "  1665|         0|            0|            0|  0.00%|        >>>\n",
      "  1666|         0|            0|            0|  0.00%|        >>> # Target are to be un-padded\n",
      "  1667|         0|            0|            0|  0.00%|        >>> T = 50      # Input sequence length\n",
      "  1668|         0|            0|            0|  0.00%|        >>> C = 20      # Number of classes (including blank)\n",
      "  1669|         0|            0|            0|  0.00%|        >>> N = 16      # Batch size\n",
      "  1670|         0|            0|            0|  0.00%|        >>>\n",
      "  1671|         0|            0|            0|  0.00%|        >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
      "  1672|         0|            0|            0|  0.00%|        >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
      "  1673|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
      "  1674|         0|            0|            0|  0.00%|        >>>\n",
      "  1675|         0|            0|            0|  0.00%|        >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
      "  1676|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
      "  1677|         0|            0|            0|  0.00%|        >>> target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
      "  1678|         0|            0|            0|  0.00%|        >>> ctc_loss = nn.CTCLoss()\n",
      "  1679|         0|            0|            0|  0.00%|        >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
      "  1680|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  1681|         0|            0|            0|  0.00%|\n",
      "  1682|         0|            0|            0|  0.00%|    Reference:\n",
      "  1683|         0|            0|            0|  0.00%|        A. Graves et al.: Connectionist Temporal Classification:\n",
      "  1684|         0|            0|            0|  0.00%|        Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n",
      "  1685|         0|            0|            0|  0.00%|        https://www.cs.toronto.edu/~graves/icml_2006.pdf\n",
      "  1686|         0|            0|            0|  0.00%|\n",
      "  1687|         0|            0|            0|  0.00%|    Note:\n",
      "  1688|         0|            0|            0|  0.00%|        In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n",
      "  1689|         0|            0|            0|  0.00%|        in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n",
      "  1690|         0|            0|            0|  0.00%|        :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n",
      "  1691|         0|            0|            0|  0.00%|        dtype :attr:`torch.int32`.\n",
      "  1692|         0|            0|            0|  0.00%|\n",
      "  1693|         0|            0|            0|  0.00%|        The regular implementation uses the (more common in PyTorch) `torch.long` dtype.\n",
      "  1694|         0|            0|            0|  0.00%|\n",
      "  1695|         0|            0|            0|  0.00%|\n",
      "  1696|         0|            0|            0|  0.00%|    Note:\n",
      "  1697|         0|            0|            0|  0.00%|        In some circumstances when using the CUDA backend with CuDNN, this operator\n",
      "  1698|         0|            0|            0|  0.00%|        may select a nondeterministic algorithm to increase performance. If this is\n",
      "  1699|         0|            0|            0|  0.00%|        undesirable, you can try to make the operation deterministic (potentially at\n",
      "  1700|         0|            0|            0|  0.00%|        a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
      "  1701|         0|            0|            0|  0.00%|        True``.\n",
      "  1702|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  1703|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1704|         0|            0|            0|  0.00%|    __constants__ = ['blank', 'reduction']\n",
      "  1705|         0|            0|            0|  0.00%|    blank: int\n",
      "  1706|         0|            0|            0|  0.00%|    zero_infinity: bool\n",
      "  1707|         0|            0|            0|  0.00%|\n",
      "  1708|         0|            0|            0|  0.00%|    def __init__(self, blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False):\n",
      "  1709|         0|            0|            0|  0.00%|        super(CTCLoss, self).__init__(reduction=reduction)\n",
      "  1710|         0|            0|            0|  0.00%|        self.blank = blank\n",
      "  1711|         0|            0|            0|  0.00%|        self.zero_infinity = zero_infinity\n",
      "  1712|         0|            0|            0|  0.00%|\n",
      "  1713|         0|            0|            0|  0.00%|    def forward(self, log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor) -> Tensor:\n",
      "  1714|         0|            0|            0|  0.00%|        return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n",
      "  1715|         0|            0|            0|  0.00%|                          self.zero_infinity)\n",
      "  1716|         0|            0|            0|  0.00%|\n",
      "  1717|         0|            0|            0|  0.00%|# TODO: L1HingeEmbeddingCriterion\n",
      "  1718|         0|            0|            0|  0.00%|# TODO: MSECriterion weight\n",
      "  1719|         0|            0|            0|  0.00%|# TODO: ClassSimplexCriterion\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_tensor.py\n",
      "File duration: 7.77245e-05s (0.03%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import OrderedDict\n",
      "     2|         0|            0|            0|  0.00%|import enum\n",
      "     3|         0|            0|            0|  0.00%|import functools\n",
      "     4|         0|            0|            0|  0.00%|from numbers import Number\n",
      "     5|         0|            0|            0|  0.00%|from typing import Any, Dict, Optional, Tuple, Union\n",
      "     6|         0|            0|            0|  0.00%|import warnings\n",
      "     7|         0|            0|            0|  0.00%|import copyreg\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|import torch\n",
      "    10|         0|            0|            0|  0.00%|import torch._C as _C\n",
      "    11|         0|            0|            0|  0.00%|from torch._namedtensor_internals import (\n",
      "    12|         0|            0|            0|  0.00%|    update_names, check_serializing_named_tensor, resolve_ellipsis,\n",
      "    13|         0|            0|            0|  0.00%|    unzip_namedshape, single_ellipsis_index, is_ellipsis)\n",
      "    14|         0|            0|            0|  0.00%|from torch.overrides import (\n",
      "    15|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n",
      "    16|         0|            0|            0|  0.00%|    handle_torch_function, get_default_nowrap_functions)\n",
      "    17|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         0|            0|            0|  0.00%|def _wrap_type_error_to_not_implemented(f):\n",
      "    21|         0|            0|            0|  0.00%|    # functools.wraps doesn't work well with methods in python 2\n",
      "    22|         0|            0|            0|  0.00%|    method_assignments = ('__name__', '__doc__')\n",
      "    23|         0|            0|            0|  0.00%|    assigned = functools.WRAPPER_ASSIGNMENTS\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|    @functools.wraps(f, assigned=assigned)\n",
      "    26|         0|            0|            0|  0.00%|    def wrapped(*args, **kwargs):\n",
      "    27|         0|            0|            0|  0.00%|        if has_torch_function(args):\n",
      "    28|         0|            0|            0|  0.00%|            return handle_torch_function(wrapped, args, *args, **kwargs)\n",
      "    29|         0|            0|            0|  0.00%|        try:\n",
      "    30|         0|            0|            0|  0.00%|            return f(*args, **kwargs)\n",
      "    31|         0|            0|            0|  0.00%|        except TypeError:\n",
      "    32|         0|            0|            0|  0.00%|            return NotImplemented\n",
      "    33|         0|            0|            0|  0.00%|    return wrapped\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses\n",
      "    36|         0|            0|            0|  0.00%|def _rebuild_from_type(func, type, args, dict):\n",
      "    37|         0|            0|            0|  0.00%|    if type is Tensor:\n",
      "    38|         0|            0|            0|  0.00%|        return func(*args)\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|    ret = func(*args).as_subclass(type)\n",
      "    41|         0|            0|            0|  0.00%|    ret.__dict__ = dict\n",
      "    42|         0|            0|            0|  0.00%|    return ret\n",
      "    43|         0|            0|            0|  0.00%|\n",
      "    44|         0|            0|            0|  0.00%|def _rebuild_from_type_v2(func, new_type, args, state):\n",
      "    45|         0|            0|            0|  0.00%|    if new_type is Tensor:\n",
      "    46|         0|            0|            0|  0.00%|        return func(*args)\n",
      "    47|         0|            0|            0|  0.00%|\n",
      "    48|         0|            0|            0|  0.00%|    ret = func(*args).as_subclass(new_type)\n",
      "    49|         0|            0|            0|  0.00%|    # Tensor does define __setstate__ even though it doesn't define\n",
      "    50|         0|            0|            0|  0.00%|    # __getstate__. So only use __setstate__ if it is NOT the one defined\n",
      "    51|         0|            0|            0|  0.00%|    # on Tensor\n",
      "    52|         0|            0|            0|  0.00%|    if getattr(ret.__class__, \"__setstate__\", Tensor.__setstate__) is not Tensor.__setstate__:\n",
      "    53|         0|            0|            0|  0.00%|        ret.__setstate__(state)\n",
      "    54|         0|            0|            0|  0.00%|    else:\n",
      "    55|         0|            0|            0|  0.00%|        if isinstance(state, tuple):\n",
      "    56|         0|            0|            0|  0.00%|            if not len(state) == 2:\n",
      "    57|         0|            0|            0|  0.00%|                raise RuntimeError(f\"Invalid serialized state: {state}\")\n",
      "    58|         0|            0|            0|  0.00%|            dict_state = state[0]\n",
      "    59|         0|            0|            0|  0.00%|            slots_state = state[1]\n",
      "    60|         0|            0|            0|  0.00%|        else:\n",
      "    61|         0|            0|            0|  0.00%|            dict_state = state\n",
      "    62|         0|            0|            0|  0.00%|            slots_state = None\n",
      "    63|         0|            0|            0|  0.00%|\n",
      "    64|         0|            0|            0|  0.00%|        for k, v in dict_state.items():\n",
      "    65|         0|            0|            0|  0.00%|            setattr(ret, k, v)\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|        if slots_state:\n",
      "    68|         0|            0|            0|  0.00%|            for k, v in slots_state.items():\n",
      "    69|         0|            0|            0|  0.00%|                setattr(ret, k, v)\n",
      "    70|         0|            0|            0|  0.00%|    return ret\n",
      "    71|         0|            0|            0|  0.00%|\n",
      "    72|         0|            0|            0|  0.00%|\n",
      "    73|         0|            0|            0|  0.00%|# NB: If you subclass Tensor, and want to share the subclassed class\n",
      "    74|         0|            0|            0|  0.00%|# across processes, you must also update torch/multiprocessing/reductions.py\n",
      "    75|         0|            0|            0|  0.00%|# to define a ForkingPickler serialization mode for the class.\n",
      "    76|         0|            0|            0|  0.00%|#\n",
      "    77|         0|            0|            0|  0.00%|# NB: If you add a new method to Tensor, you must update\n",
      "    78|         0|            0|            0|  0.00%|# torch/__init__.py.in to add a type annotation for your method;\n",
      "    79|         0|            0|            0|  0.00%|# otherwise, it will not show up in autocomplete.\n",
      "    80|         0|            0|            0|  0.00%|class Tensor(torch._C._TensorBase):\n",
      "    81|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo):\n",
      "    82|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "    83|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)\n",
      "    84|         0|            0|            0|  0.00%|        if not self.is_leaf:\n",
      "    85|         0|            0|            0|  0.00%|            raise RuntimeError(\"Only Tensors created explicitly by the user \"\n",
      "    86|         0|            0|            0|  0.00%|                               \"(graph leaves) support the deepcopy protocol at the moment\")\n",
      "    87|         0|            0|            0|  0.00%|        if id(self) in memo:\n",
      "    88|         0|            0|            0|  0.00%|            return memo[id(self)]\n",
      "    89|         0|            0|            0|  0.00%|        with torch.no_grad():\n",
      "    90|         0|            0|            0|  0.00%|            # TODO: skipping storage copy is wrong for meta, as meta\n",
      "    91|         0|            0|            0|  0.00%|            # does accurate alias tracking; however, the code below\n",
      "    92|         0|            0|            0|  0.00%|            # doesn't work because of\n",
      "    93|         0|            0|            0|  0.00%|            # https://github.com/pytorch/pytorch/issues/47442\n",
      "    94|         0|            0|            0|  0.00%|            if self.is_sparse or self.device.type in ['xla', 'mlc', 'ort', 'meta']:\n",
      "    95|         0|            0|            0|  0.00%|                new_tensor = self.clone()\n",
      "    96|         0|            0|            0|  0.00%|            else:\n",
      "    97|         0|            0|            0|  0.00%|                new_storage = self.storage().__deepcopy__(memo)\n",
      "    98|         0|            0|            0|  0.00%|                if self.is_quantized:\n",
      "    99|         0|            0|            0|  0.00%|                    # quantizer_params can be different type based on torch attribute\n",
      "   100|         0|            0|            0|  0.00%|                    quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[torch.qscheme, Tensor, Tensor, int]]\n",
      "   101|         0|            0|            0|  0.00%|                    if self.qscheme() == torch.per_tensor_affine:\n",
      "   102|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), self.q_scale(), self.q_zero_point()\n",
      "   103|         0|            0|            0|  0.00%|                    elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n",
      "   104|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), \\\n",
      "   105|         0|            0|            0|  0.00%|                            self.q_per_channel_scales(), \\\n",
      "   106|         0|            0|            0|  0.00%|                            self.q_per_channel_zero_points(), \\\n",
      "   107|         0|            0|            0|  0.00%|                            self.q_per_channel_axis()\n",
      "   108|         0|            0|            0|  0.00%|                    else:\n",
      "   109|         0|            0|            0|  0.00%|                        raise RuntimeError(f\"Unsupported qscheme {self.qscheme()} in deepcopy\")\n",
      "   110|         0|            0|            0|  0.00%|                    new_tensor = torch._utils._rebuild_qtensor(\n",
      "   111|         0|            0|            0|  0.00%|                        new_storage,\n",
      "   112|         0|            0|            0|  0.00%|                        self.storage_offset(),\n",
      "   113|         0|            0|            0|  0.00%|                        self.size(),\n",
      "   114|         0|            0|            0|  0.00%|                        self.stride(),\n",
      "   115|         0|            0|            0|  0.00%|                        quantizer_params,\n",
      "   116|         0|            0|            0|  0.00%|                        self.requires_grad,\n",
      "   117|         0|            0|            0|  0.00%|                        self._backward_hooks)\n",
      "   118|         0|            0|            0|  0.00%|                else:\n",
      "   119|         0|            0|            0|  0.00%|                    new_tensor = self.new_empty([])\n",
      "   120|         0|            0|            0|  0.00%|                    new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())\n",
      "   121|         0|            0|            0|  0.00%|                    if self.is_conj():\n",
      "   122|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.conj_physical()\n",
      "   123|         0|            0|            0|  0.00%|                    if self.is_neg():\n",
      "   124|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.neg()\n",
      "   125|         0|            0|            0|  0.00%|                    new_tensor.requires_grad = self.requires_grad\n",
      "   126|         0|            0|            0|  0.00%|            if self.grad is not None:\n",
      "   127|         0|            0|            0|  0.00%|                new_tensor.grad = self.grad.__deepcopy__(memo)\n",
      "   128|         0|            0|            0|  0.00%|            memo[id(self)] = new_tensor\n",
      "   129|         0|            0|            0|  0.00%|            return new_tensor\n",
      "   130|         0|            0|            0|  0.00%|\n",
      "   131|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):\n",
      "   132|         0|            0|            0|  0.00%|        if type(self) is Tensor:\n",
      "   133|         0|            0|            0|  0.00%|            return self._reduce_ex_internal(proto)\n",
      "   134|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   135|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)\n",
      "   136|         0|            0|            0|  0.00%|        func, args = self._reduce_ex_internal(proto)\n",
      "   137|         0|            0|            0|  0.00%|        # Get the state of the python subclass\n",
      "   138|         0|            0|            0|  0.00%|        # This loosely mimicks the function on the object class but since Tensor do not inherit\n",
      "   139|         0|            0|            0|  0.00%|        # from it, we cannot call that function directly\n",
      "   140|         0|            0|            0|  0.00%|        # https://github.com/python/cpython/blob/c83919bd635f4433f1c6ae8504996a9fe3c215e5/Objects/typeobject.c#L4891\n",
      "   141|         0|            0|            0|  0.00%|        getstate_fn = getattr(self, \"__getstate__\", None)\n",
      "   142|         0|            0|            0|  0.00%|        if getstate_fn:\n",
      "   143|         0|            0|            0|  0.00%|            state = getstate_fn()\n",
      "   144|         0|            0|            0|  0.00%|        else:\n",
      "   145|         0|            0|            0|  0.00%|            slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n",
      "   146|         0|            0|            0|  0.00%|            if slots_to_save:\n",
      "   147|         0|            0|            0|  0.00%|                state = (self.__dict__, {name: getattr(self, name) for name in slots_to_save if hasattr(self, name)})\n",
      "   148|         0|            0|            0|  0.00%|            else:\n",
      "   149|         0|            0|            0|  0.00%|                state = self.__dict__\n",
      "   150|         0|            0|            0|  0.00%|        return (_rebuild_from_type_v2, (func, type(self), args, state))\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    def _reduce_ex_internal(self, proto):\n",
      "   153|         0|            0|            0|  0.00%|        check_serializing_named_tensor(self)\n",
      "   154|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]\n",
      "   155|         0|            0|            0|  0.00%|        torch.utils.hooks.warn_if_has_hooks(self)\n",
      "   156|         0|            0|            0|  0.00%|        backward_hooks: Dict[Any, Any] = OrderedDict()\n",
      "   157|         0|            0|            0|  0.00%|        # Note: Numpy array is chosen to be the rebuild component for XLA, ORT, MLC Tensors.\n",
      "   158|         0|            0|            0|  0.00%|        # We considered a few options:\n",
      "   159|         0|            0|            0|  0.00%|        # 1. CPU tensor can't be used here.\n",
      "   160|         0|            0|            0|  0.00%|        #    Otherwise in torch.load CPU storage is reconstructed with randomly\n",
      "   161|         0|            0|            0|  0.00%|        #    initialized data, moved onto backend device, and then storage is updated\n",
      "   162|         0|            0|            0|  0.00%|        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;\n",
      "   163|         0|            0|            0|  0.00%|        #    their tensors are disconnected with storage so they don't get the update.\n",
      "   164|         0|            0|            0|  0.00%|        # 2. Python list is not a good fit due to performance reason.\n",
      "   165|         0|            0|            0|  0.00%|        #    `tolist()` converts every single element in the tensor into python objects\n",
      "   166|         0|            0|            0|  0.00%|        #    and serialize them one by one.\n",
      "   167|         0|            0|            0|  0.00%|        if self.device.type in ['xla', 'ort', 'mlc']:\n",
      "   168|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_device_tensor_from_numpy, (self.cpu().numpy(),\n",
      "   169|         0|            0|            0|  0.00%|                                                                     self.dtype,\n",
      "   170|         0|            0|            0|  0.00%|                                                                     str(self.device),\n",
      "   171|         0|            0|            0|  0.00%|                                                                     self.requires_grad))\n",
      "   172|         0|            0|            0|  0.00%|        if self.device.type == 'meta':\n",
      "   173|         0|            0|            0|  0.00%|            # NB: This implementation BREAKS storage sharing.  Current\n",
      "   174|         0|            0|            0|  0.00%|            # hypothesis is that no one cares for meta tensors.\n",
      "   175|         0|            0|            0|  0.00%|            arg_meta = (\n",
      "   176|         0|            0|            0|  0.00%|                self.dtype,\n",
      "   177|         0|            0|            0|  0.00%|                tuple(self.size()),\n",
      "   178|         0|            0|            0|  0.00%|                self.stride(),\n",
      "   179|         0|            0|            0|  0.00%|                self.requires_grad,\n",
      "   180|         0|            0|            0|  0.00%|            )\n",
      "   181|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)\n",
      "   182|         0|            0|            0|  0.00%|        if self.is_quantized:\n",
      "   183|         0|            0|            0|  0.00%|            # quantizer_params can be different type based on torch attribute\n",
      "   184|         0|            0|            0|  0.00%|            quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]]\n",
      "   185|         0|            0|            0|  0.00%|            if self.qscheme() == torch.per_tensor_affine:\n",
      "   186|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_tensor_affine,\n",
      "   187|         0|            0|            0|  0.00%|                                    self.q_scale(),\n",
      "   188|         0|            0|            0|  0.00%|                                    self.q_zero_point())\n",
      "   189|         0|            0|            0|  0.00%|            elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n",
      "   190|         0|            0|            0|  0.00%|                # convert scales and zero points to tuple to avoid recursive calls\n",
      "   191|         0|            0|            0|  0.00%|                # when/if we get multi-axis quantized tensors in the future, the shape\n",
      "   192|         0|            0|            0|  0.00%|                # is recoverable from the main tensor shape\n",
      "   193|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_channel_affine,\n",
      "   194|         0|            0|            0|  0.00%|                                    self.q_per_channel_scales(),\n",
      "   195|         0|            0|            0|  0.00%|                                    self.q_per_channel_zero_points(),\n",
      "   196|         0|            0|            0|  0.00%|                                    self.q_per_channel_axis())\n",
      "   197|         0|            0|            0|  0.00%|            else:\n",
      "   198|         0|            0|            0|  0.00%|                raise RuntimeError(f\"Serialization is not supported for tensors of type {self.qscheme()}\")\n",
      "   199|         0|            0|            0|  0.00%|            args_qtensor = (self.storage(),\n",
      "   200|         0|            0|            0|  0.00%|                            self.storage_offset(),\n",
      "   201|         0|            0|            0|  0.00%|                            tuple(self.size()),\n",
      "   202|         0|            0|            0|  0.00%|                            self.stride(),\n",
      "   203|         0|            0|            0|  0.00%|                            quantizer_params,\n",
      "   204|         0|            0|            0|  0.00%|                            self.requires_grad,\n",
      "   205|         0|            0|            0|  0.00%|                            backward_hooks)\n",
      "   206|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_qtensor, args_qtensor)\n",
      "   207|         0|            0|            0|  0.00%|        elif self.is_sparse:\n",
      "   208|         0|            0|            0|  0.00%|            if self.layout == torch.sparse_coo:\n",
      "   209|         0|            0|            0|  0.00%|                args_sparse = (self.layout,\n",
      "   210|         0|            0|            0|  0.00%|                               (self._indices(),\n",
      "   211|         0|            0|            0|  0.00%|                                self._values(),\n",
      "   212|         0|            0|            0|  0.00%|                                self.size()))\n",
      "   213|         0|            0|            0|  0.00%|            else:\n",
      "   214|         0|            0|            0|  0.00%|                raise NotImplementedError(\n",
      "   215|         0|            0|            0|  0.00%|                    'sparse tensor __reduce_ex__ for layout `%s`' % (self.layout))\n",
      "   216|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_sparse_tensor, args_sparse)\n",
      "   217|         0|            0|            0|  0.00%|        else:\n",
      "   218|         0|            0|            0|  0.00%|            args = (self.storage(),\n",
      "   219|         0|            0|            0|  0.00%|                    self.storage_offset(),\n",
      "   220|         0|            0|            0|  0.00%|                    tuple(self.size()),\n",
      "   221|         0|            0|            0|  0.00%|                    self.stride(),\n",
      "   222|         0|            0|            0|  0.00%|                    self.requires_grad,\n",
      "   223|         0|            0|            0|  0.00%|                    backward_hooks)  # previously was self._backward_hooks\n",
      "   224|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_tensor_v2, args)\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    def __setstate__(self, state):\n",
      "   227|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   228|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__setstate__, (self,), self, state)\n",
      "   229|         0|            0|            0|  0.00%|        # Warning: this method is NOT called when you torch.load() a tensor;\n",
      "   230|         0|            0|            0|  0.00%|        # that is managed by _rebuild_tensor_v2\n",
      "   231|         0|            0|            0|  0.00%|        if not self.is_leaf:\n",
      "   232|         0|            0|            0|  0.00%|            raise RuntimeError('__setstate__ can be only called on leaf Tensors')\n",
      "   233|         0|            0|            0|  0.00%|        if len(state) == 4:\n",
      "   234|         0|            0|            0|  0.00%|            # legacy serialization of Tensor\n",
      "   235|         0|            0|            0|  0.00%|            self.set_(*state)\n",
      "   236|         0|            0|            0|  0.00%|            return\n",
      "   237|         0|            0|            0|  0.00%|        elif len(state) == 5:\n",
      "   238|         0|            0|            0|  0.00%|            # legacy serialization of Variable\n",
      "   239|         0|            0|            0|  0.00%|            self.data = state[0]\n",
      "   240|         0|            0|            0|  0.00%|            state = (state[3], state[4], state[2])\n",
      "   241|         0|            0|            0|  0.00%|        # The setting of _backward_hooks is expected to be a no-op.\n",
      "   242|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]\n",
      "   243|         0|            0|            0|  0.00%|        self.requires_grad, _, self._backward_hooks = state\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "   246|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   247|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__repr__, (self,), self)\n",
      "   248|         0|            0|            0|  0.00%|        # All strings are unicode in Python 3.\n",
      "   249|         0|            0|            0|  0.00%|        return torch._tensor_str._str(self)\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         1|   1.3113e-05|   1.3113e-05|  0.01%|    def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):\n",
      "   252|         0|            0|            0|  0.00%|        r\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "   253|         0|            0|            0|  0.00%|\n",
      "   254|         0|            0|            0|  0.00%|        The graph is differentiated using the chain rule. If the tensor is\n",
      "   255|         0|            0|            0|  0.00%|        non-scalar (i.e. its data has more than one element) and requires\n",
      "   256|         0|            0|            0|  0.00%|        gradient, the function additionally requires specifying ``gradient``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   257|         0|            0|            0|  0.00%|        It should be a tensor of matching type and location, that contains\n",
      "   258|         0|            0|            0|  0.00%|        the gradient of the differentiated function w.r.t. ``self``.\n",
      "   259|         0|            0|            0|  0.00%|\n",
      "   260|         0|            0|            0|  0.00%|        This function accumulates gradients in the leaves - you might need to zero\n",
      "   261|         0|            0|            0|  0.00%|        ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "   262|         0|            0|            0|  0.00%|        See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "   263|         0|            0|            0|  0.00%|        for details on the memory layout of accumulated gradients.\n",
      "   264|         0|            0|            0|  0.00%|\n",
      "   265|         0|            0|            0|  0.00%|        .. note::\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|            If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "   268|         0|            0|            0|  0.00%|            in a user-specified CUDA stream context, see\n",
      "   269|         0|            0|            0|  0.00%|            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   270|         0|            0|            0|  0.00%|\n",
      "   271|         0|            0|            0|  0.00%|        .. note::\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|            When ``inputs`` are provided and a given input is not a leaf,\n",
      "   274|         0|            0|            0|  0.00%|            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n",
      "   275|         0|            0|            0|  0.00%|            It is an implementation detail on which the user should not rely.\n",
      "   276|         0|            0|            0|  0.00%|            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
      "   277|         0|            0|            0|  0.00%|\n",
      "   278|         0|            0|            0|  0.00%|        Args:\n",
      "   279|         0|            0|            0|  0.00%|            gradient (Tensor or None): Gradient w.r.t. the\n",
      "   280|         0|            0|            0|  0.00%|                tensor. If it is a tensor, it will be automatically converted\n",
      "   281|         0|            0|            0|  0.00%|                to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "   282|         0|            0|            0|  0.00%|                None values can be specified for scalar Tensors or ones that\n",
      "   283|         0|            0|            0|  0.00%|                don't require grad. If a None value would be acceptable then\n",
      "   284|         0|            0|            0|  0.00%|                this argument is optional.\n",
      "   285|         0|            0|            0|  0.00%|            retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "   286|         0|            0|            0|  0.00%|                the grads will be freed. Note that in nearly all cases setting\n",
      "   287|         0|            0|            0|  0.00%|                this option to True is not needed and often can be worked around\n",
      "   288|         0|            0|            0|  0.00%|                in a much more efficient way. Defaults to the value of\n",
      "   289|         0|            0|            0|  0.00%|                ``create_graph``.\n",
      "   290|         0|            0|            0|  0.00%|            create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   291|         0|            0|            0|  0.00%|                be constructed, allowing to compute higher order derivative\n",
      "   292|         0|            0|            0|  0.00%|                products. Defaults to ``False``.\n",
      "   293|         0|            0|            0|  0.00%|            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "   294|         0|            0|            0|  0.00%|                accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "   295|         0|            0|            0|  0.00%|                provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "   296|         0|            0|            0|  0.00%|                used to compute the attr::tensors.\n",
      "   297|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   298|         1|  1.19209e-05|  1.19209e-05|  0.01%|        if has_torch_function_unary(self):\n",
      "   299|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   300|         0|            0|            0|  0.00%|                Tensor.backward,\n",
      "   301|         0|            0|            0|  0.00%|                (self,),\n",
      "   302|         0|            0|            0|  0.00%|                self,\n",
      "   303|         0|            0|            0|  0.00%|                gradient=gradient,\n",
      "   304|         0|            0|            0|  0.00%|                retain_graph=retain_graph,\n",
      "   305|         0|            0|            0|  0.00%|                create_graph=create_graph,\n",
      "   306|         0|            0|            0|  0.00%|                inputs=inputs)\n",
      "   307|         1|  5.26905e-05|  5.26905e-05|  0.02%|        torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "(call)|         1|      0.11619|      0.11619| 51.47%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:69 backward\n",
      "   308|         0|            0|            0|  0.00%|\n",
      "   309|         0|            0|            0|  0.00%|    def register_hook(self, hook):\n",
      "   310|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook.\n",
      "   311|         0|            0|            0|  0.00%|\n",
      "   312|         0|            0|            0|  0.00%|        The hook will be called every time a gradient with respect to the\n",
      "   313|         0|            0|            0|  0.00%|        Tensor is computed. The hook should have the following signature::\n",
      "   314|         0|            0|            0|  0.00%|\n",
      "   315|         0|            0|            0|  0.00%|            hook(grad) -> Tensor or None\n",
      "   316|         0|            0|            0|  0.00%|\n",
      "   317|         0|            0|            0|  0.00%|\n",
      "   318|         0|            0|            0|  0.00%|        The hook should not modify its argument, but it can optionally return\n",
      "   319|         0|            0|            0|  0.00%|        a new gradient which will be used in place of :attr:`grad`.\n",
      "   320|         0|            0|            0|  0.00%|\n",
      "   321|         0|            0|            0|  0.00%|        This function returns a handle with a method ``handle.remove()``\n",
      "   322|         0|            0|            0|  0.00%|        that removes the hook from the module.\n",
      "   323|         0|            0|            0|  0.00%|\n",
      "   324|         0|            0|            0|  0.00%|        Example::\n",
      "   325|         0|            0|            0|  0.00%|\n",
      "   326|         0|            0|            0|  0.00%|            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "   327|         0|            0|            0|  0.00%|            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "   328|         0|            0|            0|  0.00%|            >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "   329|         0|            0|            0|  0.00%|            >>> v.grad\n",
      "   330|         0|            0|            0|  0.00%|\n",
      "   331|         0|            0|            0|  0.00%|             2\n",
      "   332|         0|            0|            0|  0.00%|             4\n",
      "   333|         0|            0|            0|  0.00%|             6\n",
      "   334|         0|            0|            0|  0.00%|            [torch.FloatTensor of size (3,)]\n",
      "   335|         0|            0|            0|  0.00%|\n",
      "   336|         0|            0|            0|  0.00%|            >>> h.remove()  # removes the hook\n",
      "   337|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   338|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   339|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.register_hook, (self,), self, hook)\n",
      "   340|         0|            0|            0|  0.00%|        if not self.requires_grad:\n",
      "   341|         0|            0|            0|  0.00%|            raise RuntimeError(\"cannot register a hook on a tensor that \"\n",
      "   342|         0|            0|            0|  0.00%|                               \"doesn't require gradient\")\n",
      "   343|         0|            0|            0|  0.00%|        if self._backward_hooks is None:\n",
      "   344|         0|            0|            0|  0.00%|            self._backward_hooks = OrderedDict()\n",
      "   345|         0|            0|            0|  0.00%|            if self.grad_fn is not None:\n",
      "   346|         0|            0|            0|  0.00%|                self.grad_fn._register_hook_dict(self)\n",
      "   347|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   348|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   349|         0|            0|            0|  0.00%|        return handle\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|    def reinforce(self, reward):\n",
      "   352|         0|            0|            0|  0.00%|        def trim(str):\n",
      "   353|         0|            0|            0|  0.00%|            return '\\n'.join([line.strip() for line in str.split('\\n')])\n",
      "   354|         0|            0|            0|  0.00%|\n",
      "   355|         0|            0|            0|  0.00%|        raise RuntimeError(trim(r\"\"\"reinforce() was removed.\n",
      "   356|         0|            0|            0|  0.00%|            Use torch.distributions instead.\n",
      "   357|         0|            0|            0|  0.00%|            See https://pytorch.org/docs/master/distributions.html\n",
      "   358|         0|            0|            0|  0.00%|\n",
      "   359|         0|            0|            0|  0.00%|            Instead of:\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|            probs = policy_network(state)\n",
      "   362|         0|            0|            0|  0.00%|            action = probs.multinomial()\n",
      "   363|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)\n",
      "   364|         0|            0|            0|  0.00%|            action.reinforce(reward)\n",
      "   365|         0|            0|            0|  0.00%|            action.backward()\n",
      "   366|         0|            0|            0|  0.00%|\n",
      "   367|         0|            0|            0|  0.00%|            Use:\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|            probs = policy_network(state)\n",
      "   370|         0|            0|            0|  0.00%|            # NOTE: categorical is equivalent to what used to be called multinomial\n",
      "   371|         0|            0|            0|  0.00%|            m = torch.distributions.Categorical(probs)\n",
      "   372|         0|            0|            0|  0.00%|            action = m.sample()\n",
      "   373|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)\n",
      "   374|         0|            0|            0|  0.00%|            loss = -m.log_prob(action) * reward\n",
      "   375|         0|            0|            0|  0.00%|            loss.backward()\n",
      "   376|         0|            0|            0|  0.00%|        \"\"\"))\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|    detach = _C._add_docstr(_C._TensorBase.detach, r\"\"\"\n",
      "   379|         0|            0|            0|  0.00%|    Returns a new Tensor, detached from the current graph.\n",
      "   380|         0|            0|            0|  0.00%|\n",
      "   381|         0|            0|            0|  0.00%|    The result will never require gradient.\n",
      "   382|         0|            0|            0|  0.00%|\n",
      "   383|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never\n",
      "   384|         0|            0|            0|  0.00%|    have forward mode AD gradients.\n",
      "   385|         0|            0|            0|  0.00%|\n",
      "   386|         0|            0|            0|  0.00%|    .. note::\n",
      "   387|         0|            0|            0|  0.00%|\n",
      "   388|         0|            0|            0|  0.00%|      Returned Tensor shares the same storage with the original one.\n",
      "   389|         0|            0|            0|  0.00%|      In-place modifications on either of them will be seen, and may trigger\n",
      "   390|         0|            0|            0|  0.00%|      errors in correctness checks.\n",
      "   391|         0|            0|            0|  0.00%|      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "   392|         0|            0|            0|  0.00%|      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "   393|         0|            0|            0|  0.00%|      also update the original tensor. Now, these in-place changes will not update the\n",
      "   394|         0|            0|            0|  0.00%|      original tensor anymore, and will instead trigger an error.\n",
      "   395|         0|            0|            0|  0.00%|      For sparse tensors:\n",
      "   396|         0|            0|            0|  0.00%|      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "   397|         0|            0|            0|  0.00%|      returned tensor will not update the original tensor anymore, and will instead\n",
      "   398|         0|            0|            0|  0.00%|      trigger an error.\n",
      "   399|         0|            0|            0|  0.00%|    \"\"\")\n",
      "   400|         0|            0|            0|  0.00%|\n",
      "   401|         0|            0|            0|  0.00%|    detach_ = _C._add_docstr(_C._TensorBase.detach_, r\"\"\"\n",
      "   402|         0|            0|            0|  0.00%|    Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "   403|         0|            0|            0|  0.00%|    Views cannot be detached in-place.\n",
      "   404|         0|            0|            0|  0.00%|\n",
      "   405|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never\n",
      "   406|         0|            0|            0|  0.00%|    have forward mode AD gradients.\n",
      "   407|         0|            0|            0|  0.00%|    \"\"\")\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|    def is_shared(self):\n",
      "   410|         0|            0|            0|  0.00%|        r\"\"\"Checks if tensor is in shared memory.\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|        This is always ``True`` for CUDA tensors.\n",
      "   413|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   414|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   415|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.is_shared, (self,), self)\n",
      "   416|         0|            0|            0|  0.00%|        return self.storage().is_shared()\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|    def share_memory_(self):\n",
      "   419|         0|            0|            0|  0.00%|        r\"\"\"Moves the underlying storage to shared memory.\n",
      "   420|         0|            0|            0|  0.00%|\n",
      "   421|         0|            0|            0|  0.00%|        This is a no-op if the underlying storage is already in shared memory\n",
      "   422|         0|            0|            0|  0.00%|        and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "   423|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   424|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   425|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.share_memory_, (self,), self)\n",
      "   426|         0|            0|            0|  0.00%|        self.storage().share_memory_()\n",
      "   427|         0|            0|            0|  0.00%|        return self\n",
      "   428|         0|            0|            0|  0.00%|\n",
      "   429|         0|            0|            0|  0.00%|    def __reversed__(self):\n",
      "   430|         0|            0|            0|  0.00%|        r\"\"\"Reverses the tensor along dimension 0.\"\"\"\n",
      "   431|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   432|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reversed__, (self,), self)\n",
      "   433|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   434|         0|            0|            0|  0.00%|            return self\n",
      "   435|         0|            0|            0|  0.00%|        else:\n",
      "   436|         0|            0|            0|  0.00%|            return self.flip(0)\n",
      "   437|         0|            0|            0|  0.00%|\n",
      "   438|         0|            0|            0|  0.00%|    def norm(self, p=\"fro\", dim=None, keepdim=False, dtype=None):\n",
      "   439|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.norm`\"\"\"\n",
      "   440|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   441|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype)\n",
      "   442|         0|            0|            0|  0.00%|        return torch.norm(self, p, dim, keepdim, dtype=dtype)\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|    def lu(self, pivot=True, get_infos=False):\n",
      "   445|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.lu`\"\"\"\n",
      "   446|         0|            0|            0|  0.00%|        # If get_infos is True, then we don't need to check for errors and vice versa\n",
      "   447|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   448|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos)\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|        LU, pivots, infos = torch._lu_with_info(self, pivot=pivot, check_errors=(not get_infos))\n",
      "   451|         0|            0|            0|  0.00%|        if get_infos:\n",
      "   452|         0|            0|            0|  0.00%|            return LU, pivots, infos\n",
      "   453|         0|            0|            0|  0.00%|        else:\n",
      "   454|         0|            0|            0|  0.00%|            return LU, pivots\n",
      "   455|         0|            0|            0|  0.00%|\n",
      "   456|         0|            0|            0|  0.00%|    def stft(self, n_fft: int, hop_length: Optional[int] = None,\n",
      "   457|         0|            0|            0|  0.00%|             win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n",
      "   458|         0|            0|            0|  0.00%|             center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,\n",
      "   459|         0|            0|            0|  0.00%|             onesided: Optional[bool] = None, return_complex: Optional[bool] = None):\n",
      "   460|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.stft`\n",
      "   461|         0|            0|            0|  0.00%|\n",
      "   462|         0|            0|            0|  0.00%|        .. warning::\n",
      "   463|         0|            0|            0|  0.00%|          This function changed signature at version 0.4.1. Calling with\n",
      "   464|         0|            0|            0|  0.00%|          the previous signature may cause error or return incorrect result.\n",
      "   465|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   466|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   467|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   468|         0|            0|            0|  0.00%|                Tensor.stft, (self,), self, n_fft, hop_length=hop_length,\n",
      "   469|         0|            0|            0|  0.00%|                win_length=win_length, window=window, center=center, pad_mode=pad_mode, normalized=normalized,\n",
      "   470|         0|            0|            0|  0.00%|                onesided=onesided, return_complex=return_complex\n",
      "   471|         0|            0|            0|  0.00%|            )\n",
      "   472|         0|            0|            0|  0.00%|        return torch.stft(self, n_fft, hop_length, win_length, window, center,\n",
      "   473|         0|            0|            0|  0.00%|                          pad_mode, normalized, onesided, return_complex=return_complex)\n",
      "   474|         0|            0|            0|  0.00%|\n",
      "   475|         0|            0|            0|  0.00%|    def istft(self, n_fft: int, hop_length: Optional[int] = None,\n",
      "   476|         0|            0|            0|  0.00%|              win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n",
      "   477|         0|            0|            0|  0.00%|              center: bool = True, normalized: bool = False,\n",
      "   478|         0|            0|            0|  0.00%|              onesided: Optional[bool] = None, length: Optional[int] = None,\n",
      "   479|         0|            0|            0|  0.00%|              return_complex: bool = False):\n",
      "   480|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.istft`\"\"\"\n",
      "   481|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   482|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   483|         0|            0|            0|  0.00%|                Tensor.istft, (self,), self, n_fft, hop_length=hop_length, win_length=win_length,\n",
      "   484|         0|            0|            0|  0.00%|                window=window, center=center, normalized=normalized, onesided=onesided, length=length,\n",
      "   485|         0|            0|            0|  0.00%|                return_complex=return_complex\n",
      "   486|         0|            0|            0|  0.00%|            )\n",
      "   487|         0|            0|            0|  0.00%|        return torch.istft(self, n_fft, hop_length, win_length, window, center,\n",
      "   488|         0|            0|            0|  0.00%|                           normalized, onesided, length, return_complex=return_complex)\n",
      "   489|         0|            0|            0|  0.00%|\n",
      "   490|         0|            0|            0|  0.00%|    def resize(self, *sizes):\n",
      "   491|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   492|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize, (self,), self, *sizes)\n",
      "   493|         0|            0|            0|  0.00%|        warnings.warn(\"non-inplace resize is deprecated\")\n",
      "   494|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize\n",
      "   495|         0|            0|            0|  0.00%|        return Resize.apply(self, sizes)\n",
      "   496|         0|            0|            0|  0.00%|\n",
      "   497|         0|            0|            0|  0.00%|    def resize_as(self, tensor):\n",
      "   498|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, tensor):\n",
      "   499|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)\n",
      "   500|         0|            0|            0|  0.00%|        warnings.warn(\"non-inplace resize_as is deprecated\")\n",
      "   501|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize\n",
      "   502|         0|            0|            0|  0.00%|        return Resize.apply(self, tensor.size())\n",
      "   503|         0|            0|            0|  0.00%|\n",
      "   504|         0|            0|            0|  0.00%|    def split(self, split_size, dim=0):\n",
      "   505|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.split`\n",
      "   506|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   507|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   508|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.split, (self,), self, split_size, dim=dim)\n",
      "   509|         0|            0|            0|  0.00%|        if isinstance(split_size, int):\n",
      "   510|         0|            0|            0|  0.00%|            return super(Tensor, self).split(split_size, dim)\n",
      "   511|         0|            0|            0|  0.00%|        elif isinstance(split_size, Tensor):\n",
      "   512|         0|            0|            0|  0.00%|            try:\n",
      "   513|         0|            0|            0|  0.00%|                split_size = int(split_size)\n",
      "   514|         0|            0|            0|  0.00%|                return super(Tensor, self).split(split_size, dim)\n",
      "   515|         0|            0|            0|  0.00%|            except ValueError:\n",
      "   516|         0|            0|            0|  0.00%|                return super(Tensor, self).split_with_sizes(split_size, dim)\n",
      "   517|         0|            0|            0|  0.00%|        else:\n",
      "   518|         0|            0|            0|  0.00%|            return super(Tensor, self).split_with_sizes(split_size, dim)\n",
      "   519|         0|            0|            0|  0.00%|\n",
      "   520|         0|            0|            0|  0.00%|    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):\n",
      "   521|         0|            0|            0|  0.00%|        r\"\"\"Returns the unique elements of the input tensor.\n",
      "   522|         0|            0|            0|  0.00%|\n",
      "   523|         0|            0|            0|  0.00%|        See :func:`torch.unique`\n",
      "   524|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   525|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   526|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   527|         0|            0|            0|  0.00%|                Tensor.unique, (self,), self, sorted=sorted, return_inverse=return_inverse,\n",
      "   528|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim\n",
      "   529|         0|            0|            0|  0.00%|            )\n",
      "   530|         0|            0|            0|  0.00%|        return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n",
      "   531|         0|            0|            0|  0.00%|\n",
      "   532|         0|            0|            0|  0.00%|    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):\n",
      "   533|         0|            0|            0|  0.00%|        r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "   534|         0|            0|            0|  0.00%|\n",
      "   535|         0|            0|            0|  0.00%|        See :func:`torch.unique_consecutive`\n",
      "   536|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   537|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   538|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   539|         0|            0|            0|  0.00%|                Tensor.unique_consecutive, (self,), self, return_inverse=return_inverse,\n",
      "   540|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim\n",
      "   541|         0|            0|            0|  0.00%|            )\n",
      "   542|         0|            0|            0|  0.00%|        return torch.unique_consecutive(self, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n",
      "   543|         0|            0|            0|  0.00%|\n",
      "   544|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   545|         0|            0|            0|  0.00%|    def __rsub__(self, other):\n",
      "   546|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   547|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rsub__, (self, other), self, other)\n",
      "   548|         0|            0|            0|  0.00%|        return _C._VariableFunctions.rsub(self, other)\n",
      "   549|         0|            0|            0|  0.00%|\n",
      "   550|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   551|         0|            0|            0|  0.00%|    def __rdiv__(self, other):\n",
      "   552|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   553|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rdiv__, (self, other), self, other)\n",
      "   554|         0|            0|            0|  0.00%|        return self.reciprocal() * other\n",
      "   555|         0|            0|            0|  0.00%|\n",
      "   556|         0|            0|            0|  0.00%|    __rtruediv__ = __rdiv__\n",
      "   557|         0|            0|            0|  0.00%|    __itruediv__ = _C._TensorBase.__idiv__\n",
      "   558|         0|            0|            0|  0.00%|\n",
      "   559|         0|            0|            0|  0.00%|    __pow__ = _wrap_type_error_to_not_implemented(_C._TensorBase.pow)\n",
      "   560|         0|            0|            0|  0.00%|\n",
      "   561|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   562|         0|            0|            0|  0.00%|    def __rmod__(self, other):\n",
      "   563|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   564|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rmod__, (self, other), self, other)\n",
      "   565|         0|            0|            0|  0.00%|        return torch.remainder(other, self)\n",
      "   566|         0|            0|            0|  0.00%|\n",
      "   567|         0|            0|            0|  0.00%|    def __format__(self, format_spec):\n",
      "   568|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   569|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)\n",
      "   570|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   571|         0|            0|            0|  0.00%|            return self.item().__format__(format_spec)\n",
      "   572|         0|            0|            0|  0.00%|        return object.__format__(self, format_spec)\n",
      "   573|         0|            0|            0|  0.00%|\n",
      "   574|         0|            0|            0|  0.00%|    def __ipow__(self, other):  # type: ignore[misc]\n",
      "   575|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   576|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__ipow__, (self, other), self, other)\n",
      "   577|         0|            0|            0|  0.00%|        return NotImplemented\n",
      "   578|         0|            0|            0|  0.00%|\n",
      "   579|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   580|         0|            0|            0|  0.00%|    def __rpow__(self, other):\n",
      "   581|         0|            0|            0|  0.00%|        dtype = torch.result_type(other, self)\n",
      "   582|         0|            0|            0|  0.00%|        return torch.tensor(other, dtype=dtype, device=self.device) ** self\n",
      "   583|         0|            0|            0|  0.00%|\n",
      "   584|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   585|         0|            0|            0|  0.00%|    def __floordiv__(self, other):\n",
      "   586|         0|            0|            0|  0.00%|        warnings.warn(\"__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n",
      "   587|         0|            0|            0|  0.00%|                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n",
      "   588|         0|            0|            0|  0.00%|                      \"This results in incorrect rounding for negative values. \"\n",
      "   589|         0|            0|            0|  0.00%|                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n",
      "   590|         0|            0|            0|  0.00%|                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n",
      "   591|         0|            0|            0|  0.00%|        return torch.div(self, other, rounding_mode='trunc')\n",
      "   592|         0|            0|            0|  0.00%|\n",
      "   593|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   594|         0|            0|            0|  0.00%|    def __rfloordiv__(self, other):\n",
      "   595|         0|            0|            0|  0.00%|        warnings.warn(\"__rfloordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n",
      "   596|         0|            0|            0|  0.00%|                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n",
      "   597|         0|            0|            0|  0.00%|                      \"This results in incorrect rounding for negative values. \"\n",
      "   598|         0|            0|            0|  0.00%|                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n",
      "   599|         0|            0|            0|  0.00%|                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n",
      "   600|         0|            0|            0|  0.00%|        return torch.div(other, self, rounding_mode='trunc')\n",
      "   601|         0|            0|            0|  0.00%|\n",
      "   602|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   603|         0|            0|            0|  0.00%|    def __rlshift__(self, other):\n",
      "   604|         0|            0|            0|  0.00%|        return torch.bitwise_left_shift(other, self)\n",
      "   605|         0|            0|            0|  0.00%|\n",
      "   606|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   607|         0|            0|            0|  0.00%|    def __rrshift__(self, other):\n",
      "   608|         0|            0|            0|  0.00%|        return torch.bitwise_right_shift(other, self)\n",
      "   609|         0|            0|            0|  0.00%|\n",
      "   610|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   611|         0|            0|            0|  0.00%|    def __rmatmul__(self, other):\n",
      "   612|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   613|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rmatmul__, (self, other), self, other)\n",
      "   614|         0|            0|            0|  0.00%|        return torch.matmul(other, self)\n",
      "   615|         0|            0|            0|  0.00%|\n",
      "   616|         0|            0|            0|  0.00%|    __pos__ = _C._TensorBase.positive\n",
      "   617|         0|            0|            0|  0.00%|    __neg__ = _C._TensorBase.neg\n",
      "   618|         0|            0|            0|  0.00%|    __abs__ = _C._TensorBase.abs\n",
      "   619|         0|            0|            0|  0.00%|\n",
      "   620|         0|            0|            0|  0.00%|    def __len__(self):\n",
      "   621|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   622|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__len__, (self,), self)\n",
      "   623|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   624|         0|            0|            0|  0.00%|            raise TypeError(\"len() of a 0-d tensor\")\n",
      "   625|         0|            0|            0|  0.00%|        if torch._C._get_tracing_state():\n",
      "   626|         0|            0|            0|  0.00%|            warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n",
      "   627|         0|            0|            0|  0.00%|                          'Recommended usage would be tensor.shape[0]. '\n",
      "   628|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape might lead to errors or silently give '\n",
      "   629|         0|            0|            0|  0.00%|                          'incorrect results.', category=torch.jit.TracerWarning, stacklevel=2)\n",
      "   630|         0|            0|            0|  0.00%|        return self.shape[0]\n",
      "   631|         0|            0|            0|  0.00%|\n",
      "   632|         0|            0|            0|  0.00%|    def __iter__(self):\n",
      "   633|         0|            0|            0|  0.00%|        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\n",
      "   634|         0|            0|            0|  0.00%|        # generator and don't eagerly perform all the indexes.  This could\n",
      "   635|         0|            0|            0|  0.00%|        # save us work, and also helps keep trace ordering deterministic\n",
      "   636|         0|            0|            0|  0.00%|        # (e.g., if you zip(*hiddens), the eager map will force all the\n",
      "   637|         0|            0|            0|  0.00%|        # indexes of hiddens[0] before hiddens[1], while the generator\n",
      "   638|         0|            0|            0|  0.00%|        # map will interleave them.)\n",
      "   639|         0|            0|            0|  0.00%|        # NB: We have intentionally skipped __torch_function__ dispatch here.\n",
      "   640|         0|            0|            0|  0.00%|        # See gh-54457\n",
      "   641|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   642|         0|            0|            0|  0.00%|            raise TypeError('iteration over a 0-d tensor')\n",
      "   643|         0|            0|            0|  0.00%|        if torch._C._get_tracing_state():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   644|         0|            0|            0|  0.00%|            warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "   645|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape won\\'t change the number of '\n",
      "   646|         0|            0|            0|  0.00%|                          'iterations executed (and might lead to errors or silently give '\n",
      "   647|         0|            0|            0|  0.00%|                          'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)\n",
      "   648|         0|            0|            0|  0.00%|        return iter(self.unbind(0))\n",
      "   649|         0|            0|            0|  0.00%|\n",
      "   650|         0|            0|            0|  0.00%|    def __hash__(self):\n",
      "   651|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   652|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__hash__, (self,), self)\n",
      "   653|         0|            0|            0|  0.00%|        return id(self)\n",
      "   654|         0|            0|            0|  0.00%|\n",
      "   655|         0|            0|            0|  0.00%|    def __dir__(self):\n",
      "   656|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   657|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dir__, (self,), self)\n",
      "   658|         0|            0|            0|  0.00%|        if self.is_quantized:\n",
      "   659|         0|            0|            0|  0.00%|            warnings.warn('Only a small subset of methods are supported for quantized tensors.')\n",
      "   660|         0|            0|            0|  0.00%|        tensor_methods = dir(self.__class__)\n",
      "   661|         0|            0|            0|  0.00%|        tensor_methods.remove('volatile')  # deprecated\n",
      "   662|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())\n",
      "   663|         0|            0|            0|  0.00%|        keys = tensor_methods + attrs\n",
      "   664|         0|            0|            0|  0.00%|\n",
      "   665|         0|            0|            0|  0.00%|        # property only available dense, cuda tensors\n",
      "   666|         0|            0|            0|  0.00%|        if (not self.is_cuda) or self.is_sparse:\n",
      "   667|         0|            0|            0|  0.00%|            keys.remove(\"__cuda_array_interface__\")\n",
      "   668|         0|            0|            0|  0.00%|\n",
      "   669|         0|            0|            0|  0.00%|        return sorted(keys)\n",
      "   670|         0|            0|            0|  0.00%|\n",
      "   671|         0|            0|            0|  0.00%|    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "   672|         0|            0|            0|  0.00%|    __array_priority__ = 1000    # prefer Tensor ops over numpy ones\n",
      "   673|         0|            0|            0|  0.00%|\n",
      "   674|         0|            0|            0|  0.00%|    def __array__(self, dtype=None):\n",
      "   675|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   676|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)\n",
      "   677|         0|            0|            0|  0.00%|        if dtype is None:\n",
      "   678|         0|            0|            0|  0.00%|            return self.numpy()\n",
      "   679|         0|            0|            0|  0.00%|        else:\n",
      "   680|         0|            0|            0|  0.00%|            return self.numpy().astype(dtype, copy=False)\n",
      "   681|         0|            0|            0|  0.00%|\n",
      "   682|         0|            0|            0|  0.00%|    # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "   683|         0|            0|            0|  0.00%|    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "   684|         0|            0|            0|  0.00%|    def __array_wrap__(self, array):\n",
      "   685|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   686|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array_wrap__, (self,), self, array=array)\n",
      "   687|         0|            0|            0|  0.00%|        if array.dtype == bool:\n",
      "   688|         0|            0|            0|  0.00%|            # Workaround, torch has no built-in bool tensor\n",
      "   689|         0|            0|            0|  0.00%|            array = array.astype('uint8')\n",
      "   690|         0|            0|            0|  0.00%|        return torch.from_numpy(array)\n",
      "   691|         0|            0|            0|  0.00%|\n",
      "   692|         0|            0|            0|  0.00%|    def __contains__(self, element):\n",
      "   693|         0|            0|            0|  0.00%|        r\"\"\"Check if `element` is present in tensor\n",
      "   694|         0|            0|            0|  0.00%|\n",
      "   695|         0|            0|            0|  0.00%|        Args:\n",
      "   696|         0|            0|            0|  0.00%|            element (Tensor or scalar): element to be checked\n",
      "   697|         0|            0|            0|  0.00%|                for presence in current tensor\"\n",
      "   698|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   699|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   700|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__contains__, (self,), self, element)\n",
      "   701|         0|            0|            0|  0.00%|        if isinstance(element, (torch.Tensor, Number)):\n",
      "   702|         0|            0|            0|  0.00%|            # type hint doesn't understand the __contains__ result array\n",
      "   703|         0|            0|            0|  0.00%|            return (element == self).any().item()  # type: ignore[union-attr]\n",
      "   704|         0|            0|            0|  0.00%|\n",
      "   705|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   706|         0|            0|            0|  0.00%|            \"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\" %\n",
      "   707|         0|            0|            0|  0.00%|            type(element)\n",
      "   708|         0|            0|            0|  0.00%|        )\n",
      "   709|         0|            0|            0|  0.00%|\n",
      "   710|         0|            0|            0|  0.00%|    @property\n",
      "   711|         0|            0|            0|  0.00%|    def __cuda_array_interface__(self):\n",
      "   712|         0|            0|            0|  0.00%|        \"\"\"Array view description for cuda tensors.\n",
      "   713|         0|            0|            0|  0.00%|\n",
      "   714|         0|            0|            0|  0.00%|        See:\n",
      "   715|         0|            0|            0|  0.00%|        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "   716|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   717|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   718|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "   719|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|        # raise AttributeError for unsupported tensors, so that\n",
      "   722|         0|            0|            0|  0.00%|        # hasattr(cpu_tensor, \"__cuda_array_interface__\") is False.\n",
      "   723|         0|            0|            0|  0.00%|        if not self.is_cuda:\n",
      "   724|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   725|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on non-CUDA tensor type: %s \"\n",
      "   726|         0|            0|            0|  0.00%|                \"If CUDA data is required use tensor.cuda() to copy tensor to device memory.\" %\n",
      "   727|         0|            0|            0|  0.00%|                self.type()\n",
      "   728|         0|            0|            0|  0.00%|            )\n",
      "   729|         0|            0|            0|  0.00%|\n",
      "   730|         0|            0|            0|  0.00%|        if self.is_sparse:\n",
      "   731|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   732|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on sparse type: %s \"\n",
      "   733|         0|            0|            0|  0.00%|                \"Use Tensor.to_dense() to convert to a dense tensor first.\" %\n",
      "   734|         0|            0|            0|  0.00%|                self.type()\n",
      "   735|         0|            0|            0|  0.00%|            )\n",
      "   736|         0|            0|            0|  0.00%|\n",
      "   737|         0|            0|            0|  0.00%|        # RuntimeError, matching tensor.__array__() behavior.\n",
      "   738|         0|            0|            0|  0.00%|        if self.requires_grad:\n",
      "   739|         0|            0|            0|  0.00%|            raise RuntimeError(\n",
      "   740|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on Variable that requires grad. \"\n",
      "   741|         0|            0|            0|  0.00%|                \"If gradients aren't required, use var.detach() to get Variable that doesn't require grad.\"\n",
      "   742|         0|            0|            0|  0.00%|            )\n",
      "   743|         0|            0|            0|  0.00%|\n",
      "   744|         0|            0|            0|  0.00%|        # CUDA devices are little-endian and tensors are stored in native byte\n",
      "   745|         0|            0|            0|  0.00%|        # order. 1-byte entries are endian-agnostic.\n",
      "   746|         0|            0|            0|  0.00%|        typestr = {\n",
      "   747|         0|            0|            0|  0.00%|            torch.complex64: \"<c8\",\n",
      "   748|         0|            0|            0|  0.00%|            torch.complex128: \"<c16\",\n",
      "   749|         0|            0|            0|  0.00%|            torch.float16: \"<f2\",\n",
      "   750|         0|            0|            0|  0.00%|            torch.float32: \"<f4\",\n",
      "   751|         0|            0|            0|  0.00%|            torch.float64: \"<f8\",\n",
      "   752|         0|            0|            0|  0.00%|            torch.uint8: \"|u1\",\n",
      "   753|         0|            0|            0|  0.00%|            torch.int8: \"|i1\",\n",
      "   754|         0|            0|            0|  0.00%|            torch.int16: \"<i2\",\n",
      "   755|         0|            0|            0|  0.00%|            torch.int32: \"<i4\",\n",
      "   756|         0|            0|            0|  0.00%|            torch.int64: \"<i8\",\n",
      "   757|         0|            0|            0|  0.00%|        }[self.dtype]\n",
      "   758|         0|            0|            0|  0.00%|\n",
      "   759|         0|            0|            0|  0.00%|        itemsize = self.storage().element_size()\n",
      "   760|         0|            0|            0|  0.00%|\n",
      "   761|         0|            0|            0|  0.00%|        shape = tuple(self.shape)\n",
      "   762|         0|            0|            0|  0.00%|        if self.is_contiguous():\n",
      "   763|         0|            0|            0|  0.00%|            # __cuda_array_interface__ v2 requires the strides to be omitted\n",
      "   764|         0|            0|            0|  0.00%|            # (either not set or set to None) for C-contiguous arrays.\n",
      "   765|         0|            0|            0|  0.00%|            strides = None\n",
      "   766|         0|            0|            0|  0.00%|        else:\n",
      "   767|         0|            0|            0|  0.00%|            strides = tuple(s * itemsize for s in self.stride())\n",
      "   768|         0|            0|            0|  0.00%|        data_ptr = self.data_ptr() if self.numel() > 0 else 0\n",
      "   769|         0|            0|            0|  0.00%|        data = (data_ptr, False)  # read-only is false\n",
      "   770|         0|            0|            0|  0.00%|\n",
      "   771|         0|            0|            0|  0.00%|        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)\n",
      "   772|         0|            0|            0|  0.00%|\n",
      "   773|         0|            0|            0|  0.00%|    def refine_names(self, *names):\n",
      "   774|         0|            0|            0|  0.00%|        r\"\"\"Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "   775|         0|            0|            0|  0.00%|\n",
      "   776|         0|            0|            0|  0.00%|        Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "   777|         0|            0|            0|  0.00%|        A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "   778|         0|            0|            0|  0.00%|        refined to have the same name.\n",
      "   779|         0|            0|            0|  0.00%|\n",
      "   780|         0|            0|            0|  0.00%|        Because named tensors can coexist with unnamed tensors, refining names\n",
      "   781|         0|            0|            0|  0.00%|        gives a nice way to write named-tensor-aware code that works with both\n",
      "   782|         0|            0|            0|  0.00%|        named and unnamed tensors.\n",
      "   783|         0|            0|            0|  0.00%|\n",
      "   784|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "   785|         0|            0|            0|  0.00%|        The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "   786|         0|            0|            0|  0.00%|        :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "   787|         0|            0|            0|  0.00%|        corresponding indices of ``self.names``.\n",
      "   788|         0|            0|            0|  0.00%|\n",
      "   789|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal\n",
      "   790|         0|            0|            0|  0.00%|        instead (``'...'``).\n",
      "   791|         0|            0|            0|  0.00%|\n",
      "   792|         0|            0|            0|  0.00%|        Args:\n",
      "   793|         0|            0|            0|  0.00%|            names (iterable of str): The desired names of the output tensor. May\n",
      "   794|         0|            0|            0|  0.00%|                contain up to one Ellipsis.\n",
      "   795|         0|            0|            0|  0.00%|\n",
      "   796|         0|            0|            0|  0.00%|        Examples::\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|            >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "   799|         0|            0|            0|  0.00%|            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "   800|         0|            0|            0|  0.00%|            >>> named_imgs.names\n",
      "   801|         0|            0|            0|  0.00%|            ('N', 'C', 'H', 'W')\n",
      "   802|         0|            0|            0|  0.00%|\n",
      "   803|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "   804|         0|            0|            0|  0.00%|            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "   805|         0|            0|            0|  0.00%|            >>> tensor.names\n",
      "   806|         0|            0|            0|  0.00%|            ('A', None, None, 'B', 'C')\n",
      "   807|         0|            0|            0|  0.00%|\n",
      "   808|         0|            0|            0|  0.00%|        .. warning::\n",
      "   809|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   810|         0|            0|            0|  0.00%|\n",
      "   811|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   812|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   813|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.refine_names, (self,), self, *names)\n",
      "   814|         0|            0|            0|  0.00%|        names = resolve_ellipsis(names, self.names, 'refine_names')\n",
      "   815|         0|            0|            0|  0.00%|        return super(Tensor, self).refine_names(names)\n",
      "   816|         0|            0|            0|  0.00%|\n",
      "   817|         0|            0|            0|  0.00%|    def align_to(self, *names):\n",
      "   818|         0|            0|            0|  0.00%|        r\"\"\"Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "   819|         0|            0|            0|  0.00%|        specified in :attr:`names`, adding size-one dims for any new names.\n",
      "   820|         0|            0|            0|  0.00%|\n",
      "   821|         0|            0|            0|  0.00%|        All of the dims of :attr:`self` must be named in order to use this method.\n",
      "   822|         0|            0|            0|  0.00%|        The resulting tensor is a view on the original tensor.\n",
      "   823|         0|            0|            0|  0.00%|\n",
      "   824|         0|            0|            0|  0.00%|        All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "   825|         0|            0|            0|  0.00%|        :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "   826|         0|            0|            0|  0.00%|        the output tensor has a size-one dimension for each of those new names.\n",
      "   827|         0|            0|            0|  0.00%|\n",
      "   828|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "   829|         0|            0|            0|  0.00%|        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "   830|         0|            0|            0|  0.00%|        that are not mentioned in :attr:`names`, in the order that they appear\n",
      "   831|         0|            0|            0|  0.00%|        in :attr:`self`.\n",
      "   832|         0|            0|            0|  0.00%|\n",
      "   833|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal\n",
      "   834|         0|            0|            0|  0.00%|        instead (``'...'``).\n",
      "   835|         0|            0|            0|  0.00%|\n",
      "   836|         0|            0|            0|  0.00%|        Args:\n",
      "   837|         0|            0|            0|  0.00%|            names (iterable of str): The desired dimension ordering of the\n",
      "   838|         0|            0|            0|  0.00%|                output tensor. May contain up to one Ellipsis that is expanded\n",
      "   839|         0|            0|            0|  0.00%|                to all unmentioned dim names of :attr:`self`.\n",
      "   840|         0|            0|            0|  0.00%|\n",
      "   841|         0|            0|            0|  0.00%|        Examples::\n",
      "   842|         0|            0|            0|  0.00%|\n",
      "   843|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "   844|         0|            0|            0|  0.00%|            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n",
      "   845|         0|            0|            0|  0.00%|\n",
      "   846|         0|            0|            0|  0.00%|            # Move the F and E dims to the front while keeping the rest in order\n",
      "   847|         0|            0|            0|  0.00%|            >>> named_tensor.align_to('F', 'E', ...)\n",
      "   848|         0|            0|            0|  0.00%|\n",
      "   849|         0|            0|            0|  0.00%|        .. warning::\n",
      "   850|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   851|         0|            0|            0|  0.00%|\n",
      "   852|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   853|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   854|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.align_to, (self,), self, *names)\n",
      "   855|         0|            0|            0|  0.00%|        ellipsis_idx = single_ellipsis_index(names, 'align_to')\n",
      "   856|         0|            0|            0|  0.00%|        if ellipsis_idx is None:\n",
      "   857|         0|            0|            0|  0.00%|            return super(Tensor, self).align_to(names)\n",
      "   858|         0|            0|            0|  0.00%|        return super(Tensor, self).align_to(\n",
      "   859|         0|            0|            0|  0.00%|            [name for name in names if not is_ellipsis(name)],\n",
      "   860|         0|            0|            0|  0.00%|            ellipsis_idx)\n",
      "   861|         0|            0|            0|  0.00%|\n",
      "   862|         0|            0|            0|  0.00%|    def unflatten(self, dim, sizes):\n",
      "   863|         0|            0|            0|  0.00%|        r\"\"\"Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "   864|         0|            0|            0|  0.00%|        of sizes given by :attr:`sizes`.\n",
      "   865|         0|            0|            0|  0.00%|\n",
      "   866|         0|            0|            0|  0.00%|        * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "   867|         0|            0|            0|  0.00%|          as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "   868|         0|            0|            0|  0.00%|          if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "   869|         0|            0|            0|  0.00%|          of elements in the original dim being unflattened.\n",
      "   870|         0|            0|            0|  0.00%|\n",
      "   871|         0|            0|            0|  0.00%|        Args:\n",
      "   872|         0|            0|            0|  0.00%|            dim (Union[int, str]): Dimension to unflatten\n",
      "   873|         0|            0|            0|  0.00%|            sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "   874|         0|            0|            0|  0.00%|\n",
      "   875|         0|            0|            0|  0.00%|        Examples:\n",
      "   876|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "   877|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])\n",
      "   878|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (-1, 2)).shape # the size -1 is inferred from the size of dimension 1\n",
      "   879|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])\n",
      "   880|         0|            0|            0|  0.00%|            >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "   881|         0|            0|            0|  0.00%|            tensor([[[-1.1772,  0.0180],\n",
      "   882|         0|            0|            0|  0.00%|                    [ 0.2412,  0.1431]],\n",
      "   883|         0|            0|            0|  0.00%|                    [[-1.1819, -0.8899],\n",
      "   884|         0|            0|            0|  0.00%|                    [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "   885|         0|            0|            0|  0.00%|            >>> torch.randn(2, names=('A',)).unflatten('A', (('B1', -1), ('B2', 1)))\n",
      "   886|         0|            0|            0|  0.00%|            tensor([[-0.8591],\n",
      "   887|         0|            0|            0|  0.00%|                    [ 0.3100]], names=('B1', 'B2'))\n",
      "   888|         0|            0|            0|  0.00%|\n",
      "   889|         0|            0|            0|  0.00%|        .. warning::\n",
      "   890|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   891|         0|            0|            0|  0.00%|\n",
      "   892|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   893|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   894|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)\n",
      "   895|         0|            0|            0|  0.00%|\n",
      "   896|         0|            0|            0|  0.00%|        if not sizes:\n",
      "   897|         0|            0|            0|  0.00%|            raise RuntimeError(\"unflatten: sizes must be non-empty\")\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|        names = None\n",
      "   900|         0|            0|            0|  0.00%|        if isinstance(sizes, OrderedDict) or (isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))):\n",
      "   901|         0|            0|            0|  0.00%|            names, sizes = unzip_namedshape(sizes)\n",
      "   902|         0|            0|            0|  0.00%|        return super(Tensor, self).unflatten(dim, sizes, names)\n",
      "   903|         0|            0|            0|  0.00%|\n",
      "   904|         0|            0|            0|  0.00%|\n",
      "   905|         0|            0|            0|  0.00%|    def rename_(self, *names, **rename_map):\n",
      "   906|         0|            0|            0|  0.00%|        \"\"\"In-place version of :meth:`~Tensor.rename`.\"\"\"\n",
      "   907|         0|            0|            0|  0.00%|\n",
      "   908|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   909|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename_, (self,), self, *names, **rename_map)\n",
      "   910|         0|            0|            0|  0.00%|\n",
      "   911|         0|            0|            0|  0.00%|        # Note [rename_ / rename API]\n",
      "   912|         0|            0|            0|  0.00%|        # The Python API for these is different from the C++ API. In Python:\n",
      "   913|         0|            0|            0|  0.00%|        # 1) tensor.rename(*names) takes a vararglist of names\n",
      "   914|         0|            0|            0|  0.00%|        # 2) tensor.rename(**rename_map) takes a map of names to rename.\n",
      "   915|         0|            0|            0|  0.00%|        # C++ is static, making it difficult to implement similar behavior.\n",
      "   916|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=True)\n",
      "   917|         0|            0|            0|  0.00%|\n",
      "   918|         0|            0|            0|  0.00%|    def rename(self, *names, **rename_map):\n",
      "   919|         0|            0|            0|  0.00%|        \"\"\"Renames dimension names of :attr:`self`.\n",
      "   920|         0|            0|            0|  0.00%|\n",
      "   921|         0|            0|            0|  0.00%|        There are two main usages:\n",
      "   922|         0|            0|            0|  0.00%|\n",
      "   923|         0|            0|            0|  0.00%|        ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "   924|         0|            0|            0|  0.00%|        renamed as specified in the mapping :attr:`rename_map`.\n",
      "   925|         0|            0|            0|  0.00%|\n",
      "   926|         0|            0|            0|  0.00%|        ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "   927|         0|            0|            0|  0.00%|        dimensions positionally using :attr:`names`.\n",
      "   928|         0|            0|            0|  0.00%|        Use ``self.rename(None)`` to drop names on a tensor.\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|        One cannot specify both positional args :attr:`names` and keyword args\n",
      "   931|         0|            0|            0|  0.00%|        :attr:`rename_map`.\n",
      "   932|         0|            0|            0|  0.00%|\n",
      "   933|         0|            0|            0|  0.00%|        Examples::\n",
      "   934|         0|            0|            0|  0.00%|\n",
      "   935|         0|            0|            0|  0.00%|            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "   936|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "   937|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   938|         0|            0|            0|  0.00%|            ('batch', 'channels', 'H', 'W')\n",
      "   939|         0|            0|            0|  0.00%|\n",
      "   940|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(None)\n",
      "   941|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   942|         0|            0|            0|  0.00%|            (None,)\n",
      "   943|         0|            0|            0|  0.00%|\n",
      "   944|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "   945|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   946|         0|            0|            0|  0.00%|            ('batch', 'channel', 'height', 'width')\n",
      "   947|         0|            0|            0|  0.00%|\n",
      "   948|         0|            0|            0|  0.00%|        .. warning::\n",
      "   949|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   950|         0|            0|            0|  0.00%|\n",
      "   951|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   952|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   953|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename, (self,), self, *names, **rename_map)\n",
      "   954|         0|            0|            0|  0.00%|\n",
      "   955|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]\n",
      "   956|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=False)\n",
      "   957|         0|            0|            0|  0.00%|\n",
      "   958|         0|            0|            0|  0.00%|    def to_sparse_csr(self):\n",
      "   959|         0|            0|            0|  0.00%|        \"\"\" Convert a tensor to compressed row storage format. Only works with 2D tensors.\n",
      "   960|         0|            0|            0|  0.00%|\n",
      "   961|         0|            0|            0|  0.00%|        Examples::\n",
      "   962|         0|            0|            0|  0.00%|\n",
      "   963|         0|            0|            0|  0.00%|            >>> dense = torch.randn(5, 5)\n",
      "   964|         0|            0|            0|  0.00%|            >>> sparse = dense.to_sparse_csr()\n",
      "   965|         0|            0|            0|  0.00%|            >>> sparse._nnz()\n",
      "   966|         0|            0|            0|  0.00%|            25\n",
      "   967|         0|            0|            0|  0.00%|\n",
      "   968|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   969|         0|            0|            0|  0.00%|        shape = self.size()\n",
      "   970|         0|            0|            0|  0.00%|        fill_value = 0\n",
      "   971|         0|            0|            0|  0.00%|        if len(shape) != 2:\n",
      "   972|         0|            0|            0|  0.00%|            raise RuntimeError(\"Only 2D tensors can be converted to the CSR format but got shape: \", shape)\n",
      "   973|         0|            0|            0|  0.00%|\n",
      "   974|         0|            0|            0|  0.00%|        if self.is_sparse:\n",
      "   975|         0|            0|            0|  0.00%|            coalesced_self = self.coalesce()\n",
      "   976|         0|            0|            0|  0.00%|            row_indices = coalesced_self.indices()[0]\n",
      "   977|         0|            0|            0|  0.00%|            device = coalesced_self.values().device\n",
      "   978|         0|            0|            0|  0.00%|            crow_indices = torch._convert_indices_from_coo_to_csr(\n",
      "   979|         0|            0|            0|  0.00%|                row_indices, self.shape[0], out_int32=row_indices.dtype == torch.int32)\n",
      "   980|         0|            0|            0|  0.00%|            return torch.sparse_csr_tensor(crow_indices,\n",
      "   981|         0|            0|            0|  0.00%|                                           coalesced_self.indices()[1].contiguous(),\n",
      "   982|         0|            0|            0|  0.00%|                                           coalesced_self.values(),\n",
      "   983|         0|            0|            0|  0.00%|                                           size=coalesced_self.shape,\n",
      "   984|         0|            0|            0|  0.00%|                                           dtype=coalesced_self.dtype,\n",
      "   985|         0|            0|            0|  0.00%|                                           device=device)\n",
      "   986|         0|            0|            0|  0.00%|        elif self.is_sparse_csr:\n",
      "   987|         0|            0|            0|  0.00%|            return self\n",
      "   988|         0|            0|            0|  0.00%|        else:\n",
      "   989|         0|            0|            0|  0.00%|            return self.to_sparse().to_sparse_csr()\n",
      "   990|         0|            0|            0|  0.00%|\n",
      "   991|         0|            0|            0|  0.00%|    def _update_names(self, names, inplace):\n",
      "   992|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   993|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor._update_names, (self,), self, names, inplace)\n",
      "   994|         0|            0|            0|  0.00%|\n",
      "   995|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]\n",
      "   996|         0|            0|            0|  0.00%|        if inplace:\n",
      "   997|         0|            0|            0|  0.00%|            return super(Tensor, self).rename_(names)\n",
      "   998|         0|            0|            0|  0.00%|        else:\n",
      "   999|         0|            0|            0|  0.00%|            return super(Tensor, self).rename(names)\n",
      "  1000|         0|            0|            0|  0.00%|\n",
      "  1001|         0|            0|            0|  0.00%|    @property\n",
      "  1002|         0|            0|            0|  0.00%|    def grad(self):\n",
      "  1003|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1004|         0|            0|            0|  0.00%|        This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "  1005|         0|            0|            0|  0.00%|        :func:`backward` computes gradients for ``self``.\n",
      "  1006|         0|            0|            0|  0.00%|        The attribute will then contain the gradients computed and future calls to\n",
      "  1007|         0|            0|            0|  0.00%|        :func:`backward` will accumulate (add) gradients into it.\n",
      "  1008|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1009|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1010|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1011|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__get__, (self,), self)  # type: ignore[attr-defined]\n",
      "  1012|         0|            0|            0|  0.00%|\n",
      "  1013|         0|            0|            0|  0.00%|        return self._grad\n",
      "  1014|         0|            0|            0|  0.00%|\n",
      "  1015|         0|            0|            0|  0.00%|    @grad.setter\n",
      "  1016|         0|            0|            0|  0.00%|    def grad(self, new_grad):\n",
      "  1017|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1018|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1019|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__set__, (self,), self, new_grad)  # type: ignore[attr-defined]\n",
      "  1020|         0|            0|            0|  0.00%|        self._grad = new_grad\n",
      "  1021|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1022|         0|            0|            0|  0.00%|    @grad.deleter\n",
      "  1023|         0|            0|            0|  0.00%|    def grad(self):\n",
      "  1024|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1025|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1026|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__delete__, (self,), self)  # type: ignore[attr-defined]\n",
      "  1027|         0|            0|            0|  0.00%|        del self._grad\n",
      "  1028|         0|            0|            0|  0.00%|\n",
      "  1029|         0|            0|            0|  0.00%|    @classmethod\n",
      "  1030|         0|            0|            0|  0.00%|    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
      "  1031|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1032|         0|            0|            0|  0.00%|        This __torch_function__ implementation wraps subclasses such that\n",
      "  1033|         0|            0|            0|  0.00%|        methods called on subclasses return a subclass instance instead of\n",
      "  1034|         0|            0|            0|  0.00%|        a ``torch.Tensor`` instance.\n",
      "  1035|         0|            0|            0|  0.00%|\n",
      "  1036|         0|            0|            0|  0.00%|        One corollary to this is that you need coverage for torch.Tensor\n",
      "  1037|         0|            0|            0|  0.00%|        methods if implementing __torch_function__ for subclasses.\n",
      "  1038|         0|            0|            0|  0.00%|\n",
      "  1039|         0|            0|            0|  0.00%|        We recommend always calling ``super().__torch_function__`` as the base\n",
      "  1040|         0|            0|            0|  0.00%|        case when doing the above.\n",
      "  1041|         0|            0|            0|  0.00%|\n",
      "  1042|         0|            0|            0|  0.00%|        While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "  1043|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1044|         0|            0|            0|  0.00%|        if kwargs is None:\n",
      "  1045|         0|            0|            0|  0.00%|            kwargs = {}\n",
      "  1046|         0|            0|            0|  0.00%|\n",
      "  1047|         0|            0|            0|  0.00%|        if not all(issubclass(cls, t) for t in types):\n",
      "  1048|         0|            0|            0|  0.00%|            return NotImplemented\n",
      "  1049|         0|            0|            0|  0.00%|\n",
      "  1050|         0|            0|            0|  0.00%|        with _C.DisableTorchFunction():\n",
      "  1051|         0|            0|            0|  0.00%|            ret = func(*args, **kwargs)\n",
      "  1052|         0|            0|            0|  0.00%|            if func in get_default_nowrap_functions():\n",
      "  1053|         0|            0|            0|  0.00%|                return ret\n",
      "  1054|         0|            0|            0|  0.00%|            else:\n",
      "  1055|         0|            0|            0|  0.00%|                return _convert(ret, cls)\n",
      "  1056|         0|            0|            0|  0.00%|\n",
      "  1057|         0|            0|            0|  0.00%|    def __dlpack__(self, stream=None):\n",
      "  1058|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1059|         0|            0|            0|  0.00%|        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_\n",
      "  1060|         0|            0|            0|  0.00%|        of the current tensor to be exported to other libraries.\n",
      "  1061|         0|            0|            0|  0.00%|\n",
      "  1062|         0|            0|            0|  0.00%|        This function will be called from the `from_dlpack` method\n",
      "  1063|         0|            0|            0|  0.00%|        of the library that will consume the capsule. `from_dlpack` passes the current\n",
      "  1064|         0|            0|            0|  0.00%|        stream to this method as part of the specification.\n",
      "  1065|         0|            0|            0|  0.00%|\n",
      "  1066|         0|            0|            0|  0.00%|        Args:\n",
      "  1067|         0|            0|            0|  0.00%|            stream (integer or None): An optional Python integer representing a\n",
      "  1068|         0|            0|            0|  0.00%|            pointer to a CUDA stream. The current stream is synchronized with\n",
      "  1069|         0|            0|            0|  0.00%|            this stream before the capsule is created, and since the capsule\n",
      "  1070|         0|            0|            0|  0.00%|            shares its storage with the tensor this make it safe to access from\n",
      "  1071|         0|            0|            0|  0.00%|            both streams.  If None or -1 is passed then no synchronization is performed.\n",
      "  1072|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1073|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1074|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)\n",
      "  1075|         0|            0|            0|  0.00%|\n",
      "  1076|         0|            0|            0|  0.00%|        # DLPack capsules can't capture all of PyTorch's semantics,\n",
      "  1077|         0|            0|            0|  0.00%|        # so we prohibit exporting tensors that would lose their properties like\n",
      "  1078|         0|            0|            0|  0.00%|        # requires_grad and having the conjugate bit set.\n",
      "  1079|         0|            0|            0|  0.00%|        if self.requires_grad:\n",
      "  1080|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors that require gradient, use tensor.detach()')\n",
      "  1081|         0|            0|            0|  0.00%|        if self.is_conj():\n",
      "  1082|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors with the conjugate bit set')\n",
      "  1083|         0|            0|            0|  0.00%|        if self.layout != torch.strided:\n",
      "  1084|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors with layout other than torch.strided')\n",
      "  1085|         0|            0|            0|  0.00%|\n",
      "  1086|         0|            0|            0|  0.00%|        if stream is not None and type(stream) is not int:\n",
      "  1087|         0|            0|            0|  0.00%|            # Stream pointers in CUDA/ROCm are uniquely numbered and can\n",
      "  1088|         0|            0|            0|  0.00%|            # be retrieved from their integer value.\n",
      "  1089|         0|            0|            0|  0.00%|            raise TypeError('stream must be ``int`` or ``none``')\n",
      "  1090|         0|            0|            0|  0.00%|        elif stream is not None and stream != -1:\n",
      "  1091|         0|            0|            0|  0.00%|            if self.device.type == 'cuda':\n",
      "  1092|         0|            0|            0|  0.00%|                stream = torch.cuda.streams.ExternalStream(stream)\n",
      "  1093|         0|            0|            0|  0.00%|                # Only synchronize on different streams\n",
      "  1094|         0|            0|            0|  0.00%|                if stream != torch.cuda.current_stream:\n",
      "  1095|         0|            0|            0|  0.00%|                    event = torch.cuda.Event()\n",
      "  1096|         0|            0|            0|  0.00%|                    event.record(torch.cuda.current_stream())\n",
      "  1097|         0|            0|            0|  0.00%|                    stream.wait_event(event)\n",
      "  1098|         0|            0|            0|  0.00%|        return torch.to_dlpack(self)\n",
      "  1099|         0|            0|            0|  0.00%|\n",
      "  1100|         0|            0|            0|  0.00%|    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:\n",
      "  1101|         0|            0|            0|  0.00%|        # Avoid circular import\n",
      "  1102|         0|            0|            0|  0.00%|        from torch.utils.dlpack import DLDeviceType\n",
      "  1103|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1104|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)\n",
      "  1105|         0|            0|            0|  0.00%|        idx = self.device.index if self.device.index is not None else 0\n",
      "  1106|         0|            0|            0|  0.00%|        if self.device.type == 'cuda' and torch.version.hip is not None:\n",
      "  1107|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLROCM\n",
      "  1108|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu' and self.is_pinned():\n",
      "  1109|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPUPinned\n",
      "  1110|         0|            0|            0|  0.00%|        elif self.device.type == 'cuda':\n",
      "  1111|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLGPU\n",
      "  1112|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu':\n",
      "  1113|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPU\n",
      "  1114|         0|            0|            0|  0.00%|        else:\n",
      "  1115|         0|            0|            0|  0.00%|            raise ValueError('Unknown device type {} for Dlpack'.format(self.device.type))\n",
      "  1116|         0|            0|            0|  0.00%|        return (device_type, idx)\n",
      "  1117|         0|            0|            0|  0.00%|\n",
      "  1118|         0|            0|            0|  0.00%|    __module__ = 'torch'\n",
      "  1119|         0|            0|            0|  0.00%|\n",
      "  1120|         0|            0|            0|  0.00%|def _convert(ret, cls):\n",
      "  1121|         0|            0|            0|  0.00%|    if cls is Tensor:\n",
      "  1122|         0|            0|            0|  0.00%|        return ret\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    if isinstance(ret, Tensor) and not isinstance(ret, cls):\n",
      "  1125|         0|            0|            0|  0.00%|        ret = ret.as_subclass(cls)\n",
      "  1126|         0|            0|            0|  0.00%|\n",
      "  1127|         0|            0|            0|  0.00%|    if isinstance(ret, (tuple, list)):\n",
      "  1128|         0|            0|            0|  0.00%|        # Also handles things like namedtuples\n",
      "  1129|         0|            0|            0|  0.00%|        ret = type(ret)(_convert(r, cls) for r in ret)\n",
      "  1130|         0|            0|            0|  0.00%|\n",
      "  1131|         0|            0|            0|  0.00%|    return ret\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py\n",
      "File duration: 7.43866e-05s (0.03%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\"\"\"\n",
      "     2|         0|            0|            0|  0.00%|This makes the functions in torch._C._VariableFunctions available as\n",
      "     3|         0|            0|            0|  0.00%|    torch._VF.<funcname>\n",
      "     4|         0|            0|            0|  0.00%|without mypy being able to find them.\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|A subset of those functions are mapped to ATen functions in\n",
      "     7|         0|            0|            0|  0.00%|torch/jit/_builtins.py\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|See https://github.com/pytorch/pytorch/issues/21478 for the reason for\n",
      "    10|         0|            0|            0|  0.00%|introducing torch._VF\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|\"\"\"\n",
      "    13|         0|            0|            0|  0.00%|import torch\n",
      "    14|         0|            0|            0|  0.00%|import sys\n",
      "    15|         0|            0|            0|  0.00%|import types\n",
      "    16|         0|            0|            0|  0.00%|\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|class VFModule(types.ModuleType):\n",
      "    19|         0|            0|            0|  0.00%|    vf: types.ModuleType\n",
      "    20|         0|            0|            0|  0.00%|\n",
      "    21|         0|            0|            0|  0.00%|    def __init__(self, name):\n",
      "    22|         0|            0|            0|  0.00%|        super(VFModule, self).__init__(name)\n",
      "    23|         0|            0|            0|  0.00%|        self.vf = torch._C._VariableFunctions\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|        11|  2.67029e-05|  2.42753e-06|  0.01%|    def __getattr__(self, attr):\n",
      "    26|        11|  4.76837e-05|  4.33488e-06|  0.02%|        return getattr(self.vf, attr)\n",
      "    27|         0|            0|            0|  0.00%|\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|sys.modules[__name__] = VFModule(__name__)\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/_reduction.py\n",
      "File duration: 2.40803e-05s (0.01%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from typing import Optional\n",
      "     2|         0|            0|            0|  0.00%|import warnings\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|# NB: Keep this file in sync with enums in aten/src/ATen/core/Reduction.h\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         1|  4.29153e-06|  4.29153e-06|  0.00%|def get_enum(reduction: str) -> int:\n",
      "     8|         1|  1.09673e-05|  1.09673e-05|  0.00%|    if reduction == 'none':\n",
      "     9|         0|            0|            0|  0.00%|        ret = 0\n",
      "    10|         1|   3.8147e-06|   3.8147e-06|  0.00%|    elif reduction == 'mean':\n",
      "    11|         1|  3.09944e-06|  3.09944e-06|  0.00%|        ret = 1\n",
      "    12|         0|            0|            0|  0.00%|    elif reduction == 'elementwise_mean':\n",
      "    13|         0|            0|            0|  0.00%|        warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "    14|         0|            0|            0|  0.00%|        ret = 1\n",
      "    15|         0|            0|            0|  0.00%|    elif reduction == 'sum':\n",
      "    16|         0|            0|            0|  0.00%|        ret = 2\n",
      "    17|         0|            0|            0|  0.00%|    else:\n",
      "    18|         0|            0|            0|  0.00%|        ret = -1  # TODO: remove once JIT exceptions support control flow\n",
      "    19|         0|            0|            0|  0.00%|        raise ValueError(\"{} is not a valid value for reduction\".format(reduction))\n",
      "    20|         1|  1.90735e-06|  1.90735e-06|  0.00%|    return ret\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|# In order to support previous versions, accept boolean size_average and reduce\n",
      "    23|         0|            0|            0|  0.00%|# and convert them into the new constants for now\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|# We use these functions in torch/legacy as well, in which case we'll silence the warning\n",
      "    27|         0|            0|            0|  0.00%|def legacy_get_string(size_average: Optional[bool], reduce: Optional[bool], emit_warning: bool = True) -> str:\n",
      "    28|         0|            0|            0|  0.00%|    warning = \"size_average and reduce args will be deprecated, please use reduction='{}' instead.\"\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|    if size_average is None:\n",
      "    31|         0|            0|            0|  0.00%|        size_average = True\n",
      "    32|         0|            0|            0|  0.00%|    if reduce is None:\n",
      "    33|         0|            0|            0|  0.00%|        reduce = True\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    if size_average and reduce:\n",
      "    36|         0|            0|            0|  0.00%|        ret = 'mean'\n",
      "    37|         0|            0|            0|  0.00%|    elif reduce:\n",
      "    38|         0|            0|            0|  0.00%|        ret = 'sum'\n",
      "    39|         0|            0|            0|  0.00%|    else:\n",
      "    40|         0|            0|            0|  0.00%|        ret = 'none'\n",
      "    41|         0|            0|            0|  0.00%|    if emit_warning:\n",
      "    42|         0|            0|            0|  0.00%|        warnings.warn(warning.format(ret))\n",
      "    43|         0|            0|            0|  0.00%|    return ret\n",
      "    44|         0|            0|            0|  0.00%|\n",
      "    45|         0|            0|            0|  0.00%|\n",
      "    46|         0|            0|            0|  0.00%|def legacy_get_enum(size_average: Optional[bool], reduce: Optional[bool], emit_warning: bool = True) -> int:\n",
      "    47|         0|            0|            0|  0.00%|    return get_enum(legacy_get_string(size_average, reduce, emit_warning))\n",
      "File: <string>\n",
      "File duration: 2.02656e-05s (0.01%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         2|  5.24521e-06|   2.6226e-06|  0.00%|\n",
      "    13|         0|            0|            0|  0.00%|\n",
      "    14|         2|  1.50204e-05|  7.51019e-06|  0.01%|\n",
      "File: /Users/sr_old/Desktop/sr2/sr2_functions_new.py\n",
      "File duration: 0s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|# TODO: Tensorboard? Or functionality to collect and plot gradients?\n",
      "     2|         0|            0|            0|  0.00%|# clip gradients?\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|\n",
      "     5|         0|            0|            0|  0.00%|colab = False\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|#print(__name__)\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|# Things we set here:\n",
      "    12|         0|            0|            0|  0.00%|#   terminal_output -- where to print\n",
      "    13|         0|            0|            0|  0.00%|#   optimizer\n",
      "    14|         0|            0|            0|  0.00%|#\n",
      "    15|         0|            0|            0|  0.00%|# arbitrary constants: 1000\n",
      "    16|         0|            0|            0|  0.00%|# clip grad norm, patience, big validation loss (twice), training losses placeholder\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|import pprofile\n",
      "    20|         0|            0|            0|  0.00%|profiler = pprofile.Profile()\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|import random\n",
      "    24|         0|            0|            0|  0.00%|from statistics import stdev\n",
      "    25|         0|            0|            0|  0.00%|from random import choice\n",
      "    26|         0|            0|            0|  0.00%|import numpy as np\n",
      "    27|         0|            0|            0|  0.00%|import matplotlib.pyplot as plt\n",
      "    28|         0|            0|            0|  0.00%|from matplotlib.pyplot import rcParams\n",
      "    29|         0|            0|            0|  0.00%|plt.style.use('ggplot')\n",
      "    30|         0|            0|            0|  0.00%|from sympy import *\n",
      "    31|         0|            0|            0|  0.00%|from collections import Counter\n",
      "    32|         0|            0|            0|  0.00%|from sklearn.manifold import TSNE\n",
      "    33|         0|            0|            0|  0.00%|import math\n",
      "    34|         0|            0|            0|  0.00%|from matplotlib.ticker import FuncFormatter\n",
      "    35|         0|            0|            0|  0.00%|import torch\n",
      "    36|         0|            0|            0|  0.00%|from torch.utils.data import DataLoader\n",
      "    37|         0|            0|            0|  0.00%|import torch.optim as optim\n",
      "    38|         0|            0|            0|  0.00%|import datetime\n",
      "    39|         0|            0|            0|  0.00%|import os\n",
      "    40|         0|            0|            0|  0.00%|import sys\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|torch.manual_seed(42)\n",
      "    43|         0|            0|            0|  0.00%|np.random.seed(42)\n",
      "    44|         0|            0|            0|  0.00%|random.seed(0)\n",
      "    45|         0|            0|            0|  0.00%|\n",
      "    46|         0|            0|            0|  0.00%|\n",
      "    47|         0|            0|            0|  0.00%|terminal_output = sys.stdout\n",
      "    48|         0|            0|            0|  0.00%|\n",
      "    49|         0|            0|            0|  0.00%|#if colab:\n",
      "    50|         0|            0|            0|  0.00%|#    terminal_output = sys.stdout\n",
      "    51|         0|            0|            0|  0.00%|#else:\n",
      "    52|         0|            0|            0|  0.00%|#     this outputs to terminal\n",
      "    53|         0|            0|            0|  0.00%|#    terminal_output = open('/dev/stdout', 'w')\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|if colab:\n",
      "    57|         0|            0|            0|  0.00%|    from google.colab import files\n",
      "    58|         0|            0|            0|  0.00%|\n",
      "    59|         0|            0|            0|  0.00%|# if server!?\n",
      "    60|         0|            0|            0|  0.00%|\n",
      "    61|         0|            0|            0|  0.00%|\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|####################################################################################################\n",
      "    64|         0|            0|            0|  0.00%|## Equations/data utilities\n",
      "    65|         0|            0|            0|  0.00%|####################################################################################################\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|def lambdifier(expr, nvars):\n",
      "    68|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "    69|         0|            0|            0|  0.00%|    # get an expression that accepts numpy\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|    v_names = [\"x\" + str(k) for k in range(nvars)]\n",
      "    72|         0|            0|            0|  0.00%|    for name in v_names:\n",
      "    73|         0|            0|            0|  0.00%|        globals()[name] = symbols(name)\n",
      "    74|         0|            0|            0|  0.00%|\n",
      "    75|         0|            0|            0|  0.00%|    # the case when f_d is just a number\n",
      "    76|         0|            0|            0|  0.00%|    if len(expr.free_symbols) == 0:\n",
      "    77|         0|            0|            0|  0.00%|        return round(float(expr), 2)\n",
      "    78|         0|            0|            0|  0.00%|\n",
      "    79|         0|            0|            0|  0.00%|    expr_np = lambdify([globals()[name] for name in v_names], expr)\n",
      "    80|         0|            0|            0|  0.00%|\n",
      "    81|         0|            0|            0|  0.00%|    return expr_np\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|def subber(matchobj, items, item_probs):\n",
      "    85|         0|            0|            0|  0.00%|    # 17NOV21\n",
      "    86|         0|            0|            0|  0.00%|    # this function does not depend on matchobj, but it needs to be there as a variable\n",
      "    87|         0|            0|            0|  0.00%|    # sample one of the items and return\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|    # item_probs are allowed not sum to 1, but must be between 1 and 0\n",
      "    90|         0|            0|            0|  0.00%|    out = items[np.argmax(np.random.multinomial(1, item_probs))]\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    return out\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|def illustrator_list(lengths, strn, bins = 150):\n",
      "    95|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "    96|         0|            0|            0|  0.00%|    # lengths = [len(k) for k in texts]\n",
      "    97|         0|            0|            0|  0.00%|    # round entries beforehand!\n",
      "    98|         0|            0|            0|  0.00%|\n",
      "    99|         0|            0|            0|  0.00%|    print(\"\")\n",
      "   100|         0|            0|            0|  0.00%|    print(\"corpus size,    min,    max:\")\n",
      "   101|         0|            0|            0|  0.00%|    print((len(lengths), min(lengths), max(lengths)))\n",
      "   102|         0|            0|            0|  0.00%|    print(\"mean:\")\n",
      "   103|         0|            0|            0|  0.00%|    print(round(sum(lengths) / len(lengths), 2))\n",
      "   104|         0|            0|            0|  0.00%|    #print(\"mode:\")\n",
      "   105|         0|            0|            0|  0.00%|    #print(max(set(lengths), key=lengths.count))\n",
      "   106|         0|            0|            0|  0.00%|    print(\"SD:\")\n",
      "   107|         0|            0|            0|  0.00%|    print(stdev(lengths))\n",
      "   108|         0|            0|            0|  0.00%|    print(\"min tail:\")\n",
      "   109|         0|            0|            0|  0.00%|    S = sorted(lengths, reverse=False)\n",
      "   110|         0|            0|            0|  0.00%|    print(S[:10])\n",
      "   111|         0|            0|            0|  0.00%|    print(\"max tail:\")\n",
      "   112|         0|            0|            0|  0.00%|    print(S[:10])\n",
      "   113|         0|            0|            0|  0.00%|    print(\"\")\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|    a = np.array(lengths)\n",
      "   116|         0|            0|            0|  0.00%|    rcParams['figure.figsize'] = 5, 5\n",
      "   117|         0|            0|            0|  0.00%|    plt.hist(a, bins=bins)\n",
      "   118|         0|            0|            0|  0.00%|    plt.title(strn + \"\\nN = \" + str(len(lengths)), fontsize=15)\n",
      "   119|         0|            0|            0|  0.00%|    plt.grid(True)\n",
      "   120|         0|            0|            0|  0.00%|    plt.ylabel(\"Number of items\", fontsize = 15)\n",
      "   121|         0|            0|            0|  0.00%|    # here set the plot range\n",
      "   122|         0|            0|            0|  0.00%|#    plt.xlim([0.0, 50.0])\n",
      "   123|         0|            0|            0|  0.00%|#    plt.xticks(range(0, 50, 4))\n",
      "   124|         0|            0|            0|  0.00%|\n",
      "   125|         0|            0|            0|  0.00%|    plt.tick_params(labelsize=12)\n",
      "   126|         0|            0|            0|  0.00%|    plt.show()\n",
      "   127|         0|            0|            0|  0.00%|\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|\n",
      "   130|         0|            0|            0|  0.00%|\n",
      "   131|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   132|         0|            0|            0|  0.00%|## PyTorch functions\n",
      "   133|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   134|         0|            0|            0|  0.00%|\n",
      "   135|         0|            0|            0|  0.00%|def batcher(dataset, bsize):\n",
      "   136|         0|            0|            0|  0.00%|    # 9MAY22\n",
      "   137|         0|            0|            0|  0.00%|    # go from a dataset object to batches without using a data loader\n",
      "   138|         0|            0|            0|  0.00%|    indexes = range(0, len(dataset), bsize)\n",
      "   139|         0|            0|            0|  0.00%|    for i in indexes:\n",
      "   140|         0|            0|            0|  0.00%|        yield dataset[i:i+bsize]\n",
      "   141|         0|            0|            0|  0.00%|\n",
      "   142|         0|            0|            0|  0.00%|\n",
      "   143|         0|            0|            0|  0.00%|\n",
      "   144|         0|            0|            0|  0.00%|def train_epoch(model, lossmaker, train_loader, optimizers, acc_steps, device, epoch):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   145|         0|            0|            0|  0.00%|    # 16APR22\n",
      "   146|         0|            0|            0|  0.00%|    # runs through the training set once and trains the model using batches\n",
      "   147|         0|            0|            0|  0.00%|    # collects and returns batch losses as a list\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         0|            0|            0|  0.00%|    model.train()\n",
      "   150|         0|            0|            0|  0.00%|    i = 1\n",
      "   151|         0|            0|            0|  0.00%|    loss_item = 0\n",
      "   152|         0|            0|            0|  0.00%|    losses = []\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|\n",
      "   155|         0|            0|            0|  0.00%|    for x, y in train_loader:\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         0|            0|            0|  0.00%|        # reassignment ok, yes?\n",
      "   158|         0|            0|            0|  0.00%|        # because we call .backward() and destroy computation graph?\n",
      "   159|         0|            0|            0|  0.00%|\n",
      "   160|         0|            0|            0|  0.00%|        with profiler:\n",
      "   161|         0|            0|            0|  0.00%|            loss = lossmaker(x, y, model, device, epoch)/acc_steps\n",
      "(call)|         1|    0.0883031|    0.0883031| 39.12%|# <ipython-input-176-5d68b8565542>:1 lossmaker1\n",
      "   162|         0|            0|            0|  0.00%|            loss.backward()\n",
      "(call)|         1|     0.116268|     0.116268| 51.50%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_tensor.py:251 backward\n",
      "   163|         0|            0|            0|  0.00%|\n",
      "   164|         0|            0|            0|  0.00%|            profiler.print_stats()\n",
      "   165|         0|            0|            0|  0.00%|        loss_item = loss_item + loss.item()\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|        if i % acc_steps == 0:\n",
      "   168|         0|            0|            0|  0.00%|            # clip gradients here\n",
      "   169|         0|            0|            0|  0.00%|            torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
      "   170|         0|            0|            0|  0.00%|            # update model parameters\n",
      "   171|         0|            0|            0|  0.00%|            [k.step() for k in optimizers]\n",
      "   172|         0|            0|            0|  0.00%|            # erase gradients\n",
      "   173|         0|            0|            0|  0.00%|            #[k.zero_grad() for k in optimizers]\n",
      "   174|         0|            0|            0|  0.00%|            model.zero_grad(set_to_none=True)\n",
      "   175|         0|            0|            0|  0.00%|            # save full_batch loss\n",
      "   176|         0|            0|            0|  0.00%|            losses.append(loss_item)\n",
      "   177|         0|            0|            0|  0.00%|            loss_item = 0\n",
      "   178|         0|            0|            0|  0.00%|\n",
      "   179|         0|            0|            0|  0.00%|        i = i + 1\n",
      "   180|         0|            0|            0|  0.00%|\n",
      "   181|         0|            0|            0|  0.00%|    return losses\n",
      "   182|         0|            0|            0|  0.00%|\n",
      "   183|         0|            0|            0|  0.00%|\n",
      "   184|         0|            0|            0|  0.00%|def epochend_lcalc(model, lossmaker, loader, device, epoch):\n",
      "   185|         0|            0|            0|  0.00%|    # 17APR22\n",
      "   186|         0|            0|            0|  0.00%|    # this function returns the train or validation loss (e.g. at the end of an epoch, or for evaluation)\n",
      "   187|         0|            0|            0|  0.00%|    # the loader given can be either train or val\n",
      "   188|         0|            0|            0|  0.00%|    # here the model is in evaluation mode, so training loss could come out a bit shifted wrt batch evals (?)\n",
      "   189|         0|            0|            0|  0.00%|    # you could code up e.g. accuracy here as well\n",
      "   190|         0|            0|            0|  0.00%|\n",
      "   191|         0|            0|            0|  0.00%|    model.eval()\n",
      "   192|         0|            0|            0|  0.00%|\n",
      "   193|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "   194|         0|            0|            0|  0.00%|        losses = []\n",
      "   195|         0|            0|            0|  0.00%|\n",
      "   196|         0|            0|            0|  0.00%|        for x, y in loader:\n",
      "   197|         0|            0|            0|  0.00%|            loss_item = lossmaker(x, y, model, device, epoch).item()\n",
      "   198|         0|            0|            0|  0.00%|            losses.append(loss_item)\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         0|            0|            0|  0.00%|    # we average the batch losses, this requires loss additivity of the right kind\n",
      "   201|         0|            0|            0|  0.00%|    return np.mean(losses)\n",
      "   202|         0|            0|            0|  0.00%|\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|def run_model(train_dataset, val_dataset, model_class, lossmaker, device,\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|              lrate, bsize, acc_steps, bsize_eval, epochs, patience = 1000, ratio = 1,\n",
      "   210|         0|            0|            0|  0.00%|\n",
      "   211|         0|            0|            0|  0.00%|              # for saving BOTH the learning curve and the model\n",
      "   212|         0|            0|            0|  0.00%|              save=False, path=\"\", atlas = False,\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|                # we pass these (= the rest) to the model class\n",
      "   215|         0|            0|            0|  0.00%|                **kwargs\n",
      "   216|         0|            0|            0|  0.00%|\n",
      "   217|         0|            0|            0|  0.00%|              ):\n",
      "   218|         0|            0|            0|  0.00%|    # 17APR22\n",
      "   219|         0|            0|            0|  0.00%|    # instantiate and run the model, return the final performance figure, plot the curves\n",
      "   220|         0|            0|            0|  0.00%|    # this is meant to run well both on its own and within a loop for atlases or a loop for optimization\n",
      "   221|         0|            0|            0|  0.00%|    # we leave explicit the parameters that will exist regardless of the model type\n",
      "   222|         0|            0|            0|  0.00%|    # TODO: leave optimizer choice here?\n",
      "   223|         0|            0|            0|  0.00%|    # LR scheduling?\n",
      "   224|         0|            0|            0|  0.00%|    # you could return predictions as well!?\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    global model_path, epoch\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    # MAKE_MODEL_HERE\n",
      "   229|         0|            0|            0|  0.00%|    m = model_class(**kwargs, device = device).to(device)\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|    # truncate the dictionary:\n",
      "   232|         0|            0|            0|  0.00%|    del kwargs['vocab']\n",
      "   233|         0|            0|            0|  0.00%|    del kwargs['vocab_out']\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    t = \"{:.0e}\".format(lrate) + '_' + str(ratio) + \"_\"  + str(bsize * acc_steps) + '_' + str(kwargs).replace(\" \", \"\")\n",
      "   236|         0|            0|            0|  0.00%|    t = \"{:.0e}\".format(lrate) + '_' + str(ratio) + \"_\"  + str(bsize * acc_steps) + '_' + str(kwargs).replace(\" \", \"\")\n",
      "   237|         0|            0|            0|  0.00%|    modelpath = path + \"/models\"\n",
      "   238|         0|            0|            0|  0.00%|    atlaspath = path + \"/atlases\"\n",
      "   239|         0|            0|            0|  0.00%|\n",
      "   240|         0|            0|            0|  0.00%|    if colab:\n",
      "   241|         0|            0|            0|  0.00%|        modelpath = '/content/gdrive/MyDrive/' + modelpath\n",
      "   242|         0|            0|            0|  0.00%|        atlaspath = '/content/gdrive/MyDrive/' + atlaspath\n",
      "   243|         0|            0|            0|  0.00%|        # print(modelpath)\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    if save:\n",
      "   246|         0|            0|            0|  0.00%|        os.makedirs(path, exist_ok=True)\n",
      "   247|         0|            0|            0|  0.00%|        os.makedirs(modelpath, exist_ok=True)\n",
      "   248|         0|            0|            0|  0.00%|        os.makedirs(atlaspath, exist_ok=True)\n",
      "   249|         0|            0|            0|  0.00%|        model_path = os.path.join(modelpath, t + \".pt\")\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         0|            0|            0|  0.00%|        pic_path = os.path.join(path, t + \".png\")\n",
      "   252|         0|            0|            0|  0.00%|        if colab:\n",
      "   253|         0|            0|            0|  0.00%|            pic_path = os.path.join('/content/gdrive/MyDrive/' + path, t + \".png\")\n",
      "   254|         0|            0|            0|  0.00%|            #print(pic_path)\n",
      "   255|         0|            0|            0|  0.00%|        if atlas:\n",
      "   256|         0|            0|            0|  0.00%|            pic_path = os.path.join(atlaspath, t + \".png\")\n",
      "   257|         0|            0|            0|  0.00%|\n",
      "   258|         0|            0|            0|  0.00%|\n",
      "   259|         0|            0|            0|  0.00%|    start_time = datetime.datetime.now()\n",
      "   260|         0|            0|            0|  0.00%|\n",
      "   261|         0|            0|            0|  0.00%|\n",
      "   262|         0|            0|            0|  0.00%| #   train_loader = DataLoader(train_dataset, batch_size=bsize, shuffle=False)\n",
      "   263|         0|            0|            0|  0.00%| #   train_loader_epochend = DataLoader(train_dataset, batch_size=bsize_eval, shuffle=False)\n",
      "   264|         0|            0|            0|  0.00%| #   val_loader_epochend = DataLoader(val_dataset, batch_size=bsize_eval, shuffle=False)\n",
      "   265|         0|            0|            0|  0.00%|\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|    #optimizer = optim.SGD(m.parameters(), lr=lrate)\n",
      "   268|         0|            0|            0|  0.00%|    #optimizers = [optim.Adam(m.parameters(), lr=lrate)]\n",
      "   269|         0|            0|            0|  0.00%|    optimizers = [optim.Adam(m.encoder.parameters(), lr=lrate), optim.Adam(m.decoder.parameters(), lr=lrate*ratio)]\n",
      "   270|         0|            0|            0|  0.00%|\n",
      "   271|         0|            0|            0|  0.00%|\n",
      "   272|         0|            0|            0|  0.00%|    training_losses_full = []\n",
      "   273|         0|            0|            0|  0.00%|\n",
      "   274|         0|            0|            0|  0.00%|    # these two are introduced for cleaner code: to be deleted later\n",
      "   275|         0|            0|            0|  0.00%|    training_losses = [1000]\n",
      "   276|         0|            0|            0|  0.00%|    val_losses = [1000]\n",
      "   277|         0|            0|            0|  0.00%|\n",
      "   278|         0|            0|            0|  0.00%|    ref_val_loss = 1000\n",
      "   279|         0|            0|            0|  0.00%|    trigger_times = 0\n",
      "   280|         0|            0|            0|  0.00%|    patience = patience\n",
      "   281|         0|            0|            0|  0.00%|\n",
      "   282|         0|            0|            0|  0.00%|    for epoch in range(epochs):\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Starting epoch \" + str(epoch), file=terminal_output)\n",
      "   285|         0|            0|            0|  0.00%|\n",
      "   286|         0|            0|            0|  0.00%|        # TRAINING\n",
      "   287|         0|            0|            0|  0.00%|        training_losses_full += train_epoch(m, lossmaker, batcher(train_dataset, bsize), optimizers, acc_steps, device, epoch)\n",
      "   288|         0|            0|            0|  0.00%|\n",
      "   289|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Calculating figures\", file=terminal_output)\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|        # END-OF-EPOCH loss figures\n",
      "   292|         0|            0|            0|  0.00%|\n",
      "   293|         0|            0|            0|  0.00%|        train_loss = epochend_lcalc(m, lossmaker, batcher(train_dataset, bsize_eval), device, epoch)\n",
      "   294|         0|            0|            0|  0.00%|        training_losses.append(train_loss)\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|        val_loss = epochend_lcalc(m, lossmaker, batcher(val_dataset, bsize_eval), device, epoch)\n",
      "   297|         0|            0|            0|  0.00%|\n",
      "   298|         0|            0|            0|  0.00%|        # print(train_loss, val_loss)\n",
      "   299|         0|            0|            0|  0.00%|\n",
      "   300|         0|            0|            0|  0.00%|        # FIRST: save model if current val_loss is the best so far\n",
      "   301|         0|            0|            0|  0.00%|        if val_loss <= min(val_losses):\n",
      "   302|         0|            0|            0|  0.00%|            if save:\n",
      "   303|         0|            0|            0|  0.00%|               #2+3\n",
      "   304|         0|            0|            0|  0.00%|                torch.save(m.state_dict(), model_path)\n",
      "   305|         0|            0|            0|  0.00%|\n",
      "   306|         0|            0|            0|  0.00%|        # SECOND: do the early stopping thing\n",
      "   307|         0|            0|            0|  0.00%|        if val_loss > ref_val_loss:\n",
      "   308|         0|            0|            0|  0.00%|            trigger_times += 1\n",
      "   309|         0|            0|            0|  0.00%|            # here possibly introduce lr scheduling\n",
      "   310|         0|            0|            0|  0.00%|            # optimizer =\n",
      "   311|         0|            0|            0|  0.00%|            if trigger_times == patience:\n",
      "   312|         0|            0|            0|  0.00%|                val_losses.append(val_loss)\n",
      "   313|         0|            0|            0|  0.00%|                print('Early stopping after completing epoch '+ str(epoch))\n",
      "   314|         0|            0|            0|  0.00%|                #print(val_losses)\n",
      "   315|         0|            0|            0|  0.00%|                break\n",
      "   316|         0|            0|            0|  0.00%|            else:\n",
      "   317|         0|            0|            0|  0.00%|                val_losses.append(val_loss)\n",
      "   318|         0|            0|            0|  0.00%|        else:\n",
      "   319|         0|            0|            0|  0.00%|            trigger_times = 0\n",
      "   320|         0|            0|            0|  0.00%|            ref_val_loss = val_loss\n",
      "   321|         0|            0|            0|  0.00%|            val_losses.append(val_loss)\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Ending epoch \" + str(epoch) +\n",
      "   324|         0|            0|            0|  0.00%|              \"    train_loss: \" + str(np.round(training_losses[-1], 2)) +\n",
      "   325|         0|            0|            0|  0.00%|              \"   val_loss: \" + str(np.round(val_losses[-1], 2)), file=terminal_output)\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|\n",
      "   328|         0|            0|            0|  0.00%|\n",
      "   329|         0|            0|            0|  0.00%|    end_time = datetime.datetime.now()\n",
      "   330|         0|            0|            0|  0.00%|\n",
      "   331|         0|            0|            0|  0.00%|\n",
      "   332|         0|            0|            0|  0.00%|    val_losses = val_losses[1:]\n",
      "   333|         0|            0|            0|  0.00%|    training_losses = training_losses[1:]\n",
      "   334|         0|            0|            0|  0.00%|\n",
      "   335|         0|            0|            0|  0.00%|    TLOSS = np.round(np.array(training_losses).min(), 4)\n",
      "   336|         0|            0|            0|  0.00%|    VLOSS = np.round(np.array(val_losses).min(), 4)\n",
      "   337|         0|            0|            0|  0.00%|\n",
      "   338|         0|            0|            0|  0.00%|\n",
      "   339|         0|            0|            0|  0.00%|    x = range(1, len(training_losses_full) + 1)\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|    # here we multiply an \"epochs\" array with the number of batch evaluations per epoch\n",
      "   342|         0|            0|            0|  0.00%|    # dataset of 70 and bsize of 20 gives 4 batch evaluations per epoch\n",
      "   343|         0|            0|            0|  0.00%|    # eps = np.arange(1, len(validation_losses) + 1) * math.ceil(len(train_dataset) / (bsize))\n",
      "   344|         0|            0|            0|  0.00%|    # now modify for the gradient accumulation thing:\n",
      "   345|         0|            0|            0|  0.00%|    # // integer division, / float division\n",
      "   346|         0|            0|            0|  0.00%|\n",
      "   347|         0|            0|            0|  0.00%|    evals_per_epoch = math.ceil(len(train_dataset) / (bsize))//acc_steps\n",
      "   348|         0|            0|            0|  0.00%|    #print(\"estimated\")\n",
      "   349|         0|            0|            0|  0.00%|    #print(evals_per_epoch)\n",
      "   350|         0|            0|            0|  0.00%|    #print(\"actual\")\n",
      "   351|         0|            0|            0|  0.00%|    #print(len(training_losses_full)/len(val_losses))\n",
      "   352|         0|            0|            0|  0.00%|    eps = np.arange(1, len(val_losses) + 1) * evals_per_epoch\n",
      "   353|         0|            0|            0|  0.00%|\n",
      "   354|         0|            0|            0|  0.00%|    plt.style.use('default')\n",
      "   355|         0|            0|            0|  0.00%|    rcParams['grid.linestyle'] = \"dotted\"\n",
      "   356|         0|            0|            0|  0.00%|    rcParams['figure.figsize'] = 4, 4\n",
      "   357|         0|            0|            0|  0.00%|\n",
      "   358|         0|            0|            0|  0.00%|\n",
      "   359|         0|            0|            0|  0.00%|    plt.plot(x, training_losses_full, 'r', label='tr_loss_full')  # , linewidth=0.8)\n",
      "   360|         0|            0|            0|  0.00%|    plt.plot(eps, training_losses, 'o-', label='tr_loss', color=\"green\", markersize=4)\n",
      "   361|         0|            0|            0|  0.00%|    plt.plot(eps, val_losses, 'o-', label='val_loss', color=\"blue\", markersize=4)\n",
      "   362|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"best tr_loss:\\n\" + str(TLOSS))\n",
      "   363|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"best val_loss:\\n\" + str(VLOSS))\n",
      "   364|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"duration:\\n\" + str(end_time - start_time)[0:4])\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    plt.legend(fontsize=9)\n",
      "   367|         0|            0|            0|  0.00%|\n",
      "   368|         0|            0|            0|  0.00%|    ###############################\n",
      "   369|         0|            0|            0|  0.00%|    axes = plt.gca()\n",
      "   370|         0|            0|            0|  0.00%|    # this is LR\n",
      "   371|         0|            0|            0|  0.00%|    # axes.set_ylim([0, 0.5])\n",
      "   372|         0|            0|            0|  0.00%|\n",
      "   373|         0|            0|            0|  0.00%|    axes.set_ylim([0, 8])\n",
      "   374|         0|            0|            0|  0.00%|\n",
      "   375|         0|            0|            0|  0.00%|    scientific_formatter = FuncFormatter(scientific)\n",
      "   376|         0|            0|            0|  0.00%|    plt.gca().xaxis.set_major_formatter(scientific_formatter)\n",
      "   377|         0|            0|            0|  0.00%|    plt.xticks(rotation=45)\n",
      "   378|         0|            0|            0|  0.00%|    plt.grid(color='black')\n",
      "   379|         0|            0|            0|  0.00%|    axes.set_axisbelow(False)\n",
      "   380|         0|            0|            0|  0.00%|\n",
      "   381|         0|            0|            0|  0.00%|\n",
      "   382|         0|            0|            0|  0.00%|    plt.title(\n",
      "   383|         0|            0|            0|  0.00%|        'lrate:' + \"{:.0e}\".format(lrate) + ', ratio:' + str(ratio) +  ', bsize:' + str(bsize*acc_steps) + ', \\n'\n",
      "   384|         0|            0|            0|  0.00%|        + 'n_epochs:' + str(epoch+1) + ', train:' + str(len(train_dataset)) + ', val:' + str(len(val_dataset)) + ', \\n'\n",
      "   385|         0|            0|            0|  0.00%|             + str(kwargs)[:40] + '\\n' + str(kwargs)[40:],\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|        fontsize=9\n",
      "   388|         0|            0|            0|  0.00%|    )\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    plt.tight_layout()\n",
      "   391|         0|            0|            0|  0.00%|\n",
      "   392|         0|            0|            0|  0.00%|    if save == True:\n",
      "   393|         0|            0|            0|  0.00%|        plt.savefig(pic_path)\n",
      "   394|         0|            0|            0|  0.00%|      #  if colab:\n",
      "   395|         0|            0|            0|  0.00%|      #      p = os.path.normpath(pic_path)\n",
      "   396|         0|            0|            0|  0.00%|      #      plt.savefig(p)\n",
      "   397|         0|            0|            0|  0.00%|      #      files.download(p)\n",
      "   398|         0|            0|            0|  0.00%|\n",
      "   399|         0|            0|            0|  0.00%|    print(\"\", file=terminal_output)\n",
      "   400|         0|            0|            0|  0.00%|    print(\"best training_loss = %s, best validation_loss = %s\" % (TLOSS, VLOSS), file=terminal_output)\n",
      "   401|         0|            0|            0|  0.00%|    print('Duration_: {}'.format(end_time - start_time), file=terminal_output)\n",
      "   402|         0|            0|            0|  0.00%|\n",
      "   403|         0|            0|            0|  0.00%|    print(\"best training_loss = %s, best validation_loss = %s\" % (TLOSS, VLOSS))\n",
      "   404|         0|            0|            0|  0.00%|    print('Duration_: {}'.format(end_time - start_time))\n",
      "   405|         0|            0|            0|  0.00%|\n",
      "   406|         0|            0|            0|  0.00%|    print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  END RUN_MODEL CALL\", file=terminal_output)\n",
      "   407|         0|            0|            0|  0.00%|    print(\"\", file=terminal_output)\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|\n",
      "   410|         0|            0|            0|  0.00%|    return (TLOSS, VLOSS)\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|\n",
      "   413|         0|            0|            0|  0.00%|\n",
      "   414|         0|            0|            0|  0.00%|\n",
      "   415|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   416|         0|            0|            0|  0.00%|## other utils\n",
      "   417|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   418|         0|            0|            0|  0.00%|\n",
      "   419|         0|            0|            0|  0.00%|\n",
      "   420|         0|            0|            0|  0.00%|def unison_shuffler(a, b, rng):\n",
      "   421|         0|            0|            0|  0.00%|    # only np arrays accepted?\n",
      "   422|         0|            0|            0|  0.00%|    assert len(a) == len(b)\n",
      "   423|         0|            0|            0|  0.00%|    p = rng.permutation(len(a))\n",
      "   424|         0|            0|            0|  0.00%|    return a[p], b[p]\n",
      "   425|         0|            0|            0|  0.00%|\n",
      "   426|         0|            0|            0|  0.00%|def scientific(x, pos):\n",
      "   427|         0|            0|            0|  0.00%|    # x:  tick value - ie. what you currently see in yticks\n",
      "   428|         0|            0|            0|  0.00%|    # pos: a position - ie. the index of the tick (from 0 to 9 in this example)\n",
      "   429|         0|            0|            0|  0.00%|    return '%.1E' % x\n",
      "   430|         0|            0|            0|  0.00%|\n",
      "   431|         0|            0|            0|  0.00%|\n",
      "   432|         0|            0|            0|  0.00%|def clean_list(l, index):\n",
      "   433|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "   434|         0|            0|            0|  0.00%|    # this is needed for beam search\n",
      "   435|         0|            0|            0|  0.00%|    # return e.g. [576, [576, 619, 1050]] cleaned up\n",
      "   436|         0|            0|            0|  0.00%|    #            with the last bit according to the expansion index\n",
      "   437|         0|            0|            0|  0.00%|\n",
      "   438|         0|            0|            0|  0.00%|    last_element = l[-1]\n",
      "   439|         0|            0|            0|  0.00%|\n",
      "   440|         0|            0|            0|  0.00%|    if type(last_element) != list:\n",
      "   441|         0|            0|            0|  0.00%|        assert index == 0\n",
      "   442|         0|            0|            0|  0.00%|        return l\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|    last_element = last_element[index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   445|         0|            0|            0|  0.00%|\n",
      "   446|         0|            0|            0|  0.00%|    out = l[:-1]\n",
      "   447|         0|            0|            0|  0.00%|    out.append(last_element)\n",
      "   448|         0|            0|            0|  0.00%|\n",
      "   449|         0|            0|            0|  0.00%|    return out\n",
      "Total duration: 7.98686s\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py\n",
      "File duration: 0.11619s (1.45%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\"\"\"\n",
      "     2|         0|            0|            0|  0.00%|``torch.autograd`` provides classes and functions implementing automatic\n",
      "     3|         0|            0|            0|  0.00%|differentiation of arbitrary scalar valued functions. It requires minimal\n",
      "     4|         0|            0|            0|  0.00%|changes to the existing code - you only need to declare :class:`Tensor` s\n",
      "     5|         0|            0|            0|  0.00%|for which gradients should be computed with the ``requires_grad=True`` keyword.\n",
      "     6|         0|            0|            0|  0.00%|As of now, we only support autograd for floating point :class:`Tensor` types (\n",
      "     7|         0|            0|            0|  0.00%|half, float, double and bfloat16) and complex :class:`Tensor` types (cfloat, cdouble).\n",
      "     8|         0|            0|            0|  0.00%|\"\"\"\n",
      "     9|         0|            0|            0|  0.00%|import torch\n",
      "    10|         0|            0|            0|  0.00%|import warnings\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|from torch.types import _TensorOrTensors\n",
      "    13|         0|            0|            0|  0.00%|from typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|from .variable import Variable\n",
      "    16|         0|            0|            0|  0.00%|from .function import Function, NestedIOFunction\n",
      "    17|         0|            0|            0|  0.00%|from .gradcheck import gradcheck, gradgradcheck\n",
      "    18|         0|            0|            0|  0.00%|from .grad_mode import no_grad, enable_grad, set_grad_enabled, inference_mode\n",
      "    19|         0|            0|            0|  0.00%|from .anomaly_mode import detect_anomaly, set_detect_anomaly\n",
      "    20|         0|            0|            0|  0.00%|from ..overrides import has_torch_function, handle_torch_function\n",
      "    21|         0|            0|            0|  0.00%|from . import functional\n",
      "    22|         0|            0|            0|  0.00%|from . import forward_ad\n",
      "    23|         0|            0|            0|  0.00%|from . import graph\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|__all__ = ['Variable', 'Function', 'backward', 'grad_mode']\n",
      "    26|         0|            0|            0|  0.00%|\n",
      "    27|         0|            0|            0|  0.00%|_OptionalTensor = Optional[torch.Tensor]\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         1|  7.86781e-06|  7.86781e-06|  0.00%|def _make_grads(outputs: Sequence[torch.Tensor], grads: Sequence[_OptionalTensor]) -> Tuple[_OptionalTensor, ...]:\n",
      "    30|         1|  4.76837e-06|  4.76837e-06|  0.00%|    new_grads: List[_OptionalTensor] = []\n",
      "    31|         2|  3.14713e-05|  1.57356e-05|  0.00%|    for out, grad in zip(outputs, grads):\n",
      "    32|         1|  4.05312e-06|  4.05312e-06|  0.00%|        if isinstance(grad, torch.Tensor):\n",
      "    33|         0|            0|            0|  0.00%|            if not out.shape == grad.shape:\n",
      "    34|         0|            0|            0|  0.00%|                raise RuntimeError(\"Mismatch in shape: grad_output[\"\n",
      "    35|         0|            0|            0|  0.00%|                                   + str(grads.index(grad)) + \"] has a shape of \"\n",
      "    36|         0|            0|            0|  0.00%|                                   + str(grad.shape) + \" and output[\"\n",
      "    37|         0|            0|            0|  0.00%|                                   + str(outputs.index(out)) + \"] has a shape of \"\n",
      "    38|         0|            0|            0|  0.00%|                                   + str(out.shape) + \".\")\n",
      "    39|         0|            0|            0|  0.00%|            if out.dtype.is_complex != grad.dtype.is_complex:\n",
      "    40|         0|            0|            0|  0.00%|                raise RuntimeError(\"For complex Tensors, both grad_output and output\"\n",
      "    41|         0|            0|            0|  0.00%|                                   \" are required to have the same dtype.\"\n",
      "    42|         0|            0|            0|  0.00%|                                   \" Mismatch in dtype: grad_output[\"\n",
      "    43|         0|            0|            0|  0.00%|                                   + str(grads.index(grad)) + \"] has a dtype of \"\n",
      "    44|         0|            0|            0|  0.00%|                                   + str(grad.dtype) + \" and output[\"\n",
      "    45|         0|            0|            0|  0.00%|                                   + str(outputs.index(out)) + \"] has a dtype of \"\n",
      "    46|         0|            0|            0|  0.00%|                                   + str(out.dtype) + \".\")\n",
      "    47|         0|            0|            0|  0.00%|            new_grads.append(grad)\n",
      "    48|         1|  2.86102e-06|  2.86102e-06|  0.00%|        elif grad is None:\n",
      "    49|         1|  4.05312e-06|  4.05312e-06|  0.00%|            if out.requires_grad:\n",
      "    50|         1|  4.05312e-06|  4.05312e-06|  0.00%|                if out.numel() != 1:\n",
      "    51|         0|            0|            0|  0.00%|                    raise RuntimeError(\"grad can be implicitly created only for scalar outputs\")\n",
      "    52|         1|   0.00190282|   0.00190282|  0.02%|                new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n",
      "    53|         0|            0|            0|  0.00%|            else:\n",
      "    54|         0|            0|            0|  0.00%|                new_grads.append(None)\n",
      "    55|         0|            0|            0|  0.00%|        else:\n",
      "    56|         0|            0|            0|  0.00%|            raise TypeError(\"gradients can be either Tensors or None, but got \" +\n",
      "    57|         0|            0|            0|  0.00%|                            type(grad).__name__)\n",
      "    58|         1|  5.96046e-06|  5.96046e-06|  0.00%|    return tuple(new_grads)\n",
      "    59|         0|            0|            0|  0.00%|\n",
      "    60|         0|            0|            0|  0.00%|\n",
      "    61|         1|   2.6226e-06|   2.6226e-06|  0.00%|def _tensor_or_tensors_to_tuple(tensors: Optional[_TensorOrTensors], length: int) -> Tuple[_OptionalTensor, ...]:\n",
      "    62|         1|  3.09944e-06|  3.09944e-06|  0.00%|    if tensors is None:\n",
      "    63|         1|  4.05312e-06|  4.05312e-06|  0.00%|        return (None, ) * length\n",
      "    64|         0|            0|            0|  0.00%|    if isinstance(tensors, torch.Tensor):\n",
      "    65|         0|            0|            0|  0.00%|        return (tensors, )\n",
      "    66|         0|            0|            0|  0.00%|    return tuple(tensors)\n",
      "    67|         0|            0|            0|  0.00%|\n",
      "    68|         0|            0|            0|  0.00%|\n",
      "    69|         1|  1.21593e-05|  1.21593e-05|  0.00%|def backward(\n",
      "    70|         0|            0|            0|  0.00%|    tensors: _TensorOrTensors,\n",
      "    71|         0|            0|            0|  0.00%|    grad_tensors: Optional[_TensorOrTensors] = None,\n",
      "    72|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,\n",
      "    73|         0|            0|            0|  0.00%|    create_graph: bool = False,\n",
      "    74|         0|            0|            0|  0.00%|    grad_variables: Optional[_TensorOrTensors] = None,\n",
      "    75|         0|            0|            0|  0.00%|    inputs: Optional[_TensorOrTensors] = None,\n",
      "    76|         0|            0|            0|  0.00%|) -> None:\n",
      "    77|         0|            0|            0|  0.00%|    r\"\"\"Computes the sum of gradients of given tensors with respect to graph\n",
      "    78|         0|            0|            0|  0.00%|    leaves.\n",
      "    79|         0|            0|            0|  0.00%|\n",
      "    80|         0|            0|            0|  0.00%|    The graph is differentiated using the chain rule. If any of ``tensors``\n",
      "    81|         0|            0|            0|  0.00%|    are non-scalar (i.e. their data has more than one element) and require\n",
      "    82|         0|            0|            0|  0.00%|    gradient, then the Jacobian-vector product would be computed, in this\n",
      "    83|         0|            0|            0|  0.00%|    case the function additionally requires specifying ``grad_tensors``.\n",
      "    84|         0|            0|            0|  0.00%|    It should be a sequence of matching length, that contains the \"vector\"\n",
      "    85|         0|            0|            0|  0.00%|    in the Jacobian-vector product, usually the gradient of the differentiated\n",
      "    86|         0|            0|            0|  0.00%|    function w.r.t. corresponding tensors (``None`` is an acceptable value for\n",
      "    87|         0|            0|            0|  0.00%|    all tensors that don't need gradient tensors).\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|    This function accumulates gradients in the leaves - you might need to zero\n",
      "    90|         0|            0|            0|  0.00%|    ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "    91|         0|            0|            0|  0.00%|    See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "    92|         0|            0|            0|  0.00%|    for details on the memory layout of accumulated gradients.\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|    .. note::\n",
      "    95|         0|            0|            0|  0.00%|        Using this method with ``create_graph=True`` will create a reference cycle\n",
      "    96|         0|            0|            0|  0.00%|        between the parameter and its gradient which can cause a memory leak.\n",
      "    97|         0|            0|            0|  0.00%|        We recommend using ``autograd.grad`` when creating the graph to avoid this.\n",
      "    98|         0|            0|            0|  0.00%|        If you have to use this function, make sure to reset the ``.grad`` fields of your\n",
      "    99|         0|            0|            0|  0.00%|        parameters to ``None`` after use to break the cycle and avoid the leak.\n",
      "   100|         0|            0|            0|  0.00%|\n",
      "   101|         0|            0|            0|  0.00%|    .. note::\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_tensors``, and/or call ``backward``\n",
      "   104|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see\n",
      "   105|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   106|         0|            0|            0|  0.00%|\n",
      "   107|         0|            0|            0|  0.00%|    .. note::\n",
      "   108|         0|            0|            0|  0.00%|\n",
      "   109|         0|            0|            0|  0.00%|        When ``inputs`` are provided and a given input is not a leaf,\n",
      "   110|         0|            0|            0|  0.00%|        the current implementation will call its grad_fn (even though it is not strictly needed to get this gradients).\n",
      "   111|         0|            0|            0|  0.00%|        It is an implementation detail on which the user should not rely.\n",
      "   112|         0|            0|            0|  0.00%|        See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
      "   113|         0|            0|            0|  0.00%|\n",
      "   114|         0|            0|            0|  0.00%|    Args:\n",
      "   115|         0|            0|            0|  0.00%|        tensors (Sequence[Tensor] or Tensor): Tensors of which the derivative will be\n",
      "   116|         0|            0|            0|  0.00%|            computed.\n",
      "   117|         0|            0|            0|  0.00%|        grad_tensors (Sequence[Tensor or None] or Tensor, optional): The \"vector\" in\n",
      "   118|         0|            0|            0|  0.00%|            the Jacobian-vector product, usually gradients w.r.t. each element of\n",
      "   119|         0|            0|            0|  0.00%|            corresponding tensors. None values can be specified for scalar Tensors or\n",
      "   120|         0|            0|            0|  0.00%|            ones that don't require grad. If a None value would be acceptable for all\n",
      "   121|         0|            0|            0|  0.00%|            grad_tensors, then this argument is optional.\n",
      "   122|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad\n",
      "   123|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``\n",
      "   124|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient\n",
      "   125|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.\n",
      "   126|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   127|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.\n",
      "   128|         0|            0|            0|  0.00%|            Defaults to ``False``.\n",
      "   129|         0|            0|            0|  0.00%|        inputs (Sequence[Tensor] or Tensor, optional): Inputs w.r.t. which the gradient\n",
      "   130|         0|            0|            0|  0.00%|            be will accumulated into ``.grad``. All other Tensors will be ignored. If\n",
      "   131|         0|            0|            0|  0.00%|            not provided, the gradient is accumulated into all the leaf Tensors that\n",
      "   132|         0|            0|            0|  0.00%|            were used to compute the attr::tensors.\n",
      "   133|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   134|         1|  8.10623e-06|  8.10623e-06|  0.00%|    if grad_variables is not None:\n",
      "   135|         0|            0|            0|  0.00%|        warnings.warn(\"'grad_variables' is deprecated. Use 'grad_tensors' instead.\")\n",
      "   136|         0|            0|            0|  0.00%|        if grad_tensors is None:\n",
      "   137|         0|            0|            0|  0.00%|            grad_tensors = grad_variables\n",
      "   138|         0|            0|            0|  0.00%|        else:\n",
      "   139|         0|            0|            0|  0.00%|            raise RuntimeError(\"'grad_tensors' and 'grad_variables' (deprecated) \"\n",
      "   140|         0|            0|            0|  0.00%|                               \"arguments both passed to backward(). Please only \"\n",
      "   141|         0|            0|            0|  0.00%|                               \"use 'grad_tensors'.\")\n",
      "   142|         1|  2.86102e-06|  2.86102e-06|  0.00%|    if inputs is not None and len(inputs) == 0:\n",
      "   143|         0|            0|            0|  0.00%|        raise RuntimeError(\"'inputs' argument to backward() cannot be empty.\")\n",
      "   144|         0|            0|            0|  0.00%|\n",
      "   145|         1|  5.00679e-06|  5.00679e-06|  0.00%|    tensors = (tensors,) if isinstance(tensors, torch.Tensor) else tuple(tensors)\n",
      "   146|         1|  2.86102e-06|  2.86102e-06|  0.00%|    inputs = (inputs,) if isinstance(inputs, torch.Tensor) else \\\n",
      "   147|         1|  5.00679e-06|  5.00679e-06|  0.00%|        tuple(inputs) if inputs is not None else tuple()\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         1|  1.12057e-05|  1.12057e-05|  0.00%|    grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, len(tensors))\n",
      "(call)|         1|  9.77516e-06|  9.77516e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:61 _tensor_or_tensors_to_tuple\n",
      "   150|         1|  2.12193e-05|  2.12193e-05|  0.00%|    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
      "(call)|         1|   0.00196791|   0.00196791|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:29 _make_grads\n",
      "   151|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if retain_graph is None:\n",
      "   152|         1|  2.86102e-06|  2.86102e-06|  0.00%|        retain_graph = create_graph\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         1|  1.00136e-05|  1.00136e-05|  0.00%|    Variable._execution_engine.run_backward(\n",
      "   155|         1|  4.29153e-06|  4.29153e-06|  0.00%|        tensors, grad_tensors_, retain_graph, create_graph, inputs,\n",
      "   156|         1|     0.114123|     0.114123|  1.43%|        allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "   157|         0|            0|            0|  0.00%|\n",
      "   158|         0|            0|            0|  0.00%|\n",
      "   159|         0|            0|            0|  0.00%|def grad(\n",
      "   160|         0|            0|            0|  0.00%|    outputs: _TensorOrTensors,\n",
      "   161|         0|            0|            0|  0.00%|    inputs: _TensorOrTensors,\n",
      "   162|         0|            0|            0|  0.00%|    grad_outputs: Optional[_TensorOrTensors] = None,\n",
      "   163|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,\n",
      "   164|         0|            0|            0|  0.00%|    create_graph: bool = False,\n",
      "   165|         0|            0|            0|  0.00%|    only_inputs: bool = True,\n",
      "   166|         0|            0|            0|  0.00%|    allow_unused: bool = False\n",
      "   167|         0|            0|            0|  0.00%|) -> Tuple[torch.Tensor, ...]:\n",
      "   168|         0|            0|            0|  0.00%|    r\"\"\"Computes and returns the sum of gradients of outputs with respect to\n",
      "   169|         0|            0|            0|  0.00%|    the inputs.\n",
      "   170|         0|            0|            0|  0.00%|\n",
      "   171|         0|            0|            0|  0.00%|    ``grad_outputs`` should be a sequence of length matching ``output``\n",
      "   172|         0|            0|            0|  0.00%|    containing the \"vector\" in Jacobian-vector product, usually the pre-computed\n",
      "   173|         0|            0|            0|  0.00%|    gradients w.r.t. each of the outputs. If an output doesn't require_grad,\n",
      "   174|         0|            0|            0|  0.00%|    then the gradient can be ``None``).\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|    .. note::\n",
      "   177|         0|            0|            0|  0.00%|\n",
      "   178|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_outputs``, and/or call ``grad``\n",
      "   179|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see\n",
      "   180|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    .. note::\n",
      "   183|         0|            0|            0|  0.00%|\n",
      "   184|         0|            0|            0|  0.00%|        ``only_inputs`` argument is deprecated and is ignored now (defaults to ``True``).\n",
      "   185|         0|            0|            0|  0.00%|        To accumulate gradient for other parts of the graph, please use\n",
      "   186|         0|            0|            0|  0.00%|        ``torch.autograd.backward``.\n",
      "   187|         0|            0|            0|  0.00%|\n",
      "   188|         0|            0|            0|  0.00%|    Args:\n",
      "   189|         0|            0|            0|  0.00%|        outputs (sequence of Tensor): outputs of the differentiated function.\n",
      "   190|         0|            0|            0|  0.00%|        inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "   191|         0|            0|            0|  0.00%|            returned (and not accumulated into ``.grad``).\n",
      "   192|         0|            0|            0|  0.00%|        grad_outputs (sequence of Tensor): The \"vector\" in the Jacobian-vector product.\n",
      "   193|         0|            0|            0|  0.00%|            Usually gradients w.r.t. each output. None values can be specified for scalar\n",
      "   194|         0|            0|            0|  0.00%|            Tensors or ones that don't require grad. If a None value would be acceptable\n",
      "   195|         0|            0|            0|  0.00%|            for all grad_tensors, then this argument is optional. Default: None.\n",
      "   196|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad\n",
      "   197|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``\n",
      "   198|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient\n",
      "   199|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.\n",
      "   200|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   201|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.\n",
      "   202|         0|            0|            0|  0.00%|            Default: ``False``.\n",
      "   203|         0|            0|            0|  0.00%|        allow_unused (bool, optional): If ``False``, specifying inputs that were not\n",
      "   204|         0|            0|            0|  0.00%|            used when computing outputs (and therefore their grad is always zero)\n",
      "   205|         0|            0|            0|  0.00%|            is an error. Defaults to ``False``.\n",
      "   206|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   207|         0|            0|            0|  0.00%|    outputs = (outputs,) if isinstance(outputs, torch.Tensor) else tuple(outputs)\n",
      "   208|         0|            0|            0|  0.00%|    inputs = (inputs,) if isinstance(inputs, torch.Tensor) else tuple(inputs)\n",
      "   209|         0|            0|            0|  0.00%|    overridable_args = outputs + inputs\n",
      "   210|         0|            0|            0|  0.00%|    if has_torch_function(overridable_args):\n",
      "   211|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   212|         0|            0|            0|  0.00%|            grad,\n",
      "   213|         0|            0|            0|  0.00%|            overridable_args,\n",
      "   214|         0|            0|            0|  0.00%|            outputs,\n",
      "   215|         0|            0|            0|  0.00%|            inputs,\n",
      "   216|         0|            0|            0|  0.00%|            grad_outputs=grad_outputs,\n",
      "   217|         0|            0|            0|  0.00%|            retain_graph=retain_graph,\n",
      "   218|         0|            0|            0|  0.00%|            create_graph=create_graph,\n",
      "   219|         0|            0|            0|  0.00%|            only_inputs=only_inputs,\n",
      "   220|         0|            0|            0|  0.00%|            allow_unused=allow_unused,\n",
      "   221|         0|            0|            0|  0.00%|        )\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|    if not only_inputs:\n",
      "   224|         0|            0|            0|  0.00%|        warnings.warn(\"only_inputs argument is deprecated and is ignored now \"\n",
      "   225|         0|            0|            0|  0.00%|                      \"(defaults to True). To accumulate gradient for other \"\n",
      "   226|         0|            0|            0|  0.00%|                      \"parts of the graph, please use torch.autograd.backward.\")\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    grad_outputs_ = _tensor_or_tensors_to_tuple(grad_outputs, len(outputs))\n",
      "   229|         0|            0|            0|  0.00%|    grad_outputs_ = _make_grads(outputs, grad_outputs_)\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|    if retain_graph is None:\n",
      "   232|         0|            0|            0|  0.00%|        retain_graph = create_graph\n",
      "   233|         0|            0|            0|  0.00%|\n",
      "   234|         0|            0|            0|  0.00%|    return Variable._execution_engine.run_backward(\n",
      "   235|         0|            0|            0|  0.00%|        outputs, grad_outputs_, retain_graph, create_graph,\n",
      "   236|         0|            0|            0|  0.00%|        inputs, allow_unused, accumulate_grad=False)\n",
      "   237|         0|            0|            0|  0.00%|\n",
      "   238|         0|            0|            0|  0.00%|\n",
      "   239|         0|            0|            0|  0.00%|# This function applies in case of gradient checkpointing for memory\n",
      "   240|         0|            0|            0|  0.00%|# optimization. Currently, gradient checkpointing is supported only if the\n",
      "   241|         0|            0|            0|  0.00%|# execution engine is invoked through torch.autograd.backward() and its\n",
      "   242|         0|            0|            0|  0.00%|# inputs argument is not passed. It is not supported for torch.autograd.grad().\n",
      "   243|         0|            0|            0|  0.00%|# This is because if inputs are specified, the gradient won't be calculated for\n",
      "   244|         0|            0|            0|  0.00%|# anything else e.g. model parameters like weights, bias etc.\n",
      "   245|         0|            0|            0|  0.00%|#\n",
      "   246|         0|            0|            0|  0.00%|# This function returns whether the checkpointing is valid i.e. torch.autograd.backward\n",
      "   247|         0|            0|            0|  0.00%|# or not i.e. torch.autograd.grad. The implementation works by maintaining a thread\n",
      "   248|         0|            0|            0|  0.00%|# local variable in torch/csrc/autograd/engine.cpp which looks at the NodeTask\n",
      "   249|         0|            0|            0|  0.00%|# in the stack and before a NodeTask is executed in evaluate_function, it\n",
      "   250|         0|            0|            0|  0.00%|# checks for whether reentrant backwards is imperative or not.\n",
      "   251|         0|            0|            0|  0.00%|# See https://github.com/pytorch/pytorch/pull/4594 for more discussion/context\n",
      "   252|         0|            0|            0|  0.00%|def _is_checkpoint_valid():\n",
      "   253|         0|            0|            0|  0.00%|    return Variable._execution_engine.is_checkpoint_valid()\n",
      "   254|         0|            0|            0|  0.00%|\n",
      "   255|         0|            0|            0|  0.00%|\n",
      "   256|         0|            0|            0|  0.00%|def variable(*args, **kwargs):\n",
      "   257|         0|            0|            0|  0.00%|    warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "   258|         0|            0|            0|  0.00%|    return torch.tensor(*args, **kwargs)\n",
      "   259|         0|            0|            0|  0.00%|\n",
      "   260|         0|            0|            0|  0.00%|if not torch._C._autograd_init():\n",
      "   261|         0|            0|            0|  0.00%|    raise RuntimeError(\"autograd initialization failed\")\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|# Import all native method/classes\n",
      "   264|         0|            0|            0|  0.00%|from torch._C._autograd import (DeviceType, ProfilerActivity, ProfilerState, ProfilerConfig, ProfilerEvent,\n",
      "   265|         0|            0|            0|  0.00%|                                _enable_profiler_legacy, _disable_profiler_legacy, _profiler_enabled,\n",
      "   266|         0|            0|            0|  0.00%|                                _enable_record_function, _set_empty_test_observer, kineto_available,\n",
      "   267|         0|            0|            0|  0.00%|                                _supported_activities, _add_metadata_json, SavedTensor,\n",
      "   268|         0|            0|            0|  0.00%|                                _register_saved_tensors_default_hooks, _reset_saved_tensors_default_hooks)\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         0|            0|            0|  0.00%|from torch._C._autograd import (_ProfilerResult, _KinetoEvent,\n",
      "   271|         0|            0|            0|  0.00%|                                _prepare_profiler, _enable_profiler, _disable_profiler)\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|from . import profiler\n",
      "File: <ipython-input-176-5d68b8565542>\n",
      "File duration: 0.0572484s (0.72%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         1|  1.09673e-05|  1.09673e-05|  0.00%|def lossmaker1(x, y, model, device, epoch):\n",
      "     2|         0|            0|            0|  0.00%|    # our loss function for a single batch\n",
      "     3|         0|            0|            0|  0.00%|    # this can be used both for training and for end-of-epoch evaluation\n",
      "     4|         0|            0|            0|  0.00%|    # (done in other functions)\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         1|  4.22001e-05|  4.22001e-05|  0.00%|    loss = nn.CrossEntropyLoss(reduction='mean', ignore_index = 0)\n",
      "(call)|         1|  0.000865936|  0.000865936|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:1143 __init__\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|#   we have: (input_tokens, input_lengths), (output_tokens, output_lengths)\n",
      "    10|         1|  5.00679e-06|  5.00679e-06|  0.00%|    input_tokens, input_lengths = x\n",
      "    11|         1|  1.09673e-05|  1.09673e-05|  0.00%|    input_tokens = input_tokens.to(device)\n",
      "    12|         0|            0|            0|  0.00%|\n",
      "    13|         1|  5.00679e-06|  5.00679e-06|  0.00%|    output_tokens, _ = y\n",
      "    14|         1|  5.96046e-06|  5.96046e-06|  0.00%|    output_tokens = output_tokens.to(device)\n",
      "    15|         0|            0|            0|  0.00%|\n",
      "    16|         1|  2.00272e-05|  2.00272e-05|  0.00%|    token_predictions, attentions = model(input_tokens, input_lengths, output_tokens, epoch)\n",
      "(call)|         1|    0.0828838|    0.0828838|  1.04%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|    # prediction first, target second\n",
      "    19|         1|  6.19888e-06|  6.19888e-06|  0.00%|    # L_out x B x vocab -> B x vocab x L_out\n",
      "    20|         1|  3.21865e-05|  3.21865e-05|  0.00%|    L = loss(token_predictions.transpose(0, 1).transpose(1, 2), output_tokens.transpose(0, 1))\n",
      "(call)|         1|   0.00440788|   0.00440788|  0.06%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|      1026|   0.00252914|  2.46505e-06|  0.03%|    return L\n",
      "    23|         1|  7.86781e-06|  7.86781e-06|  0.00%|\n",
      "    24|         2|  3.26633e-05|  1.63317e-05|  0.00%|\n",
      "(call)|         1|   2.7895e-05|   2.7895e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         1|  0.000311136|  0.000311136|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    25|      1034|   0.00261211|  2.52622e-06|  0.03%|# write another function that takes x and y, decodes x (greedy or beam) and returns logprobs, accuracies,\n",
      "(call)|         1|  0.000431776|  0.000431776|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:200 pack_padded_sequence\n",
      "    26|      1032|   0.00809598|  7.84494e-06|  0.10%|#                           attentions\n",
      "(call)|         8|  0.000198364|  2.47955e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|   0.00121522|  0.000151902|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    27|      1025|   0.00263047|  2.56631e-06|  0.03%|# return accuracy as well? frequency hist for tokens?\n",
      "(call)|         1|  3.02792e-05|  3.02792e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         1|    0.0128322|    0.0128322|  0.16%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    28|        10|  0.000120878|  1.20878e-05|  0.00%|# counts number of hits and misses explicitly for a particular token ID\n",
      "(call)|         1|  0.000223875|  0.000223875|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:253 pad_packed_sequence\n",
      "    29|         1|  1.21593e-05|  1.21593e-05|  0.00%|\n",
      "    30|         1|  5.00679e-06|  5.00679e-06|  0.00%|\n",
      "    31|         1|  1.88351e-05|  1.88351e-05|  0.00%|# I see two use cases: get attention for greedy\n",
      "    32|         9|  0.000671625|   7.4625e-05|  0.01%|\n",
      "(call)|         8|  0.000204563|  2.55704e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|   0.00546527|  0.000683159|  0.07%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    33|         3|   2.0504e-05|  6.83467e-06|  0.00%|\n",
      "    34|         2|  7.77245e-05|  3.88622e-05|  0.00%|# evaluate on e.g. validation dataset using bean search: get accuracy, etc.\n",
      "    35|         1|  3.19481e-05|  3.19481e-05|  0.00%|\n",
      "    36|         9|  0.000271797|  3.01997e-05|  0.00%|\n",
      "(call)|         8|   0.00021863|  2.73287e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|    0.0519533|   0.00649416|  0.65%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    37|         8|   7.1764e-05|   8.9705e-06|  0.00%|\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|        17|   0.00250793|  0.000147525|  0.03%|\n",
      "(call)|         1|  4.29153e-05|  4.29153e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         1|    0.0141277|    0.0141277|  0.18%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    40|         8|  9.58443e-05|  1.19805e-05|  0.00%|\n",
      "    41|         9|  4.02927e-05|  4.47697e-06|  0.00%|\n",
      "    42|         8|   2.3365e-05|  2.92063e-06|  0.00%|\n",
      "    43|         8|  5.67436e-05|  7.09295e-06|  0.00%|\n",
      "    44|         9|  3.40939e-05|  3.78821e-06|  0.00%|\n",
      "    45|         0|            0|            0|  0.00%|\n",
      "    46|        16|  0.000287056|   1.7941e-05|  0.00%|\n",
      "(call)|         8|  0.000216961|  2.71201e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|    0.0670869|   0.00838587|  0.84%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    47|        24|  0.000446796|  1.86165e-05|  0.01%|\n",
      "    48|        16|  0.000430346|  2.68966e-05|  0.01%|\n",
      "(call)|         8|  0.000231504|  2.89381e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|    0.0010488|    0.0001311|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    49|         0|            0|            0|  0.00%|\n",
      "    50|       144|  0.000467777|  3.24845e-06|  0.01%|\n",
      "(call)|         8|  0.000215769|  2.69711e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|         8|   0.00201416|   0.00025177|  0.03%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    51|         0|            0|            0|  0.00%|\n",
      "    52|      1160|   0.00361514|   3.1165e-06|  0.05%|\n",
      "    53|      1024|    0.0316677|  3.09255e-05|  0.40%|\n",
      "(call)|      1024|    0.0156345|  1.52681e-05|  0.20%|# <ipython-input-176-5d68b8565542>:22 energy\n",
      "    54|         8|  3.02792e-05|  3.78489e-06|  0.00%|\n",
      "    55|         8|  7.86781e-05|  9.83477e-06|  0.00%|\n",
      "(call)|         8|  0.000240803|  3.01003e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:1650 softmax\n",
      "    56|         0|            0|            0|  0.00%|\n",
      "    57|         8|   2.7895e-05|  3.48687e-06|  0.00%|\n",
      "    58|         0|            0|            0|  0.00%|\n",
      "    59|         8|  3.69549e-05|  4.61936e-06|  0.00%|\n",
      "    60|         0|            0|            0|  0.00%|\n",
      "    61|         8|  5.05447e-05|  6.31809e-06|  0.00%|\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|\n",
      "    68|         0|            0|            0|  0.00%|\n",
      "    69|         0|            0|            0|  0.00%|\n",
      "    70|         1|  1.90735e-06|  1.90735e-06|  0.00%|\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py\n",
      "File duration: 0.0178032s (0.22%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|import math\n",
      "     2|         0|            0|            0|  0.00%|import warnings\n",
      "     3|         0|            0|            0|  0.00%|import numbers\n",
      "     4|         0|            0|            0|  0.00%|from typing import List, Tuple, Optional, overload, Union, cast\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|import torch\n",
      "     7|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     8|         0|            0|            0|  0.00%|from .module import Module\n",
      "     9|         0|            0|            0|  0.00%|from ..parameter import Parameter\n",
      "    10|         0|            0|            0|  0.00%|from ..utils.rnn import PackedSequence\n",
      "    11|         0|            0|            0|  0.00%|from .. import init\n",
      "    12|         0|            0|            0|  0.00%|from ... import _VF\n",
      "    13|         0|            0|            0|  0.00%|\n",
      "    14|         0|            0|            0|  0.00%|_rnn_impls = {\n",
      "    15|         0|            0|            0|  0.00%|    'RNN_TANH': _VF.rnn_tanh,\n",
      "    16|         0|            0|            0|  0.00%|    'RNN_RELU': _VF.rnn_relu,\n",
      "    17|         0|            0|            0|  0.00%|}\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         1|  2.86102e-06|  2.86102e-06|  0.00%|def apply_permutation(tensor: Tensor, permutation: Tensor, dim: int = 1) -> Tensor:\n",
      "    21|         1|   2.5034e-05|   2.5034e-05|  0.00%|    return tensor.index_select(dim, permutation)\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|\n",
      "    24|         0|            0|            0|  0.00%|class RNNBase(Module):\n",
      "    25|         0|            0|            0|  0.00%|    __constants__ = ['mode', 'input_size', 'hidden_size', 'num_layers', 'bias',\n",
      "    26|         0|            0|            0|  0.00%|                     'batch_first', 'dropout', 'bidirectional', 'proj_size']\n",
      "    27|         0|            0|            0|  0.00%|    __jit_unused_properties__ = ['all_weights']\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|    mode: str\n",
      "    30|         0|            0|            0|  0.00%|    input_size: int\n",
      "    31|         0|            0|            0|  0.00%|    hidden_size: int\n",
      "    32|         0|            0|            0|  0.00%|    num_layers: int\n",
      "    33|         0|            0|            0|  0.00%|    bias: bool\n",
      "    34|         0|            0|            0|  0.00%|    batch_first: bool\n",
      "    35|         0|            0|            0|  0.00%|    dropout: float\n",
      "    36|         0|            0|            0|  0.00%|    bidirectional: bool\n",
      "    37|         0|            0|            0|  0.00%|    proj_size: int\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|         0|            0|            0|  0.00%|    def __init__(self, mode: str, input_size: int, hidden_size: int,\n",
      "    40|         0|            0|            0|  0.00%|                 num_layers: int = 1, bias: bool = True, batch_first: bool = False,\n",
      "    41|         0|            0|            0|  0.00%|                 dropout: float = 0., bidirectional: bool = False, proj_size: int = 0,\n",
      "    42|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "    43|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "    44|         0|            0|            0|  0.00%|        super(RNNBase, self).__init__()\n",
      "    45|         0|            0|            0|  0.00%|        self.mode = mode\n",
      "    46|         0|            0|            0|  0.00%|        self.input_size = input_size\n",
      "    47|         0|            0|            0|  0.00%|        self.hidden_size = hidden_size\n",
      "    48|         0|            0|            0|  0.00%|        self.num_layers = num_layers\n",
      "    49|         0|            0|            0|  0.00%|        self.bias = bias\n",
      "    50|         0|            0|            0|  0.00%|        self.batch_first = batch_first\n",
      "    51|         0|            0|            0|  0.00%|        self.dropout = float(dropout)\n",
      "    52|         0|            0|            0|  0.00%|        self.bidirectional = bidirectional\n",
      "    53|         0|            0|            0|  0.00%|        self.proj_size = proj_size\n",
      "    54|         0|            0|            0|  0.00%|        num_directions = 2 if bidirectional else 1\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|        if not isinstance(dropout, numbers.Number) or not 0 <= dropout <= 1 or \\\n",
      "    57|         0|            0|            0|  0.00%|                isinstance(dropout, bool):\n",
      "    58|         0|            0|            0|  0.00%|            raise ValueError(\"dropout should be a number in range [0, 1] \"\n",
      "    59|         0|            0|            0|  0.00%|                             \"representing the probability of an element being \"\n",
      "    60|         0|            0|            0|  0.00%|                             \"zeroed\")\n",
      "    61|         0|            0|            0|  0.00%|        if dropout > 0 and num_layers == 1:\n",
      "    62|         0|            0|            0|  0.00%|            warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    63|         0|            0|            0|  0.00%|                          \"recurrent layer, so non-zero dropout expects \"\n",
      "    64|         0|            0|            0|  0.00%|                          \"num_layers greater than 1, but got dropout={} and \"\n",
      "    65|         0|            0|            0|  0.00%|                          \"num_layers={}\".format(dropout, num_layers))\n",
      "    66|         0|            0|            0|  0.00%|        if proj_size < 0:\n",
      "    67|         0|            0|            0|  0.00%|            raise ValueError(\"proj_size should be a positive integer or zero to disable projections\")\n",
      "    68|         0|            0|            0|  0.00%|        if proj_size >= hidden_size:\n",
      "    69|         0|            0|            0|  0.00%|            raise ValueError(\"proj_size has to be smaller than hidden_size\")\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|        if mode == 'LSTM':\n",
      "    72|         0|            0|            0|  0.00%|            gate_size = 4 * hidden_size\n",
      "    73|         0|            0|            0|  0.00%|        elif mode == 'GRU':\n",
      "    74|         0|            0|            0|  0.00%|            gate_size = 3 * hidden_size\n",
      "    75|         0|            0|            0|  0.00%|        elif mode == 'RNN_TANH':\n",
      "    76|         0|            0|            0|  0.00%|            gate_size = hidden_size\n",
      "    77|         0|            0|            0|  0.00%|        elif mode == 'RNN_RELU':\n",
      "    78|         0|            0|            0|  0.00%|            gate_size = hidden_size\n",
      "    79|         0|            0|            0|  0.00%|        else:\n",
      "    80|         0|            0|            0|  0.00%|            raise ValueError(\"Unrecognized RNN mode: \" + mode)\n",
      "    81|         0|            0|            0|  0.00%|\n",
      "    82|         0|            0|            0|  0.00%|        self._flat_weights_names = []\n",
      "    83|         0|            0|            0|  0.00%|        self._all_weights = []\n",
      "    84|         0|            0|            0|  0.00%|        for layer in range(num_layers):\n",
      "    85|         0|            0|            0|  0.00%|            for direction in range(num_directions):\n",
      "    86|         0|            0|            0|  0.00%|                real_hidden_size = proj_size if proj_size > 0 else hidden_size\n",
      "    87|         0|            0|            0|  0.00%|                layer_input_size = input_size if layer == 0 else real_hidden_size * num_directions\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|                w_ih = Parameter(torch.empty((gate_size, layer_input_size), **factory_kwargs))\n",
      "    90|         0|            0|            0|  0.00%|                w_hh = Parameter(torch.empty((gate_size, real_hidden_size), **factory_kwargs))\n",
      "    91|         0|            0|            0|  0.00%|                b_ih = Parameter(torch.empty(gate_size, **factory_kwargs))\n",
      "    92|         0|            0|            0|  0.00%|                # Second bias vector included for CuDNN compatibility. Only one\n",
      "    93|         0|            0|            0|  0.00%|                # bias vector is needed in standard definition.\n",
      "    94|         0|            0|            0|  0.00%|                b_hh = Parameter(torch.empty(gate_size, **factory_kwargs))\n",
      "    95|         0|            0|            0|  0.00%|                layer_params: Tuple[Tensor, ...] = ()\n",
      "    96|         0|            0|            0|  0.00%|                if self.proj_size == 0:\n",
      "    97|         0|            0|            0|  0.00%|                    if bias:\n",
      "    98|         0|            0|            0|  0.00%|                        layer_params = (w_ih, w_hh, b_ih, b_hh)\n",
      "    99|         0|            0|            0|  0.00%|                    else:\n",
      "   100|         0|            0|            0|  0.00%|                        layer_params = (w_ih, w_hh)\n",
      "   101|         0|            0|            0|  0.00%|                else:\n",
      "   102|         0|            0|            0|  0.00%|                    w_hr = Parameter(torch.empty((proj_size, hidden_size), **factory_kwargs))\n",
      "   103|         0|            0|            0|  0.00%|                    if bias:\n",
      "   104|         0|            0|            0|  0.00%|                        layer_params = (w_ih, w_hh, b_ih, b_hh, w_hr)\n",
      "   105|         0|            0|            0|  0.00%|                    else:\n",
      "   106|         0|            0|            0|  0.00%|                        layer_params = (w_ih, w_hh, w_hr)\n",
      "   107|         0|            0|            0|  0.00%|\n",
      "   108|         0|            0|            0|  0.00%|                suffix = '_reverse' if direction == 1 else ''\n",
      "   109|         0|            0|            0|  0.00%|                param_names = ['weight_ih_l{}{}', 'weight_hh_l{}{}']\n",
      "   110|         0|            0|            0|  0.00%|                if bias:\n",
      "   111|         0|            0|            0|  0.00%|                    param_names += ['bias_ih_l{}{}', 'bias_hh_l{}{}']\n",
      "   112|         0|            0|            0|  0.00%|                if self.proj_size > 0:\n",
      "   113|         0|            0|            0|  0.00%|                    param_names += ['weight_hr_l{}{}']\n",
      "   114|         0|            0|            0|  0.00%|                param_names = [x.format(layer, suffix) for x in param_names]\n",
      "   115|         0|            0|            0|  0.00%|\n",
      "   116|         0|            0|            0|  0.00%|                for name, param in zip(param_names, layer_params):\n",
      "   117|         0|            0|            0|  0.00%|                    setattr(self, name, param)\n",
      "   118|         0|            0|            0|  0.00%|                self._flat_weights_names.extend(param_names)\n",
      "   119|         0|            0|            0|  0.00%|                self._all_weights.append(param_names)\n",
      "   120|         0|            0|            0|  0.00%|\n",
      "   121|         0|            0|            0|  0.00%|        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn) for wn in self._flat_weights_names]\n",
      "   122|         0|            0|            0|  0.00%|        self.flatten_parameters()\n",
      "   123|         0|            0|            0|  0.00%|\n",
      "   124|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "   125|         0|            0|            0|  0.00%|\n",
      "   126|         0|            0|            0|  0.00%|    def __setattr__(self, attr, value):\n",
      "   127|         0|            0|            0|  0.00%|        if hasattr(self, \"_flat_weights_names\") and attr in self._flat_weights_names:\n",
      "   128|         0|            0|            0|  0.00%|            # keep self._flat_weights up to date if you do self.weight = ...\n",
      "   129|         0|            0|            0|  0.00%|            idx = self._flat_weights_names.index(attr)\n",
      "   130|         0|            0|            0|  0.00%|            self._flat_weights[idx] = value\n",
      "   131|         0|            0|            0|  0.00%|        super(RNNBase, self).__setattr__(attr, value)\n",
      "   132|         0|            0|            0|  0.00%|\n",
      "   133|         0|            0|            0|  0.00%|    def flatten_parameters(self) -> None:\n",
      "   134|         0|            0|            0|  0.00%|        \"\"\"Resets parameter data pointer so that they can use faster code paths.\n",
      "   135|         0|            0|            0|  0.00%|\n",
      "   136|         0|            0|            0|  0.00%|        Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
      "   137|         0|            0|            0|  0.00%|        Otherwise, it's a no-op.\n",
      "   138|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   139|         0|            0|            0|  0.00%|        # Short-circuits if _flat_weights is only partially instantiated\n",
      "   140|         0|            0|            0|  0.00%|        if len(self._flat_weights) != len(self._flat_weights_names):\n",
      "   141|         0|            0|            0|  0.00%|            return\n",
      "   142|         0|            0|            0|  0.00%|\n",
      "   143|         0|            0|            0|  0.00%|        for w in self._flat_weights:\n",
      "   144|         0|            0|            0|  0.00%|            if not isinstance(w, Tensor):\n",
      "   145|         0|            0|            0|  0.00%|                return\n",
      "   146|         0|            0|            0|  0.00%|        # Short-circuits if any tensor in self._flat_weights is not acceptable to cuDNN\n",
      "   147|         0|            0|            0|  0.00%|        # or the tensors in _flat_weights are of different dtypes\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         0|            0|            0|  0.00%|        first_fw = self._flat_weights[0]\n",
      "   150|         0|            0|            0|  0.00%|        dtype = first_fw.dtype\n",
      "   151|         0|            0|            0|  0.00%|        for fw in self._flat_weights:\n",
      "   152|         0|            0|            0|  0.00%|            if (not isinstance(fw.data, Tensor) or not (fw.data.dtype == dtype) or\n",
      "   153|         0|            0|            0|  0.00%|                    not fw.data.is_cuda or\n",
      "   154|         0|            0|            0|  0.00%|                    not torch.backends.cudnn.is_acceptable(fw.data)):\n",
      "   155|         0|            0|            0|  0.00%|                return\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         0|            0|            0|  0.00%|        # If any parameters alias, we fall back to the slower, copying code path. This is\n",
      "   158|         0|            0|            0|  0.00%|        # a sufficient check, because overlapping parameter buffers that don't completely\n",
      "   159|         0|            0|            0|  0.00%|        # alias would break the assumptions of the uniqueness check in\n",
      "   160|         0|            0|            0|  0.00%|        # Module.named_parameters().\n",
      "   161|         0|            0|            0|  0.00%|        unique_data_ptrs = set(p.data_ptr() for p in self._flat_weights)\n",
      "   162|         0|            0|            0|  0.00%|        if len(unique_data_ptrs) != len(self._flat_weights):\n",
      "   163|         0|            0|            0|  0.00%|            return\n",
      "   164|         0|            0|            0|  0.00%|\n",
      "   165|         0|            0|            0|  0.00%|        with torch.cuda.device_of(first_fw):\n",
      "   166|         0|            0|            0|  0.00%|            import torch.backends.cudnn.rnn as rnn\n",
      "   167|         0|            0|            0|  0.00%|\n",
      "   168|         0|            0|            0|  0.00%|            # Note: no_grad() is necessary since _cudnn_rnn_flatten_weight is\n",
      "   169|         0|            0|            0|  0.00%|            # an inplace operation on self._flat_weights\n",
      "   170|         0|            0|            0|  0.00%|            with torch.no_grad():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   171|         0|            0|            0|  0.00%|                if torch._use_cudnn_rnn_flatten_weight():\n",
      "   172|         0|            0|            0|  0.00%|                    num_weights = 4 if self.bias else 2\n",
      "   173|         0|            0|            0|  0.00%|                    if self.proj_size > 0:\n",
      "   174|         0|            0|            0|  0.00%|                        num_weights += 1\n",
      "   175|         0|            0|            0|  0.00%|                    torch._cudnn_rnn_flatten_weight(\n",
      "   176|         0|            0|            0|  0.00%|                        self._flat_weights, num_weights,\n",
      "   177|         0|            0|            0|  0.00%|                        self.input_size, rnn.get_cudnn_mode(self.mode),\n",
      "   178|         0|            0|            0|  0.00%|                        self.hidden_size, self.proj_size, self.num_layers,\n",
      "   179|         0|            0|            0|  0.00%|                        self.batch_first, bool(self.bidirectional))\n",
      "   180|         0|            0|            0|  0.00%|\n",
      "   181|         0|            0|            0|  0.00%|    def _apply(self, fn):\n",
      "   182|         0|            0|            0|  0.00%|        ret = super(RNNBase, self)._apply(fn)\n",
      "   183|         0|            0|            0|  0.00%|\n",
      "   184|         0|            0|            0|  0.00%|        # Resets _flat_weights\n",
      "   185|         0|            0|            0|  0.00%|        # Note: be v. careful before removing this, as 3rd party device types\n",
      "   186|         0|            0|            0|  0.00%|        # likely rely on this behavior to properly .to() modules like LSTM.\n",
      "   187|         0|            0|            0|  0.00%|        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn) for wn in self._flat_weights_names]\n",
      "   188|         0|            0|            0|  0.00%|        # Flattens params (on CUDA)\n",
      "   189|         0|            0|            0|  0.00%|        self.flatten_parameters()\n",
      "   190|         0|            0|            0|  0.00%|\n",
      "   191|         0|            0|            0|  0.00%|        return ret\n",
      "   192|         0|            0|            0|  0.00%|\n",
      "   193|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   194|         0|            0|            0|  0.00%|        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
      "   195|         0|            0|            0|  0.00%|        for weight in self.parameters():\n",
      "   196|         0|            0|            0|  0.00%|            init.uniform_(weight, -stdv, stdv)\n",
      "   197|         0|            0|            0|  0.00%|\n",
      "   198|         9|  2.52724e-05|  2.80804e-06|  0.00%|    def check_input(self, input: Tensor, batch_sizes: Optional[Tensor]) -> None:\n",
      "   199|         9|  2.36034e-05|   2.6226e-06|  0.00%|        expected_input_dim = 2 if batch_sizes is not None else 3\n",
      "   200|         9|  2.64645e-05|   2.9405e-06|  0.00%|        if input.dim() != expected_input_dim:\n",
      "   201|         0|            0|            0|  0.00%|            raise RuntimeError(\n",
      "   202|         0|            0|            0|  0.00%|                'input must have {} dimensions, got {}'.format(\n",
      "   203|         0|            0|            0|  0.00%|                    expected_input_dim, input.dim()))\n",
      "   204|         9|  2.81334e-05|  3.12593e-06|  0.00%|        if self.input_size != input.size(-1):\n",
      "   205|         0|            0|            0|  0.00%|            raise RuntimeError(\n",
      "   206|         0|            0|            0|  0.00%|                'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n",
      "   207|         0|            0|            0|  0.00%|                    self.input_size, input.size(-1)))\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         9|  2.64645e-05|   2.9405e-06|  0.00%|    def get_expected_hidden_size(self, input: Tensor, batch_sizes: Optional[Tensor]) -> Tuple[int, int, int]:\n",
      "   210|         9|  2.16961e-05|  2.41068e-06|  0.00%|        if batch_sizes is not None:\n",
      "   211|         1|  1.00136e-05|  1.00136e-05|  0.00%|            mini_batch = int(batch_sizes[0])\n",
      "   212|         0|            0|            0|  0.00%|        else:\n",
      "   213|         8|  2.38419e-05|  2.98023e-06|  0.00%|            mini_batch = input.size(0) if self.batch_first else input.size(1)\n",
      "   214|         9|  2.64645e-05|   2.9405e-06|  0.00%|        num_directions = 2 if self.bidirectional else 1\n",
      "   215|         9|  2.45571e-05|  2.72857e-06|  0.00%|        if self.proj_size > 0:\n",
      "   216|         0|            0|            0|  0.00%|            expected_hidden_size = (self.num_layers * num_directions,\n",
      "   217|         0|            0|            0|  0.00%|                                    mini_batch, self.proj_size)\n",
      "   218|         0|            0|            0|  0.00%|        else:\n",
      "   219|         9|  2.45571e-05|  2.72857e-06|  0.00%|            expected_hidden_size = (self.num_layers * num_directions,\n",
      "   220|         9|  2.55108e-05|  2.83453e-06|  0.00%|                                    mini_batch, self.hidden_size)\n",
      "   221|         9|  1.97887e-05|  2.19875e-06|  0.00%|        return expected_hidden_size\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         9|  1.64509e-05|  1.82788e-06|  0.00%|    def check_hidden_size(self, hx: Tensor, expected_hidden_size: Tuple[int, int, int],\n",
      "   224|         0|            0|            0|  0.00%|                          msg: str = 'Expected hidden size {}, got {}') -> None:\n",
      "   225|         9|   3.0756e-05|  3.41733e-06|  0.00%|        if hx.size() != expected_hidden_size:\n",
      "   226|         0|            0|            0|  0.00%|            raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         9|  1.93119e-05|  2.14577e-06|  0.00%|    def check_forward_args(self, input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n",
      "   229|         9|  7.55787e-05|  8.39763e-06|  0.00%|        self.check_input(input, batch_sizes)\n",
      "(call)|         9|  0.000103474|  1.14971e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:198 check_input\n",
      "   230|         9|  6.69956e-05|  7.44396e-06|  0.00%|        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)\n",
      "(call)|         9|  0.000202894|  2.25438e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:209 get_expected_hidden_size\n",
      "   231|         0|            0|            0|  0.00%|\n",
      "   232|         9|   6.7234e-05|  7.47045e-06|  0.00%|        self.check_hidden_size(hidden, expected_hidden_size)\n",
      "(call)|         9|  4.72069e-05|  5.24521e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:223 check_hidden_size\n",
      "   233|         0|            0|            0|  0.00%|\n",
      "   234|        17|  4.29153e-05|  2.52443e-06|  0.00%|    def permute_hidden(self, hx: Tensor, permutation: Optional[Tensor]):\n",
      "   235|        17|  4.43459e-05|  2.60858e-06|  0.00%|        if permutation is None:\n",
      "   236|        16|  3.62396e-05|  2.26498e-06|  0.00%|            return hx\n",
      "   237|         1|  1.50204e-05|  1.50204e-05|  0.00%|        return apply_permutation(hx, permutation)\n",
      "(call)|         1|   2.7895e-05|   2.7895e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:20 apply_permutation\n",
      "   238|         0|            0|            0|  0.00%|\n",
      "   239|         0|            0|            0|  0.00%|    def forward(self,\n",
      "   240|         0|            0|            0|  0.00%|                input: Union[Tensor, PackedSequence],\n",
      "   241|         0|            0|            0|  0.00%|                hx: Optional[Tensor] = None) -> Tuple[Union[Tensor, PackedSequence], Tensor]:\n",
      "   242|         0|            0|            0|  0.00%|        is_packed = isinstance(input, PackedSequence)\n",
      "   243|         0|            0|            0|  0.00%|        if is_packed:\n",
      "   244|         0|            0|            0|  0.00%|            input, batch_sizes, sorted_indices, unsorted_indices = input\n",
      "   245|         0|            0|            0|  0.00%|            max_batch_size = int(batch_sizes[0])\n",
      "   246|         0|            0|            0|  0.00%|        else:\n",
      "   247|         0|            0|            0|  0.00%|            input = cast(Tensor, input)\n",
      "   248|         0|            0|            0|  0.00%|            batch_sizes = None\n",
      "   249|         0|            0|            0|  0.00%|            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
      "   250|         0|            0|            0|  0.00%|            sorted_indices = None\n",
      "   251|         0|            0|            0|  0.00%|            unsorted_indices = None\n",
      "   252|         0|            0|            0|  0.00%|        if hx is None:\n",
      "   253|         0|            0|            0|  0.00%|            input = cast(Tensor, input)\n",
      "   254|         0|            0|            0|  0.00%|            num_directions = 2 if self.bidirectional else 1\n",
      "   255|         0|            0|            0|  0.00%|            hx = torch.zeros(self.num_layers * num_directions,\n",
      "   256|         0|            0|            0|  0.00%|                             max_batch_size, self.hidden_size,\n",
      "   257|         0|            0|            0|  0.00%|                             dtype=input.dtype, device=input.device)\n",
      "   258|         0|            0|            0|  0.00%|        else:\n",
      "   259|         0|            0|            0|  0.00%|            # Each batch of the hidden state should match the input sequence that\n",
      "   260|         0|            0|            0|  0.00%|            # the user believes he/she is passing in.\n",
      "   261|         0|            0|            0|  0.00%|            hx = self.permute_hidden(hx, sorted_indices)\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|        assert hx is not None\n",
      "   264|         0|            0|            0|  0.00%|        input = cast(Tensor, input)\n",
      "   265|         0|            0|            0|  0.00%|        self.check_forward_args(input, hx, batch_sizes)\n",
      "   266|         0|            0|            0|  0.00%|        _impl = _rnn_impls[self.mode]\n",
      "   267|         0|            0|            0|  0.00%|        if batch_sizes is None:\n",
      "   268|         0|            0|            0|  0.00%|            result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "   269|         0|            0|            0|  0.00%|                           self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "   270|         0|            0|            0|  0.00%|        else:\n",
      "   271|         0|            0|            0|  0.00%|            result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "   272|         0|            0|            0|  0.00%|                           self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "   273|         0|            0|            0|  0.00%|\n",
      "   274|         0|            0|            0|  0.00%|        output: Union[Tensor, PackedSequence]\n",
      "   275|         0|            0|            0|  0.00%|        output = result[0]\n",
      "   276|         0|            0|            0|  0.00%|        hidden = result[1]\n",
      "   277|         0|            0|            0|  0.00%|\n",
      "   278|         0|            0|            0|  0.00%|        if is_packed:\n",
      "   279|         0|            0|            0|  0.00%|            output = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
      "   280|         0|            0|            0|  0.00%|        return output, self.permute_hidden(hidden, unsorted_indices)\n",
      "   281|         0|            0|            0|  0.00%|\n",
      "   282|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   283|         0|            0|            0|  0.00%|        s = '{input_size}, {hidden_size}'\n",
      "   284|         0|            0|            0|  0.00%|        if self.proj_size != 0:\n",
      "   285|         0|            0|            0|  0.00%|            s += ', proj_size={proj_size}'\n",
      "   286|         0|            0|            0|  0.00%|        if self.num_layers != 1:\n",
      "   287|         0|            0|            0|  0.00%|            s += ', num_layers={num_layers}'\n",
      "   288|         0|            0|            0|  0.00%|        if self.bias is not True:\n",
      "   289|         0|            0|            0|  0.00%|            s += ', bias={bias}'\n",
      "   290|         0|            0|            0|  0.00%|        if self.batch_first is not False:\n",
      "   291|         0|            0|            0|  0.00%|            s += ', batch_first={batch_first}'\n",
      "   292|         0|            0|            0|  0.00%|        if self.dropout != 0:\n",
      "   293|         0|            0|            0|  0.00%|            s += ', dropout={dropout}'\n",
      "   294|         0|            0|            0|  0.00%|        if self.bidirectional is not False:\n",
      "   295|         0|            0|            0|  0.00%|            s += ', bidirectional={bidirectional}'\n",
      "   296|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   297|         0|            0|            0|  0.00%|\n",
      "   298|         0|            0|            0|  0.00%|    def __setstate__(self, d):\n",
      "   299|         0|            0|            0|  0.00%|        super(RNNBase, self).__setstate__(d)\n",
      "   300|         0|            0|            0|  0.00%|        if 'all_weights' in d:\n",
      "   301|         0|            0|            0|  0.00%|            self._all_weights = d['all_weights']\n",
      "   302|         0|            0|            0|  0.00%|        # In PyTorch 1.8 we added a proj_size member variable to LSTM.\n",
      "   303|         0|            0|            0|  0.00%|        # LSTMs that were serialized via torch.save(module) before PyTorch 1.8\n",
      "   304|         0|            0|            0|  0.00%|        # don't have it, so to preserve compatibility we set proj_size here.\n",
      "   305|         0|            0|            0|  0.00%|        if 'proj_size' not in d:\n",
      "   306|         0|            0|            0|  0.00%|            self.proj_size = 0\n",
      "   307|         0|            0|            0|  0.00%|\n",
      "   308|         0|            0|            0|  0.00%|        if isinstance(self._all_weights[0][0], str):\n",
      "   309|         0|            0|            0|  0.00%|            return\n",
      "   310|         0|            0|            0|  0.00%|        num_layers = self.num_layers\n",
      "   311|         0|            0|            0|  0.00%|        num_directions = 2 if self.bidirectional else 1\n",
      "   312|         0|            0|            0|  0.00%|        self._flat_weights_names = []\n",
      "   313|         0|            0|            0|  0.00%|        self._all_weights = []\n",
      "   314|         0|            0|            0|  0.00%|        for layer in range(num_layers):\n",
      "   315|         0|            0|            0|  0.00%|            for direction in range(num_directions):\n",
      "   316|         0|            0|            0|  0.00%|                suffix = '_reverse' if direction == 1 else ''\n",
      "   317|         0|            0|            0|  0.00%|                weights = ['weight_ih_l{}{}', 'weight_hh_l{}{}', 'bias_ih_l{}{}',\n",
      "   318|         0|            0|            0|  0.00%|                           'bias_hh_l{}{}', 'weight_hr_l{}{}']\n",
      "   319|         0|            0|            0|  0.00%|                weights = [x.format(layer, suffix) for x in weights]\n",
      "   320|         0|            0|            0|  0.00%|                if self.bias:\n",
      "   321|         0|            0|            0|  0.00%|                    if self.proj_size > 0:\n",
      "   322|         0|            0|            0|  0.00%|                        self._all_weights += [weights]\n",
      "   323|         0|            0|            0|  0.00%|                        self._flat_weights_names.extend(weights)\n",
      "   324|         0|            0|            0|  0.00%|                    else:\n",
      "   325|         0|            0|            0|  0.00%|                        self._all_weights += [weights[:4]]\n",
      "   326|         0|            0|            0|  0.00%|                        self._flat_weights_names.extend(weights[:4])\n",
      "   327|         0|            0|            0|  0.00%|                else:\n",
      "   328|         0|            0|            0|  0.00%|                    if self.proj_size > 0:\n",
      "   329|         0|            0|            0|  0.00%|                        self._all_weights += [weights[:2]] + [weights[-1:]]\n",
      "   330|         0|            0|            0|  0.00%|                        self._flat_weights_names.extend(weights[:2] + [weights[-1:]])\n",
      "   331|         0|            0|            0|  0.00%|                    else:\n",
      "   332|         0|            0|            0|  0.00%|                        self._all_weights += [weights[:2]]\n",
      "   333|         0|            0|            0|  0.00%|                        self._flat_weights_names.extend(weights[:2])\n",
      "   334|         0|            0|            0|  0.00%|        self._flat_weights = [(lambda wn: getattr(self, wn) if hasattr(self, wn) else None)(wn) for wn in self._flat_weights_names]\n",
      "   335|         0|            0|            0|  0.00%|\n",
      "   336|         0|            0|            0|  0.00%|    @property\n",
      "   337|         0|            0|            0|  0.00%|    def all_weights(self) -> List[List[Parameter]]:\n",
      "   338|         0|            0|            0|  0.00%|        return [[getattr(self, weight) for weight in weights] for weights in self._all_weights]\n",
      "   339|         0|            0|            0|  0.00%|\n",
      "   340|         0|            0|            0|  0.00%|    def _replicate_for_data_parallel(self):\n",
      "   341|         0|            0|            0|  0.00%|        replica = super(RNNBase, self)._replicate_for_data_parallel()\n",
      "   342|         0|            0|            0|  0.00%|        # Need to copy these caches, otherwise the replica will share the same\n",
      "   343|         0|            0|            0|  0.00%|        # flat weights list.\n",
      "   344|         0|            0|            0|  0.00%|        replica._flat_weights = replica._flat_weights[:]\n",
      "   345|         0|            0|            0|  0.00%|        replica._flat_weights_names = replica._flat_weights_names[:]\n",
      "   346|         0|            0|            0|  0.00%|        return replica\n",
      "   347|         0|            0|            0|  0.00%|\n",
      "   348|         0|            0|            0|  0.00%|\n",
      "   349|         0|            0|            0|  0.00%|class RNN(RNNBase):\n",
      "   350|         0|            0|            0|  0.00%|    r\"\"\"Applies a multi-layer Elman RNN with :math:`\\tanh` or :math:`\\text{ReLU}` non-linearity to an\n",
      "   351|         0|            0|            0|  0.00%|    input sequence.\n",
      "   352|         0|            0|            0|  0.00%|\n",
      "   353|         0|            0|            0|  0.00%|\n",
      "   354|         0|            0|            0|  0.00%|    For each element in the input sequence, each layer computes the following\n",
      "   355|         0|            0|            0|  0.00%|    function:\n",
      "   356|         0|            0|            0|  0.00%|\n",
      "   357|         0|            0|            0|  0.00%|    .. math::\n",
      "   358|         0|            0|            0|  0.00%|        h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
      "   359|         0|            0|            0|  0.00%|\n",
      "   360|         0|            0|            0|  0.00%|    where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
      "   361|         0|            0|            0|  0.00%|    the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
      "   362|         0|            0|            0|  0.00%|    previous layer at time `t-1` or the initial hidden state at time `0`.\n",
      "   363|         0|            0|            0|  0.00%|    If :attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used instead of :math:`\\tanh`.\n",
      "   364|         0|            0|            0|  0.00%|\n",
      "   365|         0|            0|            0|  0.00%|    Args:\n",
      "   366|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "   367|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "   368|         0|            0|            0|  0.00%|        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      "   369|         0|            0|            0|  0.00%|            would mean stacking two RNNs together to form a `stacked RNN`,\n",
      "   370|         0|            0|            0|  0.00%|            with the second RNN taking in outputs of the first RNN and\n",
      "   371|         0|            0|            0|  0.00%|            computing the final results. Default: 1\n",
      "   372|         0|            0|            0|  0.00%|        nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
      "   373|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      "   374|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   375|         0|            0|            0|  0.00%|        batch_first: If ``True``, then the input and output tensors are provided\n",
      "   376|         0|            0|            0|  0.00%|            as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n",
      "   377|         0|            0|            0|  0.00%|            Note that this does not apply to hidden or cell states. See the\n",
      "   378|         0|            0|            0|  0.00%|            Inputs/Outputs sections below for details.  Default: ``False``\n",
      "   379|         0|            0|            0|  0.00%|        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      "   380|         0|            0|            0|  0.00%|            RNN layer except the last layer, with dropout probability equal to\n",
      "   381|         0|            0|            0|  0.00%|            :attr:`dropout`. Default: 0\n",
      "   382|         0|            0|            0|  0.00%|        bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
      "   383|         0|            0|            0|  0.00%|\n",
      "   384|         0|            0|            0|  0.00%|    Inputs: input, h_0\n",
      "   385|         0|            0|            0|  0.00%|        * **input**: tensor of shape :math:`(L, N, H_{in})` when ``batch_first=False`` or\n",
      "   386|         0|            0|            0|  0.00%|          :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n",
      "   387|         0|            0|            0|  0.00%|          the input sequence.  The input can also be a packed variable length sequence.\n",
      "   388|         0|            0|            0|  0.00%|          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      "   389|         0|            0|            0|  0.00%|          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      "   390|         0|            0|            0|  0.00%|        * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the initial hidden\n",
      "   391|         0|            0|            0|  0.00%|          state for each element in the batch. Defaults to zeros if not provided.\n",
      "   392|         0|            0|            0|  0.00%|\n",
      "   393|         0|            0|            0|  0.00%|        where:\n",
      "   394|         0|            0|            0|  0.00%|\n",
      "   395|         0|            0|            0|  0.00%|        .. math::\n",
      "   396|         0|            0|            0|  0.00%|            \\begin{aligned}\n",
      "   397|         0|            0|            0|  0.00%|                N ={} & \\text{batch size} \\\\\n",
      "   398|         0|            0|            0|  0.00%|                L ={} & \\text{sequence length} \\\\\n",
      "   399|         0|            0|            0|  0.00%|                D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n",
      "   400|         0|            0|            0|  0.00%|                H_{in} ={} & \\text{input\\_size} \\\\\n",
      "   401|         0|            0|            0|  0.00%|                H_{out} ={} & \\text{hidden\\_size}\n",
      "   402|         0|            0|            0|  0.00%|            \\end{aligned}\n",
      "   403|         0|            0|            0|  0.00%|\n",
      "   404|         0|            0|            0|  0.00%|    Outputs: output, h_n\n",
      "   405|         0|            0|            0|  0.00%|        * **output**: tensor of shape :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n",
      "   406|         0|            0|            0|  0.00%|          :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n",
      "   407|         0|            0|            0|  0.00%|          `(h_t)` from the last layer of the RNN, for each `t`. If a\n",
      "   408|         0|            0|            0|  0.00%|          :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n",
      "   409|         0|            0|            0|  0.00%|          will also be a packed sequence.\n",
      "   410|         0|            0|            0|  0.00%|        * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n",
      "   411|         0|            0|            0|  0.00%|          for each element in the batch.\n",
      "   412|         0|            0|            0|  0.00%|\n",
      "   413|         0|            0|            0|  0.00%|    Attributes:\n",
      "   414|         0|            0|            0|  0.00%|        weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
      "   415|         0|            0|            0|  0.00%|            of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
      "   416|         0|            0|            0|  0.00%|            `(hidden_size, num_directions * hidden_size)`\n",
      "   417|         0|            0|            0|  0.00%|        weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
      "   418|         0|            0|            0|  0.00%|            of shape `(hidden_size, hidden_size)`\n",
      "   419|         0|            0|            0|  0.00%|        bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
      "   420|         0|            0|            0|  0.00%|            of shape `(hidden_size)`\n",
      "   421|         0|            0|            0|  0.00%|        bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
      "   422|         0|            0|            0|  0.00%|            of shape `(hidden_size)`\n",
      "   423|         0|            0|            0|  0.00%|\n",
      "   424|         0|            0|            0|  0.00%|    .. note::\n",
      "   425|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "   426|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "   427|         0|            0|            0|  0.00%|\n",
      "   428|         0|            0|            0|  0.00%|    .. note::\n",
      "   429|         0|            0|            0|  0.00%|        For bidirectional RNNs, forward and backward are directions 0 and 1 respectively.\n",
      "   430|         0|            0|            0|  0.00%|        Example of splitting the output layers when ``batch_first=False``:\n",
      "   431|         0|            0|            0|  0.00%|        ``output.view(seq_len, batch, num_directions, hidden_size)``.\n",
      "   432|         0|            0|            0|  0.00%|\n",
      "   433|         0|            0|            0|  0.00%|    .. include:: ../cudnn_rnn_determinism.rst\n",
      "   434|         0|            0|            0|  0.00%|\n",
      "   435|         0|            0|            0|  0.00%|    .. include:: ../cudnn_persistent_rnn.rst\n",
      "   436|         0|            0|            0|  0.00%|\n",
      "   437|         0|            0|            0|  0.00%|    Examples::\n",
      "   438|         0|            0|            0|  0.00%|\n",
      "   439|         0|            0|            0|  0.00%|        >>> rnn = nn.RNN(10, 20, 2)\n",
      "   440|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 3, 10)\n",
      "   441|         0|            0|            0|  0.00%|        >>> h0 = torch.randn(2, 3, 20)\n",
      "   442|         0|            0|            0|  0.00%|        >>> output, hn = rnn(input, h0)\n",
      "   443|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   444|         0|            0|            0|  0.00%|\n",
      "   445|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):\n",
      "   446|         0|            0|            0|  0.00%|        if 'proj_size' in kwargs:\n",
      "   447|         0|            0|            0|  0.00%|            raise ValueError(\"proj_size argument is only supported for LSTM, not RNN or GRU\")\n",
      "   448|         0|            0|            0|  0.00%|        self.nonlinearity = kwargs.pop('nonlinearity', 'tanh')\n",
      "   449|         0|            0|            0|  0.00%|        if self.nonlinearity == 'tanh':\n",
      "   450|         0|            0|            0|  0.00%|            mode = 'RNN_TANH'\n",
      "   451|         0|            0|            0|  0.00%|        elif self.nonlinearity == 'relu':\n",
      "   452|         0|            0|            0|  0.00%|            mode = 'RNN_RELU'\n",
      "   453|         0|            0|            0|  0.00%|        else:\n",
      "   454|         0|            0|            0|  0.00%|            raise ValueError(\"Unknown nonlinearity '{}'\".format(self.nonlinearity))\n",
      "   455|         0|            0|            0|  0.00%|        super(RNN, self).__init__(mode, *args, **kwargs)\n",
      "   456|         0|            0|            0|  0.00%|\n",
      "   457|         0|            0|            0|  0.00%|\n",
      "   458|         0|            0|            0|  0.00%|# XXX: LSTM and GRU implementation is different from RNNBase, this is because:\n",
      "   459|         0|            0|            0|  0.00%|# 1. we want to support nn.LSTM and nn.GRU in TorchScript and TorchScript in\n",
      "   460|         0|            0|            0|  0.00%|#    its current state could not support the python Union Type or Any Type\n",
      "   461|         0|            0|            0|  0.00%|# 2. TorchScript static typing does not allow a Function or Callable type in\n",
      "   462|         0|            0|            0|  0.00%|#    Dict values, so we have to separately call _VF instead of using _rnn_impls\n",
      "   463|         0|            0|            0|  0.00%|# 3. This is temporary only and in the transition state that we want to make it\n",
      "   464|         0|            0|            0|  0.00%|#    on time for the release\n",
      "   465|         0|            0|            0|  0.00%|#\n",
      "   466|         0|            0|            0|  0.00%|# More discussion details in https://github.com/pytorch/pytorch/pull/23266\n",
      "   467|         0|            0|            0|  0.00%|#\n",
      "   468|         0|            0|            0|  0.00%|# TODO: remove the overriding implementations for LSTM and GRU when TorchScript\n",
      "   469|         0|            0|            0|  0.00%|# support expressing these two modules generally.\n",
      "   470|         0|            0|            0|  0.00%|class LSTM(RNNBase):\n",
      "   471|         0|            0|            0|  0.00%|    r\"\"\"Applies a multi-layer long short-term memory (LSTM) RNN to an input\n",
      "   472|         0|            0|            0|  0.00%|    sequence.\n",
      "   473|         0|            0|            0|  0.00%|\n",
      "   474|         0|            0|            0|  0.00%|\n",
      "   475|         0|            0|            0|  0.00%|    For each element in the input sequence, each layer computes the following\n",
      "   476|         0|            0|            0|  0.00%|    function:\n",
      "   477|         0|            0|            0|  0.00%|\n",
      "   478|         0|            0|            0|  0.00%|    .. math::\n",
      "   479|         0|            0|            0|  0.00%|        \\begin{array}{ll} \\\\\n",
      "   480|         0|            0|            0|  0.00%|            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
      "   481|         0|            0|            0|  0.00%|            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
      "   482|         0|            0|            0|  0.00%|            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
      "   483|         0|            0|            0|  0.00%|            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
      "   484|         0|            0|            0|  0.00%|            c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
      "   485|         0|            0|            0|  0.00%|            h_t = o_t \\odot \\tanh(c_t) \\\\\n",
      "   486|         0|            0|            0|  0.00%|        \\end{array}\n",
      "   487|         0|            0|            0|  0.00%|\n",
      "   488|         0|            0|            0|  0.00%|    where :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell\n",
      "   489|         0|            0|            0|  0.00%|    state at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{t-1}`\n",
      "   490|         0|            0|            0|  0.00%|    is the hidden state of the layer at time `t-1` or the initial hidden\n",
      "   491|         0|            0|            0|  0.00%|    state at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,\n",
      "   492|         0|            0|            0|  0.00%|    :math:`o_t` are the input, forget, cell, and output gates, respectively.\n",
      "   493|         0|            0|            0|  0.00%|    :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n",
      "   494|         0|            0|            0|  0.00%|\n",
      "   495|         0|            0|            0|  0.00%|    In a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n",
      "   496|         0|            0|            0|  0.00%|    (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n",
      "   497|         0|            0|            0|  0.00%|    dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n",
      "   498|         0|            0|            0|  0.00%|    variable which is :math:`0` with probability :attr:`dropout`.\n",
      "   499|         0|            0|            0|  0.00%|\n",
      "   500|         0|            0|            0|  0.00%|    If ``proj_size > 0`` is specified, LSTM with projections will be used. This changes\n",
      "   501|         0|            0|            0|  0.00%|    the LSTM cell in the following way. First, the dimension of :math:`h_t` will be changed from\n",
      "   502|         0|            0|            0|  0.00%|    ``hidden_size`` to ``proj_size`` (dimensions of :math:`W_{hi}` will be changed accordingly).\n",
      "   503|         0|            0|            0|  0.00%|    Second, the output hidden state of each layer will be multiplied by a learnable projection\n",
      "   504|         0|            0|            0|  0.00%|    matrix: :math:`h_t = W_{hr}h_t`. Note that as a consequence of this, the output\n",
      "   505|         0|            0|            0|  0.00%|    of LSTM network will be of different shape as well. See Inputs/Outputs sections below for exact\n",
      "   506|         0|            0|            0|  0.00%|    dimensions of all variables. You can find more details in https://arxiv.org/abs/1402.1128.\n",
      "   507|         0|            0|            0|  0.00%|\n",
      "   508|         0|            0|            0|  0.00%|    Args:\n",
      "   509|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "   510|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "   511|         0|            0|            0|  0.00%|        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      "   512|         0|            0|            0|  0.00%|            would mean stacking two LSTMs together to form a `stacked LSTM`,\n",
      "   513|         0|            0|            0|  0.00%|            with the second LSTM taking in outputs of the first LSTM and\n",
      "   514|         0|            0|            0|  0.00%|            computing the final results. Default: 1\n",
      "   515|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      "   516|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   517|         0|            0|            0|  0.00%|        batch_first: If ``True``, then the input and output tensors are provided\n",
      "   518|         0|            0|            0|  0.00%|            as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n",
      "   519|         0|            0|            0|  0.00%|            Note that this does not apply to hidden or cell states. See the\n",
      "   520|         0|            0|            0|  0.00%|            Inputs/Outputs sections below for details.  Default: ``False``\n",
      "   521|         0|            0|            0|  0.00%|        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      "   522|         0|            0|            0|  0.00%|            LSTM layer except the last layer, with dropout probability equal to\n",
      "   523|         0|            0|            0|  0.00%|            :attr:`dropout`. Default: 0\n",
      "   524|         0|            0|            0|  0.00%|        bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n",
      "   525|         0|            0|            0|  0.00%|        proj_size: If ``> 0``, will use LSTM with projections of corresponding size. Default: 0\n",
      "   526|         0|            0|            0|  0.00%|\n",
      "   527|         0|            0|            0|  0.00%|    Inputs: input, (h_0, c_0)\n",
      "   528|         0|            0|            0|  0.00%|        * **input**: tensor of shape :math:`(L, N, H_{in})` when ``batch_first=False`` or\n",
      "   529|         0|            0|            0|  0.00%|          :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n",
      "   530|         0|            0|            0|  0.00%|          the input sequence.  The input can also be a packed variable length sequence.\n",
      "   531|         0|            0|            0|  0.00%|          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      "   532|         0|            0|            0|  0.00%|          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      "   533|         0|            0|            0|  0.00%|        * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n",
      "   534|         0|            0|            0|  0.00%|          initial hidden state for each element in the batch.\n",
      "   535|         0|            0|            0|  0.00%|          Defaults to zeros if (h_0, c_0) is not provided.\n",
      "   536|         0|            0|            0|  0.00%|        * **c_0**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n",
      "   537|         0|            0|            0|  0.00%|          initial cell state for each element in the batch.\n",
      "   538|         0|            0|            0|  0.00%|          Defaults to zeros if (h_0, c_0) is not provided.\n",
      "   539|         0|            0|            0|  0.00%|\n",
      "   540|         0|            0|            0|  0.00%|        where:\n",
      "   541|         0|            0|            0|  0.00%|\n",
      "   542|         0|            0|            0|  0.00%|        .. math::\n",
      "   543|         0|            0|            0|  0.00%|            \\begin{aligned}\n",
      "   544|         0|            0|            0|  0.00%|                N ={} & \\text{batch size} \\\\\n",
      "   545|         0|            0|            0|  0.00%|                L ={} & \\text{sequence length} \\\\\n",
      "   546|         0|            0|            0|  0.00%|                D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n",
      "   547|         0|            0|            0|  0.00%|                H_{in} ={} & \\text{input\\_size} \\\\\n",
      "   548|         0|            0|            0|  0.00%|                H_{cell} ={} & \\text{hidden\\_size} \\\\\n",
      "   549|         0|            0|            0|  0.00%|                H_{out} ={} & \\text{proj\\_size if } \\text{proj\\_size}>0 \\text{ otherwise hidden\\_size} \\\\\n",
      "   550|         0|            0|            0|  0.00%|            \\end{aligned}\n",
      "   551|         0|            0|            0|  0.00%|\n",
      "   552|         0|            0|            0|  0.00%|    Outputs: output, (h_n, c_n)\n",
      "   553|         0|            0|            0|  0.00%|        * **output**: tensor of shape :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n",
      "   554|         0|            0|            0|  0.00%|          :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n",
      "   555|         0|            0|            0|  0.00%|          `(h_t)` from the last layer of the LSTM, for each `t`. If a\n",
      "   556|         0|            0|            0|  0.00%|          :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n",
      "   557|         0|            0|            0|  0.00%|          will also be a packed sequence.\n",
      "   558|         0|            0|            0|  0.00%|        * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n",
      "   559|         0|            0|            0|  0.00%|          final hidden state for each element in the batch.\n",
      "   560|         0|            0|            0|  0.00%|        * **c_n**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n",
      "   561|         0|            0|            0|  0.00%|          final cell state for each element in the batch.\n",
      "   562|         0|            0|            0|  0.00%|\n",
      "   563|         0|            0|            0|  0.00%|    Attributes:\n",
      "   564|         0|            0|            0|  0.00%|        weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      "   565|         0|            0|            0|  0.00%|            `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n",
      "   566|         0|            0|            0|  0.00%|            Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`. If\n",
      "   567|         0|            0|            0|  0.00%|            ``proj_size > 0`` was specified, the shape will be\n",
      "   568|         0|            0|            0|  0.00%|            `(4*hidden_size, num_directions * proj_size)` for `k > 0`\n",
      "   569|         0|            0|            0|  0.00%|        weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      "   570|         0|            0|            0|  0.00%|            `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`. If ``proj_size > 0``\n",
      "   571|         0|            0|            0|  0.00%|            was specified, the shape will be `(4*hidden_size, proj_size)`.\n",
      "   572|         0|            0|            0|  0.00%|        bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      "   573|         0|            0|            0|  0.00%|            `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n",
      "   574|         0|            0|            0|  0.00%|        bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      "   575|         0|            0|            0|  0.00%|            `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`\n",
      "   576|         0|            0|            0|  0.00%|        weight_hr_l[k] : the learnable projection weights of the :math:`\\text{k}^{th}` layer\n",
      "   577|         0|            0|            0|  0.00%|            of shape `(proj_size, hidden_size)`. Only present when ``proj_size > 0`` was\n",
      "   578|         0|            0|            0|  0.00%|            specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   579|         0|            0|            0|  0.00%|        weight_ih_l[k]_reverse: Analogous to `weight_ih_l[k]` for the reverse direction.\n",
      "   580|         0|            0|            0|  0.00%|            Only present when ``bidirectional=True``.\n",
      "   581|         0|            0|            0|  0.00%|        weight_hh_l[k]_reverse:  Analogous to `weight_hh_l[k]` for the reverse direction.\n",
      "   582|         0|            0|            0|  0.00%|            Only present when ``bidirectional=True``.\n",
      "   583|         0|            0|            0|  0.00%|        bias_ih_l[k]_reverse:  Analogous to `bias_ih_l[k]` for the reverse direction.\n",
      "   584|         0|            0|            0|  0.00%|            Only present when ``bidirectional=True``.\n",
      "   585|         0|            0|            0|  0.00%|        bias_hh_l[k]_reverse:  Analogous to `bias_hh_l[k]` for the reverse direction.\n",
      "   586|         0|            0|            0|  0.00%|            Only present when ``bidirectional=True``.\n",
      "   587|         0|            0|            0|  0.00%|        weight_hr_l[k]_reverse:  Analogous to `weight_hr_l[k]` for the reverse direction.\n",
      "   588|         0|            0|            0|  0.00%|            Only present when ``bidirectional=True`` and ``proj_size > 0`` was specified.\n",
      "   589|         0|            0|            0|  0.00%|\n",
      "   590|         0|            0|            0|  0.00%|    .. note::\n",
      "   591|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "   592|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "   593|         0|            0|            0|  0.00%|\n",
      "   594|         0|            0|            0|  0.00%|    .. note::\n",
      "   595|         0|            0|            0|  0.00%|        For bidirectional LSTMs, forward and backward are directions 0 and 1 respectively.\n",
      "   596|         0|            0|            0|  0.00%|        Example of splitting the output layers when ``batch_first=False``:\n",
      "   597|         0|            0|            0|  0.00%|        ``output.view(seq_len, batch, num_directions, hidden_size)``.\n",
      "   598|         0|            0|            0|  0.00%|\n",
      "   599|         0|            0|            0|  0.00%|    .. include:: ../cudnn_rnn_determinism.rst\n",
      "   600|         0|            0|            0|  0.00%|\n",
      "   601|         0|            0|            0|  0.00%|    .. include:: ../cudnn_persistent_rnn.rst\n",
      "   602|         0|            0|            0|  0.00%|\n",
      "   603|         0|            0|            0|  0.00%|    Examples::\n",
      "   604|         0|            0|            0|  0.00%|\n",
      "   605|         0|            0|            0|  0.00%|        >>> rnn = nn.LSTM(10, 20, 2)\n",
      "   606|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 3, 10)\n",
      "   607|         0|            0|            0|  0.00%|        >>> h0 = torch.randn(2, 3, 20)\n",
      "   608|         0|            0|            0|  0.00%|        >>> c0 = torch.randn(2, 3, 20)\n",
      "   609|         0|            0|            0|  0.00%|        >>> output, (hn, cn) = rnn(input, (h0, c0))\n",
      "   610|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   611|         0|            0|            0|  0.00%|\n",
      "   612|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):\n",
      "   613|         0|            0|            0|  0.00%|        super(LSTM, self).__init__('LSTM', *args, **kwargs)\n",
      "   614|         0|            0|            0|  0.00%|\n",
      "   615|         0|            0|            0|  0.00%|    def get_expected_cell_size(self, input: Tensor, batch_sizes: Optional[Tensor]) -> Tuple[int, int, int]:\n",
      "   616|         0|            0|            0|  0.00%|        if batch_sizes is not None:\n",
      "   617|         0|            0|            0|  0.00%|            mini_batch = int(batch_sizes[0])\n",
      "   618|         0|            0|            0|  0.00%|        else:\n",
      "   619|         0|            0|            0|  0.00%|            mini_batch = input.size(0) if self.batch_first else input.size(1)\n",
      "   620|         0|            0|            0|  0.00%|        num_directions = 2 if self.bidirectional else 1\n",
      "   621|         0|            0|            0|  0.00%|        expected_hidden_size = (self.num_layers * num_directions,\n",
      "   622|         0|            0|            0|  0.00%|                                mini_batch, self.hidden_size)\n",
      "   623|         0|            0|            0|  0.00%|        return expected_hidden_size\n",
      "   624|         0|            0|            0|  0.00%|\n",
      "   625|         0|            0|            0|  0.00%|    # In the future, we should prevent mypy from applying contravariance rules here.\n",
      "   626|         0|            0|            0|  0.00%|    # See torch/nn/modules/module.py::_forward_unimplemented\n",
      "   627|         0|            0|            0|  0.00%|    def check_forward_args(self,  # type: ignore[override]\n",
      "   628|         0|            0|            0|  0.00%|                           input: Tensor,\n",
      "   629|         0|            0|            0|  0.00%|                           hidden: Tuple[Tensor, Tensor],\n",
      "   630|         0|            0|            0|  0.00%|                           batch_sizes: Optional[Tensor],\n",
      "   631|         0|            0|            0|  0.00%|                           ):\n",
      "   632|         0|            0|            0|  0.00%|        self.check_input(input, batch_sizes)\n",
      "   633|         0|            0|            0|  0.00%|        self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n",
      "   634|         0|            0|            0|  0.00%|                               'Expected hidden[0] size {}, got {}')\n",
      "   635|         0|            0|            0|  0.00%|        self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n",
      "   636|         0|            0|            0|  0.00%|                               'Expected hidden[1] size {}, got {}')\n",
      "   637|         0|            0|            0|  0.00%|\n",
      "   638|         0|            0|            0|  0.00%|    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n",
      "   639|         0|            0|            0|  0.00%|    def permute_hidden(self,  # type: ignore[override]\n",
      "   640|         0|            0|            0|  0.00%|                       hx: Tuple[Tensor, Tensor],\n",
      "   641|         0|            0|            0|  0.00%|                       permutation: Optional[Tensor]\n",
      "   642|         0|            0|            0|  0.00%|                       ) -> Tuple[Tensor, Tensor]:\n",
      "   643|         0|            0|            0|  0.00%|        if permutation is None:\n",
      "   644|         0|            0|            0|  0.00%|            return hx\n",
      "   645|         0|            0|            0|  0.00%|        return apply_permutation(hx[0], permutation), apply_permutation(hx[1], permutation)\n",
      "   646|         0|            0|            0|  0.00%|\n",
      "   647|         0|            0|            0|  0.00%|    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n",
      "   648|         0|            0|            0|  0.00%|    @overload  # type: ignore[override]\n",
      "   649|         0|            0|            0|  0.00%|    @torch._jit_internal._overload_method  # noqa: F811\n",
      "   650|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None\n",
      "   651|         0|            0|            0|  0.00%|                ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:  # noqa: F811\n",
      "   652|         0|            0|            0|  0.00%|        pass\n",
      "   653|         0|            0|            0|  0.00%|\n",
      "   654|         0|            0|            0|  0.00%|    # Same as above, see torch/nn/modules/module.py::_forward_unimplemented\n",
      "   655|         0|            0|            0|  0.00%|    @overload\n",
      "   656|         0|            0|            0|  0.00%|    @torch._jit_internal._overload_method  # noqa: F811\n",
      "   657|         0|            0|            0|  0.00%|    def forward(self, input: PackedSequence, hx: Optional[Tuple[Tensor, Tensor]] = None\n",
      "   658|         0|            0|            0|  0.00%|                ) -> Tuple[PackedSequence, Tuple[Tensor, Tensor]]:  # noqa: F811\n",
      "   659|         0|            0|            0|  0.00%|        pass\n",
      "   660|         0|            0|            0|  0.00%|\n",
      "   661|         0|            0|            0|  0.00%|    def forward(self, input, hx=None):  # noqa: F811\n",
      "   662|         0|            0|            0|  0.00%|        orig_input = input\n",
      "   663|         0|            0|            0|  0.00%|        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
      "   664|         0|            0|            0|  0.00%|        if isinstance(orig_input, PackedSequence):\n",
      "   665|         0|            0|            0|  0.00%|            input, batch_sizes, sorted_indices, unsorted_indices = input\n",
      "   666|         0|            0|            0|  0.00%|            max_batch_size = batch_sizes[0]\n",
      "   667|         0|            0|            0|  0.00%|            max_batch_size = int(max_batch_size)\n",
      "   668|         0|            0|            0|  0.00%|        else:\n",
      "   669|         0|            0|            0|  0.00%|            batch_sizes = None\n",
      "   670|         0|            0|            0|  0.00%|            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
      "   671|         0|            0|            0|  0.00%|            sorted_indices = None\n",
      "   672|         0|            0|            0|  0.00%|            unsorted_indices = None\n",
      "   673|         0|            0|            0|  0.00%|\n",
      "   674|         0|            0|            0|  0.00%|        if hx is None:\n",
      "   675|         0|            0|            0|  0.00%|            num_directions = 2 if self.bidirectional else 1\n",
      "   676|         0|            0|            0|  0.00%|            real_hidden_size = self.proj_size if self.proj_size > 0 else self.hidden_size\n",
      "   677|         0|            0|            0|  0.00%|            h_zeros = torch.zeros(self.num_layers * num_directions,\n",
      "   678|         0|            0|            0|  0.00%|                                  max_batch_size, real_hidden_size,\n",
      "   679|         0|            0|            0|  0.00%|                                  dtype=input.dtype, device=input.device)\n",
      "   680|         0|            0|            0|  0.00%|            c_zeros = torch.zeros(self.num_layers * num_directions,\n",
      "   681|         0|            0|            0|  0.00%|                                  max_batch_size, self.hidden_size,\n",
      "   682|         0|            0|            0|  0.00%|                                  dtype=input.dtype, device=input.device)\n",
      "   683|         0|            0|            0|  0.00%|            hx = (h_zeros, c_zeros)\n",
      "   684|         0|            0|            0|  0.00%|        else:\n",
      "   685|         0|            0|            0|  0.00%|            # Each batch of the hidden state should match the input sequence that\n",
      "   686|         0|            0|            0|  0.00%|            # the user believes he/she is passing in.\n",
      "   687|         0|            0|            0|  0.00%|            hx = self.permute_hidden(hx, sorted_indices)\n",
      "   688|         0|            0|            0|  0.00%|\n",
      "   689|         0|            0|            0|  0.00%|        self.check_forward_args(input, hx, batch_sizes)\n",
      "   690|         0|            0|            0|  0.00%|        if batch_sizes is None:\n",
      "   691|         0|            0|            0|  0.00%|            result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "   692|         0|            0|            0|  0.00%|                              self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "   693|         0|            0|            0|  0.00%|        else:\n",
      "   694|         0|            0|            0|  0.00%|            result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "   695|         0|            0|            0|  0.00%|                              self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "   696|         0|            0|            0|  0.00%|        output = result[0]\n",
      "   697|         0|            0|            0|  0.00%|        hidden = result[1:]\n",
      "   698|         0|            0|            0|  0.00%|        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
      "   699|         0|            0|            0|  0.00%|        if isinstance(orig_input, PackedSequence):\n",
      "   700|         0|            0|            0|  0.00%|            output_packed = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
      "   701|         0|            0|            0|  0.00%|            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n",
      "   702|         0|            0|            0|  0.00%|        else:\n",
      "   703|         0|            0|            0|  0.00%|            return output, self.permute_hidden(hidden, unsorted_indices)\n",
      "   704|         0|            0|            0|  0.00%|\n",
      "   705|         0|            0|            0|  0.00%|\n",
      "   706|         0|            0|            0|  0.00%|class GRU(RNNBase):\n",
      "   707|         0|            0|            0|  0.00%|    r\"\"\"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
      "   708|         0|            0|            0|  0.00%|\n",
      "   709|         0|            0|            0|  0.00%|\n",
      "   710|         0|            0|            0|  0.00%|    For each element in the input sequence, each layer computes the following\n",
      "   711|         0|            0|            0|  0.00%|    function:\n",
      "   712|         0|            0|            0|  0.00%|\n",
      "   713|         0|            0|            0|  0.00%|    .. math::\n",
      "   714|         0|            0|            0|  0.00%|        \\begin{array}{ll}\n",
      "   715|         0|            0|            0|  0.00%|            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
      "   716|         0|            0|            0|  0.00%|            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
      "   717|         0|            0|            0|  0.00%|            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
      "   718|         0|            0|            0|  0.00%|            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
      "   719|         0|            0|            0|  0.00%|        \\end{array}\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|    where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\n",
      "   722|         0|            0|            0|  0.00%|    at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\n",
      "   723|         0|            0|            0|  0.00%|    at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n",
      "   724|         0|            0|            0|  0.00%|    :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n",
      "   725|         0|            0|            0|  0.00%|    :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
      "   726|         0|            0|            0|  0.00%|\n",
      "   727|         0|            0|            0|  0.00%|    In a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n",
      "   728|         0|            0|            0|  0.00%|    (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n",
      "   729|         0|            0|            0|  0.00%|    dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n",
      "   730|         0|            0|            0|  0.00%|    variable which is :math:`0` with probability :attr:`dropout`.\n",
      "   731|         0|            0|            0|  0.00%|\n",
      "   732|         0|            0|            0|  0.00%|    Args:\n",
      "   733|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "   734|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "   735|         0|            0|            0|  0.00%|        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
      "   736|         0|            0|            0|  0.00%|            would mean stacking two GRUs together to form a `stacked GRU`,\n",
      "   737|         0|            0|            0|  0.00%|            with the second GRU taking in outputs of the first GRU and\n",
      "   738|         0|            0|            0|  0.00%|            computing the final results. Default: 1\n",
      "   739|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      "   740|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   741|         0|            0|            0|  0.00%|        batch_first: If ``True``, then the input and output tensors are provided\n",
      "   742|         0|            0|            0|  0.00%|            as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n",
      "   743|         0|            0|            0|  0.00%|            Note that this does not apply to hidden or cell states. See the\n",
      "   744|         0|            0|            0|  0.00%|            Inputs/Outputs sections below for details.  Default: ``False``\n",
      "   745|         0|            0|            0|  0.00%|        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
      "   746|         0|            0|            0|  0.00%|            GRU layer except the last layer, with dropout probability equal to\n",
      "   747|         0|            0|            0|  0.00%|            :attr:`dropout`. Default: 0\n",
      "   748|         0|            0|            0|  0.00%|        bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``\n",
      "   749|         0|            0|            0|  0.00%|\n",
      "   750|         0|            0|            0|  0.00%|    Inputs: input, h_0\n",
      "   751|         0|            0|            0|  0.00%|        * **input**: tensor of shape :math:`(L, N, H_{in})` when ``batch_first=False`` or\n",
      "   752|         0|            0|            0|  0.00%|          :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n",
      "   753|         0|            0|            0|  0.00%|          the input sequence.  The input can also be a packed variable length sequence.\n",
      "   754|         0|            0|            0|  0.00%|          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n",
      "   755|         0|            0|            0|  0.00%|          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n",
      "   756|         0|            0|            0|  0.00%|        * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the initial hidden\n",
      "   757|         0|            0|            0|  0.00%|          state for each element in the batch. Defaults to zeros if not provided.\n",
      "   758|         0|            0|            0|  0.00%|\n",
      "   759|         0|            0|            0|  0.00%|        where:\n",
      "   760|         0|            0|            0|  0.00%|\n",
      "   761|         0|            0|            0|  0.00%|        .. math::\n",
      "   762|         0|            0|            0|  0.00%|            \\begin{aligned}\n",
      "   763|         0|            0|            0|  0.00%|                N ={} & \\text{batch size} \\\\\n",
      "   764|         0|            0|            0|  0.00%|                L ={} & \\text{sequence length} \\\\\n",
      "   765|         0|            0|            0|  0.00%|                D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n",
      "   766|         0|            0|            0|  0.00%|                H_{in} ={} & \\text{input\\_size} \\\\\n",
      "   767|         0|            0|            0|  0.00%|                H_{out} ={} & \\text{hidden\\_size}\n",
      "   768|         0|            0|            0|  0.00%|            \\end{aligned}\n",
      "   769|         0|            0|            0|  0.00%|\n",
      "   770|         0|            0|            0|  0.00%|    Outputs: output, h_n\n",
      "   771|         0|            0|            0|  0.00%|        * **output**: tensor of shape :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n",
      "   772|         0|            0|            0|  0.00%|          :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n",
      "   773|         0|            0|            0|  0.00%|          `(h_t)` from the last layer of the GRU, for each `t`. If a\n",
      "   774|         0|            0|            0|  0.00%|          :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n",
      "   775|         0|            0|            0|  0.00%|          will also be a packed sequence.\n",
      "   776|         0|            0|            0|  0.00%|        * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n",
      "   777|         0|            0|            0|  0.00%|          for each element in the batch.\n",
      "   778|         0|            0|            0|  0.00%|\n",
      "   779|         0|            0|            0|  0.00%|    Attributes:\n",
      "   780|         0|            0|            0|  0.00%|        weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      "   781|         0|            0|            0|  0.00%|            (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.\n",
      "   782|         0|            0|            0|  0.00%|            Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`\n",
      "   783|         0|            0|            0|  0.00%|        weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n",
      "   784|         0|            0|            0|  0.00%|            (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n",
      "   785|         0|            0|            0|  0.00%|        bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      "   786|         0|            0|            0|  0.00%|            (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n",
      "   787|         0|            0|            0|  0.00%|        bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n",
      "   788|         0|            0|            0|  0.00%|            (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n",
      "   789|         0|            0|            0|  0.00%|\n",
      "   790|         0|            0|            0|  0.00%|    .. note::\n",
      "   791|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "   792|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "   793|         0|            0|            0|  0.00%|\n",
      "   794|         0|            0|            0|  0.00%|    .. note::\n",
      "   795|         0|            0|            0|  0.00%|        For bidirectional GRUs, forward and backward are directions 0 and 1 respectively.\n",
      "   796|         0|            0|            0|  0.00%|        Example of splitting the output layers when ``batch_first=False``:\n",
      "   797|         0|            0|            0|  0.00%|        ``output.view(seq_len, batch, num_directions, hidden_size)``.\n",
      "   798|         0|            0|            0|  0.00%|\n",
      "   799|         0|            0|            0|  0.00%|    .. include:: ../cudnn_persistent_rnn.rst\n",
      "   800|         0|            0|            0|  0.00%|\n",
      "   801|         0|            0|            0|  0.00%|    Examples::\n",
      "   802|         0|            0|            0|  0.00%|\n",
      "   803|         0|            0|            0|  0.00%|        >>> rnn = nn.GRU(10, 20, 2)\n",
      "   804|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 3, 10)\n",
      "   805|         0|            0|            0|  0.00%|        >>> h0 = torch.randn(2, 3, 20)\n",
      "   806|         0|            0|            0|  0.00%|        >>> output, hn = rnn(input, h0)\n",
      "   807|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   808|         0|            0|            0|  0.00%|\n",
      "   809|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):\n",
      "   810|         0|            0|            0|  0.00%|        if 'proj_size' in kwargs:\n",
      "   811|         0|            0|            0|  0.00%|            raise ValueError(\"proj_size argument is only supported for LSTM, not RNN or GRU\")\n",
      "   812|         0|            0|            0|  0.00%|        super(GRU, self).__init__('GRU', *args, **kwargs)\n",
      "   813|         0|            0|            0|  0.00%|\n",
      "   814|         0|            0|            0|  0.00%|    @overload  # type: ignore[override]\n",
      "   815|         0|            0|            0|  0.00%|    @torch._jit_internal._overload_method  # noqa: F811\n",
      "   816|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:  # noqa: F811\n",
      "   817|         0|            0|            0|  0.00%|        pass\n",
      "   818|         0|            0|            0|  0.00%|\n",
      "   819|         0|            0|            0|  0.00%|    @overload\n",
      "   820|         0|            0|            0|  0.00%|    @torch._jit_internal._overload_method  # noqa: F811\n",
      "   821|         0|            0|            0|  0.00%|    def forward(self, input: PackedSequence, hx: Optional[Tensor] = None) -> Tuple[PackedSequence, Tensor]:  # noqa: F811\n",
      "   822|         0|            0|            0|  0.00%|        pass\n",
      "   823|         0|            0|            0|  0.00%|\n",
      "   824|         9|  3.69549e-05|   4.1061e-06|  0.00%|    def forward(self, input, hx=None):  # noqa: F811\n",
      "   825|         9|  4.19617e-05|  4.66241e-06|  0.00%|        orig_input = input\n",
      "   826|         0|            0|            0|  0.00%|        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
      "   827|         9|  3.67165e-05|  4.07961e-06|  0.00%|        if isinstance(orig_input, PackedSequence):\n",
      "   828|         1|  6.19888e-06|  6.19888e-06|  0.00%|            input, batch_sizes, sorted_indices, unsorted_indices = input\n",
      "   829|         1|  1.09673e-05|  1.09673e-05|  0.00%|            max_batch_size = batch_sizes[0]\n",
      "   830|         1|  1.09673e-05|  1.09673e-05|  0.00%|            max_batch_size = int(max_batch_size)\n",
      "   831|         0|            0|            0|  0.00%|        else:\n",
      "   832|         8|  2.71797e-05|  3.39746e-06|  0.00%|            batch_sizes = None\n",
      "   833|         8|  4.52995e-05|  5.66244e-06|  0.00%|            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
      "   834|         8|  2.67029e-05|  3.33786e-06|  0.00%|            sorted_indices = None\n",
      "   835|         8|  2.67029e-05|  3.33786e-06|  0.00%|            unsorted_indices = None\n",
      "   836|         0|            0|            0|  0.00%|\n",
      "   837|         9|  2.90871e-05|   3.2319e-06|  0.00%|        if hx is None:\n",
      "   838|         1|  4.05312e-06|  4.05312e-06|  0.00%|            num_directions = 2 if self.bidirectional else 1\n",
      "   839|         1|  4.76837e-06|  4.76837e-06|  0.00%|            hx = torch.zeros(self.num_layers * num_directions,\n",
      "   840|         1|  5.24521e-06|  5.24521e-06|  0.00%|                             max_batch_size, self.hidden_size,\n",
      "   841|         1|   1.3113e-05|   1.3113e-05|  0.00%|                             dtype=input.dtype, device=input.device)\n",
      "   842|         0|            0|            0|  0.00%|        else:\n",
      "   843|         0|            0|            0|  0.00%|            # Each batch of the hidden state should match the input sequence that\n",
      "   844|         0|            0|            0|  0.00%|            # the user believes he/she is passing in.\n",
      "   845|         8|  6.84261e-05|  8.55327e-06|  0.00%|            hx = self.permute_hidden(hx, sorted_indices)\n",
      "(call)|         8|  5.19753e-05|  6.49691e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:234 permute_hidden\n",
      "   846|         0|            0|            0|  0.00%|\n",
      "   847|         9|  8.27312e-05|  9.19236e-06|  0.00%|        self.check_forward_args(input, hx, batch_sizes)\n",
      "(call)|         9|  0.000582695|  6.47439e-05|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:228 check_forward_args\n",
      "   848|         9|  2.86102e-05|  3.17891e-06|  0.00%|        if batch_sizes is None:\n",
      "   849|         8|  9.25064e-05|  1.15633e-05|  0.00%|            result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "(call)|         8|  4.14848e-05|   5.1856e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   850|         8|   0.00386262|  0.000482827|  0.05%|                             self.dropout, self.training, self.bidirectional, self.batch_first)\n",
      "   851|         0|            0|            0|  0.00%|        else:\n",
      "   852|         1|  1.26362e-05|  1.26362e-05|  0.00%|            result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(call)|         1|  7.15256e-06|  7.15256e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   853|         1|    0.0122662|    0.0122662|  0.15%|                             self.num_layers, self.dropout, self.training, self.bidirectional)\n",
      "   854|         9|  0.000112295|  1.24772e-05|  0.00%|        output = result[0]\n",
      "   855|         9|  4.79221e-05|  5.32468e-06|  0.00%|        hidden = result[1]\n",
      "   856|         0|            0|            0|  0.00%|\n",
      "   857|         0|            0|            0|  0.00%|        # xxx: isinstance check needs to be in conditional for TorchScript to compile\n",
      "   858|         9|  3.98159e-05|  4.42399e-06|  0.00%|        if isinstance(orig_input, PackedSequence):\n",
      "   859|         1|  1.69277e-05|  1.69277e-05|  0.00%|            output_packed = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
      "(call)|         1|  0.000172853|  0.000172853|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:63 __new__\n",
      "   860|         1|  1.40667e-05|  1.40667e-05|  0.00%|            return output_packed, self.permute_hidden(hidden, unsorted_indices)\n",
      "(call)|         1|  5.10216e-05|  5.10216e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:234 permute_hidden\n",
      "   861|         0|            0|            0|  0.00%|        else:\n",
      "   862|         8|  8.34465e-05|  1.04308e-05|  0.00%|            return output, self.permute_hidden(hidden, unsorted_indices)\n",
      "(call)|         8|  6.34193e-05|  7.92742e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:234 permute_hidden\n",
      "   863|         0|            0|            0|  0.00%|\n",
      "   864|         0|            0|            0|  0.00%|\n",
      "   865|         0|            0|            0|  0.00%|class RNNCellBase(Module):\n",
      "   866|         0|            0|            0|  0.00%|    __constants__ = ['input_size', 'hidden_size', 'bias']\n",
      "   867|         0|            0|            0|  0.00%|\n",
      "   868|         0|            0|            0|  0.00%|    input_size: int\n",
      "   869|         0|            0|            0|  0.00%|    hidden_size: int\n",
      "   870|         0|            0|            0|  0.00%|    bias: bool\n",
      "   871|         0|            0|            0|  0.00%|    weight_ih: Tensor\n",
      "   872|         0|            0|            0|  0.00%|    weight_hh: Tensor\n",
      "   873|         0|            0|            0|  0.00%|    # WARNING: bias_ih and bias_hh purposely not defined here.\n",
      "   874|         0|            0|            0|  0.00%|    # See https://github.com/pytorch/pytorch/issues/39670\n",
      "   875|         0|            0|            0|  0.00%|\n",
      "   876|         0|            0|            0|  0.00%|    def __init__(self, input_size: int, hidden_size: int, bias: bool, num_chunks: int,\n",
      "   877|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   878|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   879|         0|            0|            0|  0.00%|        super(RNNCellBase, self).__init__()\n",
      "   880|         0|            0|            0|  0.00%|        self.input_size = input_size\n",
      "   881|         0|            0|            0|  0.00%|        self.hidden_size = hidden_size\n",
      "   882|         0|            0|            0|  0.00%|        self.bias = bias\n",
      "   883|         0|            0|            0|  0.00%|        self.weight_ih = Parameter(torch.empty((num_chunks * hidden_size, input_size), **factory_kwargs))\n",
      "   884|         0|            0|            0|  0.00%|        self.weight_hh = Parameter(torch.empty((num_chunks * hidden_size, hidden_size), **factory_kwargs))\n",
      "   885|         0|            0|            0|  0.00%|        if bias:\n",
      "   886|         0|            0|            0|  0.00%|            self.bias_ih = Parameter(torch.empty(num_chunks * hidden_size, **factory_kwargs))\n",
      "   887|         0|            0|            0|  0.00%|            self.bias_hh = Parameter(torch.empty(num_chunks * hidden_size, **factory_kwargs))\n",
      "   888|         0|            0|            0|  0.00%|        else:\n",
      "   889|         0|            0|            0|  0.00%|            self.register_parameter('bias_ih', None)\n",
      "   890|         0|            0|            0|  0.00%|            self.register_parameter('bias_hh', None)\n",
      "   891|         0|            0|            0|  0.00%|\n",
      "   892|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "   893|         0|            0|            0|  0.00%|\n",
      "   894|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   895|         0|            0|            0|  0.00%|        s = '{input_size}, {hidden_size}'\n",
      "   896|         0|            0|            0|  0.00%|        if 'bias' in self.__dict__ and self.bias is not True:\n",
      "   897|         0|            0|            0|  0.00%|            s += ', bias={bias}'\n",
      "   898|         0|            0|            0|  0.00%|        if 'nonlinearity' in self.__dict__ and self.nonlinearity != \"tanh\":\n",
      "   899|         0|            0|            0|  0.00%|            s += ', nonlinearity={nonlinearity}'\n",
      "   900|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   901|         0|            0|            0|  0.00%|\n",
      "   902|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   903|         0|            0|            0|  0.00%|        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
      "   904|         0|            0|            0|  0.00%|        for weight in self.parameters():\n",
      "   905|         0|            0|            0|  0.00%|            init.uniform_(weight, -stdv, stdv)\n",
      "   906|         0|            0|            0|  0.00%|\n",
      "   907|         0|            0|            0|  0.00%|\n",
      "   908|         0|            0|            0|  0.00%|class RNNCell(RNNCellBase):\n",
      "   909|         0|            0|            0|  0.00%|    r\"\"\"An Elman RNN cell with tanh or ReLU non-linearity.\n",
      "   910|         0|            0|            0|  0.00%|\n",
      "   911|         0|            0|            0|  0.00%|    .. math::\n",
      "   912|         0|            0|            0|  0.00%|\n",
      "   913|         0|            0|            0|  0.00%|        h' = \\tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})\n",
      "   914|         0|            0|            0|  0.00%|\n",
      "   915|         0|            0|            0|  0.00%|    If :attr:`nonlinearity` is `'relu'`, then ReLU is used in place of tanh.\n",
      "   916|         0|            0|            0|  0.00%|\n",
      "   917|         0|            0|            0|  0.00%|    Args:\n",
      "   918|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "   919|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "   920|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
      "   921|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   922|         0|            0|            0|  0.00%|        nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   923|         0|            0|            0|  0.00%|\n",
      "   924|         0|            0|            0|  0.00%|    Inputs: input, hidden\n",
      "   925|         0|            0|            0|  0.00%|        - **input** of shape `(batch, input_size)`: tensor containing input features\n",
      "   926|         0|            0|            0|  0.00%|        - **hidden** of shape `(batch, hidden_size)`: tensor containing the initial hidden\n",
      "   927|         0|            0|            0|  0.00%|          state for each element in the batch.\n",
      "   928|         0|            0|            0|  0.00%|          Defaults to zero if not provided.\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|    Outputs: h'\n",
      "   931|         0|            0|            0|  0.00%|        - **h'** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n",
      "   932|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "   933|         0|            0|            0|  0.00%|\n",
      "   934|         0|            0|            0|  0.00%|    Shape:\n",
      "   935|         0|            0|            0|  0.00%|        - Input1: :math:`(N, H_{in})` tensor containing input features where\n",
      "   936|         0|            0|            0|  0.00%|          :math:`H_{in}` = `input_size`\n",
      "   937|         0|            0|            0|  0.00%|        - Input2: :math:`(N, H_{out})` tensor containing the initial hidden\n",
      "   938|         0|            0|            0|  0.00%|          state for each element in the batch where :math:`H_{out}` = `hidden_size`\n",
      "   939|         0|            0|            0|  0.00%|          Defaults to zero if not provided.\n",
      "   940|         0|            0|            0|  0.00%|        - Output: :math:`(N, H_{out})` tensor containing the next hidden state\n",
      "   941|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "   942|         0|            0|            0|  0.00%|\n",
      "   943|         0|            0|            0|  0.00%|    Attributes:\n",
      "   944|         0|            0|            0|  0.00%|        weight_ih: the learnable input-hidden weights, of shape\n",
      "   945|         0|            0|            0|  0.00%|            `(hidden_size, input_size)`\n",
      "   946|         0|            0|            0|  0.00%|        weight_hh: the learnable hidden-hidden weights, of shape\n",
      "   947|         0|            0|            0|  0.00%|            `(hidden_size, hidden_size)`\n",
      "   948|         0|            0|            0|  0.00%|        bias_ih: the learnable input-hidden bias, of shape `(hidden_size)`\n",
      "   949|         0|            0|            0|  0.00%|        bias_hh: the learnable hidden-hidden bias, of shape `(hidden_size)`\n",
      "   950|         0|            0|            0|  0.00%|\n",
      "   951|         0|            0|            0|  0.00%|    .. note::\n",
      "   952|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "   953|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "   954|         0|            0|            0|  0.00%|\n",
      "   955|         0|            0|            0|  0.00%|    Examples::\n",
      "   956|         0|            0|            0|  0.00%|\n",
      "   957|         0|            0|            0|  0.00%|        >>> rnn = nn.RNNCell(10, 20)\n",
      "   958|         0|            0|            0|  0.00%|        >>> input = torch.randn(6, 3, 10)\n",
      "   959|         0|            0|            0|  0.00%|        >>> hx = torch.randn(3, 20)\n",
      "   960|         0|            0|            0|  0.00%|        >>> output = []\n",
      "   961|         0|            0|            0|  0.00%|        >>> for i in range(6):\n",
      "   962|         0|            0|            0|  0.00%|                hx = rnn(input[i], hx)\n",
      "   963|         0|            0|            0|  0.00%|                output.append(hx)\n",
      "   964|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   965|         0|            0|            0|  0.00%|    __constants__ = ['input_size', 'hidden_size', 'bias', 'nonlinearity']\n",
      "   966|         0|            0|            0|  0.00%|    nonlinearity: str\n",
      "   967|         0|            0|            0|  0.00%|\n",
      "   968|         0|            0|            0|  0.00%|    def __init__(self, input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = \"tanh\",\n",
      "   969|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   970|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   971|         0|            0|            0|  0.00%|        super(RNNCell, self).__init__(input_size, hidden_size, bias, num_chunks=1, **factory_kwargs)\n",
      "   972|         0|            0|            0|  0.00%|        self.nonlinearity = nonlinearity\n",
      "   973|         0|            0|            0|  0.00%|\n",
      "   974|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:\n",
      "   975|         0|            0|            0|  0.00%|        if hx is None:\n",
      "   976|         0|            0|            0|  0.00%|            hx = torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)\n",
      "   977|         0|            0|            0|  0.00%|        if self.nonlinearity == \"tanh\":\n",
      "   978|         0|            0|            0|  0.00%|            ret = _VF.rnn_tanh_cell(\n",
      "   979|         0|            0|            0|  0.00%|                input, hx,\n",
      "   980|         0|            0|            0|  0.00%|                self.weight_ih, self.weight_hh,\n",
      "   981|         0|            0|            0|  0.00%|                self.bias_ih, self.bias_hh,\n",
      "   982|         0|            0|            0|  0.00%|            )\n",
      "   983|         0|            0|            0|  0.00%|        elif self.nonlinearity == \"relu\":\n",
      "   984|         0|            0|            0|  0.00%|            ret = _VF.rnn_relu_cell(\n",
      "   985|         0|            0|            0|  0.00%|                input, hx,\n",
      "   986|         0|            0|            0|  0.00%|                self.weight_ih, self.weight_hh,\n",
      "   987|         0|            0|            0|  0.00%|                self.bias_ih, self.bias_hh,\n",
      "   988|         0|            0|            0|  0.00%|            )\n",
      "   989|         0|            0|            0|  0.00%|        else:\n",
      "   990|         0|            0|            0|  0.00%|            ret = input  # TODO: remove when jit supports exception flow\n",
      "   991|         0|            0|            0|  0.00%|            raise RuntimeError(\n",
      "   992|         0|            0|            0|  0.00%|                \"Unknown nonlinearity: {}\".format(self.nonlinearity))\n",
      "   993|         0|            0|            0|  0.00%|        return ret\n",
      "   994|         0|            0|            0|  0.00%|\n",
      "   995|         0|            0|            0|  0.00%|\n",
      "   996|         0|            0|            0|  0.00%|class LSTMCell(RNNCellBase):\n",
      "   997|         0|            0|            0|  0.00%|    r\"\"\"A long short-term memory (LSTM) cell.\n",
      "   998|         0|            0|            0|  0.00%|\n",
      "   999|         0|            0|            0|  0.00%|    .. math::\n",
      "  1000|         0|            0|            0|  0.00%|\n",
      "  1001|         0|            0|            0|  0.00%|        \\begin{array}{ll}\n",
      "  1002|         0|            0|            0|  0.00%|        i = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\n",
      "  1003|         0|            0|            0|  0.00%|        f = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\n",
      "  1004|         0|            0|            0|  0.00%|        g = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\n",
      "  1005|         0|            0|            0|  0.00%|        o = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\n",
      "  1006|         0|            0|            0|  0.00%|        c' = f * c + i * g \\\\\n",
      "  1007|         0|            0|            0|  0.00%|        h' = o * \\tanh(c') \\\\\n",
      "  1008|         0|            0|            0|  0.00%|        \\end{array}\n",
      "  1009|         0|            0|            0|  0.00%|\n",
      "  1010|         0|            0|            0|  0.00%|    where :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
      "  1011|         0|            0|            0|  0.00%|\n",
      "  1012|         0|            0|            0|  0.00%|    Args:\n",
      "  1013|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "  1014|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "  1015|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and\n",
      "  1016|         0|            0|            0|  0.00%|            `b_hh`. Default: ``True``\n",
      "  1017|         0|            0|            0|  0.00%|\n",
      "  1018|         0|            0|            0|  0.00%|    Inputs: input, (h_0, c_0)\n",
      "  1019|         0|            0|            0|  0.00%|        - **input** of shape `(batch, input_size)`: tensor containing input features\n",
      "  1020|         0|            0|            0|  0.00%|        - **h_0** of shape `(batch, hidden_size)`: tensor containing the initial hidden\n",
      "  1021|         0|            0|            0|  0.00%|          state for each element in the batch.\n",
      "  1022|         0|            0|            0|  0.00%|        - **c_0** of shape `(batch, hidden_size)`: tensor containing the initial cell state\n",
      "  1023|         0|            0|            0|  0.00%|          for each element in the batch.\n",
      "  1024|         0|            0|            0|  0.00%|\n",
      "  1025|         0|            0|            0|  0.00%|          If `(h_0, c_0)` is not provided, both **h_0** and **c_0** default to zero.\n",
      "  1026|         0|            0|            0|  0.00%|\n",
      "  1027|         0|            0|            0|  0.00%|    Outputs: (h_1, c_1)\n",
      "  1028|         0|            0|            0|  0.00%|        - **h_1** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n",
      "  1029|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "  1030|         0|            0|            0|  0.00%|        - **c_1** of shape `(batch, hidden_size)`: tensor containing the next cell state\n",
      "  1031|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "  1032|         0|            0|            0|  0.00%|\n",
      "  1033|         0|            0|            0|  0.00%|    Attributes:\n",
      "  1034|         0|            0|            0|  0.00%|        weight_ih: the learnable input-hidden weights, of shape\n",
      "  1035|         0|            0|            0|  0.00%|            `(4*hidden_size, input_size)`\n",
      "  1036|         0|            0|            0|  0.00%|        weight_hh: the learnable hidden-hidden weights, of shape\n",
      "  1037|         0|            0|            0|  0.00%|            `(4*hidden_size, hidden_size)`\n",
      "  1038|         0|            0|            0|  0.00%|        bias_ih: the learnable input-hidden bias, of shape `(4*hidden_size)`\n",
      "  1039|         0|            0|            0|  0.00%|        bias_hh: the learnable hidden-hidden bias, of shape `(4*hidden_size)`\n",
      "  1040|         0|            0|            0|  0.00%|\n",
      "  1041|         0|            0|            0|  0.00%|    .. note::\n",
      "  1042|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "  1043|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "  1044|         0|            0|            0|  0.00%|\n",
      "  1045|         0|            0|            0|  0.00%|    Examples::\n",
      "  1046|         0|            0|            0|  0.00%|\n",
      "  1047|         0|            0|            0|  0.00%|        >>> rnn = nn.LSTMCell(10, 20) # (input_size, hidden_size)\n",
      "  1048|         0|            0|            0|  0.00%|        >>> input = torch.randn(2, 3, 10) # (time_steps, batch, input_size)\n",
      "  1049|         0|            0|            0|  0.00%|        >>> hx = torch.randn(3, 20) # (batch, hidden_size)\n",
      "  1050|         0|            0|            0|  0.00%|        >>> cx = torch.randn(3, 20)\n",
      "  1051|         0|            0|            0|  0.00%|        >>> output = []\n",
      "  1052|         0|            0|            0|  0.00%|        >>> for i in range(input.size()[0]):\n",
      "  1053|         0|            0|            0|  0.00%|                hx, cx = rnn(input[i], (hx, cx))\n",
      "  1054|         0|            0|            0|  0.00%|                output.append(hx)\n",
      "  1055|         0|            0|            0|  0.00%|        >>> output = torch.stack(output, dim=0)\n",
      "  1056|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1057|         0|            0|            0|  0.00%|\n",
      "  1058|         0|            0|            0|  0.00%|    def __init__(self, input_size: int, hidden_size: int, bias: bool = True,\n",
      "  1059|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "  1060|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "  1061|         0|            0|            0|  0.00%|        super(LSTMCell, self).__init__(input_size, hidden_size, bias, num_chunks=4, **factory_kwargs)\n",
      "  1062|         0|            0|            0|  0.00%|\n",
      "  1063|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None) -> Tuple[Tensor, Tensor]:\n",
      "  1064|         0|            0|            0|  0.00%|        if hx is None:\n",
      "  1065|         0|            0|            0|  0.00%|            zeros = torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)\n",
      "  1066|         0|            0|            0|  0.00%|            hx = (zeros, zeros)\n",
      "  1067|         0|            0|            0|  0.00%|        return _VF.lstm_cell(\n",
      "  1068|         0|            0|            0|  0.00%|            input, hx,\n",
      "  1069|         0|            0|            0|  0.00%|            self.weight_ih, self.weight_hh,\n",
      "  1070|         0|            0|            0|  0.00%|            self.bias_ih, self.bias_hh,\n",
      "  1071|         0|            0|            0|  0.00%|        )\n",
      "  1072|         0|            0|            0|  0.00%|\n",
      "  1073|         0|            0|            0|  0.00%|\n",
      "  1074|         0|            0|            0|  0.00%|class GRUCell(RNNCellBase):\n",
      "  1075|         0|            0|            0|  0.00%|    r\"\"\"A gated recurrent unit (GRU) cell\n",
      "  1076|         0|            0|            0|  0.00%|\n",
      "  1077|         0|            0|            0|  0.00%|    .. math::\n",
      "  1078|         0|            0|            0|  0.00%|\n",
      "  1079|         0|            0|            0|  0.00%|        \\begin{array}{ll}\n",
      "  1080|         0|            0|            0|  0.00%|        r = \\sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\\\\n",
      "  1081|         0|            0|            0|  0.00%|        z = \\sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\\\\n",
      "  1082|         0|            0|            0|  0.00%|        n = \\tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\\\\n",
      "  1083|         0|            0|            0|  0.00%|        h' = (1 - z) * n + z * h\n",
      "  1084|         0|            0|            0|  0.00%|        \\end{array}\n",
      "  1085|         0|            0|            0|  0.00%|\n",
      "  1086|         0|            0|            0|  0.00%|    where :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n",
      "  1087|         0|            0|            0|  0.00%|\n",
      "  1088|         0|            0|            0|  0.00%|    Args:\n",
      "  1089|         0|            0|            0|  0.00%|        input_size: The number of expected features in the input `x`\n",
      "  1090|         0|            0|            0|  0.00%|        hidden_size: The number of features in the hidden state `h`\n",
      "  1091|         0|            0|            0|  0.00%|        bias: If ``False``, then the layer does not use bias weights `b_ih` and\n",
      "  1092|         0|            0|            0|  0.00%|            `b_hh`. Default: ``True``\n",
      "  1093|         0|            0|            0|  0.00%|\n",
      "  1094|         0|            0|            0|  0.00%|    Inputs: input, hidden\n",
      "  1095|         0|            0|            0|  0.00%|        - **input** of shape `(batch, input_size)`: tensor containing input features\n",
      "  1096|         0|            0|            0|  0.00%|        - **hidden** of shape `(batch, hidden_size)`: tensor containing the initial hidden\n",
      "  1097|         0|            0|            0|  0.00%|          state for each element in the batch.\n",
      "  1098|         0|            0|            0|  0.00%|          Defaults to zero if not provided.\n",
      "  1099|         0|            0|            0|  0.00%|\n",
      "  1100|         0|            0|            0|  0.00%|    Outputs: h'\n",
      "  1101|         0|            0|            0|  0.00%|        - **h'** of shape `(batch, hidden_size)`: tensor containing the next hidden state\n",
      "  1102|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "  1103|         0|            0|            0|  0.00%|\n",
      "  1104|         0|            0|            0|  0.00%|    Shape:\n",
      "  1105|         0|            0|            0|  0.00%|        - Input1: :math:`(N, H_{in})` tensor containing input features where\n",
      "  1106|         0|            0|            0|  0.00%|          :math:`H_{in}` = `input_size`\n",
      "  1107|         0|            0|            0|  0.00%|        - Input2: :math:`(N, H_{out})` tensor containing the initial hidden\n",
      "  1108|         0|            0|            0|  0.00%|          state for each element in the batch where :math:`H_{out}` = `hidden_size`\n",
      "  1109|         0|            0|            0|  0.00%|          Defaults to zero if not provided.\n",
      "  1110|         0|            0|            0|  0.00%|        - Output: :math:`(N, H_{out})` tensor containing the next hidden state\n",
      "  1111|         0|            0|            0|  0.00%|          for each element in the batch\n",
      "  1112|         0|            0|            0|  0.00%|\n",
      "  1113|         0|            0|            0|  0.00%|    Attributes:\n",
      "  1114|         0|            0|            0|  0.00%|        weight_ih: the learnable input-hidden weights, of shape\n",
      "  1115|         0|            0|            0|  0.00%|            `(3*hidden_size, input_size)`\n",
      "  1116|         0|            0|            0|  0.00%|        weight_hh: the learnable hidden-hidden weights, of shape\n",
      "  1117|         0|            0|            0|  0.00%|            `(3*hidden_size, hidden_size)`\n",
      "  1118|         0|            0|            0|  0.00%|        bias_ih: the learnable input-hidden bias, of shape `(3*hidden_size)`\n",
      "  1119|         0|            0|            0|  0.00%|        bias_hh: the learnable hidden-hidden bias, of shape `(3*hidden_size)`\n",
      "  1120|         0|            0|            0|  0.00%|\n",
      "  1121|         0|            0|            0|  0.00%|    .. note::\n",
      "  1122|         0|            0|            0|  0.00%|        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
      "  1123|         0|            0|            0|  0.00%|        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
      "  1124|         0|            0|            0|  0.00%|\n",
      "  1125|         0|            0|            0|  0.00%|    Examples::\n",
      "  1126|         0|            0|            0|  0.00%|\n",
      "  1127|         0|            0|            0|  0.00%|        >>> rnn = nn.GRUCell(10, 20)\n",
      "  1128|         0|            0|            0|  0.00%|        >>> input = torch.randn(6, 3, 10)\n",
      "  1129|         0|            0|            0|  0.00%|        >>> hx = torch.randn(3, 20)\n",
      "  1130|         0|            0|            0|  0.00%|        >>> output = []\n",
      "  1131|         0|            0|            0|  0.00%|        >>> for i in range(6):\n",
      "  1132|         0|            0|            0|  0.00%|                hx = rnn(input[i], hx)\n",
      "  1133|         0|            0|            0|  0.00%|                output.append(hx)\n",
      "  1134|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1135|         0|            0|            0|  0.00%|\n",
      "  1136|         0|            0|            0|  0.00%|    def __init__(self, input_size: int, hidden_size: int, bias: bool = True,\n",
      "  1137|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "  1138|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "  1139|         0|            0|            0|  0.00%|        super(GRUCell, self).__init__(input_size, hidden_size, bias, num_chunks=3, **factory_kwargs)\n",
      "  1140|         0|            0|            0|  0.00%|\n",
      "  1141|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:\n",
      "  1142|         0|            0|            0|  0.00%|        if hx is None:\n",
      "  1143|         0|            0|            0|  0.00%|            hx = torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)\n",
      "  1144|         0|            0|            0|  0.00%|        return _VF.gru_cell(\n",
      "  1145|         0|            0|            0|  0.00%|            input, hx,\n",
      "  1146|         0|            0|            0|  0.00%|            self.weight_ih, self.weight_hh,\n",
      "  1147|         0|            0|            0|  0.00%|            self.bias_ih, self.bias_hh,\n",
      "  1148|         0|            0|            0|  0.00%|        )\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py\n",
      "File duration: 0.00731707s (0.09%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|r\"\"\"Functional interface\"\"\"\n",
      "     2|         0|            0|            0|  0.00%|from typing import Callable, List, Optional, Tuple\n",
      "     3|         0|            0|            0|  0.00%|import math\n",
      "     4|         0|            0|            0|  0.00%|import warnings\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|import torch\n",
      "     7|         0|            0|            0|  0.00%|from torch import _VF\n",
      "     8|         0|            0|            0|  0.00%|from torch._C import _infer_size, _add_docstr\n",
      "     9|         0|            0|            0|  0.00%|from torch._torch_docs import reproducibility_notes, tf32_notes\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|from .._jit_internal import boolean_dispatch, _overload, BroadcastingList1, BroadcastingList2, BroadcastingList3\n",
      "    12|         0|            0|            0|  0.00%|from ..overrides import (\n",
      "    13|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n",
      "    14|         0|            0|            0|  0.00%|    handle_torch_function)\n",
      "    15|         0|            0|            0|  0.00%|from . import _reduction as _Reduction\n",
      "    16|         0|            0|            0|  0.00%|from . import grad  # noqa: F401\n",
      "    17|         0|            0|            0|  0.00%|from .modules import utils\n",
      "    18|         0|            0|            0|  0.00%|from .modules.utils import _single, _pair, _triple, _list_with_default\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         0|            0|            0|  0.00%|\n",
      "    21|         0|            0|            0|  0.00%|Tensor = torch.Tensor\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|conv1d = _add_docstr(\n",
      "    24|         0|            0|            0|  0.00%|    torch.conv1d,\n",
      "    25|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "    26|         0|            0|            0|  0.00%|conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "    27|         0|            0|            0|  0.00%|\n",
      "    28|         0|            0|            0|  0.00%|Applies a 1D convolution over an input signal composed of several input\n",
      "    29|         0|            0|            0|  0.00%|planes.\n",
      "    30|         0|            0|            0|  0.00%|\n",
      "    31|         0|            0|            0|  0.00%|{tf32_note}\n",
      "    32|         0|            0|            0|  0.00%|\n",
      "    33|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv1d` for details and output shape.\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|Note:\n",
      "    36|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "    37|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "    38|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "    39|         0|            0|            0|  0.00%|    )\n",
      "    40|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|Args:\n",
      "    43|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "    44|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kW)`\n",
      "    45|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n",
      "    46|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or\n",
      "    47|         0|            0|            0|  0.00%|      a one-element tuple `(sW,)`. Default: 1\n",
      "    48|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},\n",
      "    49|         0|            0|            0|  0.00%|      single number or a one-element tuple `(padW,)`. Default: 0\n",
      "    50|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      "    51|         0|            0|            0|  0.00%|      the input so the output has the shape as the input. However, this mode\n",
      "    52|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.\n",
      "    53|         0|            0|            0|  0.00%|\n",
      "    54|         0|            0|            0|  0.00%|      .. warning::\n",
      "    55|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and\n",
      "    56|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation\n",
      "    57|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.\n",
      "    58|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "    59|         0|            0|            0|  0.00%|      a one-element tuple `(dW,)`. Default: 1\n",
      "    60|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n",
      "    61|         0|            0|            0|  0.00%|      the number of groups. Default: 1\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|Examples::\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(33, 16, 30)\n",
      "    66|         0|            0|            0|  0.00%|    >>> filters = torch.randn(20, 16, 5)\n",
      "    67|         0|            0|            0|  0.00%|    >>> F.conv1d(inputs, filters)\n",
      "    68|         0|            0|            0|  0.00%|\"\"\",\n",
      "    69|         0|            0|            0|  0.00%|)\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|conv2d = _add_docstr(\n",
      "    72|         0|            0|            0|  0.00%|    torch.conv2d,\n",
      "    73|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "    74|         0|            0|            0|  0.00%|conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "    75|         0|            0|            0|  0.00%|\n",
      "    76|         0|            0|            0|  0.00%|Applies a 2D convolution over an input image composed of several input\n",
      "    77|         0|            0|            0|  0.00%|planes.\n",
      "    78|         0|            0|            0|  0.00%|\n",
      "    79|         0|            0|            0|  0.00%|{tf32_note}\n",
      "    80|         0|            0|            0|  0.00%|\n",
      "    81|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv2d` for details and output shape.\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|Note:\n",
      "    84|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "    85|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "    86|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "    87|         0|            0|            0|  0.00%|    )\n",
      "    88|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "    89|         0|            0|            0|  0.00%|\n",
      "    90|         0|            0|            0|  0.00%|Args:\n",
      "    91|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "    92|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW)`\n",
      "    93|         0|            0|            0|  0.00%|    bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n",
      "    94|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "    95|         0|            0|            0|  0.00%|      tuple `(sH, sW)`. Default: 1\n",
      "    96|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},\n",
      "    97|         0|            0|            0|  0.00%|      single number or a tuple `(padH, padW)`. Default: 0\n",
      "    98|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      "    99|         0|            0|            0|  0.00%|      the input so the output has the shape as the input. However, this mode\n",
      "   100|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.\n",
      "   101|         0|            0|            0|  0.00%|\n",
      "   102|         0|            0|            0|  0.00%|      .. warning::\n",
      "   103|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and\n",
      "   104|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation\n",
      "   105|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.\n",
      "   106|         0|            0|            0|  0.00%|\n",
      "   107|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   108|         0|            0|            0|  0.00%|      a tuple `(dH, dW)`. Default: 1\n",
      "   109|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   110|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   111|         0|            0|            0|  0.00%|\n",
      "   112|         0|            0|            0|  0.00%|Examples::\n",
      "   113|         0|            0|            0|  0.00%|\n",
      "   114|         0|            0|            0|  0.00%|    >>> # With square kernels and equal stride\n",
      "   115|         0|            0|            0|  0.00%|    >>> filters = torch.randn(8, 4, 3, 3)\n",
      "   116|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(1, 4, 5, 5)\n",
      "   117|         0|            0|            0|  0.00%|    >>> F.conv2d(inputs, filters, padding=1)\n",
      "   118|         0|            0|            0|  0.00%|\"\"\",\n",
      "   119|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   120|         0|            0|            0|  0.00%|\n",
      "   121|         0|            0|            0|  0.00%|conv3d = _add_docstr(\n",
      "   122|         0|            0|            0|  0.00%|    torch.conv3d,\n",
      "   123|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   124|         0|            0|            0|  0.00%|conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n",
      "   125|         0|            0|            0|  0.00%|\n",
      "   126|         0|            0|            0|  0.00%|Applies a 3D convolution over an input image composed of several input\n",
      "   127|         0|            0|            0|  0.00%|planes.\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   130|         0|            0|            0|  0.00%|\n",
      "   131|         0|            0|            0|  0.00%|See :class:`~torch.nn.Conv3d` for details and output shape.\n",
      "   132|         0|            0|            0|  0.00%|\n",
      "   133|         0|            0|            0|  0.00%|Note:\n",
      "   134|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   135|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   136|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   137|         0|            0|            0|  0.00%|    )\n",
      "   138|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   139|         0|            0|            0|  0.00%|\n",
      "   140|         0|            0|            0|  0.00%|Args:\n",
      "   141|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n",
      "   142|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kT , kH , kW)`\n",
      "   143|         0|            0|            0|  0.00%|    bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   144|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   145|         0|            0|            0|  0.00%|      tuple `(sT, sH, sW)`. Default: 1\n",
      "   146|         0|            0|            0|  0.00%|    padding: implicit paddings on both sides of the input. Can be a string {'valid', 'same'},\n",
      "   147|         0|            0|            0|  0.00%|      single number or a tuple `(padT, padH, padW)`. Default: 0\n",
      "   148|         0|            0|            0|  0.00%|      ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      "   149|         0|            0|            0|  0.00%|      the input so the output has the shape as the input. However, this mode\n",
      "   150|         0|            0|            0|  0.00%|      doesn't support any stride values other than 1.\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|      .. warning::\n",
      "   153|         0|            0|            0|  0.00%|          For ``padding='same'``, if the ``weight`` is even-length and\n",
      "   154|         0|            0|            0|  0.00%|          ``dilation`` is odd in any dimension, a full :func:`pad` operation\n",
      "   155|         0|            0|            0|  0.00%|          may be needed internally. Lowering performance.\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   158|         0|            0|            0|  0.00%|      a tuple `(dT, dH, dW)`. Default: 1\n",
      "   159|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n",
      "   160|         0|            0|            0|  0.00%|      the number of groups. Default: 1\n",
      "   161|         0|            0|            0|  0.00%|\n",
      "   162|         0|            0|            0|  0.00%|Examples::\n",
      "   163|         0|            0|            0|  0.00%|\n",
      "   164|         0|            0|            0|  0.00%|    >>> filters = torch.randn(33, 16, 3, 3, 3)\n",
      "   165|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50, 10, 20)\n",
      "   166|         0|            0|            0|  0.00%|    >>> F.conv3d(inputs, filters)\n",
      "   167|         0|            0|            0|  0.00%|\"\"\",\n",
      "   168|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   169|         0|            0|            0|  0.00%|\n",
      "   170|         0|            0|            0|  0.00%|conv_transpose1d = _add_docstr(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   171|         0|            0|            0|  0.00%|    torch.conv_transpose1d,\n",
      "   172|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   173|         0|            0|            0|  0.00%|conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "   174|         0|            0|            0|  0.00%|\n",
      "   175|         0|            0|            0|  0.00%|Applies a 1D transposed convolution operator over an input signal\n",
      "   176|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called \"deconvolution\".\n",
      "   177|         0|            0|            0|  0.00%|\n",
      "   178|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   179|         0|            0|            0|  0.00%|\n",
      "   180|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose1d` for details and output shape.\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|Note:\n",
      "   183|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   184|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   185|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   186|         0|            0|            0|  0.00%|    )\n",
      "   187|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   188|         0|            0|            0|  0.00%|\n",
      "   189|         0|            0|            0|  0.00%|Args:\n",
      "   190|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "   191|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kW)`\n",
      "   192|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   193|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   194|         0|            0|            0|  0.00%|      tuple ``(sW,)``. Default: 1\n",
      "   195|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   196|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   197|         0|            0|            0|  0.00%|      ``(padW,)``. Default: 0\n",
      "   198|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   199|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padW)``. Default: 0\n",
      "   200|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   201|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   202|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   203|         0|            0|            0|  0.00%|      a tuple ``(dW,)``. Default: 1\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|Examples::\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50)\n",
      "   208|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 5)\n",
      "   209|         0|            0|            0|  0.00%|    >>> F.conv_transpose1d(inputs, weights)\n",
      "   210|         0|            0|            0|  0.00%|\"\"\",\n",
      "   211|         0|            0|            0|  0.00%|)\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|conv_transpose2d = _add_docstr(\n",
      "   214|         0|            0|            0|  0.00%|    torch.conv_transpose2d,\n",
      "   215|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   216|         0|            0|            0|  0.00%|conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "   217|         0|            0|            0|  0.00%|\n",
      "   218|         0|            0|            0|  0.00%|Applies a 2D transposed convolution operator over an input image\n",
      "   219|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called \"deconvolution\".\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose2d` for details and output shape.\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|Note:\n",
      "   226|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   227|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   228|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   229|         0|            0|            0|  0.00%|    )\n",
      "   230|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   231|         0|            0|            0|  0.00%|\n",
      "   232|         0|            0|            0|  0.00%|Args:\n",
      "   233|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "   234|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW)`\n",
      "   235|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   236|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   237|         0|            0|            0|  0.00%|      tuple ``(sH, sW)``. Default: 1\n",
      "   238|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   239|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   240|         0|            0|            0|  0.00%|      ``(padH, padW)``. Default: 0\n",
      "   241|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   242|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple ``(out_padH, out_padW)``.\n",
      "   243|         0|            0|            0|  0.00%|      Default: 0\n",
      "   244|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   245|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   246|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   247|         0|            0|            0|  0.00%|      a tuple ``(dH, dW)``. Default: 1\n",
      "   248|         0|            0|            0|  0.00%|\n",
      "   249|         0|            0|            0|  0.00%|Examples::\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         0|            0|            0|  0.00%|    >>> # With square kernels and equal stride\n",
      "   252|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(1, 4, 5, 5)\n",
      "   253|         0|            0|            0|  0.00%|    >>> weights = torch.randn(4, 8, 3, 3)\n",
      "   254|         0|            0|            0|  0.00%|    >>> F.conv_transpose2d(inputs, weights, padding=1)\n",
      "   255|         0|            0|            0|  0.00%|\"\"\",\n",
      "   256|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   257|         0|            0|            0|  0.00%|\n",
      "   258|         0|            0|            0|  0.00%|conv_transpose3d = _add_docstr(\n",
      "   259|         0|            0|            0|  0.00%|    torch.conv_transpose3d,\n",
      "   260|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   261|         0|            0|            0|  0.00%|conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|Applies a 3D transposed convolution operator over an input image\n",
      "   264|         0|            0|            0|  0.00%|composed of several input planes, sometimes also called \"deconvolution\"\n",
      "   265|         0|            0|            0|  0.00%|\n",
      "   266|         0|            0|            0|  0.00%|{tf32_note}\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|See :class:`~torch.nn.ConvTranspose3d` for details and output shape.\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         0|            0|            0|  0.00%|Note:\n",
      "   271|         0|            0|            0|  0.00%|    {cudnn_reproducibility_note}\n",
      "   272|         0|            0|            0|  0.00%|\"\"\".format(\n",
      "   273|         0|            0|            0|  0.00%|        **reproducibility_notes, **tf32_notes\n",
      "   274|         0|            0|            0|  0.00%|    )\n",
      "   275|         0|            0|            0|  0.00%|    + r\"\"\"\n",
      "   276|         0|            0|            0|  0.00%|\n",
      "   277|         0|            0|            0|  0.00%|Args:\n",
      "   278|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n",
      "   279|         0|            0|            0|  0.00%|    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW)`\n",
      "   280|         0|            0|            0|  0.00%|    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n",
      "   281|         0|            0|            0|  0.00%|    stride: the stride of the convolving kernel. Can be a single number or a\n",
      "   282|         0|            0|            0|  0.00%|      tuple ``(sT, sH, sW)``. Default: 1\n",
      "   283|         0|            0|            0|  0.00%|    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n",
      "   284|         0|            0|            0|  0.00%|      sides of each dimension in the input. Can be a single number or a tuple\n",
      "   285|         0|            0|            0|  0.00%|      ``(padT, padH, padW)``. Default: 0\n",
      "   286|         0|            0|            0|  0.00%|    output_padding: additional size added to one side of each dimension in the\n",
      "   287|         0|            0|            0|  0.00%|      output shape. Can be a single number or a tuple\n",
      "   288|         0|            0|            0|  0.00%|      ``(out_padT, out_padH, out_padW)``. Default: 0\n",
      "   289|         0|            0|            0|  0.00%|    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n",
      "   290|         0|            0|            0|  0.00%|      number of groups. Default: 1\n",
      "   291|         0|            0|            0|  0.00%|    dilation: the spacing between kernel elements. Can be a single number or\n",
      "   292|         0|            0|            0|  0.00%|      a tuple `(dT, dH, dW)`. Default: 1\n",
      "   293|         0|            0|            0|  0.00%|\n",
      "   294|         0|            0|            0|  0.00%|Examples::\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|    >>> inputs = torch.randn(20, 16, 50, 10, 20)\n",
      "   297|         0|            0|            0|  0.00%|    >>> weights = torch.randn(16, 33, 3, 3, 3)\n",
      "   298|         0|            0|            0|  0.00%|    >>> F.conv_transpose3d(inputs, weights)\n",
      "   299|         0|            0|            0|  0.00%|\"\"\",\n",
      "   300|         0|            0|            0|  0.00%|)  # noqa: E501\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|conv_tbc = _add_docstr(\n",
      "   303|         0|            0|            0|  0.00%|    torch.conv_tbc,\n",
      "   304|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   305|         0|            0|            0|  0.00%|Applies a 1-dimensional sequence convolution over an input sequence.\n",
      "   306|         0|            0|            0|  0.00%|Input and output dimensions are (Time, Batch, Channels) - hence TBC.\n",
      "   307|         0|            0|            0|  0.00%|\n",
      "   308|         0|            0|            0|  0.00%|Args:\n",
      "   309|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{sequence length} \\times batch \\times \\text{in\\_channels})`\n",
      "   310|         0|            0|            0|  0.00%|    weight: filter of shape (:math:`\\text{kernel width} \\times \\text{in\\_channels} \\times \\text{out\\_channels}`)\n",
      "   311|         0|            0|            0|  0.00%|    bias: bias of shape (:math:`\\text{out\\_channels}`)\n",
      "   312|         0|            0|            0|  0.00%|    pad: number of timesteps to pad. Default: 0\n",
      "   313|         0|            0|            0|  0.00%|\"\"\",\n",
      "   314|         0|            0|            0|  0.00%|)\n",
      "   315|         0|            0|            0|  0.00%|\n",
      "   316|         0|            0|            0|  0.00%|\n",
      "   317|         0|            0|            0|  0.00%|# Pooling\n",
      "   318|         0|            0|            0|  0.00%|avg_pool1d = _add_docstr(\n",
      "   319|         0|            0|            0|  0.00%|    torch.avg_pool1d,\n",
      "   320|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   321|         0|            0|            0|  0.00%|avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|Applies a 1D average pooling over an input signal composed of several\n",
      "   324|         0|            0|            0|  0.00%|input planes.\n",
      "   325|         0|            0|            0|  0.00%|\n",
      "   326|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool1d` for details and output shape.\n",
      "   327|         0|            0|            0|  0.00%|\n",
      "   328|         0|            0|            0|  0.00%|Args:\n",
      "   329|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n",
      "   330|         0|            0|            0|  0.00%|    kernel_size: the size of the window. Can be a single number or a\n",
      "   331|         0|            0|            0|  0.00%|      tuple `(kW,)`\n",
      "   332|         0|            0|            0|  0.00%|    stride: the stride of the window. Can be a single number or a tuple\n",
      "   333|         0|            0|            0|  0.00%|      `(sW,)`. Default: :attr:`kernel_size`\n",
      "   334|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   335|         0|            0|            0|  0.00%|      single number or a tuple `(padW,)`. Default: 0\n",
      "   336|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` to compute the\n",
      "   337|         0|            0|            0|  0.00%|        output shape. Default: ``False``\n",
      "   338|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   339|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|Examples::\n",
      "   342|         0|            0|            0|  0.00%|\n",
      "   343|         0|            0|            0|  0.00%|    >>> # pool of square window of size=3, stride=2\n",
      "   344|         0|            0|            0|  0.00%|    >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)\n",
      "   345|         0|            0|            0|  0.00%|    >>> F.avg_pool1d(input, kernel_size=3, stride=2)\n",
      "   346|         0|            0|            0|  0.00%|    tensor([[[ 2.,  4.,  6.]]])\n",
      "   347|         0|            0|            0|  0.00%|\n",
      "   348|         0|            0|            0|  0.00%|\"\"\",\n",
      "   349|         0|            0|            0|  0.00%|)\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|avg_pool2d = _add_docstr(\n",
      "   353|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool2d,\n",
      "   354|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   355|         0|            0|            0|  0.00%|avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n",
      "   356|         0|            0|            0|  0.00%|\n",
      "   357|         0|            0|            0|  0.00%|Applies 2D average-pooling operation in :math:`kH \\times kW` regions by step size\n",
      "   358|         0|            0|            0|  0.00%|:math:`sH \\times sW` steps. The number of output features is equal to the number of\n",
      "   359|         0|            0|            0|  0.00%|input planes.\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool2d` for details and output shape.\n",
      "   362|         0|            0|            0|  0.00%|\n",
      "   363|         0|            0|            0|  0.00%|Args:\n",
      "   364|         0|            0|            0|  0.00%|    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n",
      "   365|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a\n",
      "   366|         0|            0|            0|  0.00%|      tuple `(kH, kW)`\n",
      "   367|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a\n",
      "   368|         0|            0|            0|  0.00%|      tuple `(sH, sW)`. Default: :attr:`kernel_size`\n",
      "   369|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   370|         0|            0|            0|  0.00%|      single number or a tuple `(padH, padW)`. Default: 0\n",
      "   371|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n",
      "   372|         0|            0|            0|  0.00%|        to compute the output shape. Default: ``False``\n",
      "   373|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   374|         0|            0|            0|  0.00%|        averaging calculation. Default: ``True``\n",
      "   375|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise\n",
      "   376|         0|            0|            0|  0.00%|         size of the pooling region will be used. Default: None\n",
      "   377|         0|            0|            0|  0.00%|\"\"\",\n",
      "   378|         0|            0|            0|  0.00%|)\n",
      "   379|         0|            0|            0|  0.00%|\n",
      "   380|         0|            0|            0|  0.00%|avg_pool3d = _add_docstr(\n",
      "   381|         0|            0|            0|  0.00%|    torch._C._nn.avg_pool3d,\n",
      "   382|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "   383|         0|            0|            0|  0.00%|avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n",
      "   384|         0|            0|            0|  0.00%|\n",
      "   385|         0|            0|            0|  0.00%|Applies 3D average-pooling operation in :math:`kT \\times kH \\times kW` regions by step\n",
      "   386|         0|            0|            0|  0.00%|size :math:`sT \\times sH \\times sW` steps. The number of output features is equal to\n",
      "   387|         0|            0|            0|  0.00%|:math:`\\lfloor\\frac{\\text{input planes}}{sT}\\rfloor`.\n",
      "   388|         0|            0|            0|  0.00%|\n",
      "   389|         0|            0|            0|  0.00%|See :class:`~torch.nn.AvgPool3d` for details and output shape.\n",
      "   390|         0|            0|            0|  0.00%|\n",
      "   391|         0|            0|            0|  0.00%|Args:\n",
      "   392|         0|            0|            0|  0.00%|    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iT \\times iH , iW)`\n",
      "   393|         0|            0|            0|  0.00%|    kernel_size: size of the pooling region. Can be a single number or a\n",
      "   394|         0|            0|            0|  0.00%|      tuple `(kT, kH, kW)`\n",
      "   395|         0|            0|            0|  0.00%|    stride: stride of the pooling operation. Can be a single number or a\n",
      "   396|         0|            0|            0|  0.00%|      tuple `(sT, sH, sW)`. Default: :attr:`kernel_size`\n",
      "   397|         0|            0|            0|  0.00%|    padding: implicit zero paddings on both sides of the input. Can be a\n",
      "   398|         0|            0|            0|  0.00%|      single number or a tuple `(padT, padH, padW)`, Default: 0\n",
      "   399|         0|            0|            0|  0.00%|    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n",
      "   400|         0|            0|            0|  0.00%|        to compute the output shape\n",
      "   401|         0|            0|            0|  0.00%|    count_include_pad: when True, will include the zero-padding in the\n",
      "   402|         0|            0|            0|  0.00%|        averaging calculation\n",
      "   403|         0|            0|            0|  0.00%|    divisor_override: if specified, it will be used as divisor, otherwise\n",
      "   404|         0|            0|            0|  0.00%|        size of the pooling region will be used. Default: None\n",
      "   405|         0|            0|            0|  0.00%|\"\"\",\n",
      "   406|         0|            0|            0|  0.00%|)\n",
      "   407|         0|            0|            0|  0.00%|\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|def fractional_max_pool2d_with_indices(\n",
      "   410|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   411|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,\n",
      "   412|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,\n",
      "   413|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   414|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   415|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   416|         0|            0|            0|  0.00%|    r\"\"\"Applies 2D fractional max pooling over an input signal composed of several input planes.\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n",
      "   419|         0|            0|            0|  0.00%|\n",
      "   420|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kH \\times kW` regions by a stochastic\n",
      "   421|         0|            0|            0|  0.00%|    step size determined by the target output size.\n",
      "   422|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.\n",
      "   423|         0|            0|            0|  0.00%|\n",
      "   424|         0|            0|            0|  0.00%|    Args:\n",
      "   425|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.\n",
      "   426|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \\times k`)\n",
      "   427|         0|            0|            0|  0.00%|                     or a tuple `(kH, kW)`\n",
      "   428|         0|            0|            0|  0.00%|        output_size: the target output size of the image of the form :math:`oH \\times oW`.\n",
      "   429|         0|            0|            0|  0.00%|                     Can be a tuple `(oH, oW)` or a single number :math:`oH` for a square image :math:`oH \\times oH`\n",
      "   430|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n",
      "   431|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)\n",
      "   432|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.\n",
      "   433|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool2d`.\n",
      "   434|         0|            0|            0|  0.00%|\n",
      "   435|         0|            0|            0|  0.00%|    Examples::\n",
      "   436|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32)\n",
      "   437|         0|            0|            0|  0.00%|        >>> # pool of square window of size=3, and target output size 13x12\n",
      "   438|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_size=(13, 12))\n",
      "   439|         0|            0|            0|  0.00%|        >>> # pool of square window and target output size being half of input image size\n",
      "   440|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool2d(input, 3, output_ratio=(0.5, 0.5))\n",
      "   441|         0|            0|            0|  0.00%|\n",
      "   442|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:\n",
      "   443|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071\n",
      "   444|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   445|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   446|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   447|         0|            0|            0|  0.00%|            fractional_max_pool2d_with_indices,\n",
      "   448|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   449|         0|            0|            0|  0.00%|            input,\n",
      "   450|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   451|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   452|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   453|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   454|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   455|         0|            0|            0|  0.00%|        )\n",
      "   456|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:\n",
      "   457|         0|            0|            0|  0.00%|        raise ValueError(\"fractional_max_pool2d requires specifying either \" \"an output_size or an output_ratio\")\n",
      "   458|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   459|         0|            0|            0|  0.00%|        assert output_ratio is not None\n",
      "   460|         0|            0|            0|  0.00%|        _output_ratio = _pair(output_ratio)\n",
      "   461|         0|            0|            0|  0.00%|        output_size = [int(input.size(-2) * _output_ratio[0]), int(input.size(-1) * _output_ratio[1])]\n",
      "   462|         0|            0|            0|  0.00%|\n",
      "   463|         0|            0|            0|  0.00%|    if _random_samples is None:\n",
      "   464|         0|            0|            0|  0.00%|        n_batch = 1 if input.dim() == 3 else input.size(0)\n",
      "   465|         0|            0|            0|  0.00%|        _random_samples = torch.rand(n_batch, input.size(-3), 2, dtype=input.dtype, device=input.device)\n",
      "   466|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool2d(input, kernel_size, output_size, _random_samples)\n",
      "   467|         0|            0|            0|  0.00%|\n",
      "   468|         0|            0|            0|  0.00%|\n",
      "   469|         0|            0|            0|  0.00%|def _fractional_max_pool2d(\n",
      "   470|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   471|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None,\n",
      "   472|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList2[float]] = None,\n",
      "   473|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   474|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   475|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   476|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   477|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   478|         0|            0|            0|  0.00%|            fractional_max_pool2d,\n",
      "   479|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   480|         0|            0|            0|  0.00%|            input,\n",
      "   481|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   482|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   483|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   484|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   485|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   486|         0|            0|            0|  0.00%|        )\n",
      "   487|         0|            0|            0|  0.00%|    return fractional_max_pool2d_with_indices(\n",
      "   488|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples\n",
      "   489|         0|            0|            0|  0.00%|    )[0]\n",
      "   490|         0|            0|            0|  0.00%|\n",
      "   491|         0|            0|            0|  0.00%|\n",
      "   492|         0|            0|            0|  0.00%|fractional_max_pool2d = boolean_dispatch(\n",
      "   493|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   494|         0|            0|            0|  0.00%|    arg_index=4,\n",
      "   495|         0|            0|            0|  0.00%|    default=False,\n",
      "   496|         0|            0|            0|  0.00%|    if_true=fractional_max_pool2d_with_indices,\n",
      "   497|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool2d,\n",
      "   498|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   499|         0|            0|            0|  0.00%|    func_name=\"fractional_max_pool2d\",\n",
      "   500|         0|            0|            0|  0.00%|)\n",
      "   501|         0|            0|            0|  0.00%|\n",
      "   502|         0|            0|            0|  0.00%|\n",
      "   503|         0|            0|            0|  0.00%|def fractional_max_pool3d_with_indices(\n",
      "   504|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   505|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,\n",
      "   506|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,\n",
      "   507|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   508|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   509|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   510|         0|            0|            0|  0.00%|    r\"\"\"Applies 3D fractional max pooling over an input signal composed of several input planes.\n",
      "   511|         0|            0|            0|  0.00%|\n",
      "   512|         0|            0|            0|  0.00%|    Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham\n",
      "   513|         0|            0|            0|  0.00%|\n",
      "   514|         0|            0|            0|  0.00%|    The max-pooling operation is applied in :math:`kT \\times kH \\times kW` regions by a stochastic\n",
      "   515|         0|            0|            0|  0.00%|    step size determined by the target output size.\n",
      "   516|         0|            0|            0|  0.00%|    The number of output features is equal to the number of input planes.\n",
      "   517|         0|            0|            0|  0.00%|\n",
      "   518|         0|            0|            0|  0.00%|    Args:\n",
      "   519|         0|            0|            0|  0.00%|        kernel_size: the size of the window to take a max over.\n",
      "   520|         0|            0|            0|  0.00%|                     Can be a single number :math:`k` (for a square kernel of :math:`k \\times k \\times k`)\n",
      "   521|         0|            0|            0|  0.00%|                     or a tuple `(kT, kH, kW)`\n",
      "   522|         0|            0|            0|  0.00%|        output_size: the target output size of the form :math:`oT \\times oH \\times oW`.\n",
      "   523|         0|            0|            0|  0.00%|                     Can be a tuple `(oT, oH, oW)` or a single number :math:`oH` for a cubic output\n",
      "   524|         0|            0|            0|  0.00%|                     :math:`oH \\times oH \\times oH`\n",
      "   525|         0|            0|            0|  0.00%|        output_ratio: If one wants to have an output size as a ratio of the input size, this option can be given.\n",
      "   526|         0|            0|            0|  0.00%|                      This has to be a number or tuple in the range (0, 1)\n",
      "   527|         0|            0|            0|  0.00%|        return_indices: if ``True``, will return the indices along with the outputs.\n",
      "   528|         0|            0|            0|  0.00%|                        Useful to pass to :func:`~torch.nn.functional.max_unpool3d`.\n",
      "   529|         0|            0|            0|  0.00%|\n",
      "   530|         0|            0|            0|  0.00%|    Examples::\n",
      "   531|         0|            0|            0|  0.00%|        >>> input = torch.randn(20, 16, 50, 32, 16)\n",
      "   532|         0|            0|            0|  0.00%|        >>> # pool of cubic window of size=3, and target output size 13x12x11\n",
      "   533|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_size=(13, 12, 11))\n",
      "   534|         0|            0|            0|  0.00%|        >>> # pool of cubic window and target output size being half of input size\n",
      "   535|         0|            0|            0|  0.00%|        >>> F.fractional_max_pool3d(input, 3, output_ratio=(0.5, 0.5, 0.5))\n",
      "   536|         0|            0|            0|  0.00%|\n",
      "   537|         0|            0|            0|  0.00%|    .. _Fractional MaxPooling:\n",
      "   538|         0|            0|            0|  0.00%|        http://arxiv.org/abs/1412.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   539|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   540|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   541|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   542|         0|            0|            0|  0.00%|            fractional_max_pool3d_with_indices,\n",
      "   543|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   544|         0|            0|            0|  0.00%|            input,\n",
      "   545|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   546|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   547|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   548|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   549|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   550|         0|            0|            0|  0.00%|        )\n",
      "   551|         0|            0|            0|  0.00%|    if output_size is None and output_ratio is None:\n",
      "   552|         0|            0|            0|  0.00%|        raise ValueError(\"fractional_max_pool3d requires specifying either \" \"an output_size or an output_ratio\")\n",
      "   553|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   554|         0|            0|            0|  0.00%|        assert output_ratio is not None\n",
      "   555|         0|            0|            0|  0.00%|        _output_ratio = _triple(output_ratio)\n",
      "   556|         0|            0|            0|  0.00%|        output_size = [\n",
      "   557|         0|            0|            0|  0.00%|            int(input.size(2) * _output_ratio[0]),\n",
      "   558|         0|            0|            0|  0.00%|            int(input.size(3) * _output_ratio[1]),\n",
      "   559|         0|            0|            0|  0.00%|            int(input.size(4) * _output_ratio[2]),\n",
      "   560|         0|            0|            0|  0.00%|        ]\n",
      "   561|         0|            0|            0|  0.00%|\n",
      "   562|         0|            0|            0|  0.00%|    if _random_samples is None:\n",
      "   563|         0|            0|            0|  0.00%|        _random_samples = torch.rand(input.size(0), input.size(1), 3, dtype=input.dtype, device=input.device)\n",
      "   564|         0|            0|            0|  0.00%|    return torch._C._nn.fractional_max_pool3d(input, kernel_size, output_size, _random_samples)\n",
      "   565|         0|            0|            0|  0.00%|\n",
      "   566|         0|            0|            0|  0.00%|\n",
      "   567|         0|            0|            0|  0.00%|def _fractional_max_pool3d(\n",
      "   568|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   569|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None,\n",
      "   570|         0|            0|            0|  0.00%|    output_ratio: Optional[BroadcastingList3[float]] = None,\n",
      "   571|         0|            0|            0|  0.00%|    return_indices: bool = False,\n",
      "   572|         0|            0|            0|  0.00%|    _random_samples: Optional[Tensor] = None\n",
      "   573|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   574|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, _random_samples):\n",
      "   575|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   576|         0|            0|            0|  0.00%|            fractional_max_pool3d,\n",
      "   577|         0|            0|            0|  0.00%|            (input, _random_samples),\n",
      "   578|         0|            0|            0|  0.00%|            input,\n",
      "   579|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   580|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   581|         0|            0|            0|  0.00%|            output_ratio=output_ratio,\n",
      "   582|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   583|         0|            0|            0|  0.00%|            _random_samples=_random_samples,\n",
      "   584|         0|            0|            0|  0.00%|        )\n",
      "   585|         0|            0|            0|  0.00%|    return fractional_max_pool3d_with_indices(\n",
      "   586|         0|            0|            0|  0.00%|        input, kernel_size, output_size, output_ratio, return_indices, _random_samples\n",
      "   587|         0|            0|            0|  0.00%|    )[0]\n",
      "   588|         0|            0|            0|  0.00%|\n",
      "   589|         0|            0|            0|  0.00%|\n",
      "   590|         0|            0|            0|  0.00%|fractional_max_pool3d = boolean_dispatch(\n",
      "   591|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   592|         0|            0|            0|  0.00%|    arg_index=4,\n",
      "   593|         0|            0|            0|  0.00%|    default=False,\n",
      "   594|         0|            0|            0|  0.00%|    if_true=fractional_max_pool3d_with_indices,\n",
      "   595|         0|            0|            0|  0.00%|    if_false=_fractional_max_pool3d,\n",
      "   596|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   597|         0|            0|            0|  0.00%|    func_name=\"fractional_max_pool3d\",\n",
      "   598|         0|            0|            0|  0.00%|)\n",
      "   599|         0|            0|            0|  0.00%|\n",
      "   600|         0|            0|            0|  0.00%|\n",
      "   601|         0|            0|            0|  0.00%|def max_pool1d_with_indices(\n",
      "   602|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],\n",
      "   603|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   604|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   605|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,\n",
      "   606|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   607|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   608|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   609|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D max pooling over an input signal composed of several input\n",
      "   610|         0|            0|            0|  0.00%|    planes.\n",
      "   611|         0|            0|            0|  0.00%|\n",
      "   612|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool1d` for details.\n",
      "   613|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   614|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   615|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   616|         0|            0|            0|  0.00%|            max_pool1d_with_indices,\n",
      "   617|         0|            0|            0|  0.00%|            (input,),\n",
      "   618|         0|            0|            0|  0.00%|            input,\n",
      "   619|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   620|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   621|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   622|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   623|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   624|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   625|         0|            0|            0|  0.00%|        )\n",
      "   626|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   627|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   628|         0|            0|            0|  0.00%|    return torch.max_pool1d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   629|         0|            0|            0|  0.00%|\n",
      "   630|         0|            0|            0|  0.00%|\n",
      "   631|         0|            0|            0|  0.00%|def _max_pool1d(\n",
      "   632|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList1[int],\n",
      "   633|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   634|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   635|         0|            0|            0|  0.00%|    dilation: BroadcastingList1[int] = 1,\n",
      "   636|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   637|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   638|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   639|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   640|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   641|         0|            0|            0|  0.00%|            max_pool1d,\n",
      "   642|         0|            0|            0|  0.00%|            (input,),\n",
      "   643|         0|            0|            0|  0.00%|            input,\n",
      "   644|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   645|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   646|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   647|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   648|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   649|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   650|         0|            0|            0|  0.00%|        )\n",
      "   651|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   652|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   653|         0|            0|            0|  0.00%|    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   654|         0|            0|            0|  0.00%|\n",
      "   655|         0|            0|            0|  0.00%|\n",
      "   656|         0|            0|            0|  0.00%|max_pool1d = boolean_dispatch(\n",
      "   657|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   658|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   659|         0|            0|            0|  0.00%|    default=False,\n",
      "   660|         0|            0|            0|  0.00%|    if_true=max_pool1d_with_indices,\n",
      "   661|         0|            0|            0|  0.00%|    if_false=_max_pool1d,\n",
      "   662|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   663|         0|            0|            0|  0.00%|    func_name=\"max_pool1d\",\n",
      "   664|         0|            0|            0|  0.00%|)\n",
      "   665|         0|            0|            0|  0.00%|\n",
      "   666|         0|            0|            0|  0.00%|\n",
      "   667|         0|            0|            0|  0.00%|def max_pool2d_with_indices(\n",
      "   668|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   669|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   670|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   671|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "   672|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   673|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   674|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   675|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D max pooling over an input signal composed of several input\n",
      "   676|         0|            0|            0|  0.00%|    planes.\n",
      "   677|         0|            0|            0|  0.00%|\n",
      "   678|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool2d` for details.\n",
      "   679|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   680|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   681|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   682|         0|            0|            0|  0.00%|            max_pool2d_with_indices,\n",
      "   683|         0|            0|            0|  0.00%|            (input,),\n",
      "   684|         0|            0|            0|  0.00%|            input,\n",
      "   685|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   686|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   687|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   688|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   689|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   690|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   691|         0|            0|            0|  0.00%|        )\n",
      "   692|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   693|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   694|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   695|         0|            0|            0|  0.00%|\n",
      "   696|         0|            0|            0|  0.00%|\n",
      "   697|         0|            0|            0|  0.00%|def _max_pool2d(\n",
      "   698|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "   699|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   700|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   701|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "   702|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   703|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   704|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   705|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   706|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   707|         0|            0|            0|  0.00%|            max_pool2d,\n",
      "   708|         0|            0|            0|  0.00%|            (input,),\n",
      "   709|         0|            0|            0|  0.00%|            input,\n",
      "   710|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   711|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   712|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   713|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   714|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   715|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   716|         0|            0|            0|  0.00%|        )\n",
      "   717|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   718|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   719|         0|            0|            0|  0.00%|    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|\n",
      "   722|         0|            0|            0|  0.00%|max_pool2d = boolean_dispatch(\n",
      "   723|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   724|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   725|         0|            0|            0|  0.00%|    default=False,\n",
      "   726|         0|            0|            0|  0.00%|    if_true=max_pool2d_with_indices,\n",
      "   727|         0|            0|            0|  0.00%|    if_false=_max_pool2d,\n",
      "   728|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   729|         0|            0|            0|  0.00%|    func_name=\"max_pool2d\",\n",
      "   730|         0|            0|            0|  0.00%|)\n",
      "   731|         0|            0|            0|  0.00%|\n",
      "   732|         0|            0|            0|  0.00%|\n",
      "   733|         0|            0|            0|  0.00%|def max_pool3d_with_indices(\n",
      "   734|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   735|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   736|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   737|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,\n",
      "   738|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   739|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   740|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   741|         0|            0|            0|  0.00%|    r\"\"\"Applies a 3D max pooling over an input signal composed of several input\n",
      "   742|         0|            0|            0|  0.00%|    planes.\n",
      "   743|         0|            0|            0|  0.00%|\n",
      "   744|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxPool3d` for details.\n",
      "   745|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   746|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   747|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   748|         0|            0|            0|  0.00%|            max_pool3d_with_indices,\n",
      "   749|         0|            0|            0|  0.00%|            (input,),\n",
      "   750|         0|            0|            0|  0.00%|            input,\n",
      "   751|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   752|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   753|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   754|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   755|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   756|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   757|         0|            0|            0|  0.00%|        )\n",
      "   758|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   759|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   760|         0|            0|            0|  0.00%|    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|\n",
      "   763|         0|            0|            0|  0.00%|def _max_pool3d(\n",
      "   764|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList3[int],\n",
      "   765|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   766|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   767|         0|            0|            0|  0.00%|    dilation: BroadcastingList3[int] = 1,\n",
      "   768|         0|            0|            0|  0.00%|    ceil_mode: bool = False,\n",
      "   769|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "   770|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   771|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   772|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   773|         0|            0|            0|  0.00%|            max_pool3d,\n",
      "   774|         0|            0|            0|  0.00%|            (input,),\n",
      "   775|         0|            0|            0|  0.00%|            input,\n",
      "   776|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   777|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   778|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   779|         0|            0|            0|  0.00%|            dilation=dilation,\n",
      "   780|         0|            0|            0|  0.00%|            ceil_mode=ceil_mode,\n",
      "   781|         0|            0|            0|  0.00%|            return_indices=return_indices,\n",
      "   782|         0|            0|            0|  0.00%|        )\n",
      "   783|         0|            0|            0|  0.00%|    if stride is None:\n",
      "   784|         0|            0|            0|  0.00%|        stride = torch.jit.annotate(List[int], [])\n",
      "   785|         0|            0|            0|  0.00%|    return torch.max_pool3d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "   786|         0|            0|            0|  0.00%|\n",
      "   787|         0|            0|            0|  0.00%|\n",
      "   788|         0|            0|            0|  0.00%|max_pool3d = boolean_dispatch(\n",
      "   789|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "   790|         0|            0|            0|  0.00%|    arg_index=6,\n",
      "   791|         0|            0|            0|  0.00%|    default=False,\n",
      "   792|         0|            0|            0|  0.00%|    if_true=max_pool3d_with_indices,\n",
      "   793|         0|            0|            0|  0.00%|    if_false=_max_pool3d,\n",
      "   794|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "   795|         0|            0|            0|  0.00%|    func_name=\"max_pool3d\",\n",
      "   796|         0|            0|            0|  0.00%|)\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|\n",
      "   799|         0|            0|            0|  0.00%|def _unpool_output_size(\n",
      "   800|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: List[int], stride: List[int], padding: List[int], output_size: Optional[List[int]]\n",
      "   801|         0|            0|            0|  0.00%|) -> List[int]:\n",
      "   802|         0|            0|            0|  0.00%|    input_size = input.size()\n",
      "   803|         0|            0|            0|  0.00%|    default_size = torch.jit.annotate(List[int], [])\n",
      "   804|         0|            0|            0|  0.00%|    for d in range(len(kernel_size)):\n",
      "   805|         0|            0|            0|  0.00%|        default_size.append((input_size[-len(kernel_size) + d] - 1) * stride[d] + kernel_size[d] - 2 * padding[d])\n",
      "   806|         0|            0|            0|  0.00%|    if output_size is None:\n",
      "   807|         0|            0|            0|  0.00%|        ret = default_size\n",
      "   808|         0|            0|            0|  0.00%|    else:\n",
      "   809|         0|            0|            0|  0.00%|        if len(output_size) == len(kernel_size) + 2:\n",
      "   810|         0|            0|            0|  0.00%|            output_size = output_size[2:]\n",
      "   811|         0|            0|            0|  0.00%|        if len(output_size) != len(kernel_size):\n",
      "   812|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   813|         0|            0|            0|  0.00%|                \"output_size should be a sequence containing \"\n",
      "   814|         0|            0|            0|  0.00%|                \"{} or {} elements, but it has a length of '{}'\".format(\n",
      "   815|         0|            0|            0|  0.00%|                    len(kernel_size), len(kernel_size) + 2, len(output_size)\n",
      "   816|         0|            0|            0|  0.00%|                )\n",
      "   817|         0|            0|            0|  0.00%|            )\n",
      "   818|         0|            0|            0|  0.00%|        for d in range(len(kernel_size)):\n",
      "   819|         0|            0|            0|  0.00%|            min_size = default_size[d] - stride[d]\n",
      "   820|         0|            0|            0|  0.00%|            max_size = default_size[d] + stride[d]\n",
      "   821|         0|            0|            0|  0.00%|            if not (min_size < output_size[d] < max_size):\n",
      "   822|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "   823|         0|            0|            0|  0.00%|                    'invalid output_size \"{}\" (dim {} must be between {} and {})'.format(\n",
      "   824|         0|            0|            0|  0.00%|                        output_size, d, min_size, max_size\n",
      "   825|         0|            0|            0|  0.00%|                    )\n",
      "   826|         0|            0|            0|  0.00%|                )\n",
      "   827|         0|            0|            0|  0.00%|\n",
      "   828|         0|            0|            0|  0.00%|        ret = output_size\n",
      "   829|         0|            0|            0|  0.00%|    return ret\n",
      "   830|         0|            0|            0|  0.00%|\n",
      "   831|         0|            0|            0|  0.00%|\n",
      "   832|         0|            0|            0|  0.00%|def max_unpool1d(\n",
      "   833|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   834|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList1[int],\n",
      "   835|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   836|         0|            0|            0|  0.00%|    padding: BroadcastingList1[int] = 0,\n",
      "   837|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList1[int]] = None\n",
      "   838|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   839|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool1d`.\n",
      "   840|         0|            0|            0|  0.00%|\n",
      "   841|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool1d` for details.\n",
      "   842|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   843|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   844|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   845|         0|            0|            0|  0.00%|            max_unpool1d,\n",
      "   846|         0|            0|            0|  0.00%|            (input,),\n",
      "   847|         0|            0|            0|  0.00%|            input,\n",
      "   848|         0|            0|            0|  0.00%|            indices,\n",
      "   849|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   850|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   851|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   852|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   853|         0|            0|            0|  0.00%|        )\n",
      "   854|         0|            0|            0|  0.00%|    kernel_size = _single(kernel_size)\n",
      "   855|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   856|         0|            0|            0|  0.00%|        _stride = _single(stride)\n",
      "   857|         0|            0|            0|  0.00%|    else:\n",
      "   858|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   859|         0|            0|            0|  0.00%|    padding = _single(padding)\n",
      "   860|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   861|         0|            0|            0|  0.00%|    if isinstance(output_size, list):\n",
      "   862|         0|            0|            0|  0.00%|        output_size = output_size + [1]\n",
      "   863|         0|            0|            0|  0.00%|    else:\n",
      "   864|         0|            0|            0|  0.00%|        output_size = output_size + (1,)\n",
      "   865|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input.unsqueeze(-1), indices.unsqueeze(-1), output_size).squeeze(-1)\n",
      "   866|         0|            0|            0|  0.00%|\n",
      "   867|         0|            0|            0|  0.00%|\n",
      "   868|         0|            0|            0|  0.00%|def max_unpool2d(\n",
      "   869|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   870|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],\n",
      "   871|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   872|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "   873|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList2[int]] = None\n",
      "   874|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   875|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool2d`.\n",
      "   876|         0|            0|            0|  0.00%|\n",
      "   877|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool2d` for details.\n",
      "   878|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   879|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   880|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   881|         0|            0|            0|  0.00%|            max_unpool2d,\n",
      "   882|         0|            0|            0|  0.00%|            (input,),\n",
      "   883|         0|            0|            0|  0.00%|            input,\n",
      "   884|         0|            0|            0|  0.00%|            indices,\n",
      "   885|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   886|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   887|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   888|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   889|         0|            0|            0|  0.00%|        )\n",
      "   890|         0|            0|            0|  0.00%|    kernel_size = _pair(kernel_size)\n",
      "   891|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   892|         0|            0|            0|  0.00%|        _stride = _pair(stride)\n",
      "   893|         0|            0|            0|  0.00%|    else:\n",
      "   894|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   895|         0|            0|            0|  0.00%|    padding = _pair(padding)\n",
      "   896|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   897|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool2d(input, indices, output_size)\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|\n",
      "   900|         0|            0|            0|  0.00%|def max_unpool3d(\n",
      "   901|         0|            0|            0|  0.00%|    input: Tensor, indices: Tensor,\n",
      "   902|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList3[int],\n",
      "   903|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList3[int]] = None,\n",
      "   904|         0|            0|            0|  0.00%|    padding: BroadcastingList3[int] = 0,\n",
      "   905|         0|            0|            0|  0.00%|    output_size: Optional[BroadcastingList3[int]] = None\n",
      "   906|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   907|         0|            0|            0|  0.00%|    r\"\"\"Computes a partial inverse of :class:`MaxPool3d`.\n",
      "   908|         0|            0|            0|  0.00%|\n",
      "   909|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MaxUnpool3d` for details.\n",
      "   910|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   911|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   912|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   913|         0|            0|            0|  0.00%|            max_unpool3d,\n",
      "   914|         0|            0|            0|  0.00%|            (input,),\n",
      "   915|         0|            0|            0|  0.00%|            input,\n",
      "   916|         0|            0|            0|  0.00%|            indices,\n",
      "   917|         0|            0|            0|  0.00%|            kernel_size,\n",
      "   918|         0|            0|            0|  0.00%|            stride=stride,\n",
      "   919|         0|            0|            0|  0.00%|            padding=padding,\n",
      "   920|         0|            0|            0|  0.00%|            output_size=output_size,\n",
      "   921|         0|            0|            0|  0.00%|        )\n",
      "   922|         0|            0|            0|  0.00%|    kernel_size = _triple(kernel_size)\n",
      "   923|         0|            0|            0|  0.00%|    if stride is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   924|         0|            0|            0|  0.00%|        _stride = _triple(stride)\n",
      "   925|         0|            0|            0|  0.00%|    else:\n",
      "   926|         0|            0|            0|  0.00%|        _stride = kernel_size\n",
      "   927|         0|            0|            0|  0.00%|    padding = _triple(padding)\n",
      "   928|         0|            0|            0|  0.00%|    output_size = _unpool_output_size(input, kernel_size, _stride, padding, output_size)\n",
      "   929|         0|            0|            0|  0.00%|    return torch._C._nn.max_unpool3d(input, indices, output_size, _stride, padding)\n",
      "   930|         0|            0|            0|  0.00%|\n",
      "   931|         0|            0|            0|  0.00%|\n",
      "   932|         0|            0|            0|  0.00%|def lp_pool2d(\n",
      "   933|         0|            0|            0|  0.00%|    input: Tensor, norm_type: float,\n",
      "   934|         0|            0|            0|  0.00%|    kernel_size: int,\n",
      "   935|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList2[int]] = None,\n",
      "   936|         0|            0|            0|  0.00%|    ceil_mode: bool = False\n",
      "   937|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   938|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D power-average pooling over an input signal composed of\n",
      "   939|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is\n",
      "   940|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.\n",
      "   941|         0|            0|            0|  0.00%|\n",
      "   942|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool2d` for details.\n",
      "   943|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   944|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   945|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   946|         0|            0|            0|  0.00%|            lp_pool2d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode\n",
      "   947|         0|            0|            0|  0.00%|        )\n",
      "   948|         0|            0|            0|  0.00%|    kw, kh = utils._pair(kernel_size)\n",
      "   949|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   950|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n",
      "   951|         0|            0|            0|  0.00%|    else:\n",
      "   952|         0|            0|            0|  0.00%|        out = avg_pool2d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)\n",
      "   953|         0|            0|            0|  0.00%|\n",
      "   954|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kw * kh).pow(1.0 / norm_type)\n",
      "   955|         0|            0|            0|  0.00%|\n",
      "   956|         0|            0|            0|  0.00%|\n",
      "   957|         0|            0|            0|  0.00%|def lp_pool1d(\n",
      "   958|         0|            0|            0|  0.00%|    input: Tensor, norm_type: float,\n",
      "   959|         0|            0|            0|  0.00%|    kernel_size: int,\n",
      "   960|         0|            0|            0|  0.00%|    stride: Optional[BroadcastingList1[int]] = None,\n",
      "   961|         0|            0|            0|  0.00%|    ceil_mode: bool = False\n",
      "   962|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "   963|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D power-average pooling over an input signal composed of\n",
      "   964|         0|            0|            0|  0.00%|    several input planes. If the sum of all inputs to the power of `p` is\n",
      "   965|         0|            0|            0|  0.00%|    zero, the gradient is set to zero as well.\n",
      "   966|         0|            0|            0|  0.00%|\n",
      "   967|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LPPool1d` for details.\n",
      "   968|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   969|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   970|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   971|         0|            0|            0|  0.00%|            lp_pool1d, (input,), input, norm_type, kernel_size, stride=stride, ceil_mode=ceil_mode\n",
      "   972|         0|            0|            0|  0.00%|        )\n",
      "   973|         0|            0|            0|  0.00%|    if stride is not None:\n",
      "   974|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, stride, 0, ceil_mode)\n",
      "   975|         0|            0|            0|  0.00%|    else:\n",
      "   976|         0|            0|            0|  0.00%|        out = avg_pool1d(input.pow(norm_type), kernel_size, padding=0, ceil_mode=ceil_mode)\n",
      "   977|         0|            0|            0|  0.00%|\n",
      "   978|         0|            0|            0|  0.00%|    return (torch.sign(out) * relu(torch.abs(out))).mul(kernel_size).pow(1.0 / norm_type)\n",
      "   979|         0|            0|            0|  0.00%|\n",
      "   980|         0|            0|            0|  0.00%|\n",
      "   981|         0|            0|            0|  0.00%|def adaptive_max_pool1d_with_indices(\n",
      "   982|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False\n",
      "   983|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "   984|         0|            0|            0|  0.00%|    r\"\"\"Applies a 1D adaptive max pooling over an input signal composed of\n",
      "   985|         0|            0|            0|  0.00%|    several input planes.\n",
      "   986|         0|            0|            0|  0.00%|\n",
      "   987|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool1d` for details and output shape.\n",
      "   988|         0|            0|            0|  0.00%|\n",
      "   989|         0|            0|            0|  0.00%|    Args:\n",
      "   990|         0|            0|            0|  0.00%|        output_size: the target output size (single integer)\n",
      "   991|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "   992|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   993|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "   994|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   995|         0|            0|            0|  0.00%|            adaptive_max_pool1d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "   996|         0|            0|            0|  0.00%|        )\n",
      "   997|         0|            0|            0|  0.00%|    return torch.adaptive_max_pool1d(input, output_size)\n",
      "   998|         0|            0|            0|  0.00%|\n",
      "   999|         0|            0|            0|  0.00%|\n",
      "  1000|         0|            0|            0|  0.00%|def _adaptive_max_pool1d(input: Tensor, output_size: BroadcastingList1[int], return_indices: bool = False) -> Tensor:\n",
      "  1001|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1002|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1003|         0|            0|            0|  0.00%|            adaptive_max_pool1d, (input,), input, output_size, return_indices=return_indices\n",
      "  1004|         0|            0|            0|  0.00%|        )\n",
      "  1005|         0|            0|            0|  0.00%|    return adaptive_max_pool1d_with_indices(input, output_size)[0]\n",
      "  1006|         0|            0|            0|  0.00%|\n",
      "  1007|         0|            0|            0|  0.00%|\n",
      "  1008|         0|            0|            0|  0.00%|adaptive_max_pool1d = boolean_dispatch(\n",
      "  1009|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1010|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1011|         0|            0|            0|  0.00%|    default=False,\n",
      "  1012|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool1d_with_indices,\n",
      "  1013|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool1d,\n",
      "  1014|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1015|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool1d\",\n",
      "  1016|         0|            0|            0|  0.00%|)\n",
      "  1017|         0|            0|            0|  0.00%|\n",
      "  1018|         0|            0|            0|  0.00%|\n",
      "  1019|         0|            0|            0|  0.00%|def adaptive_max_pool2d_with_indices(\n",
      "  1020|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],\n",
      "  1021|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "  1022|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  1023|         0|            0|            0|  0.00%|    r\"\"\"Applies a 2D adaptive max pooling over an input signal composed of\n",
      "  1024|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1025|         0|            0|            0|  0.00%|\n",
      "  1026|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool2d` for details and output shape.\n",
      "  1027|         0|            0|            0|  0.00%|\n",
      "  1028|         0|            0|            0|  0.00%|    Args:\n",
      "  1029|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1030|         0|            0|            0|  0.00%|            double-integer tuple)\n",
      "  1031|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "  1032|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1033|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1034|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1035|         0|            0|            0|  0.00%|            adaptive_max_pool2d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "  1036|         0|            0|            0|  0.00%|        )\n",
      "  1037|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())\n",
      "  1038|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool2d(input, output_size)\n",
      "  1039|         0|            0|            0|  0.00%|\n",
      "  1040|         0|            0|            0|  0.00%|\n",
      "  1041|         0|            0|            0|  0.00%|def _adaptive_max_pool2d(input: Tensor, output_size: BroadcastingList2[int], return_indices: bool = False) -> Tensor:\n",
      "  1042|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1043|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1044|         0|            0|            0|  0.00%|            adaptive_max_pool2d, (input,), input, output_size, return_indices=return_indices\n",
      "  1045|         0|            0|            0|  0.00%|        )\n",
      "  1046|         0|            0|            0|  0.00%|    return adaptive_max_pool2d_with_indices(input, output_size)[0]\n",
      "  1047|         0|            0|            0|  0.00%|\n",
      "  1048|         0|            0|            0|  0.00%|\n",
      "  1049|         0|            0|            0|  0.00%|adaptive_max_pool2d = boolean_dispatch(\n",
      "  1050|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1051|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1052|         0|            0|            0|  0.00%|    default=False,\n",
      "  1053|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool2d_with_indices,\n",
      "  1054|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool2d,\n",
      "  1055|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1056|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool2d\",\n",
      "  1057|         0|            0|            0|  0.00%|)\n",
      "  1058|         0|            0|            0|  0.00%|\n",
      "  1059|         0|            0|            0|  0.00%|\n",
      "  1060|         0|            0|            0|  0.00%|def adaptive_max_pool3d_with_indices(\n",
      "  1061|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList3[int],\n",
      "  1062|         0|            0|            0|  0.00%|    return_indices: bool = False\n",
      "  1063|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  1064|         0|            0|            0|  0.00%|    r\"\"\"Applies a 3D adaptive max pooling over an input signal composed of\n",
      "  1065|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1066|         0|            0|            0|  0.00%|\n",
      "  1067|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveMaxPool3d` for details and output shape.\n",
      "  1068|         0|            0|            0|  0.00%|\n",
      "  1069|         0|            0|            0|  0.00%|    Args:\n",
      "  1070|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1071|         0|            0|            0|  0.00%|            triple-integer tuple)\n",
      "  1072|         0|            0|            0|  0.00%|        return_indices: whether to return pooling indices. Default: ``False``\n",
      "  1073|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1074|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1075|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1076|         0|            0|            0|  0.00%|            adaptive_max_pool3d_with_indices, (input,), input, output_size, return_indices=return_indices\n",
      "  1077|         0|            0|            0|  0.00%|        )\n",
      "  1078|         0|            0|            0|  0.00%|    output_size = _list_with_default(output_size, input.size())\n",
      "  1079|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_max_pool3d(input, output_size)\n",
      "  1080|         0|            0|            0|  0.00%|\n",
      "  1081|         0|            0|            0|  0.00%|\n",
      "  1082|         0|            0|            0|  0.00%|def _adaptive_max_pool3d(input: Tensor, output_size: BroadcastingList3[int], return_indices: bool = False) -> Tensor:\n",
      "  1083|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1084|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1085|         0|            0|            0|  0.00%|            adaptive_max_pool3d, (input,), input, output_size, return_indices=return_indices\n",
      "  1086|         0|            0|            0|  0.00%|        )\n",
      "  1087|         0|            0|            0|  0.00%|    return adaptive_max_pool3d_with_indices(input, output_size)[0]\n",
      "  1088|         0|            0|            0|  0.00%|\n",
      "  1089|         0|            0|            0|  0.00%|\n",
      "  1090|         0|            0|            0|  0.00%|adaptive_max_pool3d = boolean_dispatch(\n",
      "  1091|         0|            0|            0|  0.00%|    arg_name=\"return_indices\",\n",
      "  1092|         0|            0|            0|  0.00%|    arg_index=2,\n",
      "  1093|         0|            0|            0|  0.00%|    default=False,\n",
      "  1094|         0|            0|            0|  0.00%|    if_true=adaptive_max_pool3d_with_indices,\n",
      "  1095|         0|            0|            0|  0.00%|    if_false=_adaptive_max_pool3d,\n",
      "  1096|         0|            0|            0|  0.00%|    module_name=__name__,\n",
      "  1097|         0|            0|            0|  0.00%|    func_name=\"adaptive_max_pool3d\",\n",
      "  1098|         0|            0|            0|  0.00%|)\n",
      "  1099|         0|            0|            0|  0.00%|\n",
      "  1100|         0|            0|            0|  0.00%|\n",
      "  1101|         0|            0|            0|  0.00%|adaptive_avg_pool1d = _add_docstr(\n",
      "  1102|         0|            0|            0|  0.00%|    torch.adaptive_avg_pool1d,\n",
      "  1103|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1104|         0|            0|            0|  0.00%|adaptive_avg_pool1d(input, output_size) -> Tensor\n",
      "  1105|         0|            0|            0|  0.00%|\n",
      "  1106|         0|            0|            0|  0.00%|Applies a 1D adaptive average pooling over an input signal composed of\n",
      "  1107|         0|            0|            0|  0.00%|several input planes.\n",
      "  1108|         0|            0|            0|  0.00%|\n",
      "  1109|         0|            0|            0|  0.00%|See :class:`~torch.nn.AdaptiveAvgPool1d` for details and output shape.\n",
      "  1110|         0|            0|            0|  0.00%|\n",
      "  1111|         0|            0|            0|  0.00%|Args:\n",
      "  1112|         0|            0|            0|  0.00%|    output_size: the target output size (single integer)\n",
      "  1113|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1114|         0|            0|            0|  0.00%|)\n",
      "  1115|         0|            0|            0|  0.00%|\n",
      "  1116|         0|            0|            0|  0.00%|\n",
      "  1117|         0|            0|            0|  0.00%|def adaptive_avg_pool2d(input: Tensor, output_size: BroadcastingList2[int]) -> Tensor:\n",
      "  1118|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1119|         0|            0|            0|  0.00%|    Applies a 2D adaptive average pooling over an input signal composed of\n",
      "  1120|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1121|         0|            0|            0|  0.00%|\n",
      "  1122|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool2d` for details and output shape.\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    Args:\n",
      "  1125|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1126|         0|            0|            0|  0.00%|            double-integer tuple)\n",
      "  1127|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1128|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1129|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool2d, (input,), input, output_size)\n",
      "  1130|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())\n",
      "  1131|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)\n",
      "  1132|         0|            0|            0|  0.00%|\n",
      "  1133|         0|            0|            0|  0.00%|\n",
      "  1134|         0|            0|            0|  0.00%|def adaptive_avg_pool3d(input: Tensor, output_size: BroadcastingList3[int]) -> Tensor:\n",
      "  1135|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1136|         0|            0|            0|  0.00%|    Applies a 3D adaptive average pooling over an input signal composed of\n",
      "  1137|         0|            0|            0|  0.00%|    several input planes.\n",
      "  1138|         0|            0|            0|  0.00%|\n",
      "  1139|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AdaptiveAvgPool3d` for details and output shape.\n",
      "  1140|         0|            0|            0|  0.00%|\n",
      "  1141|         0|            0|            0|  0.00%|    Args:\n",
      "  1142|         0|            0|            0|  0.00%|        output_size: the target output size (single integer or\n",
      "  1143|         0|            0|            0|  0.00%|            triple-integer tuple)\n",
      "  1144|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1145|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1146|         0|            0|            0|  0.00%|        return handle_torch_function(adaptive_avg_pool3d, (input,), input, output_size)\n",
      "  1147|         0|            0|            0|  0.00%|    _output_size = _list_with_default(output_size, input.size())\n",
      "  1148|         0|            0|            0|  0.00%|    return torch._C._nn.adaptive_avg_pool3d(input, _output_size)\n",
      "  1149|         0|            0|            0|  0.00%|\n",
      "  1150|         0|            0|            0|  0.00%|\n",
      "  1151|         0|            0|            0|  0.00%|# Activation functions\n",
      "  1152|         0|            0|            0|  0.00%|def dropout(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1153|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1154|         0|            0|            0|  0.00%|    During training, randomly zeroes some of the elements of the input\n",
      "  1155|         0|            0|            0|  0.00%|    tensor with probability :attr:`p` using samples from a Bernoulli\n",
      "  1156|         0|            0|            0|  0.00%|    distribution.\n",
      "  1157|         0|            0|            0|  0.00%|\n",
      "  1158|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout` for details.\n",
      "  1159|         0|            0|            0|  0.00%|\n",
      "  1160|         0|            0|            0|  0.00%|    Args:\n",
      "  1161|         0|            0|            0|  0.00%|        p: probability of an element to be zeroed. Default: 0.5\n",
      "  1162|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1163|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1164|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1165|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1166|         0|            0|            0|  0.00%|        return handle_torch_function(dropout, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1167|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1168|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1169|         0|            0|            0|  0.00%|    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "  1170|         0|            0|            0|  0.00%|\n",
      "  1171|         0|            0|            0|  0.00%|\n",
      "  1172|         0|            0|            0|  0.00%|def alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:\n",
      "  1173|         0|            0|            0|  0.00%|    r\"\"\"Applies alpha dropout to the input.\n",
      "  1174|         0|            0|            0|  0.00%|\n",
      "  1175|         0|            0|            0|  0.00%|    See :class:`~torch.nn.AlphaDropout` for details.\n",
      "  1176|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1177|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1178|         0|            0|            0|  0.00%|        return handle_torch_function(alpha_dropout, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1179|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1180|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1181|         0|            0|            0|  0.00%|    return _VF.alpha_dropout_(input, p, training) if inplace else _VF.alpha_dropout(input, p, training)\n",
      "  1182|         0|            0|            0|  0.00%|\n",
      "  1183|         0|            0|            0|  0.00%|\n",
      "  1184|         0|            0|            0|  0.00%|def dropout2d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1185|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1186|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 2D feature map,\n",
      "  1187|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the\n",
      "  1188|         0|            0|            0|  0.00%|    batched input is a 2D tensor :math:`\\text{input}[i, j]`) of the input tensor).\n",
      "  1189|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with\n",
      "  1190|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1191|         0|            0|            0|  0.00%|\n",
      "  1192|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout2d` for details.\n",
      "  1193|         0|            0|            0|  0.00%|\n",
      "  1194|         0|            0|            0|  0.00%|    Args:\n",
      "  1195|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5\n",
      "  1196|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1197|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1198|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1199|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1200|         0|            0|            0|  0.00%|        return handle_torch_function(dropout2d, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1201|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1202|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1203|         0|            0|            0|  0.00%|    return _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)\n",
      "  1204|         0|            0|            0|  0.00%|\n",
      "  1205|         0|            0|            0|  0.00%|\n",
      "  1206|         0|            0|            0|  0.00%|def dropout3d(input: Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> Tensor:\n",
      "  1207|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1208|         0|            0|            0|  0.00%|    Randomly zero out entire channels (a channel is a 3D feature map,\n",
      "  1209|         0|            0|            0|  0.00%|    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the\n",
      "  1210|         0|            0|            0|  0.00%|    batched input is a 3D tensor :math:`\\text{input}[i, j]`) of the input tensor).\n",
      "  1211|         0|            0|            0|  0.00%|    Each channel will be zeroed out independently on every forward call with\n",
      "  1212|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1213|         0|            0|            0|  0.00%|\n",
      "  1214|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Dropout3d` for details.\n",
      "  1215|         0|            0|            0|  0.00%|\n",
      "  1216|         0|            0|            0|  0.00%|    Args:\n",
      "  1217|         0|            0|            0|  0.00%|        p: probability of a channel to be zeroed. Default: 0.5\n",
      "  1218|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1219|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1220|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1221|         0|            0|            0|  0.00%|    # This is 100% the same code as dropout2d. We duplicate this code so that\n",
      "  1222|         0|            0|            0|  0.00%|    # stack traces are not confusing.\n",
      "  1223|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1224|         0|            0|            0|  0.00%|        return handle_torch_function(dropout3d, (input,), input, p=p, training=training, inplace=inplace)\n",
      "  1225|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1226|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1227|         0|            0|            0|  0.00%|    return _VF.feature_dropout_(input, p, training) if inplace else _VF.feature_dropout(input, p, training)\n",
      "  1228|         0|            0|            0|  0.00%|\n",
      "  1229|         0|            0|            0|  0.00%|\n",
      "  1230|         0|            0|            0|  0.00%|def feature_alpha_dropout(input: Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> Tensor:\n",
      "  1231|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1232|         0|            0|            0|  0.00%|    Randomly masks out entire channels (a channel is a feature map,\n",
      "  1233|         0|            0|            0|  0.00%|    e.g. the :math:`j`-th channel of the :math:`i`-th sample in the batch input\n",
      "  1234|         0|            0|            0|  0.00%|    is a tensor :math:`\\text{input}[i, j]`) of the input tensor). Instead of\n",
      "  1235|         0|            0|            0|  0.00%|    setting activations to zero, as in regular Dropout, the activations are set\n",
      "  1236|         0|            0|            0|  0.00%|    to the negative saturation value of the SELU activation function.\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    Each element will be masked independently on every forward call with\n",
      "  1239|         0|            0|            0|  0.00%|    probability :attr:`p` using samples from a Bernoulli distribution.\n",
      "  1240|         0|            0|            0|  0.00%|    The elements to be masked are randomized on every forward call, and scaled\n",
      "  1241|         0|            0|            0|  0.00%|    and shifted to maintain zero mean and unit variance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1242|         0|            0|            0|  0.00%|\n",
      "  1243|         0|            0|            0|  0.00%|    See :class:`~torch.nn.FeatureAlphaDropout` for details.\n",
      "  1244|         0|            0|            0|  0.00%|\n",
      "  1245|         0|            0|            0|  0.00%|    Args:\n",
      "  1246|         0|            0|            0|  0.00%|        p: dropout probability of a channel to be zeroed. Default: 0.5\n",
      "  1247|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``. Default: ``True``\n",
      "  1248|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1249|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1250|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1251|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1252|         0|            0|            0|  0.00%|            feature_alpha_dropout, (input,), input, p=p, training=training, inplace=inplace\n",
      "  1253|         0|            0|            0|  0.00%|        )\n",
      "  1254|         0|            0|            0|  0.00%|    if p < 0.0 or p > 1.0:\n",
      "  1255|         0|            0|            0|  0.00%|        raise ValueError(\"dropout probability has to be between 0 and 1, \" \"but got {}\".format(p))\n",
      "  1256|         0|            0|            0|  0.00%|    return _VF.feature_alpha_dropout_(input, p, training) if inplace else _VF.feature_alpha_dropout(input, p, training)\n",
      "  1257|         0|            0|            0|  0.00%|\n",
      "  1258|         0|            0|            0|  0.00%|\n",
      "  1259|         0|            0|            0|  0.00%|def _threshold(input: Tensor, threshold: float, value: float, inplace: bool = False) -> Tensor:\n",
      "  1260|         0|            0|            0|  0.00%|    r\"\"\"Thresholds each element of the input Tensor.\n",
      "  1261|         0|            0|            0|  0.00%|\n",
      "  1262|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Threshold` for more details.\n",
      "  1263|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1264|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1265|         0|            0|            0|  0.00%|        return handle_torch_function(_threshold, (input,), input, threshold, value, inplace=inplace)\n",
      "  1266|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1267|         0|            0|            0|  0.00%|        result = _VF.threshold_(input, threshold, value)\n",
      "  1268|         0|            0|            0|  0.00%|    else:\n",
      "  1269|         0|            0|            0|  0.00%|        result = _VF.threshold(input, threshold, value)\n",
      "  1270|         0|            0|            0|  0.00%|    return result\n",
      "  1271|         0|            0|            0|  0.00%|\n",
      "  1272|         0|            0|            0|  0.00%|\n",
      "  1273|         0|            0|            0|  0.00%|# We define this function as _threshold because it takes an argument\n",
      "  1274|         0|            0|            0|  0.00%|# named threshold, which clobbers the recursive reference to the\n",
      "  1275|         0|            0|            0|  0.00%|# function needed for __torch_function__ support\n",
      "  1276|         0|            0|            0|  0.00%|threshold = _threshold\n",
      "  1277|         0|            0|            0|  0.00%|\n",
      "  1278|         0|            0|            0|  0.00%|threshold_ = _add_docstr(\n",
      "  1279|         0|            0|            0|  0.00%|    _VF.threshold_,\n",
      "  1280|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1281|         0|            0|            0|  0.00%|threshold_(input, threshold, value) -> Tensor\n",
      "  1282|         0|            0|            0|  0.00%|\n",
      "  1283|         0|            0|            0|  0.00%|In-place version of :func:`~threshold`.\n",
      "  1284|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1285|         0|            0|            0|  0.00%|)\n",
      "  1286|         0|            0|            0|  0.00%|\n",
      "  1287|         0|            0|            0|  0.00%|\n",
      "  1288|         0|            0|            0|  0.00%|def relu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1289|         0|            0|            0|  0.00%|    r\"\"\"relu(input, inplace=False) -> Tensor\n",
      "  1290|         0|            0|            0|  0.00%|\n",
      "  1291|         0|            0|            0|  0.00%|    Applies the rectified linear unit function element-wise. See\n",
      "  1292|         0|            0|            0|  0.00%|    :class:`~torch.nn.ReLU` for more details.\n",
      "  1293|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1294|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1295|         0|            0|            0|  0.00%|        return handle_torch_function(relu, (input,), input, inplace=inplace)\n",
      "  1296|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1297|         0|            0|            0|  0.00%|        result = torch.relu_(input)\n",
      "  1298|         0|            0|            0|  0.00%|    else:\n",
      "  1299|         0|            0|            0|  0.00%|        result = torch.relu(input)\n",
      "  1300|         0|            0|            0|  0.00%|    return result\n",
      "  1301|         0|            0|            0|  0.00%|\n",
      "  1302|         0|            0|            0|  0.00%|\n",
      "  1303|         0|            0|            0|  0.00%|relu_ = _add_docstr(\n",
      "  1304|         0|            0|            0|  0.00%|    torch.relu_,\n",
      "  1305|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1306|         0|            0|            0|  0.00%|relu_(input) -> Tensor\n",
      "  1307|         0|            0|            0|  0.00%|\n",
      "  1308|         0|            0|            0|  0.00%|In-place version of :func:`~relu`.\n",
      "  1309|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1310|         0|            0|            0|  0.00%|)\n",
      "  1311|         0|            0|            0|  0.00%|\n",
      "  1312|         0|            0|            0|  0.00%|\n",
      "  1313|         0|            0|            0|  0.00%|def glu(input: Tensor, dim: int = -1) -> Tensor:\n",
      "  1314|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1315|         0|            0|            0|  0.00%|    glu(input, dim=-1) -> Tensor\n",
      "  1316|         0|            0|            0|  0.00%|\n",
      "  1317|         0|            0|            0|  0.00%|    The gated linear unit. Computes:\n",
      "  1318|         0|            0|            0|  0.00%|\n",
      "  1319|         0|            0|            0|  0.00%|    .. math ::\n",
      "  1320|         0|            0|            0|  0.00%|        \\text{GLU}(a, b) = a \\otimes \\sigma(b)\n",
      "  1321|         0|            0|            0|  0.00%|\n",
      "  1322|         0|            0|            0|  0.00%|    where `input` is split in half along `dim` to form `a` and `b`, :math:`\\sigma`\n",
      "  1323|         0|            0|            0|  0.00%|    is the sigmoid function and :math:`\\otimes` is the element-wise product between matrices.\n",
      "  1324|         0|            0|            0|  0.00%|\n",
      "  1325|         0|            0|            0|  0.00%|    See `Language Modeling with Gated Convolutional Networks <https://arxiv.org/abs/1612.08083>`_.\n",
      "  1326|         0|            0|            0|  0.00%|\n",
      "  1327|         0|            0|            0|  0.00%|    Args:\n",
      "  1328|         0|            0|            0|  0.00%|        input (Tensor): input tensor\n",
      "  1329|         0|            0|            0|  0.00%|        dim (int): dimension on which to split the input. Default: -1\n",
      "  1330|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1331|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1332|         0|            0|            0|  0.00%|        return handle_torch_function(glu, (input,), input, dim=dim)\n",
      "  1333|         0|            0|            0|  0.00%|    if input.dim() == 0:\n",
      "  1334|         0|            0|            0|  0.00%|        raise RuntimeError(\"glu does not support scalars because halving size must be even\")\n",
      "  1335|         0|            0|            0|  0.00%|    return torch._C._nn.glu(input, dim)\n",
      "  1336|         0|            0|            0|  0.00%|\n",
      "  1337|         0|            0|            0|  0.00%|\n",
      "  1338|         0|            0|            0|  0.00%|def hardtanh(input: Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1339|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1340|         0|            0|            0|  0.00%|    hardtanh(input, min_val=-1., max_val=1., inplace=False) -> Tensor\n",
      "  1341|         0|            0|            0|  0.00%|\n",
      "  1342|         0|            0|            0|  0.00%|    Applies the HardTanh function element-wise. See :class:`~torch.nn.Hardtanh` for more\n",
      "  1343|         0|            0|            0|  0.00%|    details.\n",
      "  1344|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1345|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1346|         0|            0|            0|  0.00%|        return handle_torch_function(hardtanh, (input,), input, min_val=min_val, max_val=max_val, inplace=inplace)\n",
      "  1347|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1348|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh_(input, min_val, max_val)\n",
      "  1349|         0|            0|            0|  0.00%|    else:\n",
      "  1350|         0|            0|            0|  0.00%|        result = torch._C._nn.hardtanh(input, min_val, max_val)\n",
      "  1351|         0|            0|            0|  0.00%|    return result\n",
      "  1352|         0|            0|            0|  0.00%|\n",
      "  1353|         0|            0|            0|  0.00%|\n",
      "  1354|         0|            0|            0|  0.00%|hardtanh_ = _add_docstr(\n",
      "  1355|         0|            0|            0|  0.00%|    torch._C._nn.hardtanh_,\n",
      "  1356|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1357|         0|            0|            0|  0.00%|hardtanh_(input, min_val=-1., max_val=1.) -> Tensor\n",
      "  1358|         0|            0|            0|  0.00%|\n",
      "  1359|         0|            0|            0|  0.00%|In-place version of :func:`~hardtanh`.\n",
      "  1360|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1361|         0|            0|            0|  0.00%|)\n",
      "  1362|         0|            0|            0|  0.00%|\n",
      "  1363|         0|            0|            0|  0.00%|\n",
      "  1364|         0|            0|            0|  0.00%|def relu6(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1365|         0|            0|            0|  0.00%|    r\"\"\"relu6(input, inplace=False) -> Tensor\n",
      "  1366|         0|            0|            0|  0.00%|\n",
      "  1367|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\\text{ReLU6}(x) = \\min(\\max(0,x), 6)`.\n",
      "  1368|         0|            0|            0|  0.00%|\n",
      "  1369|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ReLU6` for more details.\n",
      "  1370|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1371|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1372|         0|            0|            0|  0.00%|        return handle_torch_function(relu6, (input,), input, inplace=inplace)\n",
      "  1373|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1374|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6_(input)\n",
      "  1375|         0|            0|            0|  0.00%|    else:\n",
      "  1376|         0|            0|            0|  0.00%|        result = torch._C._nn.relu6(input)\n",
      "  1377|         0|            0|            0|  0.00%|    return result\n",
      "  1378|         0|            0|            0|  0.00%|\n",
      "  1379|         0|            0|            0|  0.00%|\n",
      "  1380|         0|            0|            0|  0.00%|def elu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1381|         0|            0|            0|  0.00%|    r\"\"\"Applies element-wise,\n",
      "  1382|         0|            0|            0|  0.00%|    :math:`\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))`.\n",
      "  1383|         0|            0|            0|  0.00%|\n",
      "  1384|         0|            0|            0|  0.00%|    See :class:`~torch.nn.ELU` for more details.\n",
      "  1385|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1386|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1387|         0|            0|            0|  0.00%|        return handle_torch_function(elu, (input,), input, alpha=alpha, inplace=inplace)\n",
      "  1388|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1389|         0|            0|            0|  0.00%|        result = torch._C._nn.elu_(input, alpha)\n",
      "  1390|         0|            0|            0|  0.00%|    else:\n",
      "  1391|         0|            0|            0|  0.00%|        result = torch._C._nn.elu(input, alpha)\n",
      "  1392|         0|            0|            0|  0.00%|    return result\n",
      "  1393|         0|            0|            0|  0.00%|\n",
      "  1394|         0|            0|            0|  0.00%|\n",
      "  1395|         0|            0|            0|  0.00%|elu_ = _add_docstr(\n",
      "  1396|         0|            0|            0|  0.00%|    torch._C._nn.elu_,\n",
      "  1397|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1398|         0|            0|            0|  0.00%|elu_(input, alpha=1.) -> Tensor\n",
      "  1399|         0|            0|            0|  0.00%|\n",
      "  1400|         0|            0|            0|  0.00%|In-place version of :func:`~elu`.\n",
      "  1401|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1402|         0|            0|            0|  0.00%|)\n",
      "  1403|         0|            0|            0|  0.00%|\n",
      "  1404|         0|            0|            0|  0.00%|\n",
      "  1405|         0|            0|            0|  0.00%|def selu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1406|         0|            0|            0|  0.00%|    r\"\"\"selu(input, inplace=False) -> Tensor\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1409|         0|            0|            0|  0.00%|    :math:`\\text{SELU}(x) = scale * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))`,\n",
      "  1410|         0|            0|            0|  0.00%|    with :math:`\\alpha=1.6732632423543772848170429916717` and\n",
      "  1411|         0|            0|            0|  0.00%|    :math:`scale=1.0507009873554804934193349852946`.\n",
      "  1412|         0|            0|            0|  0.00%|\n",
      "  1413|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SELU` for more details.\n",
      "  1414|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1415|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1416|         0|            0|            0|  0.00%|        return handle_torch_function(selu, (input,), input, inplace=inplace)\n",
      "  1417|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1418|         0|            0|            0|  0.00%|        result = torch.selu_(input)\n",
      "  1419|         0|            0|            0|  0.00%|    else:\n",
      "  1420|         0|            0|            0|  0.00%|        result = torch.selu(input)\n",
      "  1421|         0|            0|            0|  0.00%|    return result\n",
      "  1422|         0|            0|            0|  0.00%|\n",
      "  1423|         0|            0|            0|  0.00%|\n",
      "  1424|         0|            0|            0|  0.00%|selu_ = _add_docstr(\n",
      "  1425|         0|            0|            0|  0.00%|    torch.selu_,\n",
      "  1426|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1427|         0|            0|            0|  0.00%|selu_(input) -> Tensor\n",
      "  1428|         0|            0|            0|  0.00%|\n",
      "  1429|         0|            0|            0|  0.00%|In-place version of :func:`~selu`.\n",
      "  1430|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1431|         0|            0|            0|  0.00%|)\n",
      "  1432|         0|            0|            0|  0.00%|\n",
      "  1433|         0|            0|            0|  0.00%|\n",
      "  1434|         0|            0|            0|  0.00%|def celu(input: Tensor, alpha: float = 1.0, inplace: bool = False) -> Tensor:\n",
      "  1435|         0|            0|            0|  0.00%|    r\"\"\"celu(input, alpha=1., inplace=False) -> Tensor\n",
      "  1436|         0|            0|            0|  0.00%|\n",
      "  1437|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1438|         0|            0|            0|  0.00%|    :math:`\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))`.\n",
      "  1439|         0|            0|            0|  0.00%|\n",
      "  1440|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CELU` for more details.\n",
      "  1441|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1442|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1443|         0|            0|            0|  0.00%|        return handle_torch_function(celu, (input,), input, alpha=alpha, inplace=inplace)\n",
      "  1444|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1445|         0|            0|            0|  0.00%|        result = torch.celu_(input, alpha)\n",
      "  1446|         0|            0|            0|  0.00%|    else:\n",
      "  1447|         0|            0|            0|  0.00%|        result = torch.celu(input, alpha)\n",
      "  1448|         0|            0|            0|  0.00%|    return result\n",
      "  1449|         0|            0|            0|  0.00%|\n",
      "  1450|         0|            0|            0|  0.00%|\n",
      "  1451|         0|            0|            0|  0.00%|celu_ = _add_docstr(\n",
      "  1452|         0|            0|            0|  0.00%|    torch.celu_,\n",
      "  1453|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1454|         0|            0|            0|  0.00%|celu_(input, alpha=1.) -> Tensor\n",
      "  1455|         0|            0|            0|  0.00%|\n",
      "  1456|         0|            0|            0|  0.00%|In-place version of :func:`~celu`.\n",
      "  1457|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1458|         0|            0|            0|  0.00%|)\n",
      "  1459|         0|            0|            0|  0.00%|\n",
      "  1460|         0|            0|            0|  0.00%|\n",
      "  1461|         0|            0|            0|  0.00%|def leaky_relu(input: Tensor, negative_slope: float = 0.01, inplace: bool = False) -> Tensor:\n",
      "  1462|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1463|         0|            0|            0|  0.00%|    leaky_relu(input, negative_slope=0.01, inplace=False) -> Tensor\n",
      "  1464|         0|            0|            0|  0.00%|\n",
      "  1465|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1466|         0|            0|            0|  0.00%|    :math:`\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)`\n",
      "  1467|         0|            0|            0|  0.00%|\n",
      "  1468|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LeakyReLU` for more details.\n",
      "  1469|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1470|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1471|         0|            0|            0|  0.00%|        return handle_torch_function(leaky_relu, (input,), input, negative_slope=negative_slope, inplace=inplace)\n",
      "  1472|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1473|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu_(input, negative_slope)\n",
      "  1474|         0|            0|            0|  0.00%|    else:\n",
      "  1475|         0|            0|            0|  0.00%|        result = torch._C._nn.leaky_relu(input, negative_slope)\n",
      "  1476|         0|            0|            0|  0.00%|    return result\n",
      "  1477|         0|            0|            0|  0.00%|\n",
      "  1478|         0|            0|            0|  0.00%|\n",
      "  1479|         0|            0|            0|  0.00%|leaky_relu_ = _add_docstr(\n",
      "  1480|         0|            0|            0|  0.00%|    torch._C._nn.leaky_relu_,\n",
      "  1481|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1482|         0|            0|            0|  0.00%|leaky_relu_(input, negative_slope=0.01) -> Tensor\n",
      "  1483|         0|            0|            0|  0.00%|\n",
      "  1484|         0|            0|            0|  0.00%|In-place version of :func:`~leaky_relu`.\n",
      "  1485|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1486|         0|            0|            0|  0.00%|)\n",
      "  1487|         0|            0|            0|  0.00%|\n",
      "  1488|         0|            0|            0|  0.00%|\n",
      "  1489|         0|            0|            0|  0.00%|def prelu(input: Tensor, weight: Tensor) -> Tensor:\n",
      "  1490|         0|            0|            0|  0.00%|    r\"\"\"prelu(input, weight) -> Tensor\n",
      "  1491|         0|            0|            0|  0.00%|\n",
      "  1492|         0|            0|            0|  0.00%|    Applies element-wise the function\n",
      "  1493|         0|            0|            0|  0.00%|    :math:`\\text{PReLU}(x) = \\max(0,x) + \\text{weight} * \\min(0,x)` where weight is a\n",
      "  1494|         0|            0|            0|  0.00%|    learnable parameter.\n",
      "  1495|         0|            0|            0|  0.00%|\n",
      "  1496|         0|            0|            0|  0.00%|    See :class:`~torch.nn.PReLU` for more details.\n",
      "  1497|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1498|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1499|         0|            0|            0|  0.00%|        return handle_torch_function(prelu, (input,), input, weight)\n",
      "  1500|         0|            0|            0|  0.00%|    return torch.prelu(input, weight)\n",
      "  1501|         0|            0|            0|  0.00%|\n",
      "  1502|         0|            0|            0|  0.00%|\n",
      "  1503|         0|            0|            0|  0.00%|def rrelu(\n",
      "  1504|         0|            0|            0|  0.00%|    input: Tensor, lower: float = 1.0 / 8, upper: float = 1.0 / 3, training: bool = False, inplace: bool = False\n",
      "  1505|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  1506|         0|            0|            0|  0.00%|    r\"\"\"rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False) -> Tensor\n",
      "  1507|         0|            0|            0|  0.00%|\n",
      "  1508|         0|            0|            0|  0.00%|    Randomized leaky ReLU.\n",
      "  1509|         0|            0|            0|  0.00%|\n",
      "  1510|         0|            0|            0|  0.00%|    See :class:`~torch.nn.RReLU` for more details.\n",
      "  1511|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1512|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1513|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1514|         0|            0|            0|  0.00%|            rrelu, (input,), input, lower=lower, upper=upper, training=training, inplace=inplace\n",
      "  1515|         0|            0|            0|  0.00%|        )\n",
      "  1516|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1517|         0|            0|            0|  0.00%|        result = torch.rrelu_(input, lower, upper, training)\n",
      "  1518|         0|            0|            0|  0.00%|    else:\n",
      "  1519|         0|            0|            0|  0.00%|        result = torch.rrelu(input, lower, upper, training)\n",
      "  1520|         0|            0|            0|  0.00%|    return result\n",
      "  1521|         0|            0|            0|  0.00%|\n",
      "  1522|         0|            0|            0|  0.00%|\n",
      "  1523|         0|            0|            0|  0.00%|rrelu_ = _add_docstr(\n",
      "  1524|         0|            0|            0|  0.00%|    torch.rrelu_,\n",
      "  1525|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1526|         0|            0|            0|  0.00%|rrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor\n",
      "  1527|         0|            0|            0|  0.00%|\n",
      "  1528|         0|            0|            0|  0.00%|In-place version of :func:`~rrelu`.\n",
      "  1529|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1530|         0|            0|            0|  0.00%|)\n",
      "  1531|         0|            0|            0|  0.00%|\n",
      "  1532|         0|            0|            0|  0.00%|logsigmoid = _add_docstr(\n",
      "  1533|         0|            0|            0|  0.00%|    torch._C._nn.log_sigmoid,\n",
      "  1534|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1535|         0|            0|            0|  0.00%|logsigmoid(input) -> Tensor\n",
      "  1536|         0|            0|            0|  0.00%|\n",
      "  1537|         0|            0|            0|  0.00%|Applies element-wise :math:`\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)`\n",
      "  1538|         0|            0|            0|  0.00%|\n",
      "  1539|         0|            0|            0|  0.00%|See :class:`~torch.nn.LogSigmoid` for more details.\n",
      "  1540|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1541|         0|            0|            0|  0.00%|)\n",
      "  1542|         0|            0|            0|  0.00%|\n",
      "  1543|         0|            0|            0|  0.00%|\n",
      "  1544|         0|            0|            0|  0.00%|def gelu(input):\n",
      "  1545|         0|            0|            0|  0.00%|    r\"\"\"gelu(input) -> Tensor\n",
      "  1546|         0|            0|            0|  0.00%|\n",
      "  1547|         0|            0|            0|  0.00%|    Applies element-wise the function\n",
      "  1548|         0|            0|            0|  0.00%|    :math:`\\text{GELU}(x) = x * \\Phi(x)`\n",
      "  1549|         0|            0|            0|  0.00%|\n",
      "  1550|         0|            0|            0|  0.00%|    where :math:`\\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.\n",
      "  1551|         0|            0|            0|  0.00%|\n",
      "  1552|         0|            0|            0|  0.00%|    See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_.\n",
      "  1553|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1554|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1555|         0|            0|            0|  0.00%|        return handle_torch_function(gelu, (input,), input)\n",
      "  1556|         0|            0|            0|  0.00%|    return torch._C._nn.gelu(input)\n",
      "  1557|         0|            0|            0|  0.00%|\n",
      "  1558|         0|            0|            0|  0.00%|\n",
      "  1559|         0|            0|            0|  0.00%|def hardshrink(input: Tensor, lambd: float = 0.5) -> Tensor:\n",
      "  1560|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1561|         0|            0|            0|  0.00%|    hardshrink(input, lambd=0.5) -> Tensor\n",
      "  1562|         0|            0|            0|  0.00%|\n",
      "  1563|         0|            0|            0|  0.00%|    Applies the hard shrinkage function element-wise\n",
      "  1564|         0|            0|            0|  0.00%|\n",
      "  1565|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardshrink` for more details.\n",
      "  1566|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1567|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1568|         0|            0|            0|  0.00%|        return handle_torch_function(hardshrink, (input,), input, lambd=lambd)\n",
      "  1569|         0|            0|            0|  0.00%|    return torch.hardshrink(input, lambd)\n",
      "  1570|         0|            0|            0|  0.00%|\n",
      "  1571|         0|            0|            0|  0.00%|\n",
      "  1572|         0|            0|            0|  0.00%|def tanhshrink(input):\n",
      "  1573|         0|            0|            0|  0.00%|    r\"\"\"tanhshrink(input) -> Tensor\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|    Applies element-wise, :math:`\\text{Tanhshrink}(x) = x - \\text{Tanh}(x)`\n",
      "  1576|         0|            0|            0|  0.00%|\n",
      "  1577|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanhshrink` for more details.\n",
      "  1578|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1579|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1580|         0|            0|            0|  0.00%|        return handle_torch_function(tanhshrink, (input,), input)\n",
      "  1581|         0|            0|            0|  0.00%|    return input - input.tanh()\n",
      "  1582|         0|            0|            0|  0.00%|\n",
      "  1583|         0|            0|            0|  0.00%|\n",
      "  1584|         0|            0|            0|  0.00%|def softsign(input):\n",
      "  1585|         0|            0|            0|  0.00%|    r\"\"\"softsign(input) -> Tensor\n",
      "  1586|         0|            0|            0|  0.00%|\n",
      "  1587|         0|            0|            0|  0.00%|    Applies element-wise, the function :math:`\\text{SoftSign}(x) = \\frac{x}{1 + |x|}`\n",
      "  1588|         0|            0|            0|  0.00%|\n",
      "  1589|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softsign` for more details.\n",
      "  1590|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1591|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1592|         0|            0|            0|  0.00%|        return handle_torch_function(softsign, (input,), input)\n",
      "  1593|         0|            0|            0|  0.00%|    return input / (input.abs() + 1)\n",
      "  1594|         0|            0|            0|  0.00%|\n",
      "  1595|         0|            0|            0|  0.00%|\n",
      "  1596|         0|            0|            0|  0.00%|softplus = _add_docstr(\n",
      "  1597|         0|            0|            0|  0.00%|    torch._C._nn.softplus,\n",
      "  1598|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1599|         0|            0|            0|  0.00%|softplus(input, beta=1, threshold=20) -> Tensor\n",
      "  1600|         0|            0|            0|  0.00%|\n",
      "  1601|         0|            0|            0|  0.00%|Applies element-wise, the function :math:`\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))`.\n",
      "  1602|         0|            0|            0|  0.00%|\n",
      "  1603|         0|            0|            0|  0.00%|For numerical stability the implementation reverts to the linear function\n",
      "  1604|         0|            0|            0|  0.00%|when :math:`input \\times \\beta > threshold`.\n",
      "  1605|         0|            0|            0|  0.00%|\n",
      "  1606|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softplus` for more details.\n",
      "  1607|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1608|         0|            0|            0|  0.00%|)\n",
      "  1609|         0|            0|            0|  0.00%|\n",
      "  1610|         0|            0|            0|  0.00%|\n",
      "  1611|         0|            0|            0|  0.00%|def _get_softmax_dim(name: str, ndim: int, stacklevel: int) -> int:\n",
      "  1612|         0|            0|            0|  0.00%|    warnings.warn(\n",
      "  1613|         0|            0|            0|  0.00%|        \"Implicit dimension choice for {} has been deprecated. \"\n",
      "  1614|         0|            0|            0|  0.00%|        \"Change the call to include dim=X as an argument.\".format(name),\n",
      "  1615|         0|            0|            0|  0.00%|        stacklevel=stacklevel,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1616|         0|            0|            0|  0.00%|    )\n",
      "  1617|         0|            0|            0|  0.00%|    if ndim == 0 or ndim == 1 or ndim == 3:\n",
      "  1618|         0|            0|            0|  0.00%|        ret = 0\n",
      "  1619|         0|            0|            0|  0.00%|    else:\n",
      "  1620|         0|            0|            0|  0.00%|        ret = 1\n",
      "  1621|         0|            0|            0|  0.00%|    return ret\n",
      "  1622|         0|            0|            0|  0.00%|\n",
      "  1623|         0|            0|            0|  0.00%|\n",
      "  1624|         0|            0|            0|  0.00%|def softmin(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1625|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmin function.\n",
      "  1626|         0|            0|            0|  0.00%|\n",
      "  1627|         0|            0|            0|  0.00%|    Note that :math:`\\text{Softmin}(x) = \\text{Softmax}(-x)`. See softmax definition for mathematical formula.\n",
      "  1628|         0|            0|            0|  0.00%|\n",
      "  1629|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmin` for more details.\n",
      "  1630|         0|            0|            0|  0.00%|\n",
      "  1631|         0|            0|            0|  0.00%|    Args:\n",
      "  1632|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1633|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmin will be computed (so every slice\n",
      "  1634|         0|            0|            0|  0.00%|            along dim will sum to 1).\n",
      "  1635|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1636|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "  1637|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1638|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1639|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1640|         0|            0|            0|  0.00%|        return handle_torch_function(softmin, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1641|         0|            0|            0|  0.00%|    if dim is None:\n",
      "  1642|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"softmin\", input.dim(), _stacklevel)\n",
      "  1643|         0|            0|            0|  0.00%|    if dtype is None:\n",
      "  1644|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim)\n",
      "  1645|         0|            0|            0|  0.00%|    else:\n",
      "  1646|         0|            0|            0|  0.00%|        ret = (-input).softmax(dim, dtype=dtype)\n",
      "  1647|         0|            0|            0|  0.00%|    return ret\n",
      "  1648|         0|            0|            0|  0.00%|\n",
      "  1649|         0|            0|            0|  0.00%|\n",
      "  1650|         8|  3.19481e-05|  3.99351e-06|  0.00%|def softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1651|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmax function.\n",
      "  1652|         0|            0|            0|  0.00%|\n",
      "  1653|         0|            0|            0|  0.00%|    Softmax is defined as:\n",
      "  1654|         0|            0|            0|  0.00%|\n",
      "  1655|         0|            0|            0|  0.00%|    :math:`\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}`\n",
      "  1656|         0|            0|            0|  0.00%|\n",
      "  1657|         0|            0|            0|  0.00%|    It is applied to all slices along dim, and will re-scale them so that the elements\n",
      "  1658|         0|            0|            0|  0.00%|    lie in the range `[0, 1]` and sum to 1.\n",
      "  1659|         0|            0|            0|  0.00%|\n",
      "  1660|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Softmax` for more details.\n",
      "  1661|         0|            0|            0|  0.00%|\n",
      "  1662|         0|            0|            0|  0.00%|    Args:\n",
      "  1663|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1664|         0|            0|            0|  0.00%|        dim (int): A dimension along which softmax will be computed.\n",
      "  1665|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1666|         0|            0|            0|  0.00%|          If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "  1667|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1668|         0|            0|            0|  0.00%|\n",
      "  1669|         0|            0|            0|  0.00%|    .. note::\n",
      "  1670|         0|            0|            0|  0.00%|        This function doesn't work directly with NLLLoss,\n",
      "  1671|         0|            0|            0|  0.00%|        which expects the Log to be computed between the Softmax and itself.\n",
      "  1672|         0|            0|            0|  0.00%|        Use log_softmax instead (it's faster and has better numerical properties).\n",
      "  1673|         0|            0|            0|  0.00%|\n",
      "  1674|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1675|         8|  3.00407e-05|  3.75509e-06|  0.00%|    if has_torch_function_unary(input):\n",
      "  1676|         0|            0|            0|  0.00%|        return handle_torch_function(softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1677|         8|  2.24113e-05|  2.80142e-06|  0.00%|    if dim is None:\n",
      "  1678|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"softmax\", input.dim(), _stacklevel)\n",
      "  1679|         8|  1.90735e-05|  2.38419e-06|  0.00%|    if dtype is None:\n",
      "  1680|         8|  0.000112772|  1.40965e-05|  0.00%|        ret = input.softmax(dim)\n",
      "  1681|         0|            0|            0|  0.00%|    else:\n",
      "  1682|         0|            0|            0|  0.00%|        ret = input.softmax(dim, dtype=dtype)\n",
      "  1683|         8|  2.45571e-05|  3.06964e-06|  0.00%|    return ret\n",
      "  1684|         0|            0|            0|  0.00%|\n",
      "  1685|         0|            0|            0|  0.00%|\n",
      "  1686|         0|            0|            0|  0.00%|def gumbel_softmax(logits: Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> Tensor:\n",
      "  1687|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1688|         0|            0|            0|  0.00%|    Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.\n",
      "  1689|         0|            0|            0|  0.00%|\n",
      "  1690|         0|            0|            0|  0.00%|    Args:\n",
      "  1691|         0|            0|            0|  0.00%|      logits: `[..., num_features]` unnormalized log probabilities\n",
      "  1692|         0|            0|            0|  0.00%|      tau: non-negative scalar temperature\n",
      "  1693|         0|            0|            0|  0.00%|      hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n",
      "  1694|         0|            0|            0|  0.00%|            but will be differentiated as if it is the soft sample in autograd\n",
      "  1695|         0|            0|            0|  0.00%|      dim (int): A dimension along which softmax will be computed. Default: -1.\n",
      "  1696|         0|            0|            0|  0.00%|\n",
      "  1697|         0|            0|            0|  0.00%|    Returns:\n",
      "  1698|         0|            0|            0|  0.00%|      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n",
      "  1699|         0|            0|            0|  0.00%|      If ``hard=True``, the returned samples will be one-hot, otherwise they will\n",
      "  1700|         0|            0|            0|  0.00%|      be probability distributions that sum to 1 across `dim`.\n",
      "  1701|         0|            0|            0|  0.00%|\n",
      "  1702|         0|            0|            0|  0.00%|    .. note::\n",
      "  1703|         0|            0|            0|  0.00%|      This function is here for legacy reasons, may be removed from nn.Functional in the future.\n",
      "  1704|         0|            0|            0|  0.00%|\n",
      "  1705|         0|            0|            0|  0.00%|    .. note::\n",
      "  1706|         0|            0|            0|  0.00%|      The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`\n",
      "  1707|         0|            0|            0|  0.00%|\n",
      "  1708|         0|            0|            0|  0.00%|      It achieves two things:\n",
      "  1709|         0|            0|            0|  0.00%|      - makes the output value exactly one-hot\n",
      "  1710|         0|            0|            0|  0.00%|      (since we add then subtract y_soft value)\n",
      "  1711|         0|            0|            0|  0.00%|      - makes the gradient equal to y_soft gradient\n",
      "  1712|         0|            0|            0|  0.00%|      (since we strip all other gradients)\n",
      "  1713|         0|            0|            0|  0.00%|\n",
      "  1714|         0|            0|            0|  0.00%|    Examples::\n",
      "  1715|         0|            0|            0|  0.00%|        >>> logits = torch.randn(20, 32)\n",
      "  1716|         0|            0|            0|  0.00%|        >>> # Sample soft categorical using reparametrization trick:\n",
      "  1717|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=False)\n",
      "  1718|         0|            0|            0|  0.00%|        >>> # Sample hard categorical using \"Straight-through\" trick:\n",
      "  1719|         0|            0|            0|  0.00%|        >>> F.gumbel_softmax(logits, tau=1, hard=True)\n",
      "  1720|         0|            0|            0|  0.00%|\n",
      "  1721|         0|            0|            0|  0.00%|    .. _Link 1:\n",
      "  1722|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.00712\n",
      "  1723|         0|            0|            0|  0.00%|    .. _Link 2:\n",
      "  1724|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1611.01144\n",
      "  1725|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1726|         0|            0|            0|  0.00%|    if has_torch_function_unary(logits):\n",
      "  1727|         0|            0|            0|  0.00%|        return handle_torch_function(gumbel_softmax, (logits,), logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
      "  1728|         0|            0|            0|  0.00%|    if eps != 1e-10:\n",
      "  1729|         0|            0|            0|  0.00%|        warnings.warn(\"`eps` parameter is deprecated and has no effect.\")\n",
      "  1730|         0|            0|            0|  0.00%|\n",
      "  1731|         0|            0|            0|  0.00%|    gumbels = (\n",
      "  1732|         0|            0|            0|  0.00%|        -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()\n",
      "  1733|         0|            0|            0|  0.00%|    )  # ~Gumbel(0,1)\n",
      "  1734|         0|            0|            0|  0.00%|    gumbels = (logits + gumbels) / tau  # ~Gumbel(logits,tau)\n",
      "  1735|         0|            0|            0|  0.00%|    y_soft = gumbels.softmax(dim)\n",
      "  1736|         0|            0|            0|  0.00%|\n",
      "  1737|         0|            0|            0|  0.00%|    if hard:\n",
      "  1738|         0|            0|            0|  0.00%|        # Straight through.\n",
      "  1739|         0|            0|            0|  0.00%|        index = y_soft.max(dim, keepdim=True)[1]\n",
      "  1740|         0|            0|            0|  0.00%|        y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)\n",
      "  1741|         0|            0|            0|  0.00%|        ret = y_hard - y_soft.detach() + y_soft\n",
      "  1742|         0|            0|            0|  0.00%|    else:\n",
      "  1743|         0|            0|            0|  0.00%|        # Reparametrization trick.\n",
      "  1744|         0|            0|            0|  0.00%|        ret = y_soft\n",
      "  1745|         0|            0|            0|  0.00%|    return ret\n",
      "  1746|         0|            0|            0|  0.00%|\n",
      "  1747|         0|            0|            0|  0.00%|\n",
      "  1748|         0|            0|            0|  0.00%|def log_softmax(input: Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> Tensor:\n",
      "  1749|         0|            0|            0|  0.00%|    r\"\"\"Applies a softmax followed by a logarithm.\n",
      "  1750|         0|            0|            0|  0.00%|\n",
      "  1751|         0|            0|            0|  0.00%|    While mathematically equivalent to log(softmax(x)), doing these two\n",
      "  1752|         0|            0|            0|  0.00%|    operations separately is slower and numerically unstable. This function\n",
      "  1753|         0|            0|            0|  0.00%|    uses an alternative formulation to compute the output and gradient correctly.\n",
      "  1754|         0|            0|            0|  0.00%|\n",
      "  1755|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LogSoftmax` for more details.\n",
      "  1756|         0|            0|            0|  0.00%|\n",
      "  1757|         0|            0|            0|  0.00%|    Args:\n",
      "  1758|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  1759|         0|            0|            0|  0.00%|        dim (int): A dimension along which log_softmax will be computed.\n",
      "  1760|         0|            0|            0|  0.00%|        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "  1761|         0|            0|            0|  0.00%|          If specified, the input tensor is cast to :attr:`dtype` before the operation\n",
      "  1762|         0|            0|            0|  0.00%|          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "  1763|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1764|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1765|         0|            0|            0|  0.00%|        return handle_torch_function(log_softmax, (input,), input, dim=dim, _stacklevel=_stacklevel, dtype=dtype)\n",
      "  1766|         0|            0|            0|  0.00%|    if dim is None:\n",
      "  1767|         0|            0|            0|  0.00%|        dim = _get_softmax_dim(\"log_softmax\", input.dim(), _stacklevel)\n",
      "  1768|         0|            0|            0|  0.00%|    if dtype is None:\n",
      "  1769|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim)\n",
      "  1770|         0|            0|            0|  0.00%|    else:\n",
      "  1771|         0|            0|            0|  0.00%|        ret = input.log_softmax(dim, dtype=dtype)\n",
      "  1772|         0|            0|            0|  0.00%|    return ret\n",
      "  1773|         0|            0|            0|  0.00%|\n",
      "  1774|         0|            0|            0|  0.00%|\n",
      "  1775|         0|            0|            0|  0.00%|softshrink = _add_docstr(\n",
      "  1776|         0|            0|            0|  0.00%|    torch._C._nn.softshrink,\n",
      "  1777|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1778|         0|            0|            0|  0.00%|softshrink(input, lambd=0.5) -> Tensor\n",
      "  1779|         0|            0|            0|  0.00%|\n",
      "  1780|         0|            0|            0|  0.00%|Applies the soft shrinkage function elementwise\n",
      "  1781|         0|            0|            0|  0.00%|\n",
      "  1782|         0|            0|            0|  0.00%|See :class:`~torch.nn.Softshrink` for more details.\n",
      "  1783|         0|            0|            0|  0.00%|\"\"\",\n",
      "  1784|         0|            0|            0|  0.00%|)\n",
      "  1785|         0|            0|            0|  0.00%|\n",
      "  1786|         0|            0|            0|  0.00%|\n",
      "  1787|         0|            0|            0|  0.00%|def tanh(input):\n",
      "  1788|         0|            0|            0|  0.00%|    r\"\"\"tanh(input) -> Tensor\n",
      "  1789|         0|            0|            0|  0.00%|\n",
      "  1790|         0|            0|            0|  0.00%|    Applies element-wise,\n",
      "  1791|         0|            0|            0|  0.00%|    :math:`\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}`\n",
      "  1792|         0|            0|            0|  0.00%|\n",
      "  1793|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Tanh` for more details.\n",
      "  1794|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1795|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "  1796|         0|            0|            0|  0.00%|    return input.tanh()\n",
      "  1797|         0|            0|            0|  0.00%|\n",
      "  1798|         0|            0|            0|  0.00%|\n",
      "  1799|         0|            0|            0|  0.00%|def sigmoid(input):\n",
      "  1800|         0|            0|            0|  0.00%|    r\"\"\"sigmoid(input) -> Tensor\n",
      "  1801|         0|            0|            0|  0.00%|\n",
      "  1802|         0|            0|            0|  0.00%|    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\n",
      "  1803|         0|            0|            0|  0.00%|\n",
      "  1804|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Sigmoid` for more details.\n",
      "  1805|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1806|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "  1807|         0|            0|            0|  0.00%|    return input.sigmoid()\n",
      "  1808|         0|            0|            0|  0.00%|\n",
      "  1809|         0|            0|            0|  0.00%|\n",
      "  1810|         0|            0|            0|  0.00%|def hardsigmoid(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1811|         0|            0|            0|  0.00%|    r\"\"\"Applies the element-wise function\n",
      "  1812|         0|            0|            0|  0.00%|\n",
      "  1813|         0|            0|            0|  0.00%|    .. math::\n",
      "  1814|         0|            0|            0|  0.00%|        \\text{Hardsigmoid}(x) = \\begin{cases}\n",
      "  1815|         0|            0|            0|  0.00%|            0 & \\text{if~} x \\le -3, \\\\\n",
      "  1816|         0|            0|            0|  0.00%|            1 & \\text{if~} x \\ge +3, \\\\\n",
      "  1817|         0|            0|            0|  0.00%|            x / 6 + 1 / 2 & \\text{otherwise}\n",
      "  1818|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1819|         0|            0|            0|  0.00%|\n",
      "  1820|         0|            0|            0|  0.00%|    Args:\n",
      "  1821|         0|            0|            0|  0.00%|        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
      "  1822|         0|            0|            0|  0.00%|\n",
      "  1823|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardsigmoid` for more details.\n",
      "  1824|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1825|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1826|         0|            0|            0|  0.00%|        return handle_torch_function(hardsigmoid, (input,), input, inplace=inplace)\n",
      "  1827|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1828|         0|            0|            0|  0.00%|        return torch._C._nn.hardsigmoid_(input)\n",
      "  1829|         0|            0|            0|  0.00%|    return torch._C._nn.hardsigmoid(input)\n",
      "  1830|         0|            0|            0|  0.00%|\n",
      "  1831|         0|            0|            0|  0.00%|\n",
      "  1832|        16|  3.48091e-05|  2.17557e-06|  0.00%|def linear(input: Tensor, weight: Tensor, bias: Optional[Tensor] = None) -> Tensor:\n",
      "  1833|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1834|         0|            0|            0|  0.00%|    Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
      "  1835|         0|            0|            0|  0.00%|\n",
      "  1836|         0|            0|            0|  0.00%|    This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "  1837|         0|            0|            0|  0.00%|\n",
      "  1838|         0|            0|            0|  0.00%|    Shape:\n",
      "  1839|         0|            0|            0|  0.00%|\n",
      "  1840|         0|            0|            0|  0.00%|        - Input: :math:`(N, *, in\\_features)` N is the batch size, `*` means any number of\n",
      "  1841|         0|            0|            0|  0.00%|          additional dimensions\n",
      "  1842|         0|            0|            0|  0.00%|        - Weight: :math:`(out\\_features, in\\_features)`\n",
      "  1843|         0|            0|            0|  0.00%|        - Bias: :math:`(out\\_features)`\n",
      "  1844|         0|            0|            0|  0.00%|        - Output: :math:`(N, *, out\\_features)`\n",
      "  1845|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1846|        16|  4.07696e-05|   2.5481e-06|  0.00%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  1847|         0|            0|            0|  0.00%|        return handle_torch_function(linear, (input, weight, bias), input, weight, bias=bias)\n",
      "  1848|        16|   0.00180387|  0.000112742|  0.02%|    return torch._C._nn.linear(input, weight, bias)\n",
      "  1849|         0|            0|            0|  0.00%|\n",
      "  1850|         0|            0|            0|  0.00%|\n",
      "  1851|         0|            0|            0|  0.00%|def bilinear(input1: Tensor, input2: Tensor, weight: Tensor, bias: Optional[Tensor] = None) -> Tensor:\n",
      "  1852|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  1853|         0|            0|            0|  0.00%|    Applies a bilinear transformation to the incoming data:\n",
      "  1854|         0|            0|            0|  0.00%|    :math:`y = x_1^T A x_2 + b`\n",
      "  1855|         0|            0|            0|  0.00%|\n",
      "  1856|         0|            0|            0|  0.00%|    Shape:\n",
      "  1857|         0|            0|            0|  0.00%|\n",
      "  1858|         0|            0|            0|  0.00%|        - input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\\text{in1\\_features}`\n",
      "  1859|         0|            0|            0|  0.00%|          and :math:`*` means any number of additional dimensions.\n",
      "  1860|         0|            0|            0|  0.00%|          All but the last dimension of the inputs should be the same.\n",
      "  1861|         0|            0|            0|  0.00%|        - input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\\text{in2\\_features}`\n",
      "  1862|         0|            0|            0|  0.00%|        - weight: :math:`(\\text{out\\_features}, \\text{in1\\_features},\n",
      "  1863|         0|            0|            0|  0.00%|          \\text{in2\\_features})`\n",
      "  1864|         0|            0|            0|  0.00%|        - bias: :math:`(\\text{out\\_features})`\n",
      "  1865|         0|            0|            0|  0.00%|        - output: :math:`(N, *, H_{out})` where :math:`H_{out}=\\text{out\\_features}`\n",
      "  1866|         0|            0|            0|  0.00%|          and all but the last dimension are the same shape as the input.\n",
      "  1867|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1868|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, weight, bias):\n",
      "  1869|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  1870|         0|            0|            0|  0.00%|            bilinear,\n",
      "  1871|         0|            0|            0|  0.00%|            (input1, input2, weight, bias),\n",
      "  1872|         0|            0|            0|  0.00%|            input1, input2, weight,\n",
      "  1873|         0|            0|            0|  0.00%|            bias=bias\n",
      "  1874|         0|            0|            0|  0.00%|        )\n",
      "  1875|         0|            0|            0|  0.00%|    return torch.bilinear(input1, input2, weight, bias)\n",
      "  1876|         0|            0|            0|  0.00%|\n",
      "  1877|         0|            0|            0|  0.00%|\n",
      "  1878|         0|            0|            0|  0.00%|def silu(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1879|         0|            0|            0|  0.00%|    r\"\"\"Applies the Sigmoid Linear Unit (SiLU) function, element-wise.\n",
      "  1880|         0|            0|            0|  0.00%|    The SiLU function is also known as the swish function.\n",
      "  1881|         0|            0|            0|  0.00%|\n",
      "  1882|         0|            0|            0|  0.00%|    .. math::\n",
      "  1883|         0|            0|            0|  0.00%|        \\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\n",
      "  1884|         0|            0|            0|  0.00%|\n",
      "  1885|         0|            0|            0|  0.00%|    .. note::\n",
      "  1886|         0|            0|            0|  0.00%|        See `Gaussian Error Linear Units (GELUs) <https://arxiv.org/abs/1606.08415>`_\n",
      "  1887|         0|            0|            0|  0.00%|        where the SiLU (Sigmoid Linear Unit) was originally coined, and see\n",
      "  1888|         0|            0|            0|  0.00%|        `Sigmoid-Weighted Linear Units for Neural Network Function Approximation\n",
      "  1889|         0|            0|            0|  0.00%|        in Reinforcement Learning <https://arxiv.org/abs/1702.03118>`_ and `Swish:\n",
      "  1890|         0|            0|            0|  0.00%|        a Self-Gated Activation Function <https://arxiv.org/abs/1710.05941v1>`_\n",
      "  1891|         0|            0|            0|  0.00%|        where the SiLU was experimented with later.\n",
      "  1892|         0|            0|            0|  0.00%|\n",
      "  1893|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SiLU` for more details.\n",
      "  1894|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1895|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1896|         0|            0|            0|  0.00%|        return handle_torch_function(silu, (input,), input, inplace=inplace)\n",
      "  1897|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1898|         0|            0|            0|  0.00%|        return torch._C._nn.silu_(input)\n",
      "  1899|         0|            0|            0|  0.00%|    return torch._C._nn.silu(input)\n",
      "  1900|         0|            0|            0|  0.00%|\n",
      "  1901|         0|            0|            0|  0.00%|\n",
      "  1902|         0|            0|            0|  0.00%|def mish(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1903|         0|            0|            0|  0.00%|    r\"\"\"Applies the Mish function, element-wise.\n",
      "  1904|         0|            0|            0|  0.00%|    Mish: A Self Regularized Non-Monotonic Neural Activation Function.\n",
      "  1905|         0|            0|            0|  0.00%|\n",
      "  1906|         0|            0|            0|  0.00%|    .. math::\n",
      "  1907|         0|            0|            0|  0.00%|        \\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\n",
      "  1908|         0|            0|            0|  0.00%|\n",
      "  1909|         0|            0|            0|  0.00%|    .. note::\n",
      "  1910|         0|            0|            0|  0.00%|        See `Mish: A Self Regularized Non-Monotonic Neural Activation Function <https://arxiv.org/abs/1908.08681>`_\n",
      "  1911|         0|            0|            0|  0.00%|\n",
      "  1912|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Mish` for more details.\n",
      "  1913|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1914|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1915|         0|            0|            0|  0.00%|        return handle_torch_function(mish, (input,), input, inplace=inplace)\n",
      "  1916|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1917|         0|            0|            0|  0.00%|        return torch._C._nn.mish_(input)\n",
      "  1918|         0|            0|            0|  0.00%|    return torch._C._nn.mish(input)\n",
      "  1919|         0|            0|            0|  0.00%|\n",
      "  1920|         0|            0|            0|  0.00%|\n",
      "  1921|         0|            0|            0|  0.00%|def hardswish(input: Tensor, inplace: bool = False) -> Tensor:\n",
      "  1922|         0|            0|            0|  0.00%|    r\"\"\"Applies the hardswish function, element-wise, as described in the paper:\n",
      "  1923|         0|            0|            0|  0.00%|\n",
      "  1924|         0|            0|            0|  0.00%|    `Searching for MobileNetV3`_.\n",
      "  1925|         0|            0|            0|  0.00%|\n",
      "  1926|         0|            0|            0|  0.00%|    .. math::\n",
      "  1927|         0|            0|            0|  0.00%|        \\text{Hardswish}(x) = \\begin{cases}\n",
      "  1928|         0|            0|            0|  0.00%|            0 & \\text{if~} x \\le -3, \\\\\n",
      "  1929|         0|            0|            0|  0.00%|            x & \\text{if~} x \\ge +3, \\\\\n",
      "  1930|         0|            0|            0|  0.00%|            x \\cdot (x + 3) /6 & \\text{otherwise}\n",
      "  1931|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1932|         0|            0|            0|  0.00%|\n",
      "  1933|         0|            0|            0|  0.00%|    See :class:`~torch.nn.Hardswish` for more details.\n",
      "  1934|         0|            0|            0|  0.00%|\n",
      "  1935|         0|            0|            0|  0.00%|    .. _`Searching for MobileNetV3`:\n",
      "  1936|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1905.02244\n",
      "  1937|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1938|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  1939|         0|            0|            0|  0.00%|        return handle_torch_function(hardswish, (input,), input, inplace=inplace)\n",
      "  1940|         0|            0|            0|  0.00%|    if inplace:\n",
      "  1941|         0|            0|            0|  0.00%|        return torch._C._nn.hardswish_(input)\n",
      "  1942|         0|            0|            0|  0.00%|    return torch._C._nn.hardswish(input)\n",
      "  1943|         0|            0|            0|  0.00%|\n",
      "  1944|         0|            0|            0|  0.00%|\n",
      "  1945|         0|            0|            0|  0.00%|def _no_grad_embedding_renorm_(weight: Tensor, input: Tensor, max_norm: float, norm_type: float) -> Tensor:\n",
      "  1946|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "  1947|         0|            0|            0|  0.00%|        torch.embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  1948|         0|            0|            0|  0.00%|\n",
      "  1949|         0|            0|            0|  0.00%|\n",
      "  1950|         9|   3.3617e-05|  3.73522e-06|  0.00%|def embedding(\n",
      "  1951|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  1952|         0|            0|            0|  0.00%|    weight: Tensor,\n",
      "  1953|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,\n",
      "  1954|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,\n",
      "  1955|         0|            0|            0|  0.00%|    norm_type: float = 2.0,\n",
      "  1956|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,\n",
      "  1957|         0|            0|            0|  0.00%|    sparse: bool = False,\n",
      "  1958|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  1959|         0|            0|            0|  0.00%|    r\"\"\"A simple lookup table that looks up embeddings in a fixed dictionary and size.\n",
      "  1960|         0|            0|            0|  0.00%|\n",
      "  1961|         0|            0|            0|  0.00%|    This module is often used to retrieve word embeddings using indices.\n",
      "  1962|         0|            0|            0|  0.00%|    The input to the module is a list of indices, and the embedding matrix,\n",
      "  1963|         0|            0|            0|  0.00%|    and the output is the corresponding word embeddings.\n",
      "  1964|         0|            0|            0|  0.00%|\n",
      "  1965|         0|            0|            0|  0.00%|    See :class:`torch.nn.Embedding` for more details.\n",
      "  1966|         0|            0|            0|  0.00%|\n",
      "  1967|         0|            0|            0|  0.00%|    Args:\n",
      "  1968|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing indices into the embedding matrix\n",
      "  1969|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,\n",
      "  1970|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size\n",
      "  1971|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "  1972|         0|            0|            0|  0.00%|                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "  1973|         0|            0|            0|  0.00%|                                     i.e. it remains as a fixed \"pad\".\n",
      "  1974|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "  1975|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "  1976|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.\n",
      "  1977|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "  1978|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      "  1979|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "  1980|         0|            0|            0|  0.00%|        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under\n",
      "  1981|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.\n",
      "  1982|         0|            0|            0|  0.00%|\n",
      "  1983|         0|            0|            0|  0.00%|    Shape:\n",
      "  1984|         0|            0|            0|  0.00%|        - Input: LongTensor of arbitrary shape containing the indices to extract\n",
      "  1985|         0|            0|            0|  0.00%|        - Weight: Embedding matrix of floating point type with shape `(V, embedding_dim)`,\n",
      "  1986|         0|            0|            0|  0.00%|          where V = maximum index + 1 and embedding_dim = the embedding size\n",
      "  1987|         0|            0|            0|  0.00%|        - Output: `(*, embedding_dim)`, where `*` is the input shape\n",
      "  1988|         0|            0|            0|  0.00%|\n",
      "  1989|         0|            0|            0|  0.00%|    Examples::\n",
      "  1990|         0|            0|            0|  0.00%|\n",
      "  1991|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "  1992|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[1,2,4,5],[4,3,2,9]])\n",
      "  1993|         0|            0|            0|  0.00%|        >>> # an embedding matrix containing 10 tensors of size 3\n",
      "  1994|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  1995|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix)\n",
      "  1996|         0|            0|            0|  0.00%|        tensor([[[ 0.8490,  0.9625,  0.6753],\n",
      "  1997|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],\n",
      "  1998|         0|            0|            0|  0.00%|                 [ 0.6246,  0.9751,  0.3618],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1999|         0|            0|            0|  0.00%|                 [ 0.4161,  0.2419,  0.7383]],\n",
      "  2000|         0|            0|            0|  0.00%|\n",
      "  2001|         0|            0|            0|  0.00%|                [[ 0.6246,  0.9751,  0.3618],\n",
      "  2002|         0|            0|            0|  0.00%|                 [ 0.0237,  0.7794,  0.0528],\n",
      "  2003|         0|            0|            0|  0.00%|                 [ 0.9666,  0.7761,  0.6108],\n",
      "  2004|         0|            0|            0|  0.00%|                 [ 0.3385,  0.8612,  0.1867]]])\n",
      "  2005|         0|            0|            0|  0.00%|\n",
      "  2006|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "  2007|         0|            0|            0|  0.00%|        >>> weights = torch.rand(10, 3)\n",
      "  2008|         0|            0|            0|  0.00%|        >>> weights[0, :].zero_()\n",
      "  2009|         0|            0|            0|  0.00%|        >>> embedding_matrix = weights\n",
      "  2010|         0|            0|            0|  0.00%|        >>> input = torch.tensor([[0,2,0,5]])\n",
      "  2011|         0|            0|            0|  0.00%|        >>> F.embedding(input, embedding_matrix, padding_idx=0)\n",
      "  2012|         0|            0|            0|  0.00%|        tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "  2013|         0|            0|            0|  0.00%|                 [ 0.5609,  0.5384,  0.8720],\n",
      "  2014|         0|            0|            0|  0.00%|                 [ 0.0000,  0.0000,  0.0000],\n",
      "  2015|         0|            0|            0|  0.00%|                 [ 0.6262,  0.2438,  0.7471]]])\n",
      "  2016|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2017|         0|            0|            0|  0.00%|\n",
      "  2018|         9|  3.02792e-05|  3.36435e-06|  0.00%|    if has_torch_function_variadic(input, weight):\n",
      "  2019|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2020|         0|            0|            0|  0.00%|            embedding, (input, weight),\n",
      "  2021|         0|            0|            0|  0.00%|            input, weight, padding_idx, max_norm, norm_type,\n",
      "  2022|         0|            0|            0|  0.00%|            scale_grad_by_freq, sparse\n",
      "  2023|         0|            0|            0|  0.00%|        )\n",
      "  2024|         9|  2.69413e-05|  2.99348e-06|  0.00%|    if padding_idx is not None:\n",
      "  2025|         0|            0|            0|  0.00%|        if padding_idx > 0:\n",
      "  2026|         0|            0|            0|  0.00%|            assert padding_idx < weight.size(0), \"Padding_idx must be within num_embeddings\"\n",
      "  2027|         0|            0|            0|  0.00%|        elif padding_idx < 0:\n",
      "  2028|         0|            0|            0|  0.00%|            assert padding_idx >= -weight.size(0), \"Padding_idx must be within num_embeddings\"\n",
      "  2029|         0|            0|            0|  0.00%|            padding_idx = weight.size(0) + padding_idx\n",
      "  2030|         0|            0|            0|  0.00%|    else:\n",
      "  2031|         9|  1.95503e-05|  2.17226e-06|  0.00%|        padding_idx = -1\n",
      "  2032|         9|  2.43187e-05|  2.70208e-06|  0.00%|    if max_norm is not None:\n",
      "  2033|         0|            0|            0|  0.00%|        # Note [embedding_renorm contiguous]\n",
      "  2034|         0|            0|            0|  0.00%|        # `embedding_renorm_` will call .contiguous() on input anyways, so we\n",
      "  2035|         0|            0|            0|  0.00%|        # call it here and take advantage of the improved locality in the\n",
      "  2036|         0|            0|            0|  0.00%|        # `embedding` call below too.\n",
      "  2037|         0|            0|            0|  0.00%|        input = input.contiguous()\n",
      "  2038|         0|            0|            0|  0.00%|        # Note [embedding_renorm set_grad_enabled]\n",
      "  2039|         0|            0|            0|  0.00%|        # XXX: equivalent to\n",
      "  2040|         0|            0|            0|  0.00%|        # with torch.no_grad():\n",
      "  2041|         0|            0|            0|  0.00%|        #   torch.embedding_renorm_\n",
      "  2042|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled\n",
      "  2043|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  2044|         9|   0.00079608|  8.84533e-05|  0.01%|    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "  2045|         0|            0|            0|  0.00%|\n",
      "  2046|         0|            0|            0|  0.00%|\n",
      "  2047|         0|            0|            0|  0.00%|def embedding_bag(\n",
      "  2048|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2049|         0|            0|            0|  0.00%|    weight: Tensor,\n",
      "  2050|         0|            0|            0|  0.00%|    offsets: Optional[Tensor] = None,\n",
      "  2051|         0|            0|            0|  0.00%|    max_norm: Optional[float] = None,\n",
      "  2052|         0|            0|            0|  0.00%|    norm_type: float = 2,\n",
      "  2053|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool = False,\n",
      "  2054|         0|            0|            0|  0.00%|    mode: str = \"mean\",\n",
      "  2055|         0|            0|            0|  0.00%|    sparse: bool = False,\n",
      "  2056|         0|            0|            0|  0.00%|    per_sample_weights: Optional[Tensor] = None,\n",
      "  2057|         0|            0|            0|  0.00%|    include_last_offset: bool = False,\n",
      "  2058|         0|            0|            0|  0.00%|    padding_idx: Optional[int] = None,\n",
      "  2059|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2060|         0|            0|            0|  0.00%|    r\"\"\"Computes sums, means or maxes of `bags` of embeddings, without instantiating the\n",
      "  2061|         0|            0|            0|  0.00%|    intermediate embeddings.\n",
      "  2062|         0|            0|            0|  0.00%|\n",
      "  2063|         0|            0|            0|  0.00%|    See :class:`torch.nn.EmbeddingBag` for more details.\n",
      "  2064|         0|            0|            0|  0.00%|\n",
      "  2065|         0|            0|            0|  0.00%|    Note:\n",
      "  2066|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  2067|         0|            0|            0|  0.00%|\n",
      "  2068|         0|            0|            0|  0.00%|    Args:\n",
      "  2069|         0|            0|            0|  0.00%|        input (LongTensor): Tensor containing bags of indices into the embedding matrix\n",
      "  2070|         0|            0|            0|  0.00%|        weight (Tensor): The embedding matrix with number of rows equal to the maximum possible index + 1,\n",
      "  2071|         0|            0|            0|  0.00%|            and number of columns equal to the embedding size\n",
      "  2072|         0|            0|            0|  0.00%|        offsets (LongTensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines\n",
      "  2073|         0|            0|            0|  0.00%|                             the starting index position of each bag (sequence) in :attr:`input`.\n",
      "  2074|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "  2075|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "  2076|         0|            0|            0|  0.00%|                                    Note: this will modify :attr:`weight` in-place.\n",
      "  2077|         0|            0|            0|  0.00%|        norm_type (float, optional): The ``p`` in the ``p``-norm to compute for the :attr:`max_norm` option.\n",
      "  2078|         0|            0|            0|  0.00%|                                     Default ``2``.\n",
      "  2079|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
      "  2080|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "  2081|         0|            0|            0|  0.00%|                                                Note: this option is not supported when ``mode=\"max\"``.\n",
      "  2082|         0|            0|            0|  0.00%|        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
      "  2083|         0|            0|            0|  0.00%|                                 Default: ``\"mean\"``\n",
      "  2084|         0|            0|            0|  0.00%|        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` will be a sparse tensor. See Notes under\n",
      "  2085|         0|            0|            0|  0.00%|                                 :class:`torch.nn.Embedding` for more details regarding sparse gradients.\n",
      "  2086|         0|            0|            0|  0.00%|                                 Note: this option is not supported when ``mode=\"max\"``.\n",
      "  2087|         0|            0|            0|  0.00%|        per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
      "  2088|         0|            0|            0|  0.00%|            to indicate all weights should be taken to be 1. If specified, :attr:`per_sample_weights`\n",
      "  2089|         0|            0|            0|  0.00%|            must have exactly the same shape as input and is treated as having the same\n",
      "  2090|         0|            0|            0|  0.00%|            :attr:`offsets`, if those are not None.\n",
      "  2091|         0|            0|            0|  0.00%|\n",
      "  2092|         0|            0|            0|  0.00%|        include_last_offset (bool, optional): if ``True``, the size of offsets is equal to the number of bags + 1.\n",
      "  2093|         0|            0|            0|  0.00%|            The last element is the size of the input, or the ending index position of the last bag (sequence).\n",
      "  2094|         0|            0|            0|  0.00%|\n",
      "  2095|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the\n",
      "  2096|         0|            0|            0|  0.00%|                                     gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated\n",
      "  2097|         0|            0|            0|  0.00%|                                     during training, i.e. it remains as a fixed \"pad\". Note that the embedding\n",
      "  2098|         0|            0|            0|  0.00%|                                     vector at :attr:`padding_idx` is excluded from the reduction.\n",
      "  2099|         0|            0|            0|  0.00%|\n",
      "  2100|         0|            0|            0|  0.00%|    Shape:\n",
      "  2101|         0|            0|            0|  0.00%|        - :attr:`input` (LongTensor) and :attr:`offsets` (LongTensor, optional)\n",
      "  2102|         0|            0|            0|  0.00%|\n",
      "  2103|         0|            0|            0|  0.00%|          - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)\n",
      "  2104|         0|            0|            0|  0.00%|            each of fixed length ``N``, and this will return ``B`` values aggregated in a way\n",
      "  2105|         0|            0|            0|  0.00%|            depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
      "  2106|         0|            0|            0|  0.00%|\n",
      "  2107|         0|            0|            0|  0.00%|          - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of\n",
      "  2108|         0|            0|            0|  0.00%|            multiple bags (sequences). :attr:`offsets` is required to be a 1D tensor containing\n",
      "  2109|         0|            0|            0|  0.00%|            the starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets`\n",
      "  2110|         0|            0|            0|  0.00%|            of shape `(B)`, :attr:`input` will be viewed as having ``B`` bags.\n",
      "  2111|         0|            0|            0|  0.00%|            Empty bags (i.e., having 0-length) will have returned vectors filled by zeros.\n",
      "  2112|         0|            0|            0|  0.00%|\n",
      "  2113|         0|            0|            0|  0.00%|        - :attr:`weight` (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`\n",
      "  2114|         0|            0|            0|  0.00%|\n",
      "  2115|         0|            0|            0|  0.00%|        - :attr:`per_sample_weights` (Tensor, optional). Has the same shape as :attr:`input`.\n",
      "  2116|         0|            0|            0|  0.00%|\n",
      "  2117|         0|            0|            0|  0.00%|        - :attr:`output`: aggregated embedding values of shape `(B, embedding_dim)`\n",
      "  2118|         0|            0|            0|  0.00%|\n",
      "  2119|         0|            0|            0|  0.00%|    Examples::\n",
      "  2120|         0|            0|            0|  0.00%|\n",
      "  2121|         0|            0|            0|  0.00%|        >>> # an Embedding module containing 10 tensors of size 3\n",
      "  2122|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  2123|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "  2124|         0|            0|            0|  0.00%|        >>> input = torch.tensor([1,2,4,5,4,3,2,9])\n",
      "  2125|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])\n",
      "  2126|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets)\n",
      "  2127|         0|            0|            0|  0.00%|        tensor([[ 0.3397,  0.3552,  0.5545],\n",
      "  2128|         0|            0|            0|  0.00%|                [ 0.5893,  0.4386,  0.5882]])\n",
      "  2129|         0|            0|            0|  0.00%|\n",
      "  2130|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "  2131|         0|            0|            0|  0.00%|        >>> embedding_matrix = torch.rand(10, 3)\n",
      "  2132|         0|            0|            0|  0.00%|        >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9])\n",
      "  2133|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4])\n",
      "  2134|         0|            0|            0|  0.00%|        >>> F.embedding_bag(input, embedding_matrix, offsets, padding_idx=2, mode='sum')\n",
      "  2135|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "  2136|         0|            0|            0|  0.00%|                [-0.7082,  3.2145, -2.6251]])\n",
      "  2137|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2138|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, offsets, per_sample_weights):\n",
      "  2139|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2140|         0|            0|            0|  0.00%|            embedding_bag,\n",
      "  2141|         0|            0|            0|  0.00%|            (input, weight, offsets, per_sample_weights),\n",
      "  2142|         0|            0|            0|  0.00%|            input,\n",
      "  2143|         0|            0|            0|  0.00%|            weight,\n",
      "  2144|         0|            0|            0|  0.00%|            offsets=offsets,\n",
      "  2145|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "  2146|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "  2147|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "  2148|         0|            0|            0|  0.00%|            mode=mode,\n",
      "  2149|         0|            0|            0|  0.00%|            sparse=sparse,\n",
      "  2150|         0|            0|            0|  0.00%|            per_sample_weights=per_sample_weights,\n",
      "  2151|         0|            0|            0|  0.00%|            include_last_offset=include_last_offset,\n",
      "  2152|         0|            0|            0|  0.00%|            padding_idx=padding_idx,\n",
      "  2153|         0|            0|            0|  0.00%|        )\n",
      "  2154|         0|            0|            0|  0.00%|    # Check for backward compatibility.\n",
      "  2155|         0|            0|            0|  0.00%|    # Used to be embedding_bag(weight, input, ...)\n",
      "  2156|         0|            0|            0|  0.00%|    # Now is     embedding_bag(input, weight, ...)\n",
      "  2157|         0|            0|            0|  0.00%|    if weight.dtype == torch.long and input.is_floating_point():\n",
      "  2158|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  2159|         0|            0|            0|  0.00%|            \"Argument order of nn.functional.embedding_bag was changed. \"\n",
      "  2160|         0|            0|            0|  0.00%|            \"Usage `embedding_bag(weight, input, ...)` is deprecated, \"\n",
      "  2161|         0|            0|            0|  0.00%|            \"and should now be `embedding_bag(input, weight, ...)`.\"\n",
      "  2162|         0|            0|            0|  0.00%|        )\n",
      "  2163|         0|            0|            0|  0.00%|        weight, input = input, weight\n",
      "  2164|         0|            0|            0|  0.00%|\n",
      "  2165|         0|            0|            0|  0.00%|    if per_sample_weights is not None and input.size() != per_sample_weights.size():\n",
      "  2166|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2167|         0|            0|            0|  0.00%|            \"embedding_bag: If per_sample_weights ({}) is not None, \"\n",
      "  2168|         0|            0|            0|  0.00%|            \"then it must have the same shape as the input ({})\".format(per_sample_weights.shape, input.shape)\n",
      "  2169|         0|            0|            0|  0.00%|        )\n",
      "  2170|         0|            0|            0|  0.00%|\n",
      "  2171|         0|            0|            0|  0.00%|    if input.dim() == 2:\n",
      "  2172|         0|            0|            0|  0.00%|        if offsets is not None:\n",
      "  2173|         0|            0|            0|  0.00%|            type_str = \"<unknown>\"\n",
      "  2174|         0|            0|            0|  0.00%|            # TODO: Remove this once script supports type() calls\n",
      "  2175|         0|            0|            0|  0.00%|            if not torch.jit.is_scripting():\n",
      "  2176|         0|            0|            0|  0.00%|                type_str = str(type(offsets))\n",
      "  2177|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  2178|         0|            0|            0|  0.00%|                \"if input is 2D, then offsets has to be None\"\n",
      "  2179|         0|            0|            0|  0.00%|                \", as input is treated is a mini-batch of\"\n",
      "  2180|         0|            0|            0|  0.00%|                \" fixed length sequences. However, found \"\n",
      "  2181|         0|            0|            0|  0.00%|                \"offsets of type {}\".format(type_str)\n",
      "  2182|         0|            0|            0|  0.00%|            )\n",
      "  2183|         0|            0|            0|  0.00%|        offsets = torch.arange(0, input.numel(), input.size(1), dtype=input.dtype, device=input.device)\n",
      "  2184|         0|            0|            0|  0.00%|\n",
      "  2185|         0|            0|            0|  0.00%|        input = input.reshape(-1)\n",
      "  2186|         0|            0|            0|  0.00%|        if per_sample_weights is not None:\n",
      "  2187|         0|            0|            0|  0.00%|            per_sample_weights = per_sample_weights.reshape(-1)\n",
      "  2188|         0|            0|            0|  0.00%|    elif input.dim() == 1:\n",
      "  2189|         0|            0|            0|  0.00%|        if offsets is None:\n",
      "  2190|         0|            0|            0|  0.00%|            raise ValueError(\"offsets has to be a 1D Tensor but got None\")\n",
      "  2191|         0|            0|            0|  0.00%|        if offsets.dim() != 1:\n",
      "  2192|         0|            0|            0|  0.00%|            raise ValueError(\"offsets has to be a 1D Tensor\")\n",
      "  2193|         0|            0|            0|  0.00%|    else:\n",
      "  2194|         0|            0|            0|  0.00%|        raise ValueError(\"input has to be 1D or 2D Tensor,\" \" but got Tensor of dimension {}\".format(input.dim()))\n",
      "  2195|         0|            0|            0|  0.00%|    if mode == \"sum\":\n",
      "  2196|         0|            0|            0|  0.00%|        mode_enum = 0\n",
      "  2197|         0|            0|            0|  0.00%|    elif mode == \"mean\":\n",
      "  2198|         0|            0|            0|  0.00%|        mode_enum = 1\n",
      "  2199|         0|            0|            0|  0.00%|    elif mode == \"max\":\n",
      "  2200|         0|            0|            0|  0.00%|        mode_enum = 2\n",
      "  2201|         0|            0|            0|  0.00%|\n",
      "  2202|         0|            0|            0|  0.00%|        if scale_grad_by_freq:\n",
      "  2203|         0|            0|            0|  0.00%|            raise ValueError(\"max mode does not support scaling the gradient by the frequency\")\n",
      "  2204|         0|            0|            0|  0.00%|\n",
      "  2205|         0|            0|            0|  0.00%|        if sparse:\n",
      "  2206|         0|            0|            0|  0.00%|            raise ValueError(\"max mode does not support sparse weights\")\n",
      "  2207|         0|            0|            0|  0.00%|\n",
      "  2208|         0|            0|            0|  0.00%|    else:\n",
      "  2209|         0|            0|            0|  0.00%|        raise ValueError(\"mode has to be one of sum, mean or max\")\n",
      "  2210|         0|            0|            0|  0.00%|\n",
      "  2211|         0|            0|            0|  0.00%|    if max_norm is not None:\n",
      "  2212|         0|            0|            0|  0.00%|        # XXX: equivalent to\n",
      "  2213|         0|            0|            0|  0.00%|        # with torch.no_grad():\n",
      "  2214|         0|            0|            0|  0.00%|        #   torch.nembedding_renorm_\n",
      "  2215|         0|            0|            0|  0.00%|        # remove once script supports set_grad_enabled\n",
      "  2216|         0|            0|            0|  0.00%|        _no_grad_embedding_renorm_(weight, input, max_norm, norm_type)\n",
      "  2217|         0|            0|            0|  0.00%|\n",
      "  2218|         0|            0|            0|  0.00%|    if per_sample_weights is not None and mode != \"sum\":\n",
      "  2219|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  2220|         0|            0|            0|  0.00%|            \"embedding_bag: per_sample_weights was not None. \"\n",
      "  2221|         0|            0|            0|  0.00%|            \"per_sample_weights is only supported for mode='sum' \"\n",
      "  2222|         0|            0|            0|  0.00%|            \"(got mode='{}'). Please open a feature request on GitHub.\".format(mode)\n",
      "  2223|         0|            0|            0|  0.00%|        )\n",
      "  2224|         0|            0|            0|  0.00%|\n",
      "  2225|         0|            0|            0|  0.00%|    ret, _, _, _ = torch.embedding_bag(\n",
      "  2226|         0|            0|            0|  0.00%|        weight, input, offsets, scale_grad_by_freq, mode_enum, sparse, per_sample_weights, include_last_offset, padding_idx\n",
      "  2227|         0|            0|            0|  0.00%|    )\n",
      "  2228|         0|            0|            0|  0.00%|    return ret\n",
      "  2229|         0|            0|            0|  0.00%|\n",
      "  2230|         0|            0|            0|  0.00%|\n",
      "  2231|         0|            0|            0|  0.00%|embedding_bag.__doc__ = embedding_bag.__doc__.format(**reproducibility_notes)\n",
      "  2232|         0|            0|            0|  0.00%|\n",
      "  2233|         0|            0|            0|  0.00%|\n",
      "  2234|         0|            0|            0|  0.00%|def _verify_batch_size(size: List[int]) -> None:\n",
      "  2235|         0|            0|            0|  0.00%|    # XXX: JIT script does not support the reduce from functools, and mul op is a\n",
      "  2236|         0|            0|            0|  0.00%|    # builtin, which cannot be used as a value to a func yet, so rewrite this size\n",
      "  2237|         0|            0|            0|  0.00%|    # check to a simple equivalent for loop\n",
      "  2238|         0|            0|            0|  0.00%|    #\n",
      "  2239|         0|            0|            0|  0.00%|    # TODO: make use of reduce like below when JIT is ready with the missing features:\n",
      "  2240|         0|            0|            0|  0.00%|    # from operator import mul\n",
      "  2241|         0|            0|            0|  0.00%|    # from functools import reduce\n",
      "  2242|         0|            0|            0|  0.00%|    #\n",
      "  2243|         0|            0|            0|  0.00%|    #   if reduce(mul, size[2:], size[0]) == 1\n",
      "  2244|         0|            0|            0|  0.00%|    size_prods = size[0]\n",
      "  2245|         0|            0|            0|  0.00%|    for i in range(len(size) - 2):\n",
      "  2246|         0|            0|            0|  0.00%|        size_prods *= size[i + 2]\n",
      "  2247|         0|            0|            0|  0.00%|    if size_prods == 1:\n",
      "  2248|         0|            0|            0|  0.00%|        raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n",
      "  2249|         0|            0|            0|  0.00%|\n",
      "  2250|         0|            0|            0|  0.00%|\n",
      "  2251|         0|            0|            0|  0.00%|def batch_norm(\n",
      "  2252|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2253|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor],\n",
      "  2254|         0|            0|            0|  0.00%|    running_var: Optional[Tensor],\n",
      "  2255|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2256|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2257|         0|            0|            0|  0.00%|    training: bool = False,\n",
      "  2258|         0|            0|            0|  0.00%|    momentum: float = 0.1,\n",
      "  2259|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2260|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2261|         0|            0|            0|  0.00%|    r\"\"\"Applies Batch Normalization for each channel across a batch of data.\n",
      "  2262|         0|            0|            0|  0.00%|\n",
      "  2263|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BatchNorm1d`, :class:`~torch.nn.BatchNorm2d`,\n",
      "  2264|         0|            0|            0|  0.00%|    :class:`~torch.nn.BatchNorm3d` for details.\n",
      "  2265|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2266|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n",
      "  2267|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2268|         0|            0|            0|  0.00%|            batch_norm,\n",
      "  2269|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),\n",
      "  2270|         0|            0|            0|  0.00%|            input,\n",
      "  2271|         0|            0|            0|  0.00%|            running_mean,\n",
      "  2272|         0|            0|            0|  0.00%|            running_var,\n",
      "  2273|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2274|         0|            0|            0|  0.00%|            bias=bias,\n",
      "  2275|         0|            0|            0|  0.00%|            training=training,\n",
      "  2276|         0|            0|            0|  0.00%|            momentum=momentum,\n",
      "  2277|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2278|         0|            0|            0|  0.00%|        )\n",
      "  2279|         0|            0|            0|  0.00%|    if training:\n",
      "  2280|         0|            0|            0|  0.00%|        _verify_batch_size(input.size())\n",
      "  2281|         0|            0|            0|  0.00%|\n",
      "  2282|         0|            0|            0|  0.00%|    return torch.batch_norm(\n",
      "  2283|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled\n",
      "  2284|         0|            0|            0|  0.00%|    )\n",
      "  2285|         0|            0|            0|  0.00%|\n",
      "  2286|         0|            0|            0|  0.00%|\n",
      "  2287|         0|            0|            0|  0.00%|def _verify_spatial_size(size: List[int]) -> None:\n",
      "  2288|         0|            0|            0|  0.00%|    # Verify that there is > 1 spatial element for instance norm calculation.\n",
      "  2289|         0|            0|            0|  0.00%|    size_prods = 1\n",
      "  2290|         0|            0|            0|  0.00%|    for i in range(2, len(size)):\n",
      "  2291|         0|            0|            0|  0.00%|        size_prods *= size[i]\n",
      "  2292|         0|            0|            0|  0.00%|    if size_prods == 1:\n",
      "  2293|         0|            0|            0|  0.00%|        raise ValueError(\"Expected more than 1 spatial element when training, got input size {}\".format(size))\n",
      "  2294|         0|            0|            0|  0.00%|\n",
      "  2295|         0|            0|            0|  0.00%|\n",
      "  2296|         0|            0|            0|  0.00%|def instance_norm(\n",
      "  2297|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2298|         0|            0|            0|  0.00%|    running_mean: Optional[Tensor] = None,\n",
      "  2299|         0|            0|            0|  0.00%|    running_var: Optional[Tensor] = None,\n",
      "  2300|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2301|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2302|         0|            0|            0|  0.00%|    use_input_stats: bool = True,\n",
      "  2303|         0|            0|            0|  0.00%|    momentum: float = 0.1,\n",
      "  2304|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2305|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2306|         0|            0|            0|  0.00%|    r\"\"\"Applies Instance Normalization for each channel in each data sample in a\n",
      "  2307|         0|            0|            0|  0.00%|    batch.\n",
      "  2308|         0|            0|            0|  0.00%|\n",
      "  2309|         0|            0|            0|  0.00%|    See :class:`~torch.nn.InstanceNorm1d`, :class:`~torch.nn.InstanceNorm2d`,\n",
      "  2310|         0|            0|            0|  0.00%|    :class:`~torch.nn.InstanceNorm3d` for details.\n",
      "  2311|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2312|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, running_mean, running_var, weight, bias):\n",
      "  2313|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2314|         0|            0|            0|  0.00%|            instance_norm,\n",
      "  2315|         0|            0|            0|  0.00%|            (input, running_mean, running_var, weight, bias),\n",
      "  2316|         0|            0|            0|  0.00%|            input,\n",
      "  2317|         0|            0|            0|  0.00%|            running_mean=running_mean,\n",
      "  2318|         0|            0|            0|  0.00%|            running_var=running_var,\n",
      "  2319|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2320|         0|            0|            0|  0.00%|            bias=bias,\n",
      "  2321|         0|            0|            0|  0.00%|            use_input_stats=use_input_stats,\n",
      "  2322|         0|            0|            0|  0.00%|            momentum=momentum,\n",
      "  2323|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2324|         0|            0|            0|  0.00%|        )\n",
      "  2325|         0|            0|            0|  0.00%|    if use_input_stats:\n",
      "  2326|         0|            0|            0|  0.00%|        _verify_spatial_size(input.size())\n",
      "  2327|         0|            0|            0|  0.00%|    return torch.instance_norm(\n",
      "  2328|         0|            0|            0|  0.00%|        input, weight, bias, running_mean, running_var, use_input_stats, momentum, eps, torch.backends.cudnn.enabled\n",
      "  2329|         0|            0|            0|  0.00%|    )\n",
      "  2330|         0|            0|            0|  0.00%|\n",
      "  2331|         0|            0|            0|  0.00%|\n",
      "  2332|         0|            0|            0|  0.00%|def layer_norm(\n",
      "  2333|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2334|         0|            0|            0|  0.00%|    normalized_shape: List[int],\n",
      "  2335|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2336|         0|            0|            0|  0.00%|    bias: Optional[Tensor] = None,\n",
      "  2337|         0|            0|            0|  0.00%|    eps: float = 1e-5,\n",
      "  2338|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2339|         0|            0|            0|  0.00%|    r\"\"\"Applies Layer Normalization for last certain number of dimensions.\n",
      "  2340|         0|            0|            0|  0.00%|\n",
      "  2341|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LayerNorm` for details.\n",
      "  2342|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2343|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  2344|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2345|         0|            0|            0|  0.00%|            layer_norm, (input, weight, bias), input, normalized_shape, weight=weight, bias=bias, eps=eps\n",
      "  2346|         0|            0|            0|  0.00%|        )\n",
      "  2347|         0|            0|            0|  0.00%|    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "  2348|         0|            0|            0|  0.00%|\n",
      "  2349|         0|            0|            0|  0.00%|\n",
      "  2350|         0|            0|            0|  0.00%|def group_norm(\n",
      "  2351|         0|            0|            0|  0.00%|    input: Tensor, num_groups: int, weight: Optional[Tensor] = None, bias: Optional[Tensor] = None, eps: float = 1e-5\n",
      "  2352|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2353|         0|            0|            0|  0.00%|    r\"\"\"Applies Group Normalization for last certain number of dimensions.\n",
      "  2354|         0|            0|            0|  0.00%|\n",
      "  2355|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GroupNorm` for details.\n",
      "  2356|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2357|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, weight, bias):\n",
      "  2358|         0|            0|            0|  0.00%|        return handle_torch_function(group_norm, (input, weight, bias,), input, num_groups, weight=weight, bias=bias, eps=eps)\n",
      "  2359|         0|            0|            0|  0.00%|    _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "  2360|         0|            0|            0|  0.00%|    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "  2361|         0|            0|            0|  0.00%|\n",
      "  2362|         0|            0|            0|  0.00%|\n",
      "  2363|         0|            0|            0|  0.00%|def local_response_norm(input: Tensor, size: int, alpha: float = 1e-4, beta: float = 0.75, k: float = 1.0) -> Tensor:\n",
      "  2364|         0|            0|            0|  0.00%|    r\"\"\"Applies local response normalization over an input signal composed of\n",
      "  2365|         0|            0|            0|  0.00%|    several input planes, where channels occupy the second dimension.\n",
      "  2366|         0|            0|            0|  0.00%|    Applies normalization across channels.\n",
      "  2367|         0|            0|            0|  0.00%|\n",
      "  2368|         0|            0|            0|  0.00%|    See :class:`~torch.nn.LocalResponseNorm` for details.\n",
      "  2369|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2370|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  2371|         0|            0|            0|  0.00%|        return handle_torch_function(local_response_norm, (input,), input, size, alpha=alpha, beta=beta, k=k)\n",
      "  2372|         0|            0|            0|  0.00%|    dim = input.dim()\n",
      "  2373|         0|            0|            0|  0.00%|    if dim < 3:\n",
      "  2374|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2375|         0|            0|            0|  0.00%|            \"Expected 3D or higher dimensionality \\\n",
      "  2376|         0|            0|            0|  0.00%|                         input (got {} dimensions)\".format(\n",
      "  2377|         0|            0|            0|  0.00%|                dim\n",
      "  2378|         0|            0|            0|  0.00%|            )\n",
      "  2379|         0|            0|            0|  0.00%|        )\n",
      "  2380|         0|            0|            0|  0.00%|\n",
      "  2381|         0|            0|            0|  0.00%|    if input.numel() == 0:\n",
      "  2382|         0|            0|            0|  0.00%|        return input\n",
      "  2383|         0|            0|            0|  0.00%|\n",
      "  2384|         0|            0|            0|  0.00%|    div = input.mul(input).unsqueeze(1)\n",
      "  2385|         0|            0|            0|  0.00%|    if dim == 3:\n",
      "  2386|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, size // 2, (size - 1) // 2))\n",
      "  2387|         0|            0|            0|  0.00%|        div = avg_pool2d(div, (size, 1), stride=1).squeeze(1)\n",
      "  2388|         0|            0|            0|  0.00%|    else:\n",
      "  2389|         0|            0|            0|  0.00%|        sizes = input.size()\n",
      "  2390|         0|            0|            0|  0.00%|        div = div.view(sizes[0], 1, sizes[1], sizes[2], -1)\n",
      "  2391|         0|            0|            0|  0.00%|        div = pad(div, (0, 0, 0, 0, size // 2, (size - 1) // 2))\n",
      "  2392|         0|            0|            0|  0.00%|        div = avg_pool3d(div, (size, 1, 1), stride=1).squeeze(1)\n",
      "  2393|         0|            0|            0|  0.00%|        div = div.view(sizes)\n",
      "  2394|         0|            0|            0|  0.00%|    div = div.mul(alpha).add(k).pow(beta)\n",
      "  2395|         0|            0|            0|  0.00%|    return input / div\n",
      "  2396|         0|            0|            0|  0.00%|\n",
      "  2397|         0|            0|            0|  0.00%|\n",
      "  2398|         0|            0|            0|  0.00%|# loss\n",
      "  2399|         0|            0|            0|  0.00%|\n",
      "  2400|         0|            0|            0|  0.00%|\n",
      "  2401|         0|            0|            0|  0.00%|def ctc_loss(\n",
      "  2402|         0|            0|            0|  0.00%|    log_probs: Tensor,\n",
      "  2403|         0|            0|            0|  0.00%|    targets: Tensor,\n",
      "  2404|         0|            0|            0|  0.00%|    input_lengths: Tensor,\n",
      "  2405|         0|            0|            0|  0.00%|    target_lengths: Tensor,\n",
      "  2406|         0|            0|            0|  0.00%|    blank: int = 0,\n",
      "  2407|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2408|         0|            0|            0|  0.00%|    zero_infinity: bool = False,\n",
      "  2409|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2410|         0|            0|            0|  0.00%|    r\"\"\"The Connectionist Temporal Classification loss.\n",
      "  2411|         0|            0|            0|  0.00%|\n",
      "  2412|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CTCLoss` for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2413|         0|            0|            0|  0.00%|\n",
      "  2414|         0|            0|            0|  0.00%|    Note:\n",
      "  2415|         0|            0|            0|  0.00%|        {cudnn_reproducibility_note}\n",
      "  2416|         0|            0|            0|  0.00%|\n",
      "  2417|         0|            0|            0|  0.00%|    Note:\n",
      "  2418|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  2419|         0|            0|            0|  0.00%|\n",
      "  2420|         0|            0|            0|  0.00%|    Args:\n",
      "  2421|         0|            0|            0|  0.00%|        log_probs: :math:`(T, N, C)` where `C = number of characters in alphabet including blank`,\n",
      "  2422|         0|            0|            0|  0.00%|            `T = input length`, and `N = batch size`.\n",
      "  2423|         0|            0|            0|  0.00%|            The logarithmized probabilities of the outputs\n",
      "  2424|         0|            0|            0|  0.00%|            (e.g. obtained with :func:`torch.nn.functional.log_softmax`).\n",
      "  2425|         0|            0|            0|  0.00%|        targets: :math:`(N, S)` or `(sum(target_lengths))`.\n",
      "  2426|         0|            0|            0|  0.00%|            Targets cannot be blank. In the second form, the targets are assumed to be concatenated.\n",
      "  2427|         0|            0|            0|  0.00%|        input_lengths: :math:`(N)`.\n",
      "  2428|         0|            0|            0|  0.00%|            Lengths of the inputs (must each be :math:`\\leq T`)\n",
      "  2429|         0|            0|            0|  0.00%|        target_lengths: :math:`(N)`.\n",
      "  2430|         0|            0|            0|  0.00%|            Lengths of the targets\n",
      "  2431|         0|            0|            0|  0.00%|        blank (int, optional):\n",
      "  2432|         0|            0|            0|  0.00%|            Blank label. Default :math:`0`.\n",
      "  2433|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2434|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2435|         0|            0|            0|  0.00%|            ``'mean'``: the output losses will be divided by the target lengths and\n",
      "  2436|         0|            0|            0|  0.00%|            then the mean over the batch is taken, ``'sum'``: the output will be\n",
      "  2437|         0|            0|            0|  0.00%|            summed. Default: ``'mean'``\n",
      "  2438|         0|            0|            0|  0.00%|        zero_infinity (bool, optional):\n",
      "  2439|         0|            0|            0|  0.00%|            Whether to zero infinite losses and the associated gradients.\n",
      "  2440|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  2441|         0|            0|            0|  0.00%|            Infinite losses mainly occur when the inputs are too short\n",
      "  2442|         0|            0|            0|  0.00%|            to be aligned to the targets.\n",
      "  2443|         0|            0|            0|  0.00%|\n",
      "  2444|         0|            0|            0|  0.00%|    Example::\n",
      "  2445|         0|            0|            0|  0.00%|\n",
      "  2446|         0|            0|            0|  0.00%|        >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_()\n",
      "  2447|         0|            0|            0|  0.00%|        >>> targets = torch.randint(1, 20, (16, 30), dtype=torch.long)\n",
      "  2448|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full((16,), 50, dtype=torch.long)\n",
      "  2449|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n",
      "  2450|         0|            0|            0|  0.00%|        >>> loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
      "  2451|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2452|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2453|         0|            0|            0|  0.00%|    if has_torch_function_variadic(log_probs, targets, input_lengths, target_lengths):\n",
      "  2454|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2455|         0|            0|            0|  0.00%|            ctc_loss,\n",
      "  2456|         0|            0|            0|  0.00%|            (log_probs, targets, input_lengths, target_lengths),\n",
      "  2457|         0|            0|            0|  0.00%|            log_probs, targets, input_lengths, target_lengths,\n",
      "  2458|         0|            0|            0|  0.00%|            blank=blank, reduction=reduction, zero_infinity=zero_infinity\n",
      "  2459|         0|            0|            0|  0.00%|        )\n",
      "  2460|         0|            0|            0|  0.00%|    return torch.ctc_loss(\n",
      "  2461|         0|            0|            0|  0.00%|        log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction), zero_infinity\n",
      "  2462|         0|            0|            0|  0.00%|    )\n",
      "  2463|         0|            0|            0|  0.00%|\n",
      "  2464|         0|            0|            0|  0.00%|\n",
      "  2465|         0|            0|            0|  0.00%|ctc_loss.__doc__ = ctc_loss.__doc__.format(**reproducibility_notes)\n",
      "  2466|         0|            0|            0|  0.00%|\n",
      "  2467|         0|            0|            0|  0.00%|\n",
      "  2468|         0|            0|            0|  0.00%|def nll_loss(\n",
      "  2469|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2470|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2471|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2472|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2473|         0|            0|            0|  0.00%|    ignore_index: int = -100,\n",
      "  2474|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2475|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2476|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2477|         0|            0|            0|  0.00%|    r\"\"\"The negative log likelihood loss.\n",
      "  2478|         0|            0|            0|  0.00%|\n",
      "  2479|         0|            0|            0|  0.00%|    See :class:`~torch.nn.NLLLoss` for details.\n",
      "  2480|         0|            0|            0|  0.00%|\n",
      "  2481|         0|            0|            0|  0.00%|    Args:\n",
      "  2482|         0|            0|            0|  0.00%|        input: :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
      "  2483|         0|            0|            0|  0.00%|            in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \\geq 1`\n",
      "  2484|         0|            0|            0|  0.00%|            in the case of K-dimensional loss. `input` is expected to be log-probabilities.\n",
      "  2485|         0|            0|            0|  0.00%|        target: :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`,\n",
      "  2486|         0|            0|            0|  0.00%|            or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \\geq 1` for\n",
      "  2487|         0|            0|            0|  0.00%|            K-dimensional loss.\n",
      "  2488|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  2489|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`\n",
      "  2490|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2491|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2492|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2493|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2494|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2495|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  2496|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  2497|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Default: -100\n",
      "  2498|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2499|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2500|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2501|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2502|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2503|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2504|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2505|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2506|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2507|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2508|         0|            0|            0|  0.00%|\n",
      "  2509|         0|            0|            0|  0.00%|    Example::\n",
      "  2510|         0|            0|            0|  0.00%|\n",
      "  2511|         0|            0|            0|  0.00%|        >>> # input is of size N x C = 3 x 5\n",
      "  2512|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2513|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "  2514|         0|            0|            0|  0.00%|        >>> target = torch.tensor([1, 0, 4])\n",
      "  2515|         0|            0|            0|  0.00%|        >>> output = F.nll_loss(F.log_softmax(input), target)\n",
      "  2516|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  2517|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2518|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2519|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2520|         0|            0|            0|  0.00%|            nll_loss,\n",
      "  2521|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2522|         0|            0|            0|  0.00%|            input,\n",
      "  2523|         0|            0|            0|  0.00%|            target,\n",
      "  2524|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2525|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2526|         0|            0|            0|  0.00%|            ignore_index=ignore_index,\n",
      "  2527|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2528|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2529|         0|            0|            0|  0.00%|        )\n",
      "  2530|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2531|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2532|         0|            0|            0|  0.00%|    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n",
      "  2533|         0|            0|            0|  0.00%|\n",
      "  2534|         0|            0|            0|  0.00%|\n",
      "  2535|         0|            0|            0|  0.00%|def poisson_nll_loss(\n",
      "  2536|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2537|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2538|         0|            0|            0|  0.00%|    log_input: bool = True,\n",
      "  2539|         0|            0|            0|  0.00%|    full: bool = False,\n",
      "  2540|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2541|         0|            0|            0|  0.00%|    eps: float = 1e-8,\n",
      "  2542|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2543|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2544|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2545|         0|            0|            0|  0.00%|    r\"\"\"Poisson negative log likelihood loss.\n",
      "  2546|         0|            0|            0|  0.00%|\n",
      "  2547|         0|            0|            0|  0.00%|    See :class:`~torch.nn.PoissonNLLLoss` for details.\n",
      "  2548|         0|            0|            0|  0.00%|\n",
      "  2549|         0|            0|            0|  0.00%|    Args:\n",
      "  2550|         0|            0|            0|  0.00%|        input: expectation of underlying Poisson distribution.\n",
      "  2551|         0|            0|            0|  0.00%|        target: random sample :math:`target \\sim \\text{Poisson}(input)`.\n",
      "  2552|         0|            0|            0|  0.00%|        log_input: if ``True`` the loss is computed as\n",
      "  2553|         0|            0|            0|  0.00%|            :math:`\\exp(\\text{input}) - \\text{target} * \\text{input}`, if ``False`` then loss is\n",
      "  2554|         0|            0|            0|  0.00%|            :math:`\\text{input} - \\text{target} * \\log(\\text{input}+\\text{eps})`. Default: ``True``\n",
      "  2555|         0|            0|            0|  0.00%|        full: whether to compute full loss, i. e. to add the Stirling\n",
      "  2556|         0|            0|            0|  0.00%|            approximation term. Default: ``False``\n",
      "  2557|         0|            0|            0|  0.00%|            :math:`\\text{target} * \\log(\\text{target}) - \\text{target} + 0.5 * \\log(2 * \\pi * \\text{target})`.\n",
      "  2558|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2559|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2560|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2561|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2562|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2563|         0|            0|            0|  0.00%|        eps (float, optional): Small value to avoid evaluation of :math:`\\log(0)` when\n",
      "  2564|         0|            0|            0|  0.00%|            :attr:`log_input`\\ =\\ ``False``. Default: 1e-8\n",
      "  2565|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2566|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2567|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2568|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2569|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2570|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2571|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2572|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2573|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2574|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2575|         0|            0|            0|  0.00%|\n",
      "  2576|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2577|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2578|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2579|         0|            0|            0|  0.00%|            poisson_nll_loss,\n",
      "  2580|         0|            0|            0|  0.00%|            (input, target),\n",
      "  2581|         0|            0|            0|  0.00%|            input,\n",
      "  2582|         0|            0|            0|  0.00%|            target,\n",
      "  2583|         0|            0|            0|  0.00%|            log_input=log_input,\n",
      "  2584|         0|            0|            0|  0.00%|            full=full,\n",
      "  2585|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2586|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2587|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2588|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2589|         0|            0|            0|  0.00%|        )\n",
      "  2590|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2591|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2592|         0|            0|            0|  0.00%|    if reduction != \"none\" and reduction != \"mean\" and reduction != \"sum\":\n",
      "  2593|         0|            0|            0|  0.00%|        ret = input\n",
      "  2594|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  2595|         0|            0|            0|  0.00%|\n",
      "  2596|         0|            0|            0|  0.00%|    ret = torch.poisson_nll_loss(input, target, log_input, full, eps, _Reduction.get_enum(reduction))\n",
      "  2597|         0|            0|            0|  0.00%|    return ret\n",
      "  2598|         0|            0|            0|  0.00%|\n",
      "  2599|         0|            0|            0|  0.00%|\n",
      "  2600|         0|            0|            0|  0.00%|def gaussian_nll_loss(\n",
      "  2601|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2602|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2603|         0|            0|            0|  0.00%|    var: Tensor,\n",
      "  2604|         0|            0|            0|  0.00%|    full: bool = False,\n",
      "  2605|         0|            0|            0|  0.00%|    eps: float = 1e-6,\n",
      "  2606|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2607|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2608|         0|            0|            0|  0.00%|    r\"\"\"Gaussian negative log likelihood loss.\n",
      "  2609|         0|            0|            0|  0.00%|\n",
      "  2610|         0|            0|            0|  0.00%|    See :class:`~torch.nn.GaussianNLLLoss` for details.\n",
      "  2611|         0|            0|            0|  0.00%|\n",
      "  2612|         0|            0|            0|  0.00%|    Args:\n",
      "  2613|         0|            0|            0|  0.00%|        input: expectation of the Gaussian distribution.\n",
      "  2614|         0|            0|            0|  0.00%|        target: sample from the Gaussian distribution.\n",
      "  2615|         0|            0|            0|  0.00%|        var: tensor of positive variance(s), one for each of the expectations\n",
      "  2616|         0|            0|            0|  0.00%|            in the input (heteroscedastic), or a single one (homoscedastic).\n",
      "  2617|         0|            0|            0|  0.00%|        full (bool, optional): include the constant term in the loss calculation. Default: ``False``.\n",
      "  2618|         0|            0|            0|  0.00%|        eps (float, optional): value added to var, for stability. Default: 1e-6.\n",
      "  2619|         0|            0|            0|  0.00%|        reduction (string, optional): specifies the reduction to apply to the output:\n",
      "  2620|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2621|         0|            0|            0|  0.00%|            ``'mean'``: the output is the average of all batch member losses,\n",
      "  2622|         0|            0|            0|  0.00%|            ``'sum'``: the output is the sum of all batch member losses.\n",
      "  2623|         0|            0|            0|  0.00%|            Default: ``'mean'``.\n",
      "  2624|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2625|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, var):\n",
      "  2626|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2627|         0|            0|            0|  0.00%|            gaussian_nll_loss,\n",
      "  2628|         0|            0|            0|  0.00%|            (input, target, var),\n",
      "  2629|         0|            0|            0|  0.00%|            input,\n",
      "  2630|         0|            0|            0|  0.00%|            target,\n",
      "  2631|         0|            0|            0|  0.00%|            var,\n",
      "  2632|         0|            0|            0|  0.00%|            full=full,\n",
      "  2633|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  2634|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2635|         0|            0|            0|  0.00%|        )\n",
      "  2636|         0|            0|            0|  0.00%|\n",
      "  2637|         0|            0|            0|  0.00%|    # Check var size\n",
      "  2638|         0|            0|            0|  0.00%|    # If var.size == input.size, the case is heteroscedastic and no further checks are needed.\n",
      "  2639|         0|            0|            0|  0.00%|    # Otherwise:\n",
      "  2640|         0|            0|            0|  0.00%|    if var.size() != input.size():\n",
      "  2641|         0|            0|            0|  0.00%|\n",
      "  2642|         0|            0|            0|  0.00%|        # If var is one dimension short of input, but the sizes match otherwise, then this is a homoscedastic case.\n",
      "  2643|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2)\n",
      "  2644|         0|            0|            0|  0.00%|        # -> unsqueeze var so that var.shape = (10, 2, 1)\n",
      "  2645|         0|            0|            0|  0.00%|        # this is done so that broadcasting can happen in the loss calculation\n",
      "  2646|         0|            0|            0|  0.00%|        if input.size()[:-1] == var.size():\n",
      "  2647|         0|            0|            0|  0.00%|            var = torch.unsqueeze(var, -1)\n",
      "  2648|         0|            0|            0|  0.00%|\n",
      "  2649|         0|            0|            0|  0.00%|        # This checks if the sizes match up to the final dimension, and the final dimension of var is of size 1.\n",
      "  2650|         0|            0|            0|  0.00%|        # This is also a homoscedastic case.\n",
      "  2651|         0|            0|            0|  0.00%|        # e.g. input.size = (10, 2, 3), var.size = (10, 2, 1)\n",
      "  2652|         0|            0|            0|  0.00%|        elif input.size()[:-1] == var.size()[:-1] and var.size(-1) == 1:  # Heteroscedastic case\n",
      "  2653|         0|            0|            0|  0.00%|            pass\n",
      "  2654|         0|            0|            0|  0.00%|\n",
      "  2655|         0|            0|            0|  0.00%|        # If none of the above pass, then the size of var is incorrect.\n",
      "  2656|         0|            0|            0|  0.00%|        else:\n",
      "  2657|         0|            0|            0|  0.00%|            raise ValueError(\"var is of incorrect size\")\n",
      "  2658|         0|            0|            0|  0.00%|\n",
      "  2659|         0|            0|            0|  0.00%|    # Check validity of reduction mode\n",
      "  2660|         0|            0|            0|  0.00%|    if reduction != 'none' and reduction != 'mean' and reduction != 'sum':\n",
      "  2661|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  2662|         0|            0|            0|  0.00%|\n",
      "  2663|         0|            0|            0|  0.00%|    # Entries of var must be non-negative\n",
      "  2664|         0|            0|            0|  0.00%|    if torch.any(var < 0):\n",
      "  2665|         0|            0|            0|  0.00%|        raise ValueError(\"var has negative entry/entries\")\n",
      "  2666|         0|            0|            0|  0.00%|\n",
      "  2667|         0|            0|            0|  0.00%|    # Clamp for stability\n",
      "  2668|         0|            0|            0|  0.00%|    var = var.clone()\n",
      "  2669|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "  2670|         0|            0|            0|  0.00%|        var.clamp_(min=eps)\n",
      "  2671|         0|            0|            0|  0.00%|\n",
      "  2672|         0|            0|            0|  0.00%|    # Calculate the loss\n",
      "  2673|         0|            0|            0|  0.00%|    loss = 0.5 * (torch.log(var) + (input - target)**2 / var)\n",
      "  2674|         0|            0|            0|  0.00%|    if full:\n",
      "  2675|         0|            0|            0|  0.00%|        loss += 0.5 * math.log(2 * math.pi)\n",
      "  2676|         0|            0|            0|  0.00%|\n",
      "  2677|         0|            0|            0|  0.00%|    if reduction == 'mean':\n",
      "  2678|         0|            0|            0|  0.00%|        return loss.mean()\n",
      "  2679|         0|            0|            0|  0.00%|    elif reduction == 'sum':\n",
      "  2680|         0|            0|            0|  0.00%|        return loss.sum()\n",
      "  2681|         0|            0|            0|  0.00%|    else:\n",
      "  2682|         0|            0|            0|  0.00%|        return loss\n",
      "  2683|         0|            0|            0|  0.00%|\n",
      "  2684|         0|            0|            0|  0.00%|\n",
      "  2685|         0|            0|            0|  0.00%|def kl_div(\n",
      "  2686|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2687|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2688|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2689|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2690|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2691|         0|            0|            0|  0.00%|    log_target: bool = False,\n",
      "  2692|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2693|         0|            0|            0|  0.00%|    r\"\"\"The `Kullback-Leibler divergence Loss\n",
      "  2694|         0|            0|            0|  0.00%|    <https://en.wikipedia.org/wiki/Kullback-Leibler_divergence>`__\n",
      "  2695|         0|            0|            0|  0.00%|\n",
      "  2696|         0|            0|            0|  0.00%|    See :class:`~torch.nn.KLDivLoss` for details.\n",
      "  2697|         0|            0|            0|  0.00%|\n",
      "  2698|         0|            0|            0|  0.00%|    Args:\n",
      "  2699|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape in log-probabilities.\n",
      "  2700|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input. See :attr:`log_target` for\n",
      "  2701|         0|            0|            0|  0.00%|            the target's interpretation.\n",
      "  2702|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2703|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2704|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2705|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2706|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2707|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2708|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2709|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2710|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2711|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2712|         0|            0|            0|  0.00%|            ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.\n",
      "  2713|         0|            0|            0|  0.00%|            ``'none'``: no reduction will be applied\n",
      "  2714|         0|            0|            0|  0.00%|            ``'batchmean'``: the sum of the output will be divided by the batchsize\n",
      "  2715|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed\n",
      "  2716|         0|            0|            0|  0.00%|            ``'mean'``: the output will be divided by the number of elements in the output\n",
      "  2717|         0|            0|            0|  0.00%|            Default: ``'mean'``\n",
      "  2718|         0|            0|            0|  0.00%|        log_target (bool): A flag indicating whether ``target`` is passed in the log space.\n",
      "  2719|         0|            0|            0|  0.00%|            It is recommended to pass certain distributions (like ``softmax``)\n",
      "  2720|         0|            0|            0|  0.00%|            in the log space to avoid numerical issues caused by explicit ``log``.\n",
      "  2721|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  2722|         0|            0|            0|  0.00%|\n",
      "  2723|         0|            0|            0|  0.00%|    .. note::\n",
      "  2724|         0|            0|            0|  0.00%|        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,\n",
      "  2725|         0|            0|            0|  0.00%|        and in the meantime, specifying either of those two args will override :attr:`reduction`.\n",
      "  2726|         0|            0|            0|  0.00%|\n",
      "  2727|         0|            0|            0|  0.00%|    .. note::\n",
      "  2728|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use\n",
      "  2729|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.\n",
      "  2730|         0|            0|            0|  0.00%|        In the next major release, ``'mean'`` will be changed to be the same as 'batchmean'.\n",
      "  2731|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2732|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2733|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2734|         0|            0|            0|  0.00%|            kl_div,\n",
      "  2735|         0|            0|            0|  0.00%|            (input, target),\n",
      "  2736|         0|            0|            0|  0.00%|            input,\n",
      "  2737|         0|            0|            0|  0.00%|            target,\n",
      "  2738|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2739|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2740|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2741|         0|            0|            0|  0.00%|            log_target=log_target,\n",
      "  2742|         0|            0|            0|  0.00%|        )\n",
      "  2743|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2744|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2745|         0|            0|            0|  0.00%|    else:\n",
      "  2746|         0|            0|            0|  0.00%|        if reduction == \"mean\":\n",
      "  2747|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  2748|         0|            0|            0|  0.00%|                \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "  2749|         0|            0|            0|  0.00%|                \"'batchmean' divides only by the batch size, and aligns with the KL div math definition.\"\n",
      "  2750|         0|            0|            0|  0.00%|                \"'mean' will be changed to behave the same as 'batchmean' in the next major release.\"\n",
      "  2751|         0|            0|            0|  0.00%|            )\n",
      "  2752|         0|            0|            0|  0.00%|\n",
      "  2753|         0|            0|            0|  0.00%|        # special case for batchmean\n",
      "  2754|         0|            0|            0|  0.00%|        if reduction == \"batchmean\":\n",
      "  2755|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum(\"sum\")\n",
      "  2756|         0|            0|            0|  0.00%|        else:\n",
      "  2757|         0|            0|            0|  0.00%|            reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2758|         0|            0|            0|  0.00%|\n",
      "  2759|         0|            0|            0|  0.00%|    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)\n",
      "  2760|         0|            0|            0|  0.00%|\n",
      "  2761|         0|            0|            0|  0.00%|    if reduction == \"batchmean\" and input.dim() != 0:\n",
      "  2762|         0|            0|            0|  0.00%|        reduced = reduced / input.size()[0]\n",
      "  2763|         0|            0|            0|  0.00%|\n",
      "  2764|         0|            0|            0|  0.00%|    return reduced\n",
      "  2765|         0|            0|            0|  0.00%|\n",
      "  2766|         0|            0|            0|  0.00%|\n",
      "  2767|         1|  1.71661e-05|  1.71661e-05|  0.00%|def cross_entropy(\n",
      "  2768|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2769|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2770|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2771|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2772|         0|            0|            0|  0.00%|    ignore_index: int = -100,\n",
      "  2773|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2774|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2775|         0|            0|            0|  0.00%|    label_smoothing: float = 0.0,\n",
      "  2776|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2777|         0|            0|            0|  0.00%|    r\"\"\"This criterion computes the cross entropy loss between input and target.\n",
      "  2778|         0|            0|            0|  0.00%|\n",
      "  2779|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
      "  2780|         0|            0|            0|  0.00%|\n",
      "  2781|         0|            0|            0|  0.00%|    Args:\n",
      "  2782|         0|            0|            0|  0.00%|        input (Tensor) : :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
      "  2783|         0|            0|            0|  0.00%|            in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \\geq 1`\n",
      "  2784|         0|            0|            0|  0.00%|            in the case of K-dimensional loss. `input` is expected to contain unnormalized scores\n",
      "  2785|         0|            0|            0|  0.00%|            (often referred to as logits).\n",
      "  2786|         0|            0|            0|  0.00%|        target (Tensor) : If containing class indices, shape :math:`(N)` where each value is\n",
      "  2787|         0|            0|            0|  0.00%|            :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "  2788|         0|            0|            0|  0.00%|            :math:`K \\geq 1` in the case of K-dimensional loss. If containing class probabilities,\n",
      "  2789|         0|            0|            0|  0.00%|            same shape as the input.\n",
      "  2790|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  2791|         0|            0|            0|  0.00%|            class. If given, has to be a Tensor of size `C`\n",
      "  2792|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2793|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2794|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2795|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2796|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2797|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  2798|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  2799|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "  2800|         0|            0|            0|  0.00%|            :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "  2801|         0|            0|            0|  0.00%|            Default: -100\n",
      "  2802|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2803|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2804|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2805|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2806|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2807|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2808|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2809|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2810|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2811|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2812|         0|            0|            0|  0.00%|        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "  2813|         0|            0|            0|  0.00%|            of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "  2814|         0|            0|            0|  0.00%|            become a mixture of the original ground truth and a uniform distribution as described in\n",
      "  2815|         0|            0|            0|  0.00%|            `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "  2816|         0|            0|            0|  0.00%|\n",
      "  2817|         0|            0|            0|  0.00%|    Examples::\n",
      "  2818|         0|            0|            0|  0.00%|\n",
      "  2819|         0|            0|            0|  0.00%|        >>> # Example of target with class indices\n",
      "  2820|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2821|         0|            0|            0|  0.00%|        >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
      "  2822|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)\n",
      "  2823|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2824|         0|            0|            0|  0.00%|        >>>\n",
      "  2825|         0|            0|            0|  0.00%|        >>> # Example of target with class probabilities\n",
      "  2826|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  2827|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "  2828|         0|            0|            0|  0.00%|        >>> loss = F.cross_entropy(input, target)\n",
      "  2829|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2830|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2831|         1|  4.76837e-06|  4.76837e-06|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2832|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2833|         0|            0|            0|  0.00%|            cross_entropy,\n",
      "  2834|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2835|         0|            0|            0|  0.00%|            input,\n",
      "  2836|         0|            0|            0|  0.00%|            target,\n",
      "  2837|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2838|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2839|         0|            0|            0|  0.00%|            ignore_index=ignore_index,\n",
      "  2840|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2841|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2842|         0|            0|            0|  0.00%|            label_smoothing=label_smoothing,\n",
      "  2843|         0|            0|            0|  0.00%|        )\n",
      "  2844|         1|  3.09944e-06|  3.09944e-06|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2845|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  2846|         1|   0.00424099|   0.00424099|  0.05%|    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "(call)|         1|  2.40803e-05|  2.40803e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/_reduction.py:7 get_enum\n",
      "  2847|         0|            0|            0|  0.00%|\n",
      "  2848|         0|            0|            0|  0.00%|\n",
      "  2849|         0|            0|            0|  0.00%|def binary_cross_entropy(\n",
      "  2850|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2851|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2852|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2853|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2854|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2855|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2856|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2857|         0|            0|            0|  0.00%|    r\"\"\"Function that measures the Binary Cross Entropy between the target and input\n",
      "  2858|         0|            0|            0|  0.00%|    probabilities.\n",
      "  2859|         0|            0|            0|  0.00%|\n",
      "  2860|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCELoss` for details.\n",
      "  2861|         0|            0|            0|  0.00%|\n",
      "  2862|         0|            0|            0|  0.00%|    Args:\n",
      "  2863|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as probabilities.\n",
      "  2864|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1.\n",
      "  2865|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight\n",
      "  2866|         0|            0|            0|  0.00%|                if provided it's repeated to match input tensor shape\n",
      "  2867|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2868|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2869|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2870|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2871|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2872|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2873|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2874|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2875|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2876|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2877|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2878|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2879|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2880|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2881|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2882|         0|            0|            0|  0.00%|\n",
      "  2883|         0|            0|            0|  0.00%|    Examples::\n",
      "  2884|         0|            0|            0|  0.00%|\n",
      "  2885|         0|            0|            0|  0.00%|        >>> input = torch.randn((3, 2), requires_grad=True)\n",
      "  2886|         0|            0|            0|  0.00%|        >>> target = torch.rand((3, 2), requires_grad=False)\n",
      "  2887|         0|            0|            0|  0.00%|        >>> loss = F.binary_cross_entropy(F.sigmoid(input), target)\n",
      "  2888|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  2889|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2890|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  2891|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2892|         0|            0|            0|  0.00%|            binary_cross_entropy,\n",
      "  2893|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  2894|         0|            0|            0|  0.00%|            input,\n",
      "  2895|         0|            0|            0|  0.00%|            target,\n",
      "  2896|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2897|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2898|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2899|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2900|         0|            0|            0|  0.00%|        )\n",
      "  2901|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2902|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2903|         0|            0|            0|  0.00%|    else:\n",
      "  2904|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2905|         0|            0|            0|  0.00%|    if target.size() != input.size():\n",
      "  2906|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  2907|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n",
      "  2908|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size())\n",
      "  2909|         0|            0|            0|  0.00%|        )\n",
      "  2910|         0|            0|            0|  0.00%|\n",
      "  2911|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  2912|         0|            0|            0|  0.00%|        new_size = _infer_size(target.size(), weight.size())\n",
      "  2913|         0|            0|            0|  0.00%|        weight = weight.expand(new_size)\n",
      "  2914|         0|            0|            0|  0.00%|\n",
      "  2915|         0|            0|            0|  0.00%|    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\n",
      "  2916|         0|            0|            0|  0.00%|\n",
      "  2917|         0|            0|            0|  0.00%|\n",
      "  2918|         0|            0|            0|  0.00%|def binary_cross_entropy_with_logits(\n",
      "  2919|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2920|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2921|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  2922|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2923|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2924|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2925|         0|            0|            0|  0.00%|    pos_weight: Optional[Tensor] = None,\n",
      "  2926|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2927|         0|            0|            0|  0.00%|    r\"\"\"Function that measures Binary Cross Entropy between target and input\n",
      "  2928|         0|            0|            0|  0.00%|    logits.\n",
      "  2929|         0|            0|            0|  0.00%|\n",
      "  2930|         0|            0|            0|  0.00%|    See :class:`~torch.nn.BCEWithLogitsLoss` for details.\n",
      "  2931|         0|            0|            0|  0.00%|\n",
      "  2932|         0|            0|            0|  0.00%|    Args:\n",
      "  2933|         0|            0|            0|  0.00%|        input: Tensor of arbitrary shape as unnormalized scores (often referred to as logits).\n",
      "  2934|         0|            0|            0|  0.00%|        target: Tensor of the same shape as input with values between 0 and 1\n",
      "  2935|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight\n",
      "  2936|         0|            0|            0|  0.00%|            if provided it's repeated to match input tensor shape\n",
      "  2937|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  2938|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  2939|         0|            0|            0|  0.00%|            some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "  2940|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  2941|         0|            0|            0|  0.00%|            when reduce is ``False``. Default: ``True``\n",
      "  2942|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  2943|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  2944|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  2945|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  2946|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  2947|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  2948|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  2949|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  2950|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  2951|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  2952|         0|            0|            0|  0.00%|        pos_weight (Tensor, optional): a weight of positive examples.\n",
      "  2953|         0|            0|            0|  0.00%|                Must be a vector with length equal to the number of classes.\n",
      "  2954|         0|            0|            0|  0.00%|\n",
      "  2955|         0|            0|            0|  0.00%|    Examples::\n",
      "  2956|         0|            0|            0|  0.00%|\n",
      "  2957|         0|            0|            0|  0.00%|         >>> input = torch.randn(3, requires_grad=True)\n",
      "  2958|         0|            0|            0|  0.00%|         >>> target = torch.empty(3).random_(2)\n",
      "  2959|         0|            0|            0|  0.00%|         >>> loss = F.binary_cross_entropy_with_logits(input, target)\n",
      "  2960|         0|            0|            0|  0.00%|         >>> loss.backward()\n",
      "  2961|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2962|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight, pos_weight):\n",
      "  2963|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  2964|         0|            0|            0|  0.00%|            binary_cross_entropy_with_logits,\n",
      "  2965|         0|            0|            0|  0.00%|            (input, target, weight, pos_weight),\n",
      "  2966|         0|            0|            0|  0.00%|            input,\n",
      "  2967|         0|            0|            0|  0.00%|            target,\n",
      "  2968|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  2969|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  2970|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  2971|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  2972|         0|            0|            0|  0.00%|            pos_weight=pos_weight,\n",
      "  2973|         0|            0|            0|  0.00%|        )\n",
      "  2974|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  2975|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  2976|         0|            0|            0|  0.00%|    else:\n",
      "  2977|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  2978|         0|            0|            0|  0.00%|\n",
      "  2979|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  2980|         0|            0|            0|  0.00%|        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
      "  2981|         0|            0|            0|  0.00%|\n",
      "  2982|         0|            0|            0|  0.00%|    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)\n",
      "  2983|         0|            0|            0|  0.00%|\n",
      "  2984|         0|            0|            0|  0.00%|\n",
      "  2985|         0|            0|            0|  0.00%|def smooth_l1_loss(\n",
      "  2986|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  2987|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  2988|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  2989|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  2990|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  2991|         0|            0|            0|  0.00%|    beta: float = 1.0,\n",
      "  2992|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  2993|         0|            0|            0|  0.00%|    r\"\"\"Function that uses a squared term if the absolute\n",
      "  2994|         0|            0|            0|  0.00%|    element-wise error falls below beta and an L1 term otherwise.\n",
      "  2995|         0|            0|            0|  0.00%|\n",
      "  2996|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SmoothL1Loss` for details.\n",
      "  2997|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  2998|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  2999|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3000|         0|            0|            0|  0.00%|            smooth_l1_loss,\n",
      "  3001|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3002|         0|            0|            0|  0.00%|            input,\n",
      "  3003|         0|            0|            0|  0.00%|            target,\n",
      "  3004|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3005|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3006|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3007|         0|            0|            0|  0.00%|            beta=beta,\n",
      "  3008|         0|            0|            0|  0.00%|        )\n",
      "  3009|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3010|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3011|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3012|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3013|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3014|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3015|         0|            0|            0|  0.00%|        )\n",
      "  3016|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3017|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3018|         0|            0|            0|  0.00%|\n",
      "  3019|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3020|         0|            0|            0|  0.00%|    return torch._C._nn.smooth_l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), beta)\n",
      "  3021|         0|            0|            0|  0.00%|\n",
      "  3022|         0|            0|            0|  0.00%|\n",
      "  3023|         0|            0|            0|  0.00%|def huber_loss(\n",
      "  3024|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3025|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3026|         0|            0|            0|  0.00%|    reduction: str = 'mean',\n",
      "  3027|         0|            0|            0|  0.00%|    delta: float = 1.0,\n",
      "  3028|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3029|         0|            0|            0|  0.00%|    r\"\"\"Function that uses a squared term if the absolute\n",
      "  3030|         0|            0|            0|  0.00%|    element-wise error falls below delta and a delta-scaled L1 term otherwise.\n",
      "  3031|         0|            0|            0|  0.00%|\n",
      "  3032|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HuberLoss` for details.\n",
      "  3033|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3034|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3035|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3036|         0|            0|            0|  0.00%|            huber_loss,\n",
      "  3037|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3038|         0|            0|            0|  0.00%|            input,\n",
      "  3039|         0|            0|            0|  0.00%|            target,\n",
      "  3040|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3041|         0|            0|            0|  0.00%|            delta=delta,\n",
      "  3042|         0|            0|            0|  0.00%|        )\n",
      "  3043|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3044|         0|            0|            0|  0.00%|        warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3045|         0|            0|            0|  0.00%|                      \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3046|         0|            0|            0|  0.00%|                      \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3047|         0|            0|            0|  0.00%|                      stacklevel=2)\n",
      "  3048|         0|            0|            0|  0.00%|\n",
      "  3049|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3050|         0|            0|            0|  0.00%|    return torch._C._nn.huber_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction), delta)\n",
      "  3051|         0|            0|            0|  0.00%|\n",
      "  3052|         0|            0|            0|  0.00%|\n",
      "  3053|         0|            0|            0|  0.00%|def l1_loss(\n",
      "  3054|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3055|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3056|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3057|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3058|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3059|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3060|         0|            0|            0|  0.00%|    r\"\"\"l1_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3061|         0|            0|            0|  0.00%|\n",
      "  3062|         0|            0|            0|  0.00%|    Function that takes the mean element-wise absolute value difference.\n",
      "  3063|         0|            0|            0|  0.00%|\n",
      "  3064|         0|            0|            0|  0.00%|    See :class:`~torch.nn.L1Loss` for details.\n",
      "  3065|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3066|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3067|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3068|         0|            0|            0|  0.00%|            l1_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3069|         0|            0|            0|  0.00%|        )\n",
      "  3070|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3071|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3072|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3073|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3074|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3075|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3076|         0|            0|            0|  0.00%|        )\n",
      "  3077|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3078|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3079|         0|            0|            0|  0.00%|\n",
      "  3080|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3081|         0|            0|            0|  0.00%|    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "  3082|         0|            0|            0|  0.00%|\n",
      "  3083|         0|            0|            0|  0.00%|\n",
      "  3084|         0|            0|            0|  0.00%|def mse_loss(\n",
      "  3085|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3086|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3087|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3088|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3089|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3090|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3091|         0|            0|            0|  0.00%|    r\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3092|         0|            0|            0|  0.00%|\n",
      "  3093|         0|            0|            0|  0.00%|    Measures the element-wise mean squared error.\n",
      "  3094|         0|            0|            0|  0.00%|\n",
      "  3095|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MSELoss` for details.\n",
      "  3096|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3097|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3098|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3099|         0|            0|            0|  0.00%|            mse_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3100|         0|            0|            0|  0.00%|        )\n",
      "  3101|         0|            0|            0|  0.00%|    if not (target.size() == input.size()):\n",
      "  3102|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  3103|         0|            0|            0|  0.00%|            \"Using a target size ({}) that is different to the input size ({}). \"\n",
      "  3104|         0|            0|            0|  0.00%|            \"This will likely lead to incorrect results due to broadcasting. \"\n",
      "  3105|         0|            0|            0|  0.00%|            \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
      "  3106|         0|            0|            0|  0.00%|            stacklevel=2,\n",
      "  3107|         0|            0|            0|  0.00%|        )\n",
      "  3108|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3109|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3110|         0|            0|            0|  0.00%|\n",
      "  3111|         0|            0|            0|  0.00%|    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
      "  3112|         0|            0|            0|  0.00%|    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "  3113|         0|            0|            0|  0.00%|\n",
      "  3114|         0|            0|            0|  0.00%|\n",
      "  3115|         0|            0|            0|  0.00%|def margin_ranking_loss(\n",
      "  3116|         0|            0|            0|  0.00%|    input1: Tensor,\n",
      "  3117|         0|            0|            0|  0.00%|    input2: Tensor,\n",
      "  3118|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3119|         0|            0|            0|  0.00%|    margin: float = 0,\n",
      "  3120|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3121|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3122|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3123|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3124|         0|            0|            0|  0.00%|    r\"\"\"margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3125|         0|            0|            0|  0.00%|\n",
      "  3126|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MarginRankingLoss` for details.\n",
      "  3127|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3128|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):\n",
      "  3129|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3130|         0|            0|            0|  0.00%|            margin_ranking_loss,\n",
      "  3131|         0|            0|            0|  0.00%|            (input1, input2, target),\n",
      "  3132|         0|            0|            0|  0.00%|            input1,\n",
      "  3133|         0|            0|            0|  0.00%|            input2,\n",
      "  3134|         0|            0|            0|  0.00%|            target,\n",
      "  3135|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3136|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3137|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3138|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3139|         0|            0|            0|  0.00%|        )\n",
      "  3140|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3141|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3142|         0|            0|            0|  0.00%|    else:\n",
      "  3143|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3144|         0|            0|            0|  0.00%|    if input1.dim() == 0 or input2.dim() == 0 or target.dim() == 0:\n",
      "  3145|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "  3146|         0|            0|            0|  0.00%|            (\n",
      "  3147|         0|            0|            0|  0.00%|                \"margin_ranking_loss does not support scalars, got sizes: \"\n",
      "  3148|         0|            0|            0|  0.00%|                \"input1: {}, input2: {}, target: {} \".format(input1.size(), input2.size(), target.size())\n",
      "  3149|         0|            0|            0|  0.00%|            )\n",
      "  3150|         0|            0|            0|  0.00%|        )\n",
      "  3151|         0|            0|            0|  0.00%|    return torch.margin_ranking_loss(input1, input2, target, margin, reduction_enum)\n",
      "  3152|         0|            0|            0|  0.00%|\n",
      "  3153|         0|            0|            0|  0.00%|\n",
      "  3154|         0|            0|            0|  0.00%|def hinge_embedding_loss(\n",
      "  3155|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3156|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3157|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  3158|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3159|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3160|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3161|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3162|         0|            0|            0|  0.00%|    r\"\"\"hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3163|         0|            0|            0|  0.00%|\n",
      "  3164|         0|            0|            0|  0.00%|    See :class:`~torch.nn.HingeEmbeddingLoss` for details.\n",
      "  3165|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3166|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3167|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3168|         0|            0|            0|  0.00%|            hinge_embedding_loss,\n",
      "  3169|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3170|         0|            0|            0|  0.00%|            input,\n",
      "  3171|         0|            0|            0|  0.00%|            target,\n",
      "  3172|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3173|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3174|         0|            0|            0|  0.00%|            reduce=reduce,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3175|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3176|         0|            0|            0|  0.00%|        )\n",
      "  3177|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3178|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3179|         0|            0|            0|  0.00%|    else:\n",
      "  3180|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3181|         0|            0|            0|  0.00%|    return torch.hinge_embedding_loss(input, target, margin, reduction_enum)\n",
      "  3182|         0|            0|            0|  0.00%|\n",
      "  3183|         0|            0|            0|  0.00%|\n",
      "  3184|         0|            0|            0|  0.00%|def multilabel_margin_loss(\n",
      "  3185|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3186|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3187|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3188|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3189|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3190|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3191|         0|            0|            0|  0.00%|    r\"\"\"multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3192|         0|            0|            0|  0.00%|\n",
      "  3193|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelMarginLoss` for details.\n",
      "  3194|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3195|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3196|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3197|         0|            0|            0|  0.00%|            multilabel_margin_loss,\n",
      "  3198|         0|            0|            0|  0.00%|            (input, target),\n",
      "  3199|         0|            0|            0|  0.00%|            input,\n",
      "  3200|         0|            0|            0|  0.00%|            target,\n",
      "  3201|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3202|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3203|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3204|         0|            0|            0|  0.00%|        )\n",
      "  3205|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3206|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3207|         0|            0|            0|  0.00%|    else:\n",
      "  3208|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3209|         0|            0|            0|  0.00%|    return torch._C._nn.multilabel_margin_loss(input, target, reduction_enum)\n",
      "  3210|         0|            0|            0|  0.00%|\n",
      "  3211|         0|            0|            0|  0.00%|\n",
      "  3212|         0|            0|            0|  0.00%|def soft_margin_loss(\n",
      "  3213|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3214|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3215|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3216|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3217|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3218|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3219|         0|            0|            0|  0.00%|    r\"\"\"soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3220|         0|            0|            0|  0.00%|\n",
      "  3221|         0|            0|            0|  0.00%|    See :class:`~torch.nn.SoftMarginLoss` for details.\n",
      "  3222|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3223|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target):\n",
      "  3224|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3225|         0|            0|            0|  0.00%|            soft_margin_loss, (input, target), input, target, size_average=size_average, reduce=reduce, reduction=reduction\n",
      "  3226|         0|            0|            0|  0.00%|        )\n",
      "  3227|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3228|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3229|         0|            0|            0|  0.00%|    else:\n",
      "  3230|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3231|         0|            0|            0|  0.00%|    return torch._C._nn.soft_margin_loss(input, target, reduction_enum)\n",
      "  3232|         0|            0|            0|  0.00%|\n",
      "  3233|         0|            0|            0|  0.00%|\n",
      "  3234|         0|            0|            0|  0.00%|def multilabel_soft_margin_loss(\n",
      "  3235|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3236|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3237|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  3238|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3239|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3240|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3241|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3242|         0|            0|            0|  0.00%|    r\"\"\"multilabel_soft_margin_loss(input, target, weight=None, size_average=None) -> Tensor\n",
      "  3243|         0|            0|            0|  0.00%|\n",
      "  3244|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiLabelSoftMarginLoss` for details.\n",
      "  3245|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3246|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  3247|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3248|         0|            0|            0|  0.00%|            multilabel_soft_margin_loss,\n",
      "  3249|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  3250|         0|            0|            0|  0.00%|            input,\n",
      "  3251|         0|            0|            0|  0.00%|            target,\n",
      "  3252|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  3253|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3254|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3255|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3256|         0|            0|            0|  0.00%|        )\n",
      "  3257|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3258|         0|            0|            0|  0.00%|        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
      "  3259|         0|            0|            0|  0.00%|\n",
      "  3260|         0|            0|            0|  0.00%|    loss = -(target * logsigmoid(input) + (1 - target) * logsigmoid(-input))\n",
      "  3261|         0|            0|            0|  0.00%|\n",
      "  3262|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  3263|         0|            0|            0|  0.00%|        loss = loss * weight\n",
      "  3264|         0|            0|            0|  0.00%|\n",
      "  3265|         0|            0|            0|  0.00%|    loss = loss.sum(dim=1) / input.size(1)  # only return N loss values\n",
      "  3266|         0|            0|            0|  0.00%|\n",
      "  3267|         0|            0|            0|  0.00%|    if reduction == \"none\":\n",
      "  3268|         0|            0|            0|  0.00%|        ret = loss\n",
      "  3269|         0|            0|            0|  0.00%|    elif reduction == \"mean\":\n",
      "  3270|         0|            0|            0|  0.00%|        ret = loss.mean()\n",
      "  3271|         0|            0|            0|  0.00%|    elif reduction == \"sum\":\n",
      "  3272|         0|            0|            0|  0.00%|        ret = loss.sum()\n",
      "  3273|         0|            0|            0|  0.00%|    else:\n",
      "  3274|         0|            0|            0|  0.00%|        ret = input\n",
      "  3275|         0|            0|            0|  0.00%|        raise ValueError(reduction + \" is not valid\")\n",
      "  3276|         0|            0|            0|  0.00%|    return ret\n",
      "  3277|         0|            0|            0|  0.00%|\n",
      "  3278|         0|            0|            0|  0.00%|\n",
      "  3279|         0|            0|            0|  0.00%|def cosine_embedding_loss(\n",
      "  3280|         0|            0|            0|  0.00%|    input1: Tensor,\n",
      "  3281|         0|            0|            0|  0.00%|    input2: Tensor,\n",
      "  3282|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3283|         0|            0|            0|  0.00%|    margin: float = 0,\n",
      "  3284|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3285|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3286|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3287|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3288|         0|            0|            0|  0.00%|    r\"\"\"cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
      "  3289|         0|            0|            0|  0.00%|\n",
      "  3290|         0|            0|            0|  0.00%|    See :class:`~torch.nn.CosineEmbeddingLoss` for details.\n",
      "  3291|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3292|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input1, input2, target):\n",
      "  3293|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3294|         0|            0|            0|  0.00%|            cosine_embedding_loss,\n",
      "  3295|         0|            0|            0|  0.00%|            (input1, input2, target),\n",
      "  3296|         0|            0|            0|  0.00%|            input1,\n",
      "  3297|         0|            0|            0|  0.00%|            input2,\n",
      "  3298|         0|            0|            0|  0.00%|            target,\n",
      "  3299|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3300|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3301|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3302|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3303|         0|            0|            0|  0.00%|        )\n",
      "  3304|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3305|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3306|         0|            0|            0|  0.00%|    else:\n",
      "  3307|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3308|         0|            0|            0|  0.00%|    return torch.cosine_embedding_loss(input1, input2, target, margin, reduction_enum)\n",
      "  3309|         0|            0|            0|  0.00%|\n",
      "  3310|         0|            0|            0|  0.00%|\n",
      "  3311|         0|            0|            0|  0.00%|def multi_margin_loss(\n",
      "  3312|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3313|         0|            0|            0|  0.00%|    target: Tensor,\n",
      "  3314|         0|            0|            0|  0.00%|    p: int = 1,\n",
      "  3315|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  3316|         0|            0|            0|  0.00%|    weight: Optional[Tensor] = None,\n",
      "  3317|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  3318|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  3319|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  3320|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3321|         0|            0|            0|  0.00%|    r\"\"\"multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None,\n",
      "  3322|         0|            0|            0|  0.00%|                          reduce=None, reduction='mean') -> Tensor\n",
      "  3323|         0|            0|            0|  0.00%|\n",
      "  3324|         0|            0|            0|  0.00%|    See :class:`~torch.nn.MultiMarginLoss` for details.\n",
      "  3325|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3326|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, target, weight):\n",
      "  3327|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3328|         0|            0|            0|  0.00%|            multi_margin_loss,\n",
      "  3329|         0|            0|            0|  0.00%|            (input, target, weight),\n",
      "  3330|         0|            0|            0|  0.00%|            input,\n",
      "  3331|         0|            0|            0|  0.00%|            target,\n",
      "  3332|         0|            0|            0|  0.00%|            p=p,\n",
      "  3333|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  3334|         0|            0|            0|  0.00%|            weight=weight,\n",
      "  3335|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  3336|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  3337|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  3338|         0|            0|            0|  0.00%|        )\n",
      "  3339|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  3340|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  3341|         0|            0|            0|  0.00%|    else:\n",
      "  3342|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  3343|         0|            0|            0|  0.00%|    if p != 1 and p != 2:\n",
      "  3344|         0|            0|            0|  0.00%|        raise ValueError(\"only p == 1 and p == 2 supported\")\n",
      "  3345|         0|            0|            0|  0.00%|    if weight is not None:\n",
      "  3346|         0|            0|            0|  0.00%|        if weight.dim() != 1:\n",
      "  3347|         0|            0|            0|  0.00%|            raise ValueError(\"weight must be one-dimensional\")\n",
      "  3348|         0|            0|            0|  0.00%|\n",
      "  3349|         0|            0|            0|  0.00%|    return torch._C._nn.multi_margin_loss(input, target, p, margin, weight, reduction_enum)\n",
      "  3350|         0|            0|            0|  0.00%|\n",
      "  3351|         0|            0|            0|  0.00%|\n",
      "  3352|         0|            0|            0|  0.00%|pixel_shuffle = _add_docstr(\n",
      "  3353|         0|            0|            0|  0.00%|    torch.pixel_shuffle,\n",
      "  3354|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3355|         0|            0|            0|  0.00%|pixel_shuffle(input, upscale_factor) -> Tensor\n",
      "  3356|         0|            0|            0|  0.00%|\n",
      "  3357|         0|            0|            0|  0.00%|Rearranges elements in a tensor of shape :math:`(*, C \\times r^2, H, W)` to a\n",
      "  3358|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \\times r, W \\times r)`, where r is the :attr:`upscale_factor`.\n",
      "  3359|         0|            0|            0|  0.00%|\n",
      "  3360|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelShuffle` for details.\n",
      "  3361|         0|            0|            0|  0.00%|\n",
      "  3362|         0|            0|            0|  0.00%|Args:\n",
      "  3363|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3364|         0|            0|            0|  0.00%|    upscale_factor (int): factor to increase spatial resolution by\n",
      "  3365|         0|            0|            0|  0.00%|\n",
      "  3366|         0|            0|            0|  0.00%|Examples::\n",
      "  3367|         0|            0|            0|  0.00%|\n",
      "  3368|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 9, 4, 4)\n",
      "  3369|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_shuffle(input, 3)\n",
      "  3370|         0|            0|            0|  0.00%|    >>> print(output.size())\n",
      "  3371|         0|            0|            0|  0.00%|    torch.Size([1, 1, 12, 12])\n",
      "  3372|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3373|         0|            0|            0|  0.00%|)\n",
      "  3374|         0|            0|            0|  0.00%|\n",
      "  3375|         0|            0|            0|  0.00%|pixel_unshuffle = _add_docstr(\n",
      "  3376|         0|            0|            0|  0.00%|    torch.pixel_unshuffle,\n",
      "  3377|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3378|         0|            0|            0|  0.00%|pixel_unshuffle(input, downscale_factor) -> Tensor\n",
      "  3379|         0|            0|            0|  0.00%|\n",
      "  3380|         0|            0|            0|  0.00%|Reverses the :class:`~torch.nn.PixelShuffle` operation by rearranging elements in a\n",
      "  3381|         0|            0|            0|  0.00%|tensor of shape :math:`(*, C, H \\times r, W \\times r)` to a tensor of shape\n",
      "  3382|         0|            0|            0|  0.00%|:math:`(*, C \\times r^2, H, W)`, where r is the :attr:`downscale_factor`.\n",
      "  3383|         0|            0|            0|  0.00%|\n",
      "  3384|         0|            0|            0|  0.00%|See :class:`~torch.nn.PixelUnshuffle` for details.\n",
      "  3385|         0|            0|            0|  0.00%|\n",
      "  3386|         0|            0|            0|  0.00%|Args:\n",
      "  3387|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3388|         0|            0|            0|  0.00%|    downscale_factor (int): factor to increase spatial resolution by\n",
      "  3389|         0|            0|            0|  0.00%|\n",
      "  3390|         0|            0|            0|  0.00%|Examples::\n",
      "  3391|         0|            0|            0|  0.00%|\n",
      "  3392|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 1, 12, 12)\n",
      "  3393|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.pixel_unshuffle(input, 3)\n",
      "  3394|         0|            0|            0|  0.00%|    >>> print(output.size())\n",
      "  3395|         0|            0|            0|  0.00%|    torch.Size([1, 9, 4, 4])\n",
      "  3396|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3397|         0|            0|            0|  0.00%|)\n",
      "  3398|         0|            0|            0|  0.00%|\n",
      "  3399|         0|            0|            0|  0.00%|channel_shuffle = _add_docstr(\n",
      "  3400|         0|            0|            0|  0.00%|    torch.channel_shuffle,\n",
      "  3401|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  3402|         0|            0|            0|  0.00%|channel_shuffle(input, groups) -> Tensor\n",
      "  3403|         0|            0|            0|  0.00%|\n",
      "  3404|         0|            0|            0|  0.00%|Divide the channels in a tensor of shape :math:`(*, C , H, W)`\n",
      "  3405|         0|            0|            0|  0.00%|into g groups and rearrange them as :math:`(*, C \\frac g, g, H, W)`,\n",
      "  3406|         0|            0|            0|  0.00%|while keeping the original tensor shape.\n",
      "  3407|         0|            0|            0|  0.00%|\n",
      "  3408|         0|            0|            0|  0.00%|See :class:`~torch.nn.ChannelShuffle` for details.\n",
      "  3409|         0|            0|            0|  0.00%|\n",
      "  3410|         0|            0|            0|  0.00%|Args:\n",
      "  3411|         0|            0|            0|  0.00%|    input (Tensor): the input tensor\n",
      "  3412|         0|            0|            0|  0.00%|    groups (int): number of groups to divide channels in and rearrange.\n",
      "  3413|         0|            0|            0|  0.00%|\n",
      "  3414|         0|            0|            0|  0.00%|Examples::\n",
      "  3415|         0|            0|            0|  0.00%|\n",
      "  3416|         0|            0|            0|  0.00%|    >>> input = torch.randn(1, 4, 2, 2)\n",
      "  3417|         0|            0|            0|  0.00%|    >>> print(input)\n",
      "  3418|         0|            0|            0|  0.00%|    [[[[1, 2],\n",
      "  3419|         0|            0|            0|  0.00%|       [3, 4]],\n",
      "  3420|         0|            0|            0|  0.00%|      [[5, 6],\n",
      "  3421|         0|            0|            0|  0.00%|       [7, 8]],\n",
      "  3422|         0|            0|            0|  0.00%|      [[9, 10],\n",
      "  3423|         0|            0|            0|  0.00%|       [11, 12]],\n",
      "  3424|         0|            0|            0|  0.00%|      [[13, 14],\n",
      "  3425|         0|            0|            0|  0.00%|       [15, 16]],\n",
      "  3426|         0|            0|            0|  0.00%|     ]]\n",
      "  3427|         0|            0|            0|  0.00%|    >>> output = torch.nn.functional.channel_shuffle(input, 2)\n",
      "  3428|         0|            0|            0|  0.00%|    >>> print(output)\n",
      "  3429|         0|            0|            0|  0.00%|    [[[[1, 2],\n",
      "  3430|         0|            0|            0|  0.00%|       [3, 4]],\n",
      "  3431|         0|            0|            0|  0.00%|      [[9, 10],\n",
      "  3432|         0|            0|            0|  0.00%|       [11, 12]],\n",
      "  3433|         0|            0|            0|  0.00%|      [[5, 6],\n",
      "  3434|         0|            0|            0|  0.00%|       [7, 8]],\n",
      "  3435|         0|            0|            0|  0.00%|      [[13, 14],\n",
      "  3436|         0|            0|            0|  0.00%|       [15, 16]],\n",
      "  3437|         0|            0|            0|  0.00%|     ]]\n",
      "  3438|         0|            0|            0|  0.00%|\"\"\",\n",
      "  3439|         0|            0|            0|  0.00%|)\n",
      "  3440|         0|            0|            0|  0.00%|\n",
      "  3441|         0|            0|            0|  0.00%|\n",
      "  3442|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3443|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = \"nearest\", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3444|         0|            0|            0|  0.00%|    pass\n",
      "  3445|         0|            0|            0|  0.00%|\n",
      "  3446|         0|            0|            0|  0.00%|\n",
      "  3447|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3448|         0|            0|            0|  0.00%|def upsample(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None, mode: str = \"nearest\", align_corners: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3449|         0|            0|            0|  0.00%|    pass\n",
      "  3450|         0|            0|            0|  0.00%|\n",
      "  3451|         0|            0|            0|  0.00%|\n",
      "  3452|         0|            0|            0|  0.00%|def upsample(input, size=None, scale_factor=None, mode=\"nearest\", align_corners=None):  # noqa: F811\n",
      "  3453|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input to either the given :attr:`size` or the given\n",
      "  3454|         0|            0|            0|  0.00%|    :attr:`scale_factor`\n",
      "  3455|         0|            0|            0|  0.00%|\n",
      "  3456|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3457|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3458|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(...)``.\n",
      "  3459|         0|            0|            0|  0.00%|\n",
      "  3460|         0|            0|            0|  0.00%|    Note:\n",
      "  3461|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3462|         0|            0|            0|  0.00%|\n",
      "  3463|         0|            0|            0|  0.00%|    The algorithm used for upsampling is determined by :attr:`mode`.\n",
      "  3464|         0|            0|            0|  0.00%|\n",
      "  3465|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric upsampling are supported, i.e.\n",
      "  3466|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.\n",
      "  3467|         0|            0|            0|  0.00%|\n",
      "  3468|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:\n",
      "  3469|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.\n",
      "  3470|         0|            0|            0|  0.00%|\n",
      "  3471|         0|            0|            0|  0.00%|    The modes available for upsampling are: `nearest`, `linear` (3D-only),\n",
      "  3472|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only)\n",
      "  3473|         0|            0|            0|  0.00%|\n",
      "  3474|         0|            0|            0|  0.00%|    Args:\n",
      "  3475|         0|            0|            0|  0.00%|        input (Tensor): the input tensor\n",
      "  3476|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):\n",
      "  3477|         0|            0|            0|  0.00%|            output spatial size.\n",
      "  3478|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. Has to match input size if it is a tuple.\n",
      "  3479|         0|            0|            0|  0.00%|        mode (string): algorithm used for upsampling:\n",
      "  3480|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |\n",
      "  3481|         0|            0|            0|  0.00%|            ``'trilinear'``. Default: ``'nearest'``\n",
      "  3482|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3483|         0|            0|            0|  0.00%|            input and output as squares rather than points.\n",
      "  3484|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the\n",
      "  3485|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.\n",
      "  3486|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner\n",
      "  3487|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding\n",
      "  3488|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size\n",
      "  3489|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`\n",
      "  3490|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.\n",
      "  3491|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3492|         0|            0|            0|  0.00%|\n",
      "  3493|         0|            0|            0|  0.00%|    .. note::\n",
      "  3494|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce\n",
      "  3495|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.\n",
      "  3496|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot\n",
      "  3497|         0|            0|            0|  0.00%|        when displaying the image.\n",
      "  3498|         0|            0|            0|  0.00%|\n",
      "  3499|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3500|         0|            0|            0|  0.00%|        With ``align_corners = True``, the linearly interpolating modes\n",
      "  3501|         0|            0|            0|  0.00%|        (`linear`, `bilinear`, and `trilinear`) don't proportionally align the\n",
      "  3502|         0|            0|            0|  0.00%|        output and input pixels, and thus the output values can depend on the\n",
      "  3503|         0|            0|            0|  0.00%|        input size. This was the default behavior for these modes up to version\n",
      "  3504|         0|            0|            0|  0.00%|        0.3.1. Since then, the default behavior is ``align_corners = False``.\n",
      "  3505|         0|            0|            0|  0.00%|        See :class:`~torch.nn.Upsample` for concrete examples on how this\n",
      "  3506|         0|            0|            0|  0.00%|        affects the outputs.\n",
      "  3507|         0|            0|            0|  0.00%|\n",
      "  3508|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3509|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3510|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode, align_corners)\n",
      "  3511|         0|            0|            0|  0.00%|\n",
      "  3512|         0|            0|            0|  0.00%|\n",
      "  3513|         0|            0|            0|  0.00%|upsample.__doc__ = upsample.__doc__.format(**reproducibility_notes)\n",
      "  3514|         0|            0|            0|  0.00%|\n",
      "  3515|         0|            0|            0|  0.00%|\n",
      "  3516|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3517|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3518|         0|            0|            0|  0.00%|    pass\n",
      "  3519|         0|            0|            0|  0.00%|\n",
      "  3520|         0|            0|            0|  0.00%|\n",
      "  3521|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3522|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3523|         0|            0|            0|  0.00%|    pass\n",
      "  3524|         0|            0|            0|  0.00%|\n",
      "  3525|         0|            0|            0|  0.00%|\n",
      "  3526|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3527|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3528|         0|            0|            0|  0.00%|    pass\n",
      "  3529|         0|            0|            0|  0.00%|\n",
      "  3530|         0|            0|            0|  0.00%|\n",
      "  3531|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3532|         0|            0|            0|  0.00%|def interpolate(  # noqa: F811\n",
      "  3533|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3534|         0|            0|            0|  0.00%|    size: Optional[List[int]] = None,\n",
      "  3535|         0|            0|            0|  0.00%|    scale_factor: Optional[float] = None,\n",
      "  3536|         0|            0|            0|  0.00%|    mode: str = \"nearest\",\n",
      "  3537|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,\n",
      "  3538|         0|            0|            0|  0.00%|    recompute_scale_factor: Optional[bool] = None,\n",
      "  3539|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3540|         0|            0|            0|  0.00%|    pass\n",
      "  3541|         0|            0|            0|  0.00%|\n",
      "  3542|         0|            0|            0|  0.00%|def interpolate(input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> Tensor:  # noqa: F811\n",
      "  3543|         0|            0|            0|  0.00%|    r\"\"\"Down/up samples the input to either the given :attr:`size` or the given\n",
      "  3544|         0|            0|            0|  0.00%|    :attr:`scale_factor`\n",
      "  3545|         0|            0|            0|  0.00%|\n",
      "  3546|         0|            0|            0|  0.00%|    The algorithm used for interpolation is determined by :attr:`mode`.\n",
      "  3547|         0|            0|            0|  0.00%|\n",
      "  3548|         0|            0|            0|  0.00%|    Currently temporal, spatial and volumetric sampling are supported, i.e.\n",
      "  3549|         0|            0|            0|  0.00%|    expected inputs are 3-D, 4-D or 5-D in shape.\n",
      "  3550|         0|            0|            0|  0.00%|\n",
      "  3551|         0|            0|            0|  0.00%|    The input dimensions are interpreted in the form:\n",
      "  3552|         0|            0|            0|  0.00%|    `mini-batch x channels x [optional depth] x [optional height] x width`.\n",
      "  3553|         0|            0|            0|  0.00%|\n",
      "  3554|         0|            0|            0|  0.00%|    The modes available for resizing are: `nearest`, `linear` (3D-only),\n",
      "  3555|         0|            0|            0|  0.00%|    `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`\n",
      "  3556|         0|            0|            0|  0.00%|\n",
      "  3557|         0|            0|            0|  0.00%|    Args:\n",
      "  3558|         0|            0|            0|  0.00%|        input (Tensor): the input tensor\n",
      "  3559|         0|            0|            0|  0.00%|        size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]):\n",
      "  3560|         0|            0|            0|  0.00%|            output spatial size.\n",
      "  3561|         0|            0|            0|  0.00%|        scale_factor (float or Tuple[float]): multiplier for spatial size. If `scale_factor` is a tuple,\n",
      "  3562|         0|            0|            0|  0.00%|            its length has to match `input.dim()`.\n",
      "  3563|         0|            0|            0|  0.00%|        mode (str): algorithm used for upsampling:\n",
      "  3564|         0|            0|            0|  0.00%|            ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |\n",
      "  3565|         0|            0|            0|  0.00%|            ``'trilinear'`` | ``'area'``. Default: ``'nearest'``\n",
      "  3566|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3567|         0|            0|            0|  0.00%|            input and output as squares rather than points.\n",
      "  3568|         0|            0|            0|  0.00%|            If set to ``True``, the input and output tensors are aligned by the\n",
      "  3569|         0|            0|            0|  0.00%|            center points of their corner pixels, preserving the values at the corner pixels.\n",
      "  3570|         0|            0|            0|  0.00%|            If set to ``False``, the input and output tensors are aligned by the corner\n",
      "  3571|         0|            0|            0|  0.00%|            points of their corner pixels, and the interpolation uses edge value padding\n",
      "  3572|         0|            0|            0|  0.00%|            for out-of-boundary values, making this operation *independent* of input size\n",
      "  3573|         0|            0|            0|  0.00%|            when :attr:`scale_factor` is kept the same. This only has an effect when :attr:`mode`\n",
      "  3574|         0|            0|            0|  0.00%|            is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.\n",
      "  3575|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3576|         0|            0|            0|  0.00%|        recompute_scale_factor (bool, optional): recompute the scale_factor for use in the\n",
      "  3577|         0|            0|            0|  0.00%|            interpolation calculation. If `recompute_scale_factor` is ``True``, then\n",
      "  3578|         0|            0|            0|  0.00%|            `scale_factor` must be passed in and `scale_factor` is used to compute the\n",
      "  3579|         0|            0|            0|  0.00%|            output `size`. The computed output `size` will be used to infer new scales for\n",
      "  3580|         0|            0|            0|  0.00%|            the interpolation. Note that when `scale_factor` is floating-point, it may differ\n",
      "  3581|         0|            0|            0|  0.00%|            from the recomputed `scale_factor` due to rounding and precision issues.\n",
      "  3582|         0|            0|            0|  0.00%|            If `recomputed_scale_factor` is ``False``, then `size` or `scale_factor` will\n",
      "  3583|         0|            0|            0|  0.00%|            be used directly for interpolation.\n",
      "  3584|         0|            0|            0|  0.00%|\n",
      "  3585|         0|            0|            0|  0.00%|    .. note::\n",
      "  3586|         0|            0|            0|  0.00%|        With ``mode='bicubic'``, it's possible to cause overshoot, in other words it can produce\n",
      "  3587|         0|            0|            0|  0.00%|        negative values or values greater than 255 for images.\n",
      "  3588|         0|            0|            0|  0.00%|        Explicitly call ``result.clamp(min=0, max=255)`` if you want to reduce the overshoot\n",
      "  3589|         0|            0|            0|  0.00%|        when displaying the image.\n",
      "  3590|         0|            0|            0|  0.00%|\n",
      "  3591|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3592|         0|            0|            0|  0.00%|        With ``align_corners = True``, the linearly interpolating modes\n",
      "  3593|         0|            0|            0|  0.00%|        (`linear`, `bilinear`, and `trilinear`) don't proportionally align the\n",
      "  3594|         0|            0|            0|  0.00%|        output and input pixels, and thus the output values can depend on the\n",
      "  3595|         0|            0|            0|  0.00%|        input size. This was the default behavior for these modes up to version\n",
      "  3596|         0|            0|            0|  0.00%|        0.3.1. Since then, the default behavior is ``align_corners = False``.\n",
      "  3597|         0|            0|            0|  0.00%|        See :class:`~torch.nn.Upsample` for concrete examples on how this\n",
      "  3598|         0|            0|            0|  0.00%|        affects the outputs.\n",
      "  3599|         0|            0|            0|  0.00%|\n",
      "  3600|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3601|         0|            0|            0|  0.00%|        When scale_factor is specified, if recompute_scale_factor=True,\n",
      "  3602|         0|            0|            0|  0.00%|        scale_factor is used to compute the output_size which will then\n",
      "  3603|         0|            0|            0|  0.00%|        be used to infer new scales for the interpolation.\n",
      "  3604|         0|            0|            0|  0.00%|        The default behavior for recompute_scale_factor changed to False\n",
      "  3605|         0|            0|            0|  0.00%|        in 1.6.0, and scale_factor is used in the interpolation\n",
      "  3606|         0|            0|            0|  0.00%|        calculation.\n",
      "  3607|         0|            0|            0|  0.00%|\n",
      "  3608|         0|            0|            0|  0.00%|    Note:\n",
      "  3609|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3610|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3611|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  3612|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3613|         0|            0|            0|  0.00%|            interpolate,\n",
      "  3614|         0|            0|            0|  0.00%|            (input,),\n",
      "  3615|         0|            0|            0|  0.00%|            input,\n",
      "  3616|         0|            0|            0|  0.00%|            size=size,\n",
      "  3617|         0|            0|            0|  0.00%|            scale_factor=scale_factor,\n",
      "  3618|         0|            0|            0|  0.00%|            mode=mode,\n",
      "  3619|         0|            0|            0|  0.00%|            align_corners=align_corners,\n",
      "  3620|         0|            0|            0|  0.00%|            recompute_scale_factor=recompute_scale_factor,\n",
      "  3621|         0|            0|            0|  0.00%|        )\n",
      "  3622|         0|            0|            0|  0.00%|\n",
      "  3623|         0|            0|            0|  0.00%|    if mode in (\"nearest\", \"area\"):\n",
      "  3624|         0|            0|            0|  0.00%|        if align_corners is not None:\n",
      "  3625|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  3626|         0|            0|            0|  0.00%|                \"align_corners option can only be set with the \"\n",
      "  3627|         0|            0|            0|  0.00%|                \"interpolating modes: linear | bilinear | bicubic | trilinear\"\n",
      "  3628|         0|            0|            0|  0.00%|            )\n",
      "  3629|         0|            0|            0|  0.00%|    else:\n",
      "  3630|         0|            0|            0|  0.00%|        if align_corners is None:\n",
      "  3631|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  3632|         0|            0|            0|  0.00%|                \"Default upsampling behavior when mode={} is changed \"\n",
      "  3633|         0|            0|            0|  0.00%|                \"to align_corners=False since 0.4.0. Please specify \"\n",
      "  3634|         0|            0|            0|  0.00%|                \"align_corners=True if the old behavior is desired. \"\n",
      "  3635|         0|            0|            0|  0.00%|                \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "  3636|         0|            0|            0|  0.00%|            )\n",
      "  3637|         0|            0|            0|  0.00%|            align_corners = False\n",
      "  3638|         0|            0|            0|  0.00%|\n",
      "  3639|         0|            0|            0|  0.00%|    dim = input.dim() - 2  # Number of spatial dimensions.\n",
      "  3640|         0|            0|            0|  0.00%|\n",
      "  3641|         0|            0|            0|  0.00%|    # Process size and scale_factor.  Validate that exactly one is set.\n",
      "  3642|         0|            0|            0|  0.00%|    # Validate its length if it is a list, or expand it if it is a scalar.\n",
      "  3643|         0|            0|            0|  0.00%|    # After this block, exactly one of output_size and scale_factors will\n",
      "  3644|         0|            0|            0|  0.00%|    # be non-None, and it will be a list (or tuple).\n",
      "  3645|         0|            0|            0|  0.00%|    if size is not None and scale_factor is not None:\n",
      "  3646|         0|            0|            0|  0.00%|        raise ValueError(\"only one of size or scale_factor should be defined\")\n",
      "  3647|         0|            0|            0|  0.00%|    elif size is not None:\n",
      "  3648|         0|            0|            0|  0.00%|        assert scale_factor is None\n",
      "  3649|         0|            0|            0|  0.00%|        scale_factors = None\n",
      "  3650|         0|            0|            0|  0.00%|        if isinstance(size, (list, tuple)):\n",
      "  3651|         0|            0|            0|  0.00%|            if len(size) != dim:\n",
      "  3652|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "  3653|         0|            0|            0|  0.00%|                    \"size shape must match input shape. \" \"Input is {}D, size is {}\".format(dim, len(size))\n",
      "  3654|         0|            0|            0|  0.00%|                )\n",
      "  3655|         0|            0|            0|  0.00%|            output_size = size\n",
      "  3656|         0|            0|            0|  0.00%|        else:\n",
      "  3657|         0|            0|            0|  0.00%|            output_size = [size for _ in range(dim)]\n",
      "  3658|         0|            0|            0|  0.00%|    elif scale_factor is not None:\n",
      "  3659|         0|            0|            0|  0.00%|        assert size is None\n",
      "  3660|         0|            0|            0|  0.00%|        output_size = None\n",
      "  3661|         0|            0|            0|  0.00%|        if isinstance(scale_factor, (list, tuple)):\n",
      "  3662|         0|            0|            0|  0.00%|            if len(scale_factor) != dim:\n",
      "  3663|         0|            0|            0|  0.00%|                raise ValueError(\n",
      "  3664|         0|            0|            0|  0.00%|                    \"scale_factor shape must match input shape. \"\n",
      "  3665|         0|            0|            0|  0.00%|                    \"Input is {}D, scale_factor is {}\".format(dim, len(scale_factor))\n",
      "  3666|         0|            0|            0|  0.00%|                )\n",
      "  3667|         0|            0|            0|  0.00%|            scale_factors = scale_factor\n",
      "  3668|         0|            0|            0|  0.00%|        else:\n",
      "  3669|         0|            0|            0|  0.00%|            scale_factors = [scale_factor for _ in range(dim)]\n",
      "  3670|         0|            0|            0|  0.00%|    else:\n",
      "  3671|         0|            0|            0|  0.00%|        raise ValueError(\"either size or scale_factor should be defined\")\n",
      "  3672|         0|            0|            0|  0.00%|\n",
      "  3673|         0|            0|            0|  0.00%|    if recompute_scale_factor is None:\n",
      "  3674|         0|            0|            0|  0.00%|        # only warn when the scales have floating values since\n",
      "  3675|         0|            0|            0|  0.00%|        # the result for ints is the same with/without recompute_scale_factor\n",
      "  3676|         0|            0|            0|  0.00%|        if scale_factors is not None:\n",
      "  3677|         0|            0|            0|  0.00%|            for scale in scale_factors:\n",
      "  3678|         0|            0|            0|  0.00%|                if math.floor(scale) != scale:\n",
      "  3679|         0|            0|            0|  0.00%|                    warnings.warn(\n",
      "  3680|         0|            0|            0|  0.00%|                        \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "  3681|         0|            0|            0|  0.00%|                        \"in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, \"\n",
      "  3682|         0|            0|            0|  0.00%|                        \"instead of relying on the computed output size. \"\n",
      "  3683|         0|            0|            0|  0.00%|                        \"If you wish to restore the old behavior, please set recompute_scale_factor=True. \"\n",
      "  3684|         0|            0|            0|  0.00%|                        \"See the documentation of nn.Upsample for details. \"\n",
      "  3685|         0|            0|            0|  0.00%|                    )\n",
      "  3686|         0|            0|            0|  0.00%|                    break\n",
      "  3687|         0|            0|            0|  0.00%|    elif recompute_scale_factor and size is not None:\n",
      "  3688|         0|            0|            0|  0.00%|        raise ValueError(\"recompute_scale_factor is not meaningful with an explicit size.\")\n",
      "  3689|         0|            0|            0|  0.00%|\n",
      "  3690|         0|            0|            0|  0.00%|    # \"area\" mode always requires an explicit size rather than scale factor.\n",
      "  3691|         0|            0|            0|  0.00%|    # Re-use the recompute_scale_factor code path.\n",
      "  3692|         0|            0|            0|  0.00%|    if mode == \"area\" and output_size is None:\n",
      "  3693|         0|            0|            0|  0.00%|        recompute_scale_factor = True\n",
      "  3694|         0|            0|            0|  0.00%|\n",
      "  3695|         0|            0|            0|  0.00%|    if recompute_scale_factor is not None and recompute_scale_factor:\n",
      "  3696|         0|            0|            0|  0.00%|        # We compute output_size here, then un-set scale_factors.\n",
      "  3697|         0|            0|            0|  0.00%|        # The C++ code will recompute it based on the (integer) output size.\n",
      "  3698|         0|            0|            0|  0.00%|        if not torch.jit.is_scripting() and torch._C._get_tracing_state():\n",
      "  3699|         0|            0|            0|  0.00%|            # make scale_factor a tensor in tracing so constant doesn't get baked in\n",
      "  3700|         0|            0|            0|  0.00%|            output_size = [\n",
      "  3701|         0|            0|            0|  0.00%|                (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
      "  3702|         0|            0|            0|  0.00%|                for i in range(dim)\n",
      "  3703|         0|            0|            0|  0.00%|            ]\n",
      "  3704|         0|            0|            0|  0.00%|        else:\n",
      "  3705|         0|            0|            0|  0.00%|            assert scale_factors is not None\n",
      "  3706|         0|            0|            0|  0.00%|            output_size = [int(math.floor(float(input.size(i + 2)) * scale_factors[i])) for i in range(dim)]\n",
      "  3707|         0|            0|            0|  0.00%|        scale_factors = None\n",
      "  3708|         0|            0|            0|  0.00%|\n",
      "  3709|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"nearest\":\n",
      "  3710|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)\n",
      "  3711|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"nearest\":\n",
      "  3712|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n",
      "  3713|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"nearest\":\n",
      "  3714|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)\n",
      "  3715|         0|            0|            0|  0.00%|\n",
      "  3716|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"area\":\n",
      "  3717|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3718|         0|            0|            0|  0.00%|        return adaptive_avg_pool1d(input, output_size)\n",
      "  3719|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"area\":\n",
      "  3720|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3721|         0|            0|            0|  0.00%|        return adaptive_avg_pool2d(input, output_size)\n",
      "  3722|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"area\":\n",
      "  3723|         0|            0|            0|  0.00%|        assert output_size is not None\n",
      "  3724|         0|            0|            0|  0.00%|        return adaptive_avg_pool3d(input, output_size)\n",
      "  3725|         0|            0|            0|  0.00%|\n",
      "  3726|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"linear\":\n",
      "  3727|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3728|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_linear1d(input, output_size, align_corners, scale_factors)\n",
      "  3729|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"bilinear\":\n",
      "  3730|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3731|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)\n",
      "  3732|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"trilinear\":\n",
      "  3733|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3734|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_trilinear3d(input, output_size, align_corners, scale_factors)\n",
      "  3735|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"bicubic\":\n",
      "  3736|         0|            0|            0|  0.00%|        assert align_corners is not None\n",
      "  3737|         0|            0|            0|  0.00%|        return torch._C._nn.upsample_bicubic2d(input, output_size, align_corners, scale_factors)\n",
      "  3738|         0|            0|            0|  0.00%|\n",
      "  3739|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"bilinear\":\n",
      "  3740|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 3D input, but bilinear mode needs 4D input\")\n",
      "  3741|         0|            0|            0|  0.00%|    if input.dim() == 3 and mode == \"trilinear\":\n",
      "  3742|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 3D input, but trilinear mode needs 5D input\")\n",
      "  3743|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"linear\":\n",
      "  3744|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 4D input, but linear mode needs 3D input\")\n",
      "  3745|         0|            0|            0|  0.00%|    if input.dim() == 4 and mode == \"trilinear\":\n",
      "  3746|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 4D input, but trilinear mode needs 5D input\")\n",
      "  3747|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"linear\":\n",
      "  3748|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 5D input, but linear mode needs 3D input\")\n",
      "  3749|         0|            0|            0|  0.00%|    if input.dim() == 5 and mode == \"bilinear\":\n",
      "  3750|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Got 5D input, but bilinear mode needs 4D input\")\n",
      "  3751|         0|            0|            0|  0.00%|\n",
      "  3752|         0|            0|            0|  0.00%|    raise NotImplementedError(\n",
      "  3753|         0|            0|            0|  0.00%|        \"Input Error: Only 3D, 4D and 5D input Tensors supported\"\n",
      "  3754|         0|            0|            0|  0.00%|        \" (got {}D) for the modes: nearest | linear | bilinear | bicubic | trilinear\"\n",
      "  3755|         0|            0|            0|  0.00%|        \" (got {})\".format(input.dim(), mode)\n",
      "  3756|         0|            0|            0|  0.00%|    )\n",
      "  3757|         0|            0|            0|  0.00%|\n",
      "  3758|         0|            0|            0|  0.00%|\n",
      "  3759|         0|            0|            0|  0.00%|interpolate.__doc__ = interpolate.__doc__.format(**reproducibility_notes)\n",
      "  3760|         0|            0|            0|  0.00%|\n",
      "  3761|         0|            0|            0|  0.00%|\n",
      "  3762|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3763|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811\n",
      "  3764|         0|            0|            0|  0.00%|    pass\n",
      "  3765|         0|            0|            0|  0.00%|\n",
      "  3766|         0|            0|            0|  0.00%|\n",
      "  3767|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3768|         0|            0|            0|  0.00%|def upsample_nearest(input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None) -> Tensor:  # noqa: F811\n",
      "  3769|         0|            0|            0|  0.00%|    pass\n",
      "  3770|         0|            0|            0|  0.00%|\n",
      "  3771|         0|            0|            0|  0.00%|\n",
      "  3772|         0|            0|            0|  0.00%|def upsample_nearest(input, size=None, scale_factor=None):  # noqa: F811\n",
      "  3773|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input, using nearest neighbours' pixel values.\n",
      "  3774|         0|            0|            0|  0.00%|\n",
      "  3775|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3776|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3777|         0|            0|            0|  0.00%|        This is equivalent with ``nn.functional.interpolate(..., mode='nearest')``.\n",
      "  3778|         0|            0|            0|  0.00%|\n",
      "  3779|         0|            0|            0|  0.00%|    Currently spatial and volumetric upsampling are supported (i.e. expected\n",
      "  3780|         0|            0|            0|  0.00%|    inputs are 4 or 5 dimensional).\n",
      "  3781|         0|            0|            0|  0.00%|\n",
      "  3782|         0|            0|            0|  0.00%|    Args:\n",
      "  3783|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  3784|         0|            0|            0|  0.00%|        size (int or Tuple[int, int] or Tuple[int, int, int]): output spatia\n",
      "  3785|         0|            0|            0|  0.00%|            size.\n",
      "  3786|         0|            0|            0|  0.00%|        scale_factor (int): multiplier for spatial size. Has to be an integer.\n",
      "  3787|         0|            0|            0|  0.00%|\n",
      "  3788|         0|            0|            0|  0.00%|    Note:\n",
      "  3789|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3790|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3791|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default\n",
      "  3792|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3793|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode=\"nearest\")\n",
      "  3794|         0|            0|            0|  0.00%|\n",
      "  3795|         0|            0|            0|  0.00%|\n",
      "  3796|         0|            0|            0|  0.00%|upsample_nearest.__doc__ = upsample_nearest.__doc__.format(**reproducibility_notes)\n",
      "  3797|         0|            0|            0|  0.00%|\n",
      "  3798|         0|            0|            0|  0.00%|\n",
      "  3799|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3800|         0|            0|            0|  0.00%|def upsample_bilinear(\n",
      "  3801|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[float] = None\n",
      "  3802|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3803|         0|            0|            0|  0.00%|    pass\n",
      "  3804|         0|            0|            0|  0.00%|\n",
      "  3805|         0|            0|            0|  0.00%|\n",
      "  3806|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3807|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3808|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[float] = None\n",
      "  3809|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3810|         0|            0|            0|  0.00%|    pass\n",
      "  3811|         0|            0|            0|  0.00%|\n",
      "  3812|         0|            0|            0|  0.00%|\n",
      "  3813|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3814|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3815|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None\n",
      "  3816|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3817|         0|            0|            0|  0.00%|    pass\n",
      "  3818|         0|            0|            0|  0.00%|\n",
      "  3819|         0|            0|            0|  0.00%|\n",
      "  3820|         0|            0|            0|  0.00%|@_overload  # noqa: F811\n",
      "  3821|         0|            0|            0|  0.00%|def upsample_bilinear(  # noqa: F811\n",
      "  3822|         0|            0|            0|  0.00%|    input: Tensor, size: Optional[List[int]] = None, scale_factor: Optional[List[float]] = None\n",
      "  3823|         0|            0|            0|  0.00%|) -> Tensor:  # noqa: F811\n",
      "  3824|         0|            0|            0|  0.00%|    pass\n",
      "  3825|         0|            0|            0|  0.00%|\n",
      "  3826|         0|            0|            0|  0.00%|\n",
      "  3827|         0|            0|            0|  0.00%|def upsample_bilinear(input, size=None, scale_factor=None):  # noqa: F811\n",
      "  3828|         0|            0|            0|  0.00%|    r\"\"\"Upsamples the input, using bilinear upsampling.\n",
      "  3829|         0|            0|            0|  0.00%|\n",
      "  3830|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3831|         0|            0|            0|  0.00%|        This function is deprecated in favor of :func:`torch.nn.functional.interpolate`.\n",
      "  3832|         0|            0|            0|  0.00%|        This is equivalent with\n",
      "  3833|         0|            0|            0|  0.00%|        ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.\n",
      "  3834|         0|            0|            0|  0.00%|\n",
      "  3835|         0|            0|            0|  0.00%|    Expected inputs are spatial (4 dimensional). Use `upsample_trilinear` fo\n",
      "  3836|         0|            0|            0|  0.00%|    volumetric (5 dimensional) inputs.\n",
      "  3837|         0|            0|            0|  0.00%|\n",
      "  3838|         0|            0|            0|  0.00%|    Args:\n",
      "  3839|         0|            0|            0|  0.00%|        input (Tensor): input\n",
      "  3840|         0|            0|            0|  0.00%|        size (int or Tuple[int, int]): output spatial size.\n",
      "  3841|         0|            0|            0|  0.00%|        scale_factor (int or Tuple[int, int]): multiplier for spatial size\n",
      "  3842|         0|            0|            0|  0.00%|\n",
      "  3843|         0|            0|            0|  0.00%|    Note:\n",
      "  3844|         0|            0|            0|  0.00%|        {backward_reproducibility_note}\n",
      "  3845|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3846|         0|            0|            0|  0.00%|    # DeprecationWarning is ignored by default\n",
      "  3847|         0|            0|            0|  0.00%|    warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  3848|         0|            0|            0|  0.00%|    return interpolate(input, size, scale_factor, mode=\"bilinear\", align_corners=True)\n",
      "  3849|         0|            0|            0|  0.00%|\n",
      "  3850|         0|            0|            0|  0.00%|\n",
      "  3851|         0|            0|            0|  0.00%|upsample_bilinear.__doc__ = upsample_bilinear.__doc__.format(**reproducibility_notes)\n",
      "  3852|         0|            0|            0|  0.00%|\n",
      "  3853|         0|            0|            0|  0.00%|GRID_SAMPLE_INTERPOLATION_MODES = {\n",
      "  3854|         0|            0|            0|  0.00%|    \"bilinear\": 0,\n",
      "  3855|         0|            0|            0|  0.00%|    \"nearest\": 1,\n",
      "  3856|         0|            0|            0|  0.00%|    \"bicubic\": 2,\n",
      "  3857|         0|            0|            0|  0.00%|}\n",
      "  3858|         0|            0|            0|  0.00%|\n",
      "  3859|         0|            0|            0|  0.00%|GRID_SAMPLE_PADDING_MODES = {\n",
      "  3860|         0|            0|            0|  0.00%|    \"zeros\": 0,\n",
      "  3861|         0|            0|            0|  0.00%|    \"border\": 1,\n",
      "  3862|         0|            0|            0|  0.00%|    \"reflection\": 2,\n",
      "  3863|         0|            0|            0|  0.00%|}\n",
      "  3864|         0|            0|            0|  0.00%|\n",
      "  3865|         0|            0|            0|  0.00%|\n",
      "  3866|         0|            0|            0|  0.00%|def grid_sample(\n",
      "  3867|         0|            0|            0|  0.00%|    input: Tensor,\n",
      "  3868|         0|            0|            0|  0.00%|    grid: Tensor,\n",
      "  3869|         0|            0|            0|  0.00%|    mode: str = \"bilinear\",\n",
      "  3870|         0|            0|            0|  0.00%|    padding_mode: str = \"zeros\",\n",
      "  3871|         0|            0|            0|  0.00%|    align_corners: Optional[bool] = None,\n",
      "  3872|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  3873|         0|            0|            0|  0.00%|    r\"\"\"Given an :attr:`input` and a flow-field :attr:`grid`, computes the\n",
      "  3874|         0|            0|            0|  0.00%|    ``output`` using :attr:`input` values and pixel locations from :attr:`grid`.\n",
      "  3875|         0|            0|            0|  0.00%|\n",
      "  3876|         0|            0|            0|  0.00%|    Currently, only spatial (4-D) and volumetric (5-D) :attr:`input` are\n",
      "  3877|         0|            0|            0|  0.00%|    supported.\n",
      "  3878|         0|            0|            0|  0.00%|\n",
      "  3879|         0|            0|            0|  0.00%|    In the spatial (4-D) case, for :attr:`input` with shape\n",
      "  3880|         0|            0|            0|  0.00%|    :math:`(N, C, H_\\text{in}, W_\\text{in})` and :attr:`grid` with shape\n",
      "  3881|         0|            0|            0|  0.00%|    :math:`(N, H_\\text{out}, W_\\text{out}, 2)`, the output will have shape\n",
      "  3882|         0|            0|            0|  0.00%|    :math:`(N, C, H_\\text{out}, W_\\text{out})`.\n",
      "  3883|         0|            0|            0|  0.00%|\n",
      "  3884|         0|            0|            0|  0.00%|    For each output location ``output[n, :, h, w]``, the size-2 vector\n",
      "  3885|         0|            0|            0|  0.00%|    ``grid[n, h, w]`` specifies :attr:`input` pixel locations ``x`` and ``y``,\n",
      "  3886|         0|            0|            0|  0.00%|    which are used to interpolate the output value ``output[n, :, h, w]``.\n",
      "  3887|         0|            0|            0|  0.00%|    In the case of 5D inputs, ``grid[n, d, h, w]`` specifies the\n",
      "  3888|         0|            0|            0|  0.00%|    ``x``, ``y``, ``z`` pixel locations for interpolating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3889|         0|            0|            0|  0.00%|    ``output[n, :, d, h, w]``. :attr:`mode` argument specifies ``nearest`` or\n",
      "  3890|         0|            0|            0|  0.00%|    ``bilinear`` interpolation method to sample the input pixels.\n",
      "  3891|         0|            0|            0|  0.00%|\n",
      "  3892|         0|            0|            0|  0.00%|    :attr:`grid` specifies the sampling pixel locations normalized by the\n",
      "  3893|         0|            0|            0|  0.00%|    :attr:`input` spatial dimensions. Therefore, it should have most values in\n",
      "  3894|         0|            0|            0|  0.00%|    the range of ``[-1, 1]``. For example, values ``x = -1, y = -1`` is the\n",
      "  3895|         0|            0|            0|  0.00%|    left-top pixel of :attr:`input`, and values  ``x = 1, y = 1`` is the\n",
      "  3896|         0|            0|            0|  0.00%|    right-bottom pixel of :attr:`input`.\n",
      "  3897|         0|            0|            0|  0.00%|\n",
      "  3898|         0|            0|            0|  0.00%|    If :attr:`grid` has values outside the range of ``[-1, 1]``, the corresponding\n",
      "  3899|         0|            0|            0|  0.00%|    outputs are handled as defined by :attr:`padding_mode`. Options are\n",
      "  3900|         0|            0|            0|  0.00%|\n",
      "  3901|         0|            0|            0|  0.00%|        * ``padding_mode=\"zeros\"``: use ``0`` for out-of-bound grid locations,\n",
      "  3902|         0|            0|            0|  0.00%|        * ``padding_mode=\"border\"``: use border values for out-of-bound grid locations,\n",
      "  3903|         0|            0|            0|  0.00%|        * ``padding_mode=\"reflection\"``: use values at locations reflected by\n",
      "  3904|         0|            0|            0|  0.00%|          the border for out-of-bound grid locations. For location far away\n",
      "  3905|         0|            0|            0|  0.00%|          from the border, it will keep being reflected until becoming in bound,\n",
      "  3906|         0|            0|            0|  0.00%|          e.g., (normalized) pixel location ``x = -3.5`` reflects by border ``-1``\n",
      "  3907|         0|            0|            0|  0.00%|          and becomes ``x' = 1.5``, then reflects by border ``1`` and becomes\n",
      "  3908|         0|            0|            0|  0.00%|          ``x'' = -0.5``.\n",
      "  3909|         0|            0|            0|  0.00%|\n",
      "  3910|         0|            0|            0|  0.00%|    Note:\n",
      "  3911|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`affine_grid`\n",
      "  3912|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .\n",
      "  3913|         0|            0|            0|  0.00%|\n",
      "  3914|         0|            0|            0|  0.00%|    Note:\n",
      "  3915|         0|            0|            0|  0.00%|        When using the CUDA backend, this operation may induce nondeterministic\n",
      "  3916|         0|            0|            0|  0.00%|        behaviour in its backward pass that is not easily switched off.\n",
      "  3917|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  3918|         0|            0|            0|  0.00%|\n",
      "  3919|         0|            0|            0|  0.00%|    Note:\n",
      "  3920|         0|            0|            0|  0.00%|        NaN values in :attr:`grid` would be interpreted as ``-1``.\n",
      "  3921|         0|            0|            0|  0.00%|\n",
      "  3922|         0|            0|            0|  0.00%|    Args:\n",
      "  3923|         0|            0|            0|  0.00%|        input (Tensor): input of shape :math:`(N, C, H_\\text{in}, W_\\text{in})` (4-D case)\n",
      "  3924|         0|            0|            0|  0.00%|                        or :math:`(N, C, D_\\text{in}, H_\\text{in}, W_\\text{in})` (5-D case)\n",
      "  3925|         0|            0|            0|  0.00%|        grid (Tensor): flow-field of shape :math:`(N, H_\\text{out}, W_\\text{out}, 2)` (4-D case)\n",
      "  3926|         0|            0|            0|  0.00%|                       or :math:`(N, D_\\text{out}, H_\\text{out}, W_\\text{out}, 3)` (5-D case)\n",
      "  3927|         0|            0|            0|  0.00%|        mode (str): interpolation mode to calculate output values\n",
      "  3928|         0|            0|            0|  0.00%|            ``'bilinear'`` | ``'nearest'`` | ``'bicubic'``. Default: ``'bilinear'``\n",
      "  3929|         0|            0|            0|  0.00%|            Note: ``mode='bicubic'`` supports only 4-D input.\n",
      "  3930|         0|            0|            0|  0.00%|            When ``mode='bilinear'`` and the input is 5-D, the interpolation mode\n",
      "  3931|         0|            0|            0|  0.00%|            used internally will actually be trilinear. However, when the input is 4-D,\n",
      "  3932|         0|            0|            0|  0.00%|            the interpolation mode will legitimately be bilinear.\n",
      "  3933|         0|            0|            0|  0.00%|        padding_mode (str): padding mode for outside grid values\n",
      "  3934|         0|            0|            0|  0.00%|            ``'zeros'`` | ``'border'`` | ``'reflection'``. Default: ``'zeros'``\n",
      "  3935|         0|            0|            0|  0.00%|        align_corners (bool, optional): Geometrically, we consider the pixels of the\n",
      "  3936|         0|            0|            0|  0.00%|            input  as squares rather than points.\n",
      "  3937|         0|            0|            0|  0.00%|            If set to ``True``, the extrema (``-1`` and ``1``) are considered as referring\n",
      "  3938|         0|            0|            0|  0.00%|            to the center points of the input's corner pixels. If set to ``False``, they\n",
      "  3939|         0|            0|            0|  0.00%|            are instead considered as referring to the corner points of the input's corner\n",
      "  3940|         0|            0|            0|  0.00%|            pixels, making the sampling more resolution agnostic.\n",
      "  3941|         0|            0|            0|  0.00%|            This option parallels the ``align_corners`` option in\n",
      "  3942|         0|            0|            0|  0.00%|            :func:`interpolate`, and so whichever option is used here\n",
      "  3943|         0|            0|            0|  0.00%|            should also be used there to resize the input image before grid sampling.\n",
      "  3944|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  3945|         0|            0|            0|  0.00%|\n",
      "  3946|         0|            0|            0|  0.00%|    Returns:\n",
      "  3947|         0|            0|            0|  0.00%|        output (Tensor): output Tensor\n",
      "  3948|         0|            0|            0|  0.00%|\n",
      "  3949|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:\n",
      "  3950|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025\n",
      "  3951|         0|            0|            0|  0.00%|\n",
      "  3952|         0|            0|            0|  0.00%|    .. warning::\n",
      "  3953|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel\n",
      "  3954|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by\n",
      "  3955|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different\n",
      "  3956|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).\n",
      "  3957|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.\n",
      "  3958|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,\n",
      "  3959|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.\n",
      "  3960|         0|            0|            0|  0.00%|\n",
      "  3961|         0|            0|            0|  0.00%|    .. note::\n",
      "  3962|         0|            0|            0|  0.00%|        ``mode='bicubic'`` is implemented using the `cubic convolution algorithm`_ with :math:`\\alpha=-0.75`.\n",
      "  3963|         0|            0|            0|  0.00%|        The constant :math:`\\alpha` might be different from packages to packages.\n",
      "  3964|         0|            0|            0|  0.00%|        For example, `PIL`_ and `OpenCV`_ use -0.5 and -0.75 respectively.\n",
      "  3965|         0|            0|            0|  0.00%|        This algorithm may \"overshoot\" the range of values it's interpolating.\n",
      "  3966|         0|            0|            0|  0.00%|        For example, it may produce negative values or values greater than 255 when interpolating input in [0, 255].\n",
      "  3967|         0|            0|            0|  0.00%|        Clamp the results with :func: `torch.clamp` to ensure they are within the valid range.\n",
      "  3968|         0|            0|            0|  0.00%|    .. _`cubic convolution algorithm`: https://en.wikipedia.org/wiki/Bicubic_interpolation\n",
      "  3969|         0|            0|            0|  0.00%|    .. _`PIL`: https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51\n",
      "  3970|         0|            0|            0|  0.00%|    .. _`OpenCV`: https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908\n",
      "  3971|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  3972|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, grid):\n",
      "  3973|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  3974|         0|            0|            0|  0.00%|            grid_sample, (input, grid), input, grid, mode=mode, padding_mode=padding_mode, align_corners=align_corners\n",
      "  3975|         0|            0|            0|  0.00%|        )\n",
      "  3976|         0|            0|            0|  0.00%|    if mode != \"bilinear\" and mode != \"nearest\" and mode != \"bicubic\":\n",
      "  3977|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  3978|         0|            0|            0|  0.00%|            \"nn.functional.grid_sample(): expected mode to be \"\n",
      "  3979|         0|            0|            0|  0.00%|            \"'bilinear', 'nearest' or 'bicubic', but got: '{}'\".format(mode)\n",
      "  3980|         0|            0|            0|  0.00%|        )\n",
      "  3981|         0|            0|            0|  0.00%|    if padding_mode != \"zeros\" and padding_mode != \"border\" and padding_mode != \"reflection\":\n",
      "  3982|         0|            0|            0|  0.00%|        raise ValueError(\n",
      "  3983|         0|            0|            0|  0.00%|            \"nn.functional.grid_sample(): expected padding_mode \"\n",
      "  3984|         0|            0|            0|  0.00%|            \"to be 'zeros', 'border', or 'reflection', \"\n",
      "  3985|         0|            0|            0|  0.00%|            \"but got: '{}'\".format(padding_mode)\n",
      "  3986|         0|            0|            0|  0.00%|        )\n",
      "  3987|         0|            0|            0|  0.00%|\n",
      "  3988|         0|            0|            0|  0.00%|    if mode == \"bilinear\":\n",
      "  3989|         0|            0|            0|  0.00%|        mode_enum = 0\n",
      "  3990|         0|            0|            0|  0.00%|    elif mode == \"nearest\":\n",
      "  3991|         0|            0|            0|  0.00%|        mode_enum = 1\n",
      "  3992|         0|            0|            0|  0.00%|    else:  # mode == 'bicubic'\n",
      "  3993|         0|            0|            0|  0.00%|        mode_enum = 2\n",
      "  3994|         0|            0|            0|  0.00%|\n",
      "  3995|         0|            0|            0|  0.00%|    if padding_mode == \"zeros\":\n",
      "  3996|         0|            0|            0|  0.00%|        padding_mode_enum = 0\n",
      "  3997|         0|            0|            0|  0.00%|    elif padding_mode == \"border\":\n",
      "  3998|         0|            0|            0|  0.00%|        padding_mode_enum = 1\n",
      "  3999|         0|            0|            0|  0.00%|    else:  # padding_mode == 'reflection'\n",
      "  4000|         0|            0|            0|  0.00%|        padding_mode_enum = 2\n",
      "  4001|         0|            0|            0|  0.00%|\n",
      "  4002|         0|            0|            0|  0.00%|    if align_corners is None:\n",
      "  4003|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4004|         0|            0|            0|  0.00%|            \"Default grid_sample and affine_grid behavior has changed \"\n",
      "  4005|         0|            0|            0|  0.00%|            \"to align_corners=False since 1.3.0. Please specify \"\n",
      "  4006|         0|            0|            0|  0.00%|            \"align_corners=True if the old behavior is desired. \"\n",
      "  4007|         0|            0|            0|  0.00%|            \"See the documentation of grid_sample for details.\"\n",
      "  4008|         0|            0|            0|  0.00%|        )\n",
      "  4009|         0|            0|            0|  0.00%|        align_corners = False\n",
      "  4010|         0|            0|            0|  0.00%|\n",
      "  4011|         0|            0|            0|  0.00%|    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)\n",
      "  4012|         0|            0|            0|  0.00%|\n",
      "  4013|         0|            0|            0|  0.00%|\n",
      "  4014|         0|            0|            0|  0.00%|def affine_grid(theta: Tensor, size: List[int], align_corners: Optional[bool] = None) -> Tensor:\n",
      "  4015|         0|            0|            0|  0.00%|    r\"\"\"Generates a 2D or 3D flow field (sampling grid), given a batch of\n",
      "  4016|         0|            0|            0|  0.00%|    affine matrices :attr:`theta`.\n",
      "  4017|         0|            0|            0|  0.00%|\n",
      "  4018|         0|            0|            0|  0.00%|    .. note::\n",
      "  4019|         0|            0|            0|  0.00%|        This function is often used in conjunction with :func:`grid_sample`\n",
      "  4020|         0|            0|            0|  0.00%|        to build `Spatial Transformer Networks`_ .\n",
      "  4021|         0|            0|            0|  0.00%|\n",
      "  4022|         0|            0|            0|  0.00%|    Args:\n",
      "  4023|         0|            0|            0|  0.00%|        theta (Tensor): input batch of affine matrices with shape\n",
      "  4024|         0|            0|            0|  0.00%|            (:math:`N \\times 2 \\times 3`) for 2D or\n",
      "  4025|         0|            0|            0|  0.00%|            (:math:`N \\times 3 \\times 4`) for 3D\n",
      "  4026|         0|            0|            0|  0.00%|        size (torch.Size): the target output image size.\n",
      "  4027|         0|            0|            0|  0.00%|            (:math:`N \\times C \\times H \\times W` for 2D or\n",
      "  4028|         0|            0|            0|  0.00%|            :math:`N \\times C \\times D \\times H \\times W` for 3D)\n",
      "  4029|         0|            0|            0|  0.00%|            Example: torch.Size((32, 3, 24, 24))\n",
      "  4030|         0|            0|            0|  0.00%|        align_corners (bool, optional): if ``True``, consider ``-1`` and ``1``\n",
      "  4031|         0|            0|            0|  0.00%|            to refer to the centers of the corner pixels rather than the image corners.\n",
      "  4032|         0|            0|            0|  0.00%|            Refer to :func:`grid_sample` for a more complete description.\n",
      "  4033|         0|            0|            0|  0.00%|            A grid generated by :func:`affine_grid` should be passed to :func:`grid_sample`\n",
      "  4034|         0|            0|            0|  0.00%|            with the same setting for this option.\n",
      "  4035|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  4036|         0|            0|            0|  0.00%|\n",
      "  4037|         0|            0|            0|  0.00%|    Returns:\n",
      "  4038|         0|            0|            0|  0.00%|        output (Tensor): output Tensor of size (:math:`N \\times H \\times W \\times 2`)\n",
      "  4039|         0|            0|            0|  0.00%|\n",
      "  4040|         0|            0|            0|  0.00%|    .. _`Spatial Transformer Networks`:\n",
      "  4041|         0|            0|            0|  0.00%|        https://arxiv.org/abs/1506.02025\n",
      "  4042|         0|            0|            0|  0.00%|\n",
      "  4043|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4044|         0|            0|            0|  0.00%|        When ``align_corners = True``, the grid positions depend on the pixel\n",
      "  4045|         0|            0|            0|  0.00%|        size relative to the input image size, and so the locations sampled by\n",
      "  4046|         0|            0|            0|  0.00%|        :func:`grid_sample` will differ for the same input given at different\n",
      "  4047|         0|            0|            0|  0.00%|        resolutions (that is, after being upsampled or downsampled).\n",
      "  4048|         0|            0|            0|  0.00%|        The default behavior up to version 1.2.0 was ``align_corners = True``.\n",
      "  4049|         0|            0|            0|  0.00%|        Since then, the default behavior has been changed to ``align_corners = False``,\n",
      "  4050|         0|            0|            0|  0.00%|        in order to bring it in line with the default for :func:`interpolate`.\n",
      "  4051|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4052|         0|            0|            0|  0.00%|        When ``align_corners = True``, 2D affine transforms on 1D data and\n",
      "  4053|         0|            0|            0|  0.00%|        3D affine transforms on 2D data (that is, when one of the spatial\n",
      "  4054|         0|            0|            0|  0.00%|        dimensions has unit size) are ill-defined, and not an intended use case.\n",
      "  4055|         0|            0|            0|  0.00%|        This is not a problem when ``align_corners = False``.\n",
      "  4056|         0|            0|            0|  0.00%|        Up to version 1.2.0, all grid points along a unit dimension were\n",
      "  4057|         0|            0|            0|  0.00%|        considered arbitrarily to be at ``-1``.\n",
      "  4058|         0|            0|            0|  0.00%|        From version 1.3.0, under ``align_corners = True`` all grid points\n",
      "  4059|         0|            0|            0|  0.00%|        along a unit dimension are considered to be at ``0``\n",
      "  4060|         0|            0|            0|  0.00%|        (the center of the input image).\n",
      "  4061|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4062|         0|            0|            0|  0.00%|    if has_torch_function_unary(theta):\n",
      "  4063|         0|            0|            0|  0.00%|        return handle_torch_function(affine_grid, (theta,), theta, size, align_corners=align_corners)\n",
      "  4064|         0|            0|            0|  0.00%|    if align_corners is None:\n",
      "  4065|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4066|         0|            0|            0|  0.00%|            \"Default grid_sample and affine_grid behavior has changed \"\n",
      "  4067|         0|            0|            0|  0.00%|            \"to align_corners=False since 1.3.0. Please specify \"\n",
      "  4068|         0|            0|            0|  0.00%|            \"align_corners=True if the old behavior is desired. \"\n",
      "  4069|         0|            0|            0|  0.00%|            \"See the documentation of grid_sample for details.\"\n",
      "  4070|         0|            0|            0|  0.00%|        )\n",
      "  4071|         0|            0|            0|  0.00%|        align_corners = False\n",
      "  4072|         0|            0|            0|  0.00%|\n",
      "  4073|         0|            0|            0|  0.00%|    # enforce floating point dtype on theta\n",
      "  4074|         0|            0|            0|  0.00%|    if not theta.is_floating_point():\n",
      "  4075|         0|            0|            0|  0.00%|        raise ValueError(\"Expected theta to have floating point type, but got {}\".format(theta.dtype))\n",
      "  4076|         0|            0|            0|  0.00%|    # check that shapes and sizes match\n",
      "  4077|         0|            0|            0|  0.00%|    if len(size) == 4:\n",
      "  4078|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 2 or theta.shape[-1] != 3:\n",
      "  4079|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  4080|         0|            0|            0|  0.00%|                \"Expected a batch of 2D affine matrices of shape Nx2x3 \"\n",
      "  4081|         0|            0|            0|  0.00%|                \"for size {}. Got {}.\".format(size, theta.shape)\n",
      "  4082|         0|            0|            0|  0.00%|            )\n",
      "  4083|         0|            0|            0|  0.00%|        spatial_size = size[-2:]  # spatial dimension sizes\n",
      "  4084|         0|            0|            0|  0.00%|    elif len(size) == 5:\n",
      "  4085|         0|            0|            0|  0.00%|        if theta.dim() != 3 or theta.shape[-2] != 3 or theta.shape[-1] != 4:\n",
      "  4086|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "  4087|         0|            0|            0|  0.00%|                \"Expected a batch of 3D affine matrices of shape Nx3x4 \"\n",
      "  4088|         0|            0|            0|  0.00%|                \"for size {}. Got {}.\".format(size, theta.shape)\n",
      "  4089|         0|            0|            0|  0.00%|            )\n",
      "  4090|         0|            0|            0|  0.00%|        spatial_size = size[-3:]  # spatial dimension sizes\n",
      "  4091|         0|            0|            0|  0.00%|    else:\n",
      "  4092|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  4093|         0|            0|            0|  0.00%|            \"affine_grid only supports 4D and 5D sizes, \"\n",
      "  4094|         0|            0|            0|  0.00%|            \"for 2D and 3D affine transforms, respectively. \"\n",
      "  4095|         0|            0|            0|  0.00%|            \"Got size {}.\".format(size)\n",
      "  4096|         0|            0|            0|  0.00%|        )\n",
      "  4097|         0|            0|            0|  0.00%|    # check for empty span\n",
      "  4098|         0|            0|            0|  0.00%|    if align_corners and min(spatial_size) == 1:\n",
      "  4099|         0|            0|            0|  0.00%|        warnings.warn(\n",
      "  4100|         0|            0|            0|  0.00%|            \"Since version 1.3.0, affine_grid behavior has changed \"\n",
      "  4101|         0|            0|            0|  0.00%|            \"for unit-size grids when align_corners=True. \"\n",
      "  4102|         0|            0|            0|  0.00%|            \"This is not an intended use case of affine_grid. \"\n",
      "  4103|         0|            0|            0|  0.00%|            \"See the documentation of affine_grid for details.\"\n",
      "  4104|         0|            0|            0|  0.00%|        )\n",
      "  4105|         0|            0|            0|  0.00%|    elif min(size) <= 0:\n",
      "  4106|         0|            0|            0|  0.00%|        raise ValueError(\"Expected non-zero, positive output size. Got {}\".format(size))\n",
      "  4107|         0|            0|            0|  0.00%|\n",
      "  4108|         0|            0|            0|  0.00%|    return torch.affine_grid_generator(theta, size, align_corners)\n",
      "  4109|         0|            0|            0|  0.00%|\n",
      "  4110|         0|            0|            0|  0.00%|\n",
      "  4111|         0|            0|            0|  0.00%|def _pad(input: Tensor, pad: List[int], mode: str = \"constant\", value: float = 0.0) -> Tensor:\n",
      "  4112|         0|            0|            0|  0.00%|    r\"\"\"Pads tensor.\n",
      "  4113|         0|            0|            0|  0.00%|\n",
      "  4114|         0|            0|            0|  0.00%|    Padding size:\n",
      "  4115|         0|            0|            0|  0.00%|        The padding size by which to pad some dimensions of :attr:`input`\n",
      "  4116|         0|            0|            0|  0.00%|        are described starting from the last dimension and moving forward.\n",
      "  4117|         0|            0|            0|  0.00%|        :math:`\\left\\lfloor\\frac{\\text{len(pad)}}{2}\\right\\rfloor` dimensions\n",
      "  4118|         0|            0|            0|  0.00%|        of ``input`` will be padded.\n",
      "  4119|         0|            0|            0|  0.00%|        For example, to pad only the last dimension of the input tensor, then\n",
      "  4120|         0|            0|            0|  0.00%|        :attr:`pad` has the form\n",
      "  4121|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right})`;\n",
      "  4122|         0|            0|            0|  0.00%|        to pad the last 2 dimensions of the input tensor, then use\n",
      "  4123|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "  4124|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_top}, \\text{padding\\_bottom})`;\n",
      "  4125|         0|            0|            0|  0.00%|        to pad the last 3 dimensions, use\n",
      "  4126|         0|            0|            0|  0.00%|        :math:`(\\text{padding\\_left}, \\text{padding\\_right},`\n",
      "  4127|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_top}, \\text{padding\\_bottom}`\n",
      "  4128|         0|            0|            0|  0.00%|        :math:`\\text{padding\\_front}, \\text{padding\\_back})`.\n",
      "  4129|         0|            0|            0|  0.00%|\n",
      "  4130|         0|            0|            0|  0.00%|    Padding mode:\n",
      "  4131|         0|            0|            0|  0.00%|        See :class:`torch.nn.ConstantPad2d`, :class:`torch.nn.ReflectionPad2d`, and\n",
      "  4132|         0|            0|            0|  0.00%|        :class:`torch.nn.ReplicationPad2d` for concrete examples on how each of the\n",
      "  4133|         0|            0|            0|  0.00%|        padding modes works. Constant padding is implemented for arbitrary dimensions.\n",
      "  4134|         0|            0|            0|  0.00%|        Replicate and reflection padding is implemented for padding the last 3\n",
      "  4135|         0|            0|            0|  0.00%|        dimensions of 5D input tensor, or the last 2 dimensions of 4D input\n",
      "  4136|         0|            0|            0|  0.00%|        tensor, or the last dimension of 3D input tensor.\n",
      "  4137|         0|            0|            0|  0.00%|\n",
      "  4138|         0|            0|            0|  0.00%|    Note:\n",
      "  4139|         0|            0|            0|  0.00%|        When using the CUDA backend, this operation may induce nondeterministic\n",
      "  4140|         0|            0|            0|  0.00%|        behaviour in its backward pass that is not easily switched off.\n",
      "  4141|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  4142|         0|            0|            0|  0.00%|\n",
      "  4143|         0|            0|            0|  0.00%|    Args:\n",
      "  4144|         0|            0|            0|  0.00%|        input (Tensor): N-dimensional tensor\n",
      "  4145|         0|            0|            0|  0.00%|        pad (tuple): m-elements tuple, where\n",
      "  4146|         0|            0|            0|  0.00%|            :math:`\\frac{m}{2} \\leq` input dimensions and :math:`m` is even.\n",
      "  4147|         0|            0|            0|  0.00%|        mode: ``'constant'``, ``'reflect'``, ``'replicate'`` or ``'circular'``.\n",
      "  4148|         0|            0|            0|  0.00%|            Default: ``'constant'``\n",
      "  4149|         0|            0|            0|  0.00%|        value: fill value for ``'constant'`` padding. Default: ``0``\n",
      "  4150|         0|            0|            0|  0.00%|\n",
      "  4151|         0|            0|            0|  0.00%|    Examples::\n",
      "  4152|         0|            0|            0|  0.00%|\n",
      "  4153|         0|            0|            0|  0.00%|        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "  4154|         0|            0|            0|  0.00%|        >>> p1d = (1, 1) # pad last dim by 1 on each side\n",
      "  4155|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
      "  4156|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4157|         0|            0|            0|  0.00%|        torch.Size([3, 3, 4, 4])\n",
      "  4158|         0|            0|            0|  0.00%|        >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)\n",
      "  4159|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p2d, \"constant\", 0)\n",
      "  4160|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4161|         0|            0|            0|  0.00%|        torch.Size([3, 3, 8, 4])\n",
      "  4162|         0|            0|            0|  0.00%|        >>> t4d = torch.empty(3, 3, 4, 2)\n",
      "  4163|         0|            0|            0|  0.00%|        >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)\n",
      "  4164|         0|            0|            0|  0.00%|        >>> out = F.pad(t4d, p3d, \"constant\", 0)\n",
      "  4165|         0|            0|            0|  0.00%|        >>> print(out.size())\n",
      "  4166|         0|            0|            0|  0.00%|        torch.Size([3, 9, 7, 3])\n",
      "  4167|         0|            0|            0|  0.00%|\n",
      "  4168|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4169|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4170|         0|            0|            0|  0.00%|        return handle_torch_function(_pad, (input,), input, pad, mode=mode, value=value)\n",
      "  4171|         0|            0|            0|  0.00%|    assert len(pad) % 2 == 0, \"Padding length must be divisible by 2\"\n",
      "  4172|         0|            0|            0|  0.00%|    assert len(pad) // 2 <= input.dim(), \"Padding length too large\"\n",
      "  4173|         0|            0|            0|  0.00%|    if mode == \"constant\":\n",
      "  4174|         0|            0|            0|  0.00%|        return _VF.constant_pad_nd(input, pad, value)\n",
      "  4175|         0|            0|            0|  0.00%|    else:\n",
      "  4176|         0|            0|            0|  0.00%|        assert value == 0.0, 'Padding mode \"{}\"\" doesn\\'t take in value argument'.format(mode)\n",
      "  4177|         0|            0|            0|  0.00%|        if len(pad) == 2 and (input.dim() == 2 or input.dim() == 3):\n",
      "  4178|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4179|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad1d(input, pad)\n",
      "  4180|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4181|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad1d(input, pad)\n",
      "  4182|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4183|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4184|         0|            0|            0|  0.00%|            else:\n",
      "  4185|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4186|         0|            0|            0|  0.00%|\n",
      "  4187|         0|            0|            0|  0.00%|        elif len(pad) == 4 and (input.dim() == 3 or input.dim() == 4):\n",
      "  4188|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4189|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad2d(input, pad)\n",
      "  4190|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4191|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad2d(input, pad)\n",
      "  4192|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4193|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4194|         0|            0|            0|  0.00%|            else:\n",
      "  4195|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4196|         0|            0|            0|  0.00%|\n",
      "  4197|         0|            0|            0|  0.00%|        elif len(pad) == 6 and (input.dim() == 4 or input.dim() == 5):\n",
      "  4198|         0|            0|            0|  0.00%|            if mode == \"reflect\":\n",
      "  4199|         0|            0|            0|  0.00%|                return torch._C._nn.reflection_pad3d(input, pad)\n",
      "  4200|         0|            0|            0|  0.00%|            elif mode == \"replicate\":\n",
      "  4201|         0|            0|            0|  0.00%|                return torch._C._nn.replication_pad3d(input, pad)\n",
      "  4202|         0|            0|            0|  0.00%|            elif mode == \"circular\":\n",
      "  4203|         0|            0|            0|  0.00%|                return _pad_circular(input, pad)\n",
      "  4204|         0|            0|            0|  0.00%|            else:\n",
      "  4205|         0|            0|            0|  0.00%|                raise NotImplementedError\n",
      "  4206|         0|            0|            0|  0.00%|        else:\n",
      "  4207|         0|            0|            0|  0.00%|            raise NotImplementedError(\"Only 2D, 3D, 4D, 5D padding with non-constant padding are supported for now\")\n",
      "  4208|         0|            0|            0|  0.00%|\n",
      "  4209|         0|            0|            0|  0.00%|\n",
      "  4210|         0|            0|            0|  0.00%|# We define this function as _pad because it takes an argument\n",
      "  4211|         0|            0|            0|  0.00%|# named pad, which clobbers the recursive reference to the pad\n",
      "  4212|         0|            0|            0|  0.00%|# function needed for __torch_function__ support\n",
      "  4213|         0|            0|            0|  0.00%|pad = _pad\n",
      "  4214|         0|            0|            0|  0.00%|\n",
      "  4215|         0|            0|            0|  0.00%|# distance\n",
      "  4216|         0|            0|            0|  0.00%|\n",
      "  4217|         0|            0|            0|  0.00%|\n",
      "  4218|         0|            0|            0|  0.00%|def pairwise_distance(x1: Tensor, x2: Tensor, p: float = 2.0, eps: float = 1e-6, keepdim: bool = False) -> Tensor:\n",
      "  4219|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4220|         0|            0|            0|  0.00%|    See :class:`torch.nn.PairwiseDistance` for details\n",
      "  4221|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4222|         0|            0|            0|  0.00%|    if has_torch_function_variadic(x1, x2):\n",
      "  4223|         0|            0|            0|  0.00%|        return handle_torch_function(pairwise_distance, (x1, x2), x1, x2, p=p, eps=eps, keepdim=keepdim)\n",
      "  4224|         0|            0|            0|  0.00%|    return torch.pairwise_distance(x1, x2, p, eps, keepdim)\n",
      "  4225|         0|            0|            0|  0.00%|\n",
      "  4226|         0|            0|            0|  0.00%|\n",
      "  4227|         0|            0|            0|  0.00%|pdist = _add_docstr(\n",
      "  4228|         0|            0|            0|  0.00%|    torch.pdist,\n",
      "  4229|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4230|         0|            0|            0|  0.00%|pdist(input, p=2) -> Tensor\n",
      "  4231|         0|            0|            0|  0.00%|\n",
      "  4232|         0|            0|            0|  0.00%|Computes the p-norm distance between every pair of row vectors in the input.\n",
      "  4233|         0|            0|            0|  0.00%|This is identical to the upper triangular portion, excluding the diagonal, of\n",
      "  4234|         0|            0|            0|  0.00%|`torch.norm(input[:, None] - input, dim=2, p=p)`. This function will be faster\n",
      "  4235|         0|            0|            0|  0.00%|if the rows are contiguous.\n",
      "  4236|         0|            0|            0|  0.00%|\n",
      "  4237|         0|            0|            0|  0.00%|If input has shape :math:`N \\times M` then the output will have shape\n",
      "  4238|         0|            0|            0|  0.00%|:math:`\\frac{1}{2} N (N - 1)`.\n",
      "  4239|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4240|         0|            0|            0|  0.00%|This function is equivalent to `scipy.spatial.distance.pdist(input,\n",
      "  4241|         0|            0|            0|  0.00%|'minkowski', p=p)` if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is\n",
      "  4242|         0|            0|            0|  0.00%|equivalent to `scipy.spatial.distance.pdist(input, 'hamming') * M`.\n",
      "  4243|         0|            0|            0|  0.00%|When :math:`p = \\infty`, the closest scipy function is\n",
      "  4244|         0|            0|            0|  0.00%|`scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())`.\n",
      "  4245|         0|            0|            0|  0.00%|\n",
      "  4246|         0|            0|            0|  0.00%|Args:\n",
      "  4247|         0|            0|            0|  0.00%|    input: input tensor of shape :math:`N \\times M`.\n",
      "  4248|         0|            0|            0|  0.00%|    p: p value for the p-norm distance to calculate between each vector pair\n",
      "  4249|         0|            0|            0|  0.00%|        :math:`\\in [0, \\infty]`.\n",
      "  4250|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4251|         0|            0|            0|  0.00%|)\n",
      "  4252|         0|            0|            0|  0.00%|\n",
      "  4253|         0|            0|            0|  0.00%|\n",
      "  4254|         0|            0|            0|  0.00%|cosine_similarity = _add_docstr(\n",
      "  4255|         0|            0|            0|  0.00%|    torch.cosine_similarity,\n",
      "  4256|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4257|         0|            0|            0|  0.00%|cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor\n",
      "  4258|         0|            0|            0|  0.00%|\n",
      "  4259|         0|            0|            0|  0.00%|Returns cosine similarity between ``x1`` and ``x2``, computed along dim. ``x1`` and ``x2`` must be broadcastable\n",
      "  4260|         0|            0|            0|  0.00%|to a common shape. ``dim`` refers to the dimension in this common shape. Dimension ``dim`` of the output is\n",
      "  4261|         0|            0|            0|  0.00%|squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "  4262|         0|            0|            0|  0.00%|output tensor having 1 fewer dimension.\n",
      "  4263|         0|            0|            0|  0.00%|\n",
      "  4264|         0|            0|            0|  0.00%|.. math ::\n",
      "  4265|         0|            0|            0|  0.00%|    \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n",
      "  4266|         0|            0|            0|  0.00%|\n",
      "  4267|         0|            0|            0|  0.00%|Supports :ref:`type promotion <type-promotion-doc>`.\n",
      "  4268|         0|            0|            0|  0.00%|\n",
      "  4269|         0|            0|            0|  0.00%|Args:\n",
      "  4270|         0|            0|            0|  0.00%|    x1 (Tensor): First input.\n",
      "  4271|         0|            0|            0|  0.00%|    x2 (Tensor): Second input.\n",
      "  4272|         0|            0|            0|  0.00%|    dim (int, optional): Dimension along which cosine similarity is computed. Default: 1\n",
      "  4273|         0|            0|            0|  0.00%|    eps (float, optional): Small value to avoid division by zero.\n",
      "  4274|         0|            0|            0|  0.00%|        Default: 1e-8\n",
      "  4275|         0|            0|            0|  0.00%|\n",
      "  4276|         0|            0|            0|  0.00%|Example::\n",
      "  4277|         0|            0|            0|  0.00%|\n",
      "  4278|         0|            0|            0|  0.00%|    >>> input1 = torch.randn(100, 128)\n",
      "  4279|         0|            0|            0|  0.00%|    >>> input2 = torch.randn(100, 128)\n",
      "  4280|         0|            0|            0|  0.00%|    >>> output = F.cosine_similarity(input1, input2)\n",
      "  4281|         0|            0|            0|  0.00%|    >>> print(output)\n",
      "  4282|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4283|         0|            0|            0|  0.00%|)\n",
      "  4284|         0|            0|            0|  0.00%|\n",
      "  4285|         0|            0|            0|  0.00%|\n",
      "  4286|         0|            0|            0|  0.00%|one_hot = _add_docstr(\n",
      "  4287|         0|            0|            0|  0.00%|    torch._C._nn.one_hot,\n",
      "  4288|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4289|         0|            0|            0|  0.00%|one_hot(tensor, num_classes=-1) -> LongTensor\n",
      "  4290|         0|            0|            0|  0.00%|\n",
      "  4291|         0|            0|            0|  0.00%|Takes LongTensor with index values of shape ``(*)`` and returns a tensor\n",
      "  4292|         0|            0|            0|  0.00%|of shape ``(*, num_classes)`` that have zeros everywhere except where the\n",
      "  4293|         0|            0|            0|  0.00%|index of last dimension matches the corresponding value of the input tensor,\n",
      "  4294|         0|            0|            0|  0.00%|in which case it will be 1.\n",
      "  4295|         0|            0|            0|  0.00%|\n",
      "  4296|         0|            0|            0|  0.00%|See also `One-hot on Wikipedia`_ .\n",
      "  4297|         0|            0|            0|  0.00%|\n",
      "  4298|         0|            0|            0|  0.00%|.. _One-hot on Wikipedia:\n",
      "  4299|         0|            0|            0|  0.00%|    https://en.wikipedia.org/wiki/One-hot\n",
      "  4300|         0|            0|            0|  0.00%|\n",
      "  4301|         0|            0|            0|  0.00%|Arguments:\n",
      "  4302|         0|            0|            0|  0.00%|    tensor (LongTensor): class values of any shape.\n",
      "  4303|         0|            0|            0|  0.00%|    num_classes (int):  Total number of classes. If set to -1, the number\n",
      "  4304|         0|            0|            0|  0.00%|        of classes will be inferred as one greater than the largest class\n",
      "  4305|         0|            0|            0|  0.00%|        value in the input tensor.\n",
      "  4306|         0|            0|            0|  0.00%|\n",
      "  4307|         0|            0|            0|  0.00%|Returns:\n",
      "  4308|         0|            0|            0|  0.00%|    LongTensor that has one more dimension with 1 values at the\n",
      "  4309|         0|            0|            0|  0.00%|    index of last dimension indicated by the input, and 0 everywhere\n",
      "  4310|         0|            0|            0|  0.00%|    else.\n",
      "  4311|         0|            0|            0|  0.00%|\n",
      "  4312|         0|            0|            0|  0.00%|Examples:\n",
      "  4313|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3)\n",
      "  4314|         0|            0|            0|  0.00%|    tensor([[1, 0, 0],\n",
      "  4315|         0|            0|            0|  0.00%|            [0, 1, 0],\n",
      "  4316|         0|            0|            0|  0.00%|            [0, 0, 1],\n",
      "  4317|         0|            0|            0|  0.00%|            [1, 0, 0],\n",
      "  4318|         0|            0|            0|  0.00%|            [0, 1, 0]])\n",
      "  4319|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\n",
      "  4320|         0|            0|            0|  0.00%|    tensor([[1, 0, 0, 0, 0],\n",
      "  4321|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0],\n",
      "  4322|         0|            0|            0|  0.00%|            [0, 0, 1, 0, 0],\n",
      "  4323|         0|            0|            0|  0.00%|            [1, 0, 0, 0, 0],\n",
      "  4324|         0|            0|            0|  0.00%|            [0, 1, 0, 0, 0]])\n",
      "  4325|         0|            0|            0|  0.00%|    >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3)\n",
      "  4326|         0|            0|            0|  0.00%|    tensor([[[1, 0, 0],\n",
      "  4327|         0|            0|            0|  0.00%|             [0, 1, 0]],\n",
      "  4328|         0|            0|            0|  0.00%|            [[0, 0, 1],\n",
      "  4329|         0|            0|            0|  0.00%|             [1, 0, 0]],\n",
      "  4330|         0|            0|            0|  0.00%|            [[0, 1, 0],\n",
      "  4331|         0|            0|            0|  0.00%|             [0, 0, 1]]])\n",
      "  4332|         0|            0|            0|  0.00%|\"\"\",\n",
      "  4333|         0|            0|            0|  0.00%|)\n",
      "  4334|         0|            0|            0|  0.00%|\n",
      "  4335|         0|            0|            0|  0.00%|\n",
      "  4336|         0|            0|            0|  0.00%|def triplet_margin_loss(\n",
      "  4337|         0|            0|            0|  0.00%|    anchor: Tensor,\n",
      "  4338|         0|            0|            0|  0.00%|    positive: Tensor,\n",
      "  4339|         0|            0|            0|  0.00%|    negative: Tensor,\n",
      "  4340|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  4341|         0|            0|            0|  0.00%|    p: float = 2,\n",
      "  4342|         0|            0|            0|  0.00%|    eps: float = 1e-6,\n",
      "  4343|         0|            0|            0|  0.00%|    swap: bool = False,\n",
      "  4344|         0|            0|            0|  0.00%|    size_average: Optional[bool] = None,\n",
      "  4345|         0|            0|            0|  0.00%|    reduce: Optional[bool] = None,\n",
      "  4346|         0|            0|            0|  0.00%|    reduction: str = \"mean\",\n",
      "  4347|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4348|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4349|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginLoss` for details\n",
      "  4350|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4351|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):\n",
      "  4352|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4353|         0|            0|            0|  0.00%|            triplet_margin_loss,\n",
      "  4354|         0|            0|            0|  0.00%|            (anchor, positive, negative),\n",
      "  4355|         0|            0|            0|  0.00%|            anchor,\n",
      "  4356|         0|            0|            0|  0.00%|            positive,\n",
      "  4357|         0|            0|            0|  0.00%|            negative,\n",
      "  4358|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  4359|         0|            0|            0|  0.00%|            p=p,\n",
      "  4360|         0|            0|            0|  0.00%|            eps=eps,\n",
      "  4361|         0|            0|            0|  0.00%|            swap=swap,\n",
      "  4362|         0|            0|            0|  0.00%|            size_average=size_average,\n",
      "  4363|         0|            0|            0|  0.00%|            reduce=reduce,\n",
      "  4364|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  4365|         0|            0|            0|  0.00%|        )\n",
      "  4366|         0|            0|            0|  0.00%|    if size_average is not None or reduce is not None:\n",
      "  4367|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n",
      "  4368|         0|            0|            0|  0.00%|    else:\n",
      "  4369|         0|            0|            0|  0.00%|        reduction_enum = _Reduction.get_enum(reduction)\n",
      "  4370|         0|            0|            0|  0.00%|    return torch.triplet_margin_loss(anchor, positive, negative, margin, p, eps, swap, reduction_enum)\n",
      "  4371|         0|            0|            0|  0.00%|\n",
      "  4372|         0|            0|            0|  0.00%|\n",
      "  4373|         0|            0|            0|  0.00%|def triplet_margin_with_distance_loss(\n",
      "  4374|         0|            0|            0|  0.00%|    anchor: Tensor,\n",
      "  4375|         0|            0|            0|  0.00%|    positive: Tensor,\n",
      "  4376|         0|            0|            0|  0.00%|    negative: Tensor,\n",
      "  4377|         0|            0|            0|  0.00%|    *,\n",
      "  4378|         0|            0|            0|  0.00%|    distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n",
      "  4379|         0|            0|            0|  0.00%|    margin: float = 1.0,\n",
      "  4380|         0|            0|            0|  0.00%|    swap: bool = False,\n",
      "  4381|         0|            0|            0|  0.00%|    reduction: str = \"mean\"\n",
      "  4382|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4383|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4384|         0|            0|            0|  0.00%|    See :class:`~torch.nn.TripletMarginWithDistanceLoss` for details.\n",
      "  4385|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4386|         0|            0|            0|  0.00%|    if torch.jit.is_scripting():\n",
      "  4387|         0|            0|            0|  0.00%|        raise NotImplementedError(\n",
      "  4388|         0|            0|            0|  0.00%|            \"F.triplet_margin_with_distance_loss does not support JIT scripting: \"\n",
      "  4389|         0|            0|            0|  0.00%|            \"functions requiring Callables cannot be scripted.\"\n",
      "  4390|         0|            0|            0|  0.00%|        )\n",
      "  4391|         0|            0|            0|  0.00%|\n",
      "  4392|         0|            0|            0|  0.00%|    if has_torch_function_variadic(anchor, positive, negative):\n",
      "  4393|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4394|         0|            0|            0|  0.00%|            triplet_margin_with_distance_loss,\n",
      "  4395|         0|            0|            0|  0.00%|            (anchor, positive, negative),\n",
      "  4396|         0|            0|            0|  0.00%|            anchor,\n",
      "  4397|         0|            0|            0|  0.00%|            positive,\n",
      "  4398|         0|            0|            0|  0.00%|            negative,\n",
      "  4399|         0|            0|            0|  0.00%|            distance_function=distance_function,\n",
      "  4400|         0|            0|            0|  0.00%|            margin=margin,\n",
      "  4401|         0|            0|            0|  0.00%|            swap=swap,\n",
      "  4402|         0|            0|            0|  0.00%|            reduction=reduction,\n",
      "  4403|         0|            0|            0|  0.00%|        )\n",
      "  4404|         0|            0|            0|  0.00%|\n",
      "  4405|         0|            0|            0|  0.00%|    distance_function = distance_function if distance_function is not None else pairwise_distance\n",
      "  4406|         0|            0|            0|  0.00%|\n",
      "  4407|         0|            0|            0|  0.00%|    positive_dist = distance_function(anchor, positive)\n",
      "  4408|         0|            0|            0|  0.00%|    negative_dist = distance_function(anchor, negative)\n",
      "  4409|         0|            0|            0|  0.00%|\n",
      "  4410|         0|            0|            0|  0.00%|    if swap:\n",
      "  4411|         0|            0|            0|  0.00%|        swap_dist = distance_function(positive, negative)\n",
      "  4412|         0|            0|            0|  0.00%|        negative_dist = torch.min(negative_dist, swap_dist)\n",
      "  4413|         0|            0|            0|  0.00%|\n",
      "  4414|         0|            0|            0|  0.00%|    output = torch.clamp(positive_dist - negative_dist + margin, min=0.0)\n",
      "  4415|         0|            0|            0|  0.00%|\n",
      "  4416|         0|            0|            0|  0.00%|    reduction_enum = _Reduction.get_enum(reduction)\n",
      "  4417|         0|            0|            0|  0.00%|    if reduction_enum == 1:\n",
      "  4418|         0|            0|            0|  0.00%|        return output.mean()\n",
      "  4419|         0|            0|            0|  0.00%|    elif reduction_enum == 2:\n",
      "  4420|         0|            0|            0|  0.00%|        return output.sum()\n",
      "  4421|         0|            0|            0|  0.00%|    else:\n",
      "  4422|         0|            0|            0|  0.00%|        return output\n",
      "  4423|         0|            0|            0|  0.00%|\n",
      "  4424|         0|            0|            0|  0.00%|\n",
      "  4425|         0|            0|            0|  0.00%|def normalize(input: Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[Tensor] = None) -> Tensor:\n",
      "  4426|         0|            0|            0|  0.00%|    r\"\"\"Performs :math:`L_p` normalization of inputs over specified dimension.\n",
      "  4427|         0|            0|            0|  0.00%|\n",
      "  4428|         0|            0|            0|  0.00%|    For a tensor :attr:`input` of sizes :math:`(n_0, ..., n_{dim}, ..., n_k)`, each\n",
      "  4429|         0|            0|            0|  0.00%|    :math:`n_{dim}` -element vector :math:`v` along dimension :attr:`dim` is transformed as\n",
      "  4430|         0|            0|            0|  0.00%|\n",
      "  4431|         0|            0|            0|  0.00%|    .. math::\n",
      "  4432|         0|            0|            0|  0.00%|        v = \\frac{v}{\\max(\\lVert v \\rVert_p, \\epsilon)}.\n",
      "  4433|         0|            0|            0|  0.00%|\n",
      "  4434|         0|            0|            0|  0.00%|    With the default arguments it uses the Euclidean norm over vectors along dimension :math:`1` for normalization.\n",
      "  4435|         0|            0|            0|  0.00%|\n",
      "  4436|         0|            0|            0|  0.00%|    Args:\n",
      "  4437|         0|            0|            0|  0.00%|        input: input tensor of any shape\n",
      "  4438|         0|            0|            0|  0.00%|        p (float): the exponent value in the norm formulation. Default: 2\n",
      "  4439|         0|            0|            0|  0.00%|        dim (int): the dimension to reduce. Default: 1\n",
      "  4440|         0|            0|            0|  0.00%|        eps (float): small value to avoid division by zero. Default: 1e-12\n",
      "  4441|         0|            0|            0|  0.00%|        out (Tensor, optional): the output tensor. If :attr:`out` is used, this\n",
      "  4442|         0|            0|            0|  0.00%|                                operation won't be differentiable.\n",
      "  4443|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4444|         0|            0|            0|  0.00%|    if has_torch_function_variadic(input, out):\n",
      "  4445|         0|            0|            0|  0.00%|        return handle_torch_function(normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out)\n",
      "  4446|         0|            0|            0|  0.00%|    if out is None:\n",
      "  4447|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)\n",
      "  4448|         0|            0|            0|  0.00%|        return input / denom\n",
      "  4449|         0|            0|            0|  0.00%|    else:\n",
      "  4450|         0|            0|            0|  0.00%|        denom = input.norm(p, dim, keepdim=True).clamp_min_(eps).expand_as(input)\n",
      "  4451|         0|            0|            0|  0.00%|        return torch.div(input, denom, out=out)\n",
      "  4452|         0|            0|            0|  0.00%|\n",
      "  4453|         0|            0|            0|  0.00%|\n",
      "  4454|         0|            0|            0|  0.00%|def assert_int_or_pair(arg: List[int], arg_name: str, message: str) -> None:\n",
      "  4455|         0|            0|            0|  0.00%|    assert isinstance(arg, int) or len(arg) == 2, message.format(arg_name)\n",
      "  4456|         0|            0|            0|  0.00%|\n",
      "  4457|         0|            0|            0|  0.00%|\n",
      "  4458|         0|            0|            0|  0.00%|def unfold(\n",
      "  4459|         0|            0|            0|  0.00%|    input: Tensor, kernel_size: BroadcastingList2[int],\n",
      "  4460|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "  4461|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "  4462|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1\n",
      "  4463|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4464|         0|            0|            0|  0.00%|    r\"\"\"Extracts sliding local blocks from a batched input tensor.\n",
      "  4465|         0|            0|            0|  0.00%|\n",
      "  4466|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4467|         0|            0|            0|  0.00%|        Currently, only 4-D input tensors (batched image-like tensors) are\n",
      "  4468|         0|            0|            0|  0.00%|        supported.\n",
      "  4469|         0|            0|            0|  0.00%|\n",
      "  4470|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4471|         0|            0|            0|  0.00%|\n",
      "  4472|         0|            0|            0|  0.00%|        More than one element of the unfolded tensor may refer to a single\n",
      "  4473|         0|            0|            0|  0.00%|        memory location. As a result, in-place operations (especially ones that\n",
      "  4474|         0|            0|            0|  0.00%|        are vectorized) may result in incorrect behavior. If you need to write\n",
      "  4475|         0|            0|            0|  0.00%|        to the tensor, please clone it first.\n",
      "  4476|         0|            0|            0|  0.00%|\n",
      "  4477|         0|            0|            0|  0.00%|\n",
      "  4478|         0|            0|            0|  0.00%|    See :class:`torch.nn.Unfold` for details\n",
      "  4479|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4480|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4481|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4482|         0|            0|            0|  0.00%|            unfold, (input,), input, kernel_size, dilation=dilation, padding=padding, stride=stride\n",
      "  4483|         0|            0|            0|  0.00%|        )\n",
      "  4484|         0|            0|            0|  0.00%|    if input.dim() == 4:\n",
      "  4485|         0|            0|            0|  0.00%|        msg = \"{} must be int or 2-tuple for 4D input\"\n",
      "  4486|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, \"kernel_size\", msg)\n",
      "  4487|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, \"dilation\", msg)\n",
      "  4488|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, \"padding\", msg)\n",
      "  4489|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, \"stride\", msg)\n",
      "  4490|         0|            0|            0|  0.00%|\n",
      "  4491|         0|            0|            0|  0.00%|        return torch._C._nn.im2col(input, _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride))\n",
      "  4492|         0|            0|            0|  0.00%|    else:\n",
      "  4493|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Input Error: Only 4D input Tensors are supported (got {}D)\".format(input.dim()))\n",
      "  4494|         0|            0|            0|  0.00%|\n",
      "  4495|         0|            0|            0|  0.00%|\n",
      "  4496|         0|            0|            0|  0.00%|def fold(\n",
      "  4497|         0|            0|            0|  0.00%|    input: Tensor, output_size: BroadcastingList2[int],\n",
      "  4498|         0|            0|            0|  0.00%|    kernel_size: BroadcastingList2[int],\n",
      "  4499|         0|            0|            0|  0.00%|    dilation: BroadcastingList2[int] = 1,\n",
      "  4500|         0|            0|            0|  0.00%|    padding: BroadcastingList2[int] = 0,\n",
      "  4501|         0|            0|            0|  0.00%|    stride: BroadcastingList2[int] = 1\n",
      "  4502|         0|            0|            0|  0.00%|) -> Tensor:\n",
      "  4503|         0|            0|            0|  0.00%|    r\"\"\"Combines an array of sliding local blocks into a large containing\n",
      "  4504|         0|            0|            0|  0.00%|    tensor.\n",
      "  4505|         0|            0|            0|  0.00%|\n",
      "  4506|         0|            0|            0|  0.00%|    .. warning::\n",
      "  4507|         0|            0|            0|  0.00%|        Currently, only 3-D output tensors (unfolded batched image-like tensors) are\n",
      "  4508|         0|            0|            0|  0.00%|        supported.\n",
      "  4509|         0|            0|            0|  0.00%|\n",
      "  4510|         0|            0|            0|  0.00%|    See :class:`torch.nn.Fold` for details\n",
      "  4511|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4512|         0|            0|            0|  0.00%|    if has_torch_function_unary(input):\n",
      "  4513|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4514|         0|            0|            0|  0.00%|            fold, (input,), input, output_size, kernel_size, dilation=dilation, padding=padding, stride=stride\n",
      "  4515|         0|            0|            0|  0.00%|        )\n",
      "  4516|         0|            0|            0|  0.00%|    if input.dim() == 3:\n",
      "  4517|         0|            0|            0|  0.00%|        msg = \"{} must be int or 2-tuple for 3D input\"\n",
      "  4518|         0|            0|            0|  0.00%|        assert_int_or_pair(output_size, \"output_size\", msg)\n",
      "  4519|         0|            0|            0|  0.00%|        assert_int_or_pair(kernel_size, \"kernel_size\", msg)\n",
      "  4520|         0|            0|            0|  0.00%|        assert_int_or_pair(dilation, \"dilation\", msg)\n",
      "  4521|         0|            0|            0|  0.00%|        assert_int_or_pair(padding, \"padding\", msg)\n",
      "  4522|         0|            0|            0|  0.00%|        assert_int_or_pair(stride, \"stride\", msg)\n",
      "  4523|         0|            0|            0|  0.00%|\n",
      "  4524|         0|            0|            0|  0.00%|        return torch._C._nn.col2im(\n",
      "  4525|         0|            0|            0|  0.00%|            input, _pair(output_size), _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride)\n",
      "  4526|         0|            0|            0|  0.00%|        )\n",
      "  4527|         0|            0|            0|  0.00%|    else:\n",
      "  4528|         0|            0|            0|  0.00%|        raise NotImplementedError(\"Input Error: Only 3D input Tensors are supported (got {}D)\".format(input.dim()))\n",
      "  4529|         0|            0|            0|  0.00%|\n",
      "  4530|         0|            0|            0|  0.00%|\n",
      "  4531|         0|            0|            0|  0.00%|def _pad_circular(input: Tensor, padding: List[int]) -> Tensor:\n",
      "  4532|         0|            0|            0|  0.00%|    \"\"\"Circularly pads tensor.\n",
      "  4533|         0|            0|            0|  0.00%|\n",
      "  4534|         0|            0|            0|  0.00%|    Tensor values at the beginning are used to pad the end, and values at the\n",
      "  4535|         0|            0|            0|  0.00%|    end are used to pad the beginning. For example, consider a single dimension\n",
      "  4536|         0|            0|            0|  0.00%|    with values [0, 1, 2, 3]. With circular padding of (1, 1) it would be\n",
      "  4537|         0|            0|            0|  0.00%|    padded to [3, 0, 1, 2, 3, 0], and with padding (1, 2) it would be padded to\n",
      "  4538|         0|            0|            0|  0.00%|    [3, 0, 1, 2, 3, 0, 1]. If negative padding is applied then the ends of the\n",
      "  4539|         0|            0|            0|  0.00%|    tensor get removed. With circular padding of (-1, -1) the previous example\n",
      "  4540|         0|            0|            0|  0.00%|    would become [1, 2]. Circular padding of (-1, 1) would produce\n",
      "  4541|         0|            0|            0|  0.00%|    [1, 2, 3, 1].\n",
      "  4542|         0|            0|            0|  0.00%|\n",
      "  4543|         0|            0|            0|  0.00%|    The first and second dimensions of the tensor are not padded.\n",
      "  4544|         0|            0|            0|  0.00%|\n",
      "  4545|         0|            0|            0|  0.00%|    Args:\n",
      "  4546|         0|            0|            0|  0.00%|        input: Tensor with shape :math:`(N, C, D[, H, W])`.\n",
      "  4547|         0|            0|            0|  0.00%|        padding: Tuple containing the number of elements to pad each side of\n",
      "  4548|         0|            0|            0|  0.00%|            the tensor. The length of padding must be twice the number of\n",
      "  4549|         0|            0|            0|  0.00%|            paddable dimensions. For example, the length of padding should be 4\n",
      "  4550|         0|            0|            0|  0.00%|            for a tensor of shape :math:`(N, C, H, W)`, and the length should\n",
      "  4551|         0|            0|            0|  0.00%|            be 6 for a tensor of shape :math:`(N, C, D, H, W)`.\n",
      "  4552|         0|            0|            0|  0.00%|\n",
      "  4553|         0|            0|            0|  0.00%|    Examples::\n",
      "  4554|         0|            0|            0|  0.00%|\n",
      "  4555|         0|            0|            0|  0.00%|        >>> x = torch.tensor([[[[0, 1, 2], [3, 4, 5]]]])  # Create tensor\n",
      "  4556|         0|            0|            0|  0.00%|        >>> # Example 1\n",
      "  4557|         0|            0|            0|  0.00%|        >>> padding = (1, 1, 1, 1)\n",
      "  4558|         0|            0|            0|  0.00%|        >>> y = F.pad(x, padding, mode='circular')\n",
      "  4559|         0|            0|            0|  0.00%|        >>> print(y)\n",
      "  4560|         0|            0|            0|  0.00%|        tensor([[[[5, 3, 4, 5, 3],\n",
      "  4561|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4562|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4563|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0]]]])\n",
      "  4564|         0|            0|            0|  0.00%|        >>> print(y.shape)\n",
      "  4565|         0|            0|            0|  0.00%|        torch.Size([1, 1, 4, 5])\n",
      "  4566|         0|            0|            0|  0.00%|        >>> # Example 2\n",
      "  4567|         0|            0|            0|  0.00%|        >>> padding = (1, 1, 2, 2)\n",
      "  4568|         0|            0|            0|  0.00%|        >>> z = F.pad(x, padding, mode='circular')\n",
      "  4569|         0|            0|            0|  0.00%|        >>> print(z)\n",
      "  4570|         0|            0|            0|  0.00%|        tensor([[[[2, 0, 1, 2, 0],\n",
      "  4571|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4572|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4573|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3],\n",
      "  4574|         0|            0|            0|  0.00%|                  [2, 0, 1, 2, 0],\n",
      "  4575|         0|            0|            0|  0.00%|                  [5, 3, 4, 5, 3]]]])\n",
      "  4576|         0|            0|            0|  0.00%|        >>> print(z.shape)\n",
      "  4577|         0|            0|            0|  0.00%|        torch.Size([1, 1, 6, 5])\n",
      "  4578|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4579|         0|            0|            0|  0.00%|    in_shape = input.shape\n",
      "  4580|         0|            0|            0|  0.00%|    paddable_shape = in_shape[2:]\n",
      "  4581|         0|            0|            0|  0.00%|    ndim = len(paddable_shape)\n",
      "  4582|         0|            0|            0|  0.00%|\n",
      "  4583|         0|            0|            0|  0.00%|    for idx, size in enumerate(paddable_shape):\n",
      "  4584|         0|            0|            0|  0.00%|        # Only supports wrapping around once\n",
      "  4585|         0|            0|            0|  0.00%|        assert padding[-(idx * 2 + 1)] <= size, \"Padding value causes wrapping around more than once.\"\n",
      "  4586|         0|            0|            0|  0.00%|        assert padding[-(idx * 2 + 2)] <= size, \"Padding value causes wrapping around more than once.\"\n",
      "  4587|         0|            0|            0|  0.00%|        # Negative padding should not result in negative sizes\n",
      "  4588|         0|            0|            0|  0.00%|        assert (\n",
      "  4589|         0|            0|            0|  0.00%|            padding[-(idx * 2 + 1)] + padding[-(idx * 2 + 2)] + size >= 0\n",
      "  4590|         0|            0|            0|  0.00%|        ), \"Negative padding value is resulting in an empty dimension.\"\n",
      "  4591|         0|            0|            0|  0.00%|\n",
      "  4592|         0|            0|            0|  0.00%|    # Get shape of padded tensor\n",
      "  4593|         0|            0|            0|  0.00%|    out_shape = in_shape[:2]\n",
      "  4594|         0|            0|            0|  0.00%|    for idx, size in enumerate(paddable_shape):\n",
      "  4595|         0|            0|            0|  0.00%|        out_shape += (size + padding[-(idx * 2 + 1)] + padding[-(idx * 2 + 2)],)\n",
      "  4596|         0|            0|            0|  0.00%|\n",
      "  4597|         0|            0|            0|  0.00%|    out = torch.empty(out_shape, dtype=input.dtype, layout=input.layout, device=input.device)\n",
      "  4598|         0|            0|            0|  0.00%|\n",
      "  4599|         0|            0|            0|  0.00%|    # Put original array in padded array\n",
      "  4600|         0|            0|            0|  0.00%|    if ndim == 1:\n",
      "  4601|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4602|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4603|         0|            0|            0|  0.00%|\n",
      "  4604|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4605|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4606|         0|            0|            0|  0.00%|\n",
      "  4607|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1] = input[..., in_d0:in_d1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4608|         0|            0|            0|  0.00%|    elif ndim == 2:\n",
      "  4609|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4610|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4611|         0|            0|            0|  0.00%|\n",
      "  4612|         0|            0|            0|  0.00%|        out_h0 = max(padding[-4], 0)\n",
      "  4613|         0|            0|            0|  0.00%|        out_h1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4614|         0|            0|            0|  0.00%|\n",
      "  4615|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4616|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4617|         0|            0|            0|  0.00%|\n",
      "  4618|         0|            0|            0|  0.00%|        in_h0 = max(-padding[-4], 0)\n",
      "  4619|         0|            0|            0|  0.00%|        in_h1 = in_shape[3] - max(-padding[-3], 0)\n",
      "  4620|         0|            0|            0|  0.00%|\n",
      "  4621|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1, out_h0:out_h1] = input[..., in_d0:in_d1, in_h0:in_h1]\n",
      "  4622|         0|            0|            0|  0.00%|    elif ndim == 3:\n",
      "  4623|         0|            0|            0|  0.00%|        out_d0 = max(padding[-2], 0)\n",
      "  4624|         0|            0|            0|  0.00%|        out_d1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4625|         0|            0|            0|  0.00%|\n",
      "  4626|         0|            0|            0|  0.00%|        out_h0 = max(padding[-4], 0)\n",
      "  4627|         0|            0|            0|  0.00%|        out_h1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4628|         0|            0|            0|  0.00%|\n",
      "  4629|         0|            0|            0|  0.00%|        out_w0 = max(padding[-6], 0)\n",
      "  4630|         0|            0|            0|  0.00%|        out_w1 = out_shape[4] - max(padding[-5], 0)\n",
      "  4631|         0|            0|            0|  0.00%|\n",
      "  4632|         0|            0|            0|  0.00%|        in_d0 = max(-padding[-2], 0)\n",
      "  4633|         0|            0|            0|  0.00%|        in_d1 = in_shape[2] - max(-padding[-1], 0)\n",
      "  4634|         0|            0|            0|  0.00%|\n",
      "  4635|         0|            0|            0|  0.00%|        in_h0 = max(-padding[-4], 0)\n",
      "  4636|         0|            0|            0|  0.00%|        in_h1 = in_shape[3] - max(-padding[-3], 0)\n",
      "  4637|         0|            0|            0|  0.00%|\n",
      "  4638|         0|            0|            0|  0.00%|        in_w0 = max(-padding[-6], 0)\n",
      "  4639|         0|            0|            0|  0.00%|        in_w1 = in_shape[4] - max(-padding[-5], 0)\n",
      "  4640|         0|            0|            0|  0.00%|\n",
      "  4641|         0|            0|            0|  0.00%|        out[..., out_d0:out_d1, out_h0:out_h1, out_w0:out_w1] = input[..., in_d0:in_d1, in_h0:in_h1, in_w0:in_w1]\n",
      "  4642|         0|            0|            0|  0.00%|\n",
      "  4643|         0|            0|            0|  0.00%|    # The following steps first pad the beginning of the tensor (left side),\n",
      "  4644|         0|            0|            0|  0.00%|    # and then pad the end of the tensor (right side).\n",
      "  4645|         0|            0|            0|  0.00%|    # Note: Corners will be written more than once when ndim > 1.\n",
      "  4646|         0|            0|            0|  0.00%|\n",
      "  4647|         0|            0|            0|  0.00%|    # Only in cases where padding values are > 0 are when additional copying\n",
      "  4648|         0|            0|            0|  0.00%|    # is required.\n",
      "  4649|         0|            0|            0|  0.00%|\n",
      "  4650|         0|            0|            0|  0.00%|    # Pad first dimension (depth)\n",
      "  4651|         0|            0|            0|  0.00%|    if padding[-2] > 0:\n",
      "  4652|         0|            0|            0|  0.00%|        i0 = out_shape[2] - padding[-2] - max(padding[-1], 0)\n",
      "  4653|         0|            0|            0|  0.00%|        i1 = out_shape[2] - max(padding[-1], 0)\n",
      "  4654|         0|            0|            0|  0.00%|        o0 = 0\n",
      "  4655|         0|            0|            0|  0.00%|        o1 = padding[-2]\n",
      "  4656|         0|            0|            0|  0.00%|        out[:, :, o0:o1] = out[:, :, i0:i1]\n",
      "  4657|         0|            0|            0|  0.00%|    if padding[-1] > 0:\n",
      "  4658|         0|            0|            0|  0.00%|        i0 = max(padding[-2], 0)\n",
      "  4659|         0|            0|            0|  0.00%|        i1 = max(padding[-2], 0) + padding[-1]\n",
      "  4660|         0|            0|            0|  0.00%|        o0 = out_shape[2] - padding[-1]\n",
      "  4661|         0|            0|            0|  0.00%|        o1 = out_shape[2]\n",
      "  4662|         0|            0|            0|  0.00%|        out[:, :, o0:o1] = out[:, :, i0:i1]\n",
      "  4663|         0|            0|            0|  0.00%|\n",
      "  4664|         0|            0|            0|  0.00%|    # Pad second dimension (height)\n",
      "  4665|         0|            0|            0|  0.00%|    if len(padding) > 2:\n",
      "  4666|         0|            0|            0|  0.00%|        if padding[-4] > 0:\n",
      "  4667|         0|            0|            0|  0.00%|            i0 = out_shape[3] - padding[-4] - max(padding[-3], 0)\n",
      "  4668|         0|            0|            0|  0.00%|            i1 = out_shape[3] - max(padding[-3], 0)\n",
      "  4669|         0|            0|            0|  0.00%|            o0 = 0\n",
      "  4670|         0|            0|            0|  0.00%|            o1 = padding[-4]\n",
      "  4671|         0|            0|            0|  0.00%|            out[:, :, :, o0:o1] = out[:, :, :, i0:i1]\n",
      "  4672|         0|            0|            0|  0.00%|        if padding[-3] > 0:\n",
      "  4673|         0|            0|            0|  0.00%|            i0 = max(padding[-4], 0)\n",
      "  4674|         0|            0|            0|  0.00%|            i1 = max(padding[-4], 0) + padding[-3]\n",
      "  4675|         0|            0|            0|  0.00%|            o0 = out_shape[3] - padding[-3]\n",
      "  4676|         0|            0|            0|  0.00%|            o1 = out_shape[3]\n",
      "  4677|         0|            0|            0|  0.00%|            out[:, :, :, o0:o1] = out[:, :, :, i0:i1]\n",
      "  4678|         0|            0|            0|  0.00%|\n",
      "  4679|         0|            0|            0|  0.00%|    # Pad third dimension (width)\n",
      "  4680|         0|            0|            0|  0.00%|    if len(padding) > 4:\n",
      "  4681|         0|            0|            0|  0.00%|        if padding[-6] > 0:\n",
      "  4682|         0|            0|            0|  0.00%|            i0 = out_shape[4] - padding[-6] - max(padding[-5], 0)\n",
      "  4683|         0|            0|            0|  0.00%|            i1 = out_shape[4] - max(padding[-5], 0)\n",
      "  4684|         0|            0|            0|  0.00%|            o0 = 0\n",
      "  4685|         0|            0|            0|  0.00%|            o1 = padding[-6]\n",
      "  4686|         0|            0|            0|  0.00%|            out[:, :, :, :, o0:o1] = out[:, :, :, :, i0:i1]\n",
      "  4687|         0|            0|            0|  0.00%|        if padding[-5] > 0:\n",
      "  4688|         0|            0|            0|  0.00%|            i0 = max(padding[-6], 0)\n",
      "  4689|         0|            0|            0|  0.00%|            i1 = max(padding[-6], 0) + padding[-5]\n",
      "  4690|         0|            0|            0|  0.00%|            o0 = out_shape[4] - padding[-5]\n",
      "  4691|         0|            0|            0|  0.00%|            o1 = out_shape[4]\n",
      "  4692|         0|            0|            0|  0.00%|            out[:, :, :, :, o0:o1] = out[:, :, :, :, i0:i1]\n",
      "  4693|         0|            0|            0|  0.00%|\n",
      "  4694|         0|            0|            0|  0.00%|    return out\n",
      "  4695|         0|            0|            0|  0.00%|\n",
      "  4696|         0|            0|            0|  0.00%|#\n",
      "  4697|         0|            0|            0|  0.00%|# multihead attention\n",
      "  4698|         0|            0|            0|  0.00%|#\n",
      "  4699|         0|            0|            0|  0.00%|\n",
      "  4700|         0|            0|            0|  0.00%|def _in_projection_packed(\n",
      "  4701|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4702|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4703|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4704|         0|            0|            0|  0.00%|    w: Tensor,\n",
      "  4705|         0|            0|            0|  0.00%|    b: Optional[Tensor] = None,\n",
      "  4706|         0|            0|            0|  0.00%|) -> List[Tensor]:\n",
      "  4707|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4708|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation, using packed weights.\n",
      "  4709|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.\n",
      "  4710|         0|            0|            0|  0.00%|\n",
      "  4711|         0|            0|            0|  0.00%|    Args:\n",
      "  4712|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected. For self-attention,\n",
      "  4713|         0|            0|            0|  0.00%|            these are typically the same tensor; for encoder-decoder attention,\n",
      "  4714|         0|            0|            0|  0.00%|            k and v are typically the same tensor. (We take advantage of these\n",
      "  4715|         0|            0|            0|  0.00%|            identities for performance if they are present.) Regardless, q, k and v\n",
      "  4716|         0|            0|            0|  0.00%|            must share a common embedding dimension; otherwise their shapes may vary.\n",
      "  4717|         0|            0|            0|  0.00%|        w: projection weights for q, k and v, packed into a single tensor. Weights\n",
      "  4718|         0|            0|            0|  0.00%|            are packed along dimension 0, in q, k, v order.\n",
      "  4719|         0|            0|            0|  0.00%|        b: optional projection biases for q, k and v, packed into a single tensor\n",
      "  4720|         0|            0|            0|  0.00%|            in q, k, v order.\n",
      "  4721|         0|            0|            0|  0.00%|\n",
      "  4722|         0|            0|            0|  0.00%|    Shape:\n",
      "  4723|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4724|         0|            0|            0|  0.00%|        - q: :math:`(..., E)` where E is the embedding dimension\n",
      "  4725|         0|            0|            0|  0.00%|        - k: :math:`(..., E)` where E is the embedding dimension\n",
      "  4726|         0|            0|            0|  0.00%|        - v: :math:`(..., E)` where E is the embedding dimension\n",
      "  4727|         0|            0|            0|  0.00%|        - w: :math:`(E * 3, E)` where E is the embedding dimension\n",
      "  4728|         0|            0|            0|  0.00%|        - b: :math:`E * 3` where E is the embedding dimension\n",
      "  4729|         0|            0|            0|  0.00%|\n",
      "  4730|         0|            0|            0|  0.00%|        Output:\n",
      "  4731|         0|            0|            0|  0.00%|        - in output list :math:`[q', k', v']`, each output tensor will have the\n",
      "  4732|         0|            0|            0|  0.00%|            same shape as the corresponding input tensor.\n",
      "  4733|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4734|         0|            0|            0|  0.00%|    E = q.size(-1)\n",
      "  4735|         0|            0|            0|  0.00%|    if k is v:\n",
      "  4736|         0|            0|            0|  0.00%|        if q is k:\n",
      "  4737|         0|            0|            0|  0.00%|            # self-attention\n",
      "  4738|         0|            0|            0|  0.00%|            return linear(q, w, b).chunk(3, dim=-1)\n",
      "  4739|         0|            0|            0|  0.00%|        else:\n",
      "  4740|         0|            0|            0|  0.00%|            # encoder-decoder attention\n",
      "  4741|         0|            0|            0|  0.00%|            w_q, w_kv = w.split([E, E * 2])\n",
      "  4742|         0|            0|            0|  0.00%|            if b is None:\n",
      "  4743|         0|            0|            0|  0.00%|                b_q = b_kv = None\n",
      "  4744|         0|            0|            0|  0.00%|            else:\n",
      "  4745|         0|            0|            0|  0.00%|                b_q, b_kv = b.split([E, E * 2])\n",
      "  4746|         0|            0|            0|  0.00%|            return (linear(q, w_q, b_q),) + linear(k, w_kv, b_kv).chunk(2, dim=-1)\n",
      "  4747|         0|            0|            0|  0.00%|    else:\n",
      "  4748|         0|            0|            0|  0.00%|        w_q, w_k, w_v = w.chunk(3)\n",
      "  4749|         0|            0|            0|  0.00%|        if b is None:\n",
      "  4750|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None\n",
      "  4751|         0|            0|            0|  0.00%|        else:\n",
      "  4752|         0|            0|            0|  0.00%|            b_q, b_k, b_v = b.chunk(3)\n",
      "  4753|         0|            0|            0|  0.00%|        return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "  4754|         0|            0|            0|  0.00%|\n",
      "  4755|         0|            0|            0|  0.00%|\n",
      "  4756|         0|            0|            0|  0.00%|def _in_projection(\n",
      "  4757|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4758|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4759|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4760|         0|            0|            0|  0.00%|    w_q: Tensor,\n",
      "  4761|         0|            0|            0|  0.00%|    w_k: Tensor,\n",
      "  4762|         0|            0|            0|  0.00%|    w_v: Tensor,\n",
      "  4763|         0|            0|            0|  0.00%|    b_q: Optional[Tensor] = None,\n",
      "  4764|         0|            0|            0|  0.00%|    b_k: Optional[Tensor] = None,\n",
      "  4765|         0|            0|            0|  0.00%|    b_v: Optional[Tensor] = None,\n",
      "  4766|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  4767|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4768|         0|            0|            0|  0.00%|    Performs the in-projection step of the attention operation. This is simply\n",
      "  4769|         0|            0|            0|  0.00%|    a triple of linear projections, with shape constraints on the weights which\n",
      "  4770|         0|            0|            0|  0.00%|    ensure embedding dimension uniformity in the projected outputs.\n",
      "  4771|         0|            0|            0|  0.00%|    Output is a triple containing projection tensors for query, key and value.\n",
      "  4772|         0|            0|            0|  0.00%|\n",
      "  4773|         0|            0|            0|  0.00%|    Args:\n",
      "  4774|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors to be projected.\n",
      "  4775|         0|            0|            0|  0.00%|        w_q, w_k, w_v: weights for q, k and v, respectively.\n",
      "  4776|         0|            0|            0|  0.00%|        b_q, b_k, b_v: optional biases for q, k and v, respectively.\n",
      "  4777|         0|            0|            0|  0.00%|\n",
      "  4778|         0|            0|            0|  0.00%|    Shape:\n",
      "  4779|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4780|         0|            0|            0|  0.00%|        - q: :math:`(Qdims..., Eq)` where Eq is the query embedding dimension and Qdims are any\n",
      "  4781|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4782|         0|            0|            0|  0.00%|        - k: :math:`(Kdims..., Ek)` where Ek is the key embedding dimension and Kdims are any\n",
      "  4783|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4784|         0|            0|            0|  0.00%|        - v: :math:`(Vdims..., Ev)` where Ev is the value embedding dimension and Vdims are any\n",
      "  4785|         0|            0|            0|  0.00%|            number of leading dimensions.\n",
      "  4786|         0|            0|            0|  0.00%|        - w_q: :math:`(Eq, Eq)`\n",
      "  4787|         0|            0|            0|  0.00%|        - w_k: :math:`(Eq, Ek)`\n",
      "  4788|         0|            0|            0|  0.00%|        - w_v: :math:`(Eq, Ev)`\n",
      "  4789|         0|            0|            0|  0.00%|        - b_q: :math:`(Eq)`\n",
      "  4790|         0|            0|            0|  0.00%|        - b_k: :math:`(Eq)`\n",
      "  4791|         0|            0|            0|  0.00%|        - b_v: :math:`(Eq)`\n",
      "  4792|         0|            0|            0|  0.00%|\n",
      "  4793|         0|            0|            0|  0.00%|        Output: in output triple :math:`(q', k', v')`,\n",
      "  4794|         0|            0|            0|  0.00%|         - q': :math:`[Qdims..., Eq]`\n",
      "  4795|         0|            0|            0|  0.00%|         - k': :math:`[Kdims..., Eq]`\n",
      "  4796|         0|            0|            0|  0.00%|         - v': :math:`[Vdims..., Eq]`\n",
      "  4797|         0|            0|            0|  0.00%|\n",
      "  4798|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4799|         0|            0|            0|  0.00%|    Eq, Ek, Ev = q.size(-1), k.size(-1), v.size(-1)\n",
      "  4800|         0|            0|            0|  0.00%|    assert w_q.shape == (Eq, Eq), f\"expecting query weights shape of {(Eq, Eq)}, but got {w_q.shape}\"\n",
      "  4801|         0|            0|            0|  0.00%|    assert w_k.shape == (Eq, Ek), f\"expecting key weights shape of {(Eq, Ek)}, but got {w_k.shape}\"\n",
      "  4802|         0|            0|            0|  0.00%|    assert w_v.shape == (Eq, Ev), f\"expecting value weights shape of {(Eq, Ev)}, but got {w_v.shape}\"\n",
      "  4803|         0|            0|            0|  0.00%|    assert b_q is None or b_q.shape == (Eq,), f\"expecting query bias shape of {(Eq,)}, but got {b_q.shape}\"\n",
      "  4804|         0|            0|            0|  0.00%|    assert b_k is None or b_k.shape == (Eq,), f\"expecting key bias shape of {(Eq,)}, but got {b_k.shape}\"\n",
      "  4805|         0|            0|            0|  0.00%|    assert b_v is None or b_v.shape == (Eq,), f\"expecting value bias shape of {(Eq,)}, but got {b_v.shape}\"\n",
      "  4806|         0|            0|            0|  0.00%|    return linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "  4807|         0|            0|            0|  0.00%|\n",
      "  4808|         0|            0|            0|  0.00%|\n",
      "  4809|         0|            0|            0|  0.00%|def _scaled_dot_product_attention(\n",
      "  4810|         0|            0|            0|  0.00%|    q: Tensor,\n",
      "  4811|         0|            0|            0|  0.00%|    k: Tensor,\n",
      "  4812|         0|            0|            0|  0.00%|    v: Tensor,\n",
      "  4813|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,\n",
      "  4814|         0|            0|            0|  0.00%|    dropout_p: float = 0.0,\n",
      "  4815|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Tensor]:\n",
      "  4816|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4817|         0|            0|            0|  0.00%|    Computes scaled dot product attention on query, key and value tensors, using\n",
      "  4818|         0|            0|            0|  0.00%|    an optional attention mask if passed, and applying dropout if a probability\n",
      "  4819|         0|            0|            0|  0.00%|    greater than 0.0 is specified.\n",
      "  4820|         0|            0|            0|  0.00%|    Returns a tensor pair containing attended values and attention weights.\n",
      "  4821|         0|            0|            0|  0.00%|\n",
      "  4822|         0|            0|            0|  0.00%|    Args:\n",
      "  4823|         0|            0|            0|  0.00%|        q, k, v: query, key and value tensors. See Shape section for shape details.\n",
      "  4824|         0|            0|            0|  0.00%|        attn_mask: optional tensor containing mask values to be added to calculated\n",
      "  4825|         0|            0|            0|  0.00%|            attention. May be 2D or 3D; see Shape section for details.\n",
      "  4826|         0|            0|            0|  0.00%|        dropout_p: dropout probability. If greater than 0.0, dropout is applied.\n",
      "  4827|         0|            0|            0|  0.00%|\n",
      "  4828|         0|            0|            0|  0.00%|    Shape:\n",
      "  4829|         0|            0|            0|  0.00%|        - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,\n",
      "  4830|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4831|         0|            0|            0|  0.00%|        - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,\n",
      "  4832|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4833|         0|            0|            0|  0.00%|        - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,\n",
      "  4834|         0|            0|            0|  0.00%|            and E is embedding dimension.\n",
      "  4835|         0|            0|            0|  0.00%|        - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of\n",
      "  4836|         0|            0|            0|  0.00%|            shape :math:`(Nt, Ns)`.\n",
      "  4837|         0|            0|            0|  0.00%|\n",
      "  4838|         0|            0|            0|  0.00%|        - Output: attention values have shape :math:`(B, Nt, E)`; attention weights\n",
      "  4839|         0|            0|            0|  0.00%|            have shape :math:`(B, Nt, Ns)`\n",
      "  4840|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4841|         0|            0|            0|  0.00%|    B, Nt, E = q.shape\n",
      "  4842|         0|            0|            0|  0.00%|    q = q / math.sqrt(E)\n",
      "  4843|         0|            0|            0|  0.00%|    # (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)\n",
      "  4844|         0|            0|            0|  0.00%|    attn = torch.bmm(q, k.transpose(-2, -1))\n",
      "  4845|         0|            0|            0|  0.00%|    if attn_mask is not None:\n",
      "  4846|         0|            0|            0|  0.00%|        attn += attn_mask\n",
      "  4847|         0|            0|            0|  0.00%|    attn = softmax(attn, dim=-1)\n",
      "  4848|         0|            0|            0|  0.00%|    if dropout_p > 0.0:\n",
      "  4849|         0|            0|            0|  0.00%|        attn = dropout(attn, p=dropout_p)\n",
      "  4850|         0|            0|            0|  0.00%|    # (B, Nt, Ns) x (B, Ns, E) -> (B, Nt, E)\n",
      "  4851|         0|            0|            0|  0.00%|    output = torch.bmm(attn, v)\n",
      "  4852|         0|            0|            0|  0.00%|    return output, attn\n",
      "  4853|         0|            0|            0|  0.00%|\n",
      "  4854|         0|            0|            0|  0.00%|\n",
      "  4855|         0|            0|            0|  0.00%|def multi_head_attention_forward(\n",
      "  4856|         0|            0|            0|  0.00%|    query: Tensor,\n",
      "  4857|         0|            0|            0|  0.00%|    key: Tensor,\n",
      "  4858|         0|            0|            0|  0.00%|    value: Tensor,\n",
      "  4859|         0|            0|            0|  0.00%|    embed_dim_to_check: int,\n",
      "  4860|         0|            0|            0|  0.00%|    num_heads: int,\n",
      "  4861|         0|            0|            0|  0.00%|    in_proj_weight: Tensor,\n",
      "  4862|         0|            0|            0|  0.00%|    in_proj_bias: Optional[Tensor],\n",
      "  4863|         0|            0|            0|  0.00%|    bias_k: Optional[Tensor],\n",
      "  4864|         0|            0|            0|  0.00%|    bias_v: Optional[Tensor],\n",
      "  4865|         0|            0|            0|  0.00%|    add_zero_attn: bool,\n",
      "  4866|         0|            0|            0|  0.00%|    dropout_p: float,\n",
      "  4867|         0|            0|            0|  0.00%|    out_proj_weight: Tensor,\n",
      "  4868|         0|            0|            0|  0.00%|    out_proj_bias: Optional[Tensor],\n",
      "  4869|         0|            0|            0|  0.00%|    training: bool = True,\n",
      "  4870|         0|            0|            0|  0.00%|    key_padding_mask: Optional[Tensor] = None,\n",
      "  4871|         0|            0|            0|  0.00%|    need_weights: bool = True,\n",
      "  4872|         0|            0|            0|  0.00%|    attn_mask: Optional[Tensor] = None,\n",
      "  4873|         0|            0|            0|  0.00%|    use_separate_proj_weight: bool = False,\n",
      "  4874|         0|            0|            0|  0.00%|    q_proj_weight: Optional[Tensor] = None,\n",
      "  4875|         0|            0|            0|  0.00%|    k_proj_weight: Optional[Tensor] = None,\n",
      "  4876|         0|            0|            0|  0.00%|    v_proj_weight: Optional[Tensor] = None,\n",
      "  4877|         0|            0|            0|  0.00%|    static_k: Optional[Tensor] = None,\n",
      "  4878|         0|            0|            0|  0.00%|    static_v: Optional[Tensor] = None,\n",
      "  4879|         0|            0|            0|  0.00%|) -> Tuple[Tensor, Optional[Tensor]]:\n",
      "  4880|         0|            0|            0|  0.00%|    r\"\"\"\n",
      "  4881|         0|            0|            0|  0.00%|    Args:\n",
      "  4882|         0|            0|            0|  0.00%|        query, key, value: map a query and a set of key-value pairs to an output.\n",
      "  4883|         0|            0|            0|  0.00%|            See \"Attention Is All You Need\" for more details.\n",
      "  4884|         0|            0|            0|  0.00%|        embed_dim_to_check: total dimension of the model.\n",
      "  4885|         0|            0|            0|  0.00%|        num_heads: parallel attention heads.\n",
      "  4886|         0|            0|            0|  0.00%|        in_proj_weight, in_proj_bias: input projection weight and bias.\n",
      "  4887|         0|            0|            0|  0.00%|        bias_k, bias_v: bias of the key and value sequences to be added at dim=0.\n",
      "  4888|         0|            0|            0|  0.00%|        add_zero_attn: add a new batch of zeros to the key and\n",
      "  4889|         0|            0|            0|  0.00%|                       value sequences at dim=1.\n",
      "  4890|         0|            0|            0|  0.00%|        dropout_p: probability of an element to be zeroed.\n",
      "  4891|         0|            0|            0|  0.00%|        out_proj_weight, out_proj_bias: the output projection weight and bias.\n",
      "  4892|         0|            0|            0|  0.00%|        training: apply dropout if is ``True``.\n",
      "  4893|         0|            0|            0|  0.00%|        key_padding_mask: if provided, specified padding elements in the key will\n",
      "  4894|         0|            0|            0|  0.00%|            be ignored by the attention. This is an binary mask. When the value is True,\n",
      "  4895|         0|            0|            0|  0.00%|            the corresponding value on the attention layer will be filled with -inf.\n",
      "  4896|         0|            0|            0|  0.00%|        need_weights: output attn_output_weights.\n",
      "  4897|         0|            0|            0|  0.00%|        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all\n",
      "  4898|         0|            0|            0|  0.00%|            the batches while a 3D mask allows to specify a different mask for the entries of each batch.\n",
      "  4899|         0|            0|            0|  0.00%|        use_separate_proj_weight: the function accept the proj. weights for query, key,\n",
      "  4900|         0|            0|            0|  0.00%|            and value in different forms. If false, in_proj_weight will be used, which is\n",
      "  4901|         0|            0|            0|  0.00%|            a combination of q_proj_weight, k_proj_weight, v_proj_weight.\n",
      "  4902|         0|            0|            0|  0.00%|        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.\n",
      "  4903|         0|            0|            0|  0.00%|        static_k, static_v: static key and value used for attention operators.\n",
      "  4904|         0|            0|            0|  0.00%|\n",
      "  4905|         0|            0|            0|  0.00%|\n",
      "  4906|         0|            0|            0|  0.00%|    Shape:\n",
      "  4907|         0|            0|            0|  0.00%|        Inputs:\n",
      "  4908|         0|            0|            0|  0.00%|        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
      "  4909|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4910|         0|            0|            0|  0.00%|        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
      "  4911|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4912|         0|            0|            0|  0.00%|        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
      "  4913|         0|            0|            0|  0.00%|          the embedding dimension.\n",
      "  4914|         0|            0|            0|  0.00%|        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.\n",
      "  4915|         0|            0|            0|  0.00%|          If a ByteTensor is provided, the non-zero positions will be ignored while the zero positions\n",
      "  4916|         0|            0|            0|  0.00%|          will be unchanged. If a BoolTensor is provided, the positions with the\n",
      "  4917|         0|            0|            0|  0.00%|          value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.\n",
      "  4918|         0|            0|            0|  0.00%|        - attn_mask: 2D mask :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
      "  4919|         0|            0|            0|  0.00%|          3D mask :math:`(N*num_heads, L, S)` where N is the batch size, L is the target sequence length,\n",
      "  4920|         0|            0|            0|  0.00%|          S is the source sequence length. attn_mask ensures that position i is allowed to attend the unmasked\n",
      "  4921|         0|            0|            0|  0.00%|          positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend\n",
      "  4922|         0|            0|            0|  0.00%|          while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``\n",
      "  4923|         0|            0|            0|  0.00%|          are not allowed to attend while ``False`` values will be unchanged. If a FloatTensor\n",
      "  4924|         0|            0|            0|  0.00%|          is provided, it will be added to the attention weight.\n",
      "  4925|         0|            0|            0|  0.00%|        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n",
      "  4926|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n",
      "  4927|         0|            0|            0|  0.00%|        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n",
      "  4928|         0|            0|            0|  0.00%|          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n",
      "  4929|         0|            0|            0|  0.00%|\n",
      "  4930|         0|            0|            0|  0.00%|        Outputs:\n",
      "  4931|         0|            0|            0|  0.00%|        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
      "  4932|         0|            0|            0|  0.00%|          E is the embedding dimension.\n",
      "  4933|         0|            0|            0|  0.00%|        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n",
      "  4934|         0|            0|            0|  0.00%|          L is the target sequence length, S is the source sequence length.\n",
      "  4935|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  4936|         0|            0|            0|  0.00%|    tens_ops = (query, key, value, in_proj_weight, in_proj_bias, bias_k, bias_v, out_proj_weight, out_proj_bias)\n",
      "  4937|         0|            0|            0|  0.00%|    if has_torch_function(tens_ops):\n",
      "  4938|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "  4939|         0|            0|            0|  0.00%|            multi_head_attention_forward,\n",
      "  4940|         0|            0|            0|  0.00%|            tens_ops,\n",
      "  4941|         0|            0|            0|  0.00%|            query,\n",
      "  4942|         0|            0|            0|  0.00%|            key,\n",
      "  4943|         0|            0|            0|  0.00%|            value,\n",
      "  4944|         0|            0|            0|  0.00%|            embed_dim_to_check,\n",
      "  4945|         0|            0|            0|  0.00%|            num_heads,\n",
      "  4946|         0|            0|            0|  0.00%|            in_proj_weight,\n",
      "  4947|         0|            0|            0|  0.00%|            in_proj_bias,\n",
      "  4948|         0|            0|            0|  0.00%|            bias_k,\n",
      "  4949|         0|            0|            0|  0.00%|            bias_v,\n",
      "  4950|         0|            0|            0|  0.00%|            add_zero_attn,\n",
      "  4951|         0|            0|            0|  0.00%|            dropout_p,\n",
      "  4952|         0|            0|            0|  0.00%|            out_proj_weight,\n",
      "  4953|         0|            0|            0|  0.00%|            out_proj_bias,\n",
      "  4954|         0|            0|            0|  0.00%|            training=training,\n",
      "  4955|         0|            0|            0|  0.00%|            key_padding_mask=key_padding_mask,\n",
      "  4956|         0|            0|            0|  0.00%|            need_weights=need_weights,\n",
      "  4957|         0|            0|            0|  0.00%|            attn_mask=attn_mask,\n",
      "  4958|         0|            0|            0|  0.00%|            use_separate_proj_weight=use_separate_proj_weight,\n",
      "  4959|         0|            0|            0|  0.00%|            q_proj_weight=q_proj_weight,\n",
      "  4960|         0|            0|            0|  0.00%|            k_proj_weight=k_proj_weight,\n",
      "  4961|         0|            0|            0|  0.00%|            v_proj_weight=v_proj_weight,\n",
      "  4962|         0|            0|            0|  0.00%|            static_k=static_k,\n",
      "  4963|         0|            0|            0|  0.00%|            static_v=static_v,\n",
      "  4964|         0|            0|            0|  0.00%|        )\n",
      "  4965|         0|            0|            0|  0.00%|\n",
      "  4966|         0|            0|            0|  0.00%|    # set up shape vars\n",
      "  4967|         0|            0|            0|  0.00%|    tgt_len, bsz, embed_dim = query.shape\n",
      "  4968|         0|            0|            0|  0.00%|    src_len, _, _ = key.shape\n",
      "  4969|         0|            0|            0|  0.00%|    assert embed_dim == embed_dim_to_check, \\\n",
      "  4970|         0|            0|            0|  0.00%|        f\"was expecting embedding dimension of {embed_dim_to_check}, but got {embed_dim}\"\n",
      "  4971|         0|            0|            0|  0.00%|    if isinstance(embed_dim, torch.Tensor):\n",
      "  4972|         0|            0|            0|  0.00%|        # embed_dim can be a tensor when JIT tracing\n",
      "  4973|         0|            0|            0|  0.00%|        head_dim = embed_dim.div(num_heads, rounding_mode='trunc')\n",
      "  4974|         0|            0|            0|  0.00%|    else:\n",
      "  4975|         0|            0|            0|  0.00%|        head_dim = embed_dim // num_heads\n",
      "  4976|         0|            0|            0|  0.00%|    assert head_dim * num_heads == embed_dim, f\"embed_dim {embed_dim} not divisible by num_heads {num_heads}\"\n",
      "  4977|         0|            0|            0|  0.00%|    if use_separate_proj_weight:\n",
      "  4978|         0|            0|            0|  0.00%|        # allow MHA to have different embedding dimensions when separate projection weights are used\n",
      "  4979|         0|            0|            0|  0.00%|        assert key.shape[:2] == value.shape[:2], \\\n",
      "  4980|         0|            0|            0|  0.00%|            f\"key's sequence and batch dims {key.shape[:2]} do not match value's {value.shape[:2]}\"\n",
      "  4981|         0|            0|            0|  0.00%|    else:\n",
      "  4982|         0|            0|            0|  0.00%|        assert key.shape == value.shape, f\"key shape {key.shape} does not match value shape {value.shape}\"\n",
      "  4983|         0|            0|            0|  0.00%|\n",
      "  4984|         0|            0|            0|  0.00%|    #\n",
      "  4985|         0|            0|            0|  0.00%|    # compute in-projection\n",
      "  4986|         0|            0|            0|  0.00%|    #\n",
      "  4987|         0|            0|            0|  0.00%|    if not use_separate_proj_weight:\n",
      "  4988|         0|            0|            0|  0.00%|        q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n",
      "  4989|         0|            0|            0|  0.00%|    else:\n",
      "  4990|         0|            0|            0|  0.00%|        assert q_proj_weight is not None, \"use_separate_proj_weight is True but q_proj_weight is None\"\n",
      "  4991|         0|            0|            0|  0.00%|        assert k_proj_weight is not None, \"use_separate_proj_weight is True but k_proj_weight is None\"\n",
      "  4992|         0|            0|            0|  0.00%|        assert v_proj_weight is not None, \"use_separate_proj_weight is True but v_proj_weight is None\"\n",
      "  4993|         0|            0|            0|  0.00%|        if in_proj_bias is None:\n",
      "  4994|         0|            0|            0|  0.00%|            b_q = b_k = b_v = None\n",
      "  4995|         0|            0|            0|  0.00%|        else:\n",
      "  4996|         0|            0|            0|  0.00%|            b_q, b_k, b_v = in_proj_bias.chunk(3)\n",
      "  4997|         0|            0|            0|  0.00%|        q, k, v = _in_projection(query, key, value, q_proj_weight, k_proj_weight, v_proj_weight, b_q, b_k, b_v)\n",
      "  4998|         0|            0|            0|  0.00%|\n",
      "  4999|         0|            0|            0|  0.00%|    # prep attention mask\n",
      "  5000|         0|            0|            0|  0.00%|    if attn_mask is not None:\n",
      "  5001|         0|            0|            0|  0.00%|        if attn_mask.dtype == torch.uint8:\n",
      "  5002|         0|            0|            0|  0.00%|            warnings.warn(\"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
      "  5003|         0|            0|            0|  0.00%|            attn_mask = attn_mask.to(torch.bool)\n",
      "  5004|         0|            0|            0|  0.00%|        else:\n",
      "  5005|         0|            0|            0|  0.00%|            assert attn_mask.is_floating_point() or attn_mask.dtype == torch.bool, \\\n",
      "  5006|         0|            0|            0|  0.00%|                f\"Only float, byte, and bool types are supported for attn_mask, not {attn_mask.dtype}\"\n",
      "  5007|         0|            0|            0|  0.00%|        # ensure attn_mask's dim is 3\n",
      "  5008|         0|            0|            0|  0.00%|        if attn_mask.dim() == 2:\n",
      "  5009|         0|            0|            0|  0.00%|            correct_2d_size = (tgt_len, src_len)\n",
      "  5010|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_2d_size:\n",
      "  5011|         0|            0|            0|  0.00%|                raise RuntimeError(f\"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.\")\n",
      "  5012|         0|            0|            0|  0.00%|            attn_mask = attn_mask.unsqueeze(0)\n",
      "  5013|         0|            0|            0|  0.00%|        elif attn_mask.dim() == 3:\n",
      "  5014|         0|            0|            0|  0.00%|            correct_3d_size = (bsz * num_heads, tgt_len, src_len)\n",
      "  5015|         0|            0|            0|  0.00%|            if attn_mask.shape != correct_3d_size:\n",
      "  5016|         0|            0|            0|  0.00%|                raise RuntimeError(f\"The shape of the 3D attn_mask is {attn_mask.shape}, but should be {correct_3d_size}.\")\n",
      "  5017|         0|            0|            0|  0.00%|        else:\n",
      "  5018|         0|            0|            0|  0.00%|            raise RuntimeError(f\"attn_mask's dimension {attn_mask.dim()} is not supported\")\n",
      "  5019|         0|            0|            0|  0.00%|\n",
      "  5020|         0|            0|            0|  0.00%|    # prep key padding mask\n",
      "  5021|         0|            0|            0|  0.00%|    if key_padding_mask is not None and key_padding_mask.dtype == torch.uint8:\n",
      "  5022|         0|            0|            0|  0.00%|        warnings.warn(\"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\")\n",
      "  5023|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.to(torch.bool)\n",
      "  5024|         0|            0|            0|  0.00%|\n",
      "  5025|         0|            0|            0|  0.00%|    # add bias along batch dimension (currently second)\n",
      "  5026|         0|            0|            0|  0.00%|    if bias_k is not None and bias_v is not None:\n",
      "  5027|         0|            0|            0|  0.00%|        assert static_k is None, \"bias cannot be added to static key.\"\n",
      "  5028|         0|            0|            0|  0.00%|        assert static_v is None, \"bias cannot be added to static value.\"\n",
      "  5029|         0|            0|            0|  0.00%|        k = torch.cat([k, bias_k.repeat(1, bsz, 1)])\n",
      "  5030|         0|            0|            0|  0.00%|        v = torch.cat([v, bias_v.repeat(1, bsz, 1)])\n",
      "  5031|         0|            0|            0|  0.00%|        if attn_mask is not None:\n",
      "  5032|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))\n",
      "  5033|         0|            0|            0|  0.00%|        if key_padding_mask is not None:\n",
      "  5034|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))\n",
      "  5035|         0|            0|            0|  0.00%|    else:\n",
      "  5036|         0|            0|            0|  0.00%|        assert bias_k is None\n",
      "  5037|         0|            0|            0|  0.00%|        assert bias_v is None\n",
      "  5038|         0|            0|            0|  0.00%|\n",
      "  5039|         0|            0|            0|  0.00%|    #\n",
      "  5040|         0|            0|            0|  0.00%|    # reshape q, k, v for multihead attention and make em batch first\n",
      "  5041|         0|            0|            0|  0.00%|    #\n",
      "  5042|         0|            0|            0|  0.00%|    q = q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5043|         0|            0|            0|  0.00%|    if static_k is None:\n",
      "  5044|         0|            0|            0|  0.00%|        k = k.contiguous().view(k.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5045|         0|            0|            0|  0.00%|    else:\n",
      "  5046|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
      "  5047|         0|            0|            0|  0.00%|        assert static_k.size(0) == bsz * num_heads, \\\n",
      "  5048|         0|            0|            0|  0.00%|            f\"expecting static_k.size(0) of {bsz * num_heads}, but got {static_k.size(0)}\"\n",
      "  5049|         0|            0|            0|  0.00%|        assert static_k.size(2) == head_dim, \\\n",
      "  5050|         0|            0|            0|  0.00%|            f\"expecting static_k.size(2) of {head_dim}, but got {static_k.size(2)}\"\n",
      "  5051|         0|            0|            0|  0.00%|        k = static_k\n",
      "  5052|         0|            0|            0|  0.00%|    if static_v is None:\n",
      "  5053|         0|            0|            0|  0.00%|        v = v.contiguous().view(v.shape[0], bsz * num_heads, head_dim).transpose(0, 1)\n",
      "  5054|         0|            0|            0|  0.00%|    else:\n",
      "  5055|         0|            0|            0|  0.00%|        # TODO finish disentangling control flow so we don't do in-projections when statics are passed\n",
      "  5056|         0|            0|            0|  0.00%|        assert static_v.size(0) == bsz * num_heads, \\\n",
      "  5057|         0|            0|            0|  0.00%|            f\"expecting static_v.size(0) of {bsz * num_heads}, but got {static_v.size(0)}\"\n",
      "  5058|         0|            0|            0|  0.00%|        assert static_v.size(2) == head_dim, \\\n",
      "  5059|         0|            0|            0|  0.00%|            f\"expecting static_v.size(2) of {head_dim}, but got {static_v.size(2)}\"\n",
      "  5060|         0|            0|            0|  0.00%|        v = static_v\n",
      "  5061|         0|            0|            0|  0.00%|\n",
      "  5062|         0|            0|            0|  0.00%|    # add zero attention along batch dimension (now first)\n",
      "  5063|         0|            0|            0|  0.00%|    if add_zero_attn:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5064|         0|            0|            0|  0.00%|        zero_attn_shape = (bsz * num_heads, 1, head_dim)\n",
      "  5065|         0|            0|            0|  0.00%|        k = torch.cat([k, torch.zeros(zero_attn_shape, dtype=k.dtype, device=k.device)], dim=1)\n",
      "  5066|         0|            0|            0|  0.00%|        v = torch.cat([v, torch.zeros(zero_attn_shape, dtype=v.dtype, device=v.device)], dim=1)\n",
      "  5067|         0|            0|            0|  0.00%|        if attn_mask is not None:\n",
      "  5068|         0|            0|            0|  0.00%|            attn_mask = pad(attn_mask, (0, 1))\n",
      "  5069|         0|            0|            0|  0.00%|        if key_padding_mask is not None:\n",
      "  5070|         0|            0|            0|  0.00%|            key_padding_mask = pad(key_padding_mask, (0, 1))\n",
      "  5071|         0|            0|            0|  0.00%|\n",
      "  5072|         0|            0|            0|  0.00%|    # update source sequence length after adjustments\n",
      "  5073|         0|            0|            0|  0.00%|    src_len = k.size(1)\n",
      "  5074|         0|            0|            0|  0.00%|\n",
      "  5075|         0|            0|            0|  0.00%|    # merge key padding and attention masks\n",
      "  5076|         0|            0|            0|  0.00%|    if key_padding_mask is not None:\n",
      "  5077|         0|            0|            0|  0.00%|        assert key_padding_mask.shape == (bsz, src_len), \\\n",
      "  5078|         0|            0|            0|  0.00%|            f\"expecting key_padding_mask shape of {(bsz, src_len)}, but got {key_padding_mask.shape}\"\n",
      "  5079|         0|            0|            0|  0.00%|        key_padding_mask = key_padding_mask.view(bsz, 1, 1, src_len).   \\\n",
      "  5080|         0|            0|            0|  0.00%|            expand(-1, num_heads, -1, -1).reshape(bsz * num_heads, 1, src_len)\n",
      "  5081|         0|            0|            0|  0.00%|        if attn_mask is None:\n",
      "  5082|         0|            0|            0|  0.00%|            attn_mask = key_padding_mask\n",
      "  5083|         0|            0|            0|  0.00%|        elif attn_mask.dtype == torch.bool:\n",
      "  5084|         0|            0|            0|  0.00%|            attn_mask = attn_mask.logical_or(key_padding_mask)\n",
      "  5085|         0|            0|            0|  0.00%|        else:\n",
      "  5086|         0|            0|            0|  0.00%|            attn_mask = attn_mask.masked_fill(key_padding_mask, float(\"-inf\"))\n",
      "  5087|         0|            0|            0|  0.00%|\n",
      "  5088|         0|            0|            0|  0.00%|    # convert mask to float\n",
      "  5089|         0|            0|            0|  0.00%|    if attn_mask is not None and attn_mask.dtype == torch.bool:\n",
      "  5090|         0|            0|            0|  0.00%|        new_attn_mask = torch.zeros_like(attn_mask, dtype=torch.float)\n",
      "  5091|         0|            0|            0|  0.00%|        new_attn_mask.masked_fill_(attn_mask, float(\"-inf\"))\n",
      "  5092|         0|            0|            0|  0.00%|        attn_mask = new_attn_mask\n",
      "  5093|         0|            0|            0|  0.00%|\n",
      "  5094|         0|            0|            0|  0.00%|    # adjust dropout probability\n",
      "  5095|         0|            0|            0|  0.00%|    if not training:\n",
      "  5096|         0|            0|            0|  0.00%|        dropout_p = 0.0\n",
      "  5097|         0|            0|            0|  0.00%|\n",
      "  5098|         0|            0|            0|  0.00%|    #\n",
      "  5099|         0|            0|            0|  0.00%|    # (deep breath) calculate attention and out projection\n",
      "  5100|         0|            0|            0|  0.00%|    #\n",
      "  5101|         0|            0|            0|  0.00%|    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
      "  5102|         0|            0|            0|  0.00%|    attn_output = attn_output.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
      "  5103|         0|            0|            0|  0.00%|    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "  5104|         0|            0|            0|  0.00%|\n",
      "  5105|         0|            0|            0|  0.00%|    if need_weights:\n",
      "  5106|         0|            0|            0|  0.00%|        # average attention weights over heads\n",
      "  5107|         0|            0|            0|  0.00%|        attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
      "  5108|         0|            0|            0|  0.00%|        return attn_output, attn_output_weights.sum(dim=1) / num_heads\n",
      "  5109|         0|            0|            0|  0.00%|    else:\n",
      "  5110|         0|            0|            0|  0.00%|        return attn_output, None\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py\n",
      "File duration: 0.00421929s (0.05%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import OrderedDict, namedtuple\n",
      "     2|         0|            0|            0|  0.00%|import itertools\n",
      "     3|         0|            0|            0|  0.00%|import warnings\n",
      "     4|         0|            0|            0|  0.00%|import functools\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|import torch\n",
      "     7|         0|            0|            0|  0.00%|from ..parameter import Parameter\n",
      "     8|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|from torch import Tensor, device, dtype\n",
      "    11|         0|            0|            0|  0.00%|from typing import Union, Tuple, Any, Callable, Iterator, Set, Optional, overload, TypeVar, Mapping, Dict, List\n",
      "    12|         0|            0|            0|  0.00%|from ...utils.hooks import RemovableHandle\n",
      "    13|         0|            0|            0|  0.00%|\n",
      "    14|         0|            0|            0|  0.00%|_grad_t = Union[Tuple[Tensor, ...], Tensor]\n",
      "    15|         0|            0|            0|  0.00%|# See https://mypy.readthedocs.io/en/latest/generics.html#generic-methods-and-generic-self for the use\n",
      "    16|         0|            0|            0|  0.00%|# of `T` to annotate `self`. Many methods of `Module` return `self` and we want those return values to be\n",
      "    17|         0|            0|            0|  0.00%|# the type of the subclass, not the looser type of `Module`.\n",
      "    18|         0|            0|            0|  0.00%|T = TypeVar('T', bound='Module')\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         0|            0|            0|  0.00%|class _IncompatibleKeys(namedtuple('IncompatibleKeys', ['missing_keys', 'unexpected_keys'])):\n",
      "    21|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "    22|         0|            0|            0|  0.00%|        if not self.missing_keys and not self.unexpected_keys:\n",
      "    23|         0|            0|            0|  0.00%|            return '<All keys matched successfully>'\n",
      "    24|         0|            0|            0|  0.00%|        return super(_IncompatibleKeys, self).__repr__()\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|    __str__ = __repr__\n",
      "    27|         0|            0|            0|  0.00%|\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|def _addindent(s_, numSpaces):\n",
      "    30|         0|            0|            0|  0.00%|    s = s_.split('\\n')\n",
      "    31|         0|            0|            0|  0.00%|    # don't do anything for single-line stuff\n",
      "    32|         0|            0|            0|  0.00%|    if len(s) == 1:\n",
      "    33|         0|            0|            0|  0.00%|        return s_\n",
      "    34|         0|            0|            0|  0.00%|    first = s.pop(0)\n",
      "    35|         0|            0|            0|  0.00%|    s = [(numSpaces * ' ') + line for line in s]\n",
      "    36|         0|            0|            0|  0.00%|    s = '\\n'.join(s)\n",
      "    37|         0|            0|            0|  0.00%|    s = first + '\\n' + s\n",
      "    38|         0|            0|            0|  0.00%|    return s\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|\n",
      "    41|         0|            0|            0|  0.00%|r\"\"\"This tracks hooks common to all modules that are executed before/after\n",
      "    42|         0|            0|            0|  0.00%|calling forward and backward. This is global state used for debugging/profiling\n",
      "    43|         0|            0|            0|  0.00%|purposes\"\"\"\n",
      "    44|         0|            0|            0|  0.00%|_global_backward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    45|         0|            0|            0|  0.00%|_global_is_full_backward_hook: Optional[bool] = None\n",
      "    46|         0|            0|            0|  0.00%|_global_forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    47|         0|            0|            0|  0.00%|_global_forward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "    48|         0|            0|            0|  0.00%|\n",
      "    49|         0|            0|            0|  0.00%|_EXTRA_STATE_KEY_SUFFIX = '_extra_state'\n",
      "    50|         0|            0|            0|  0.00%|\n",
      "    51|         0|            0|            0|  0.00%|\n",
      "    52|         0|            0|            0|  0.00%|def register_module_forward_pre_hook(hook: Callable[..., None]) -> RemovableHandle:\n",
      "    53|         0|            0|            0|  0.00%|    r\"\"\"Registers a forward pre-hook common to all modules.\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|    .. warning ::\n",
      "    56|         0|            0|            0|  0.00%|\n",
      "    57|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "    58|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "    59|         0|            0|            0|  0.00%|\n",
      "    60|         0|            0|            0|  0.00%|    The hook will be called every time before :func:`forward` is invoked.\n",
      "    61|         0|            0|            0|  0.00%|    It should have the following signature::\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|        hook(module, input) -> None or modified input\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.\n",
      "    66|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "    67|         0|            0|            0|  0.00%|    The hook can modify the input. User can either return a tuple or a\n",
      "    68|         0|            0|            0|  0.00%|    single modified value in the hook. We will wrap the value into a tuple\n",
      "    69|         0|            0|            0|  0.00%|    if a single value is returned(unless that value is already a tuple).\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|    This hook has precedence over the specific module hooks registered with\n",
      "    72|         0|            0|            0|  0.00%|    ``register_forward_pre_hook``.\n",
      "    73|         0|            0|            0|  0.00%|\n",
      "    74|         0|            0|            0|  0.00%|    Returns:\n",
      "    75|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "    76|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "    77|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "    78|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    79|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_pre_hooks)\n",
      "    80|         0|            0|            0|  0.00%|    _global_forward_pre_hooks[handle.id] = hook\n",
      "    81|         0|            0|            0|  0.00%|    return handle\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|def register_module_forward_hook(hook: Callable[..., None]) -> RemovableHandle:\n",
      "    85|         0|            0|            0|  0.00%|    r\"\"\"Registers a global forward hook for all the modules\n",
      "    86|         0|            0|            0|  0.00%|\n",
      "    87|         0|            0|            0|  0.00%|    .. warning ::\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "    90|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    The hook will be called every time after :func:`forward` has computed an output.\n",
      "    93|         0|            0|            0|  0.00%|    It should have the following signature::\n",
      "    94|         0|            0|            0|  0.00%|\n",
      "    95|         0|            0|            0|  0.00%|        hook(module, input, output) -> None or modified output\n",
      "    96|         0|            0|            0|  0.00%|\n",
      "    97|         0|            0|            0|  0.00%|    The input contains only the positional arguments given to the module.\n",
      "    98|         0|            0|            0|  0.00%|    Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "    99|         0|            0|            0|  0.00%|    The hook can modify the output. It can modify the input inplace but\n",
      "   100|         0|            0|            0|  0.00%|    it will not have effect on forward since this is called after\n",
      "   101|         0|            0|            0|  0.00%|    :func:`forward` is called.\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    Returns:\n",
      "   104|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   105|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   106|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   107|         0|            0|            0|  0.00%|\n",
      "   108|         0|            0|            0|  0.00%|    This hook will be executed before specific module hooks registered with\n",
      "   109|         0|            0|            0|  0.00%|    ``register_forward_hook``.\n",
      "   110|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   111|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_forward_hooks)\n",
      "   112|         0|            0|            0|  0.00%|    _global_forward_hooks[handle.id] = hook\n",
      "   113|         0|            0|            0|  0.00%|    return handle\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|def register_module_backward_hook(\n",
      "   116|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   117|         0|            0|            0|  0.00%|) -> RemovableHandle:\n",
      "   118|         0|            0|            0|  0.00%|    r\"\"\"Registers a backward hook common to all the modules.\n",
      "   119|         0|            0|            0|  0.00%|\n",
      "   120|         0|            0|            0|  0.00%|    This function is deprecated in favor of\n",
      "   121|         0|            0|            0|  0.00%|    :func:`torch.nn.modules.module.register_module_full_backward_hook`\n",
      "   122|         0|            0|            0|  0.00%|    and the behavior of this function will change in future versions.\n",
      "   123|         0|            0|            0|  0.00%|\n",
      "   124|         0|            0|            0|  0.00%|    Returns:\n",
      "   125|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   126|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   127|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   130|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook\n",
      "   131|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is True:\n",
      "   132|         0|            0|            0|  0.00%|        raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks as a \"\n",
      "   133|         0|            0|            0|  0.00%|                           \"global Module hook. Please use only one of them.\")\n",
      "   134|         0|            0|            0|  0.00%|\n",
      "   135|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = False\n",
      "   136|         0|            0|            0|  0.00%|\n",
      "   137|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)\n",
      "   138|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook\n",
      "   139|         0|            0|            0|  0.00%|    return handle\n",
      "   140|         0|            0|            0|  0.00%|\n",
      "   141|         0|            0|            0|  0.00%|def register_module_full_backward_hook(\n",
      "   142|         0|            0|            0|  0.00%|    hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   143|         0|            0|            0|  0.00%|) -> RemovableHandle:\n",
      "   144|         0|            0|            0|  0.00%|    r\"\"\"Registers a backward hook common to all the modules.\n",
      "   145|         0|            0|            0|  0.00%|\n",
      "   146|         0|            0|            0|  0.00%|    .. warning ::\n",
      "   147|         0|            0|            0|  0.00%|        This adds global state to the `nn.module` module\n",
      "   148|         0|            0|            0|  0.00%|        and it is only intended for debugging/profiling purposes.\n",
      "   149|         0|            0|            0|  0.00%|\n",
      "   150|         0|            0|            0|  0.00%|    The hook will be called every time the gradients with respect to module\n",
      "   151|         0|            0|            0|  0.00%|    inputs are computed. The hook should have the following signature::\n",
      "   152|         0|            0|            0|  0.00%|\n",
      "   153|         0|            0|            0|  0.00%|        hook(module, grad_input, grad_output) -> Tensor or None\n",
      "   154|         0|            0|            0|  0.00%|\n",
      "   155|         0|            0|            0|  0.00%|    The :attr:`grad_input` and :attr:`grad_output` are tuples. The hook should\n",
      "   156|         0|            0|            0|  0.00%|    not modify its arguments, but it can optionally return a new gradient with\n",
      "   157|         0|            0|            0|  0.00%|    respect to the input that will be used in place of :attr:`grad_input` in\n",
      "   158|         0|            0|            0|  0.00%|    subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      "   159|         0|            0|            0|  0.00%|    as positional arguments and all kwarg arguments will not appear in the hook. Entries\n",
      "   160|         0|            0|            0|  0.00%|    in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      "   161|         0|            0|            0|  0.00%|    arguments.\n",
      "   162|         0|            0|            0|  0.00%|\n",
      "   163|         0|            0|            0|  0.00%|    For technical reasons, when this hook is applied to a Module, its forward function will\n",
      "   164|         0|            0|            0|  0.00%|    receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      "   165|         0|            0|            0|  0.00%|    of each Tensor returned by the Module's forward function.\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|    Global hooks are called before hooks registered with `register_backward_hook`\n",
      "   168|         0|            0|            0|  0.00%|\n",
      "   169|         0|            0|            0|  0.00%|    Returns:\n",
      "   170|         0|            0|            0|  0.00%|        :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   171|         0|            0|            0|  0.00%|            a handle that can be used to remove the added hook by calling\n",
      "   172|         0|            0|            0|  0.00%|            ``handle.remove()``\n",
      "   173|         0|            0|            0|  0.00%|\n",
      "   174|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   175|         0|            0|            0|  0.00%|    global _global_is_full_backward_hook\n",
      "   176|         0|            0|            0|  0.00%|    if _global_is_full_backward_hook is False:\n",
      "   177|         0|            0|            0|  0.00%|        raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks as a \"\n",
      "   178|         0|            0|            0|  0.00%|                           \"global Module hook. Please use only one of them.\")\n",
      "   179|         0|            0|            0|  0.00%|\n",
      "   180|         0|            0|            0|  0.00%|    _global_is_full_backward_hook = True\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    handle = hooks.RemovableHandle(_global_backward_hooks)\n",
      "   183|         0|            0|            0|  0.00%|    _global_backward_hooks[handle.id] = hook\n",
      "   184|         0|            0|            0|  0.00%|    return handle\n",
      "   185|         0|            0|            0|  0.00%|\n",
      "   186|         0|            0|            0|  0.00%|\n",
      "   187|         0|            0|            0|  0.00%|# Trick mypy into not applying contravariance rules to inputs by defining\n",
      "   188|         0|            0|            0|  0.00%|# forward as a value, rather than a function.  See also\n",
      "   189|         0|            0|            0|  0.00%|# https://github.com/python/mypy/issues/8795\n",
      "   190|         0|            0|            0|  0.00%|def _forward_unimplemented(self, *input: Any) -> None:\n",
      "   191|         0|            0|            0|  0.00%|    r\"\"\"Defines the computation performed at every call.\n",
      "   192|         0|            0|            0|  0.00%|\n",
      "   193|         0|            0|            0|  0.00%|    Should be overridden by all subclasses.\n",
      "   194|         0|            0|            0|  0.00%|\n",
      "   195|         0|            0|            0|  0.00%|    .. note::\n",
      "   196|         0|            0|            0|  0.00%|        Although the recipe for forward pass needs to be defined within\n",
      "   197|         0|            0|            0|  0.00%|        this function, one should call the :class:`Module` instance afterwards\n",
      "   198|         0|            0|            0|  0.00%|        instead of this since the former takes care of running the\n",
      "   199|         0|            0|            0|  0.00%|        registered hooks while the latter silently ignores them.\n",
      "   200|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   201|         0|            0|            0|  0.00%|    raise NotImplementedError\n",
      "   202|         0|            0|            0|  0.00%|\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|class Module:\n",
      "   205|         0|            0|            0|  0.00%|    r\"\"\"Base class for all neural network modules.\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|    Your models should also subclass this class.\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|    Modules can also contain other Modules, allowing to nest them in\n",
      "   210|         0|            0|            0|  0.00%|    a tree structure. You can assign the submodules as regular attributes::\n",
      "   211|         0|            0|            0|  0.00%|\n",
      "   212|         0|            0|            0|  0.00%|        import torch.nn as nn\n",
      "   213|         0|            0|            0|  0.00%|        import torch.nn.functional as F\n",
      "   214|         0|            0|            0|  0.00%|\n",
      "   215|         0|            0|            0|  0.00%|        class Model(nn.Module):\n",
      "   216|         0|            0|            0|  0.00%|            def __init__(self):\n",
      "   217|         0|            0|            0|  0.00%|                super(Model, self).__init__()\n",
      "   218|         0|            0|            0|  0.00%|                self.conv1 = nn.Conv2d(1, 20, 5)\n",
      "   219|         0|            0|            0|  0.00%|                self.conv2 = nn.Conv2d(20, 20, 5)\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|            def forward(self, x):\n",
      "   222|         0|            0|            0|  0.00%|                x = F.relu(self.conv1(x))\n",
      "   223|         0|            0|            0|  0.00%|                return F.relu(self.conv2(x))\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|    Submodules assigned in this way will be registered, and will have their\n",
      "   226|         0|            0|            0|  0.00%|    parameters converted too when you call :meth:`to`, etc.\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    :ivar training: Boolean represents whether this module is in training or\n",
      "   229|         0|            0|            0|  0.00%|                    evaluation mode.\n",
      "   230|         0|            0|            0|  0.00%|    :vartype training: bool\n",
      "   231|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   232|         0|            0|            0|  0.00%|\n",
      "   233|         0|            0|            0|  0.00%|    dump_patches: bool = False\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    r\"\"\"This allows better BC support for :meth:`load_state_dict`. In\n",
      "   236|         0|            0|            0|  0.00%|    :meth:`state_dict`, the version number will be saved as in the attribute\n",
      "   237|         0|            0|            0|  0.00%|    `_metadata` of the returned state dict, and thus pickled. `_metadata` is a\n",
      "   238|         0|            0|            0|  0.00%|    dictionary with keys that follow the naming convention of state dict. See\n",
      "   239|         0|            0|            0|  0.00%|    ``_load_from_state_dict`` on how to use this information in loading.\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    If new parameters/buffers are added/removed from a module, this number shall\n",
      "   242|         0|            0|            0|  0.00%|    be bumped, and the module's `_load_from_state_dict` method can compare the\n",
      "   243|         0|            0|            0|  0.00%|    version number and do appropriate changes if the state dict is from before\n",
      "   244|         0|            0|            0|  0.00%|    the change.\"\"\"\n",
      "   245|         0|            0|            0|  0.00%|    _version: int = 1\n",
      "   246|         0|            0|            0|  0.00%|\n",
      "   247|         0|            0|            0|  0.00%|    training: bool\n",
      "   248|         0|            0|            0|  0.00%|    _is_full_backward_hook: Optional[bool]\n",
      "   249|         0|            0|            0|  0.00%|\n",
      "   250|         1|  3.09944e-06|  3.09944e-06|  0.00%|    def __init__(self) -> None:\n",
      "   251|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   252|         0|            0|            0|  0.00%|        Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "   253|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   254|         1|  1.09673e-05|  1.09673e-05|  0.00%|        torch._C._log_api_usage_once(\"python.nn_module\")\n",
      "   255|         0|            0|            0|  0.00%|\n",
      "   256|         1|  1.66893e-05|  1.66893e-05|  0.00%|        self.training = True\n",
      "(call)|         1|  6.31809e-05|  6.31809e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   257|         1|  1.28746e-05|  1.28746e-05|  0.00%|        self._parameters: Dict[str, Optional[Parameter]] = OrderedDict()\n",
      "(call)|         1|  3.40939e-05|  3.40939e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   258|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._buffers: Dict[str, Optional[Tensor]] = OrderedDict()\n",
      "(call)|         1|  3.29018e-05|  3.29018e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   259|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._non_persistent_buffers_set: Set[str] = set()\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   260|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._backward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   261|         1|  1.19209e-05|  1.19209e-05|  0.00%|        self._is_full_backward_hook = None\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   262|         1|  1.09673e-05|  1.09673e-05|  0.00%|        self._forward_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   263|         1|  1.12057e-05|  1.12057e-05|  0.00%|        self._forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   264|         1|  1.19209e-05|  1.19209e-05|  0.00%|        self._state_dict_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.09944e-05|  3.09944e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   265|         1|  1.21593e-05|  1.21593e-05|  0.00%|        self._load_state_dict_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   266|         1|   1.4782e-05|   1.4782e-05|  0.00%|        self._modules: Dict[str, Optional['Module']] = OrderedDict()\n",
      "(call)|         1|  3.31402e-05|  3.31402e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|    forward: Callable[..., Any] = _forward_unimplemented\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         1|  8.82149e-06|  8.82149e-06|  0.00%|    def register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True) -> None:\n",
      "   271|         0|            0|            0|  0.00%|        r\"\"\"Adds a buffer to the module.\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|        This is typically used to register a buffer that should not to be\n",
      "   274|         0|            0|            0|  0.00%|        considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      "   275|         0|            0|            0|  0.00%|        is not a parameter, but is part of the module's state. Buffers, by\n",
      "   276|         0|            0|            0|  0.00%|        default, are persistent and will be saved alongside parameters. This\n",
      "   277|         0|            0|            0|  0.00%|        behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      "   278|         0|            0|            0|  0.00%|        only difference between a persistent buffer and a non-persistent buffer\n",
      "   279|         0|            0|            0|  0.00%|        is that the latter will not be a part of this module's\n",
      "   280|         0|            0|            0|  0.00%|        :attr:`state_dict`.\n",
      "   281|         0|            0|            0|  0.00%|\n",
      "   282|         0|            0|            0|  0.00%|        Buffers can be accessed as attributes using given names.\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|        Args:\n",
      "   285|         0|            0|            0|  0.00%|            name (string): name of the buffer. The buffer can be accessed\n",
      "   286|         0|            0|            0|  0.00%|                from this module using the given name\n",
      "   287|         0|            0|            0|  0.00%|            tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      "   288|         0|            0|            0|  0.00%|                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      "   289|         0|            0|            0|  0.00%|                the buffer is **not** included in the module's :attr:`state_dict`.\n",
      "   290|         0|            0|            0|  0.00%|            persistent (bool): whether the buffer is part of this module's\n",
      "   291|         0|            0|            0|  0.00%|                :attr:`state_dict`.\n",
      "   292|         0|            0|            0|  0.00%|\n",
      "   293|         0|            0|            0|  0.00%|        Example::\n",
      "   294|         0|            0|            0|  0.00%|\n",
      "   295|         0|            0|            0|  0.00%|            >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      "   296|         0|            0|            0|  0.00%|\n",
      "   297|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   298|         1|  4.05312e-06|  4.05312e-06|  0.00%|        if persistent is False and isinstance(self, torch.jit.ScriptModule):\n",
      "   299|         0|            0|            0|  0.00%|            raise RuntimeError(\"ScriptModule does not support non-persistent buffers\")\n",
      "   300|         0|            0|            0|  0.00%|\n",
      "   301|         1|  5.00679e-06|  5.00679e-06|  0.00%|        if '_buffers' not in self.__dict__:\n",
      "   302|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   303|         0|            0|            0|  0.00%|                \"cannot assign buffer before Module.__init__() call\")\n",
      "   304|         1|  4.05312e-06|  4.05312e-06|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   305|         0|            0|            0|  0.00%|            raise TypeError(\"buffer name should be a string. \"\n",
      "   306|         0|            0|            0|  0.00%|                            \"Got {}\".format(torch.typename(name)))\n",
      "   307|         1|   3.8147e-06|   3.8147e-06|  0.00%|        elif '.' in name:\n",
      "   308|         0|            0|            0|  0.00%|            raise KeyError(\"buffer name can't contain \\\".\\\"\")\n",
      "   309|         1|  4.05312e-06|  4.05312e-06|  0.00%|        elif name == '':\n",
      "   310|         0|            0|            0|  0.00%|            raise KeyError(\"buffer name can't be empty string \\\"\\\"\")\n",
      "   311|         1|  1.40667e-05|  1.40667e-05|  0.00%|        elif hasattr(self, name) and name not in self._buffers:\n",
      "(call)|         1|  5.19753e-05|  5.19753e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "   312|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   313|         1|  5.00679e-06|  5.00679e-06|  0.00%|        elif tensor is not None and not isinstance(tensor, torch.Tensor):\n",
      "   314|         0|            0|            0|  0.00%|            raise TypeError(\"cannot assign '{}' object to buffer '{}' \"\n",
      "   315|         0|            0|            0|  0.00%|                            \"(torch Tensor or None required)\"\n",
      "   316|         0|            0|            0|  0.00%|                            .format(torch.typename(tensor), name))\n",
      "   317|         0|            0|            0|  0.00%|        else:\n",
      "   318|         1|  4.05312e-06|  4.05312e-06|  0.00%|            self._buffers[name] = tensor\n",
      "   319|         1|  4.05312e-06|  4.05312e-06|  0.00%|            if persistent:\n",
      "   320|         1|   3.8147e-06|   3.8147e-06|  0.00%|                self._non_persistent_buffers_set.discard(name)\n",
      "   321|         0|            0|            0|  0.00%|            else:\n",
      "   322|         0|            0|            0|  0.00%|                self._non_persistent_buffers_set.add(name)\n",
      "   323|         0|            0|            0|  0.00%|\n",
      "   324|         0|            0|            0|  0.00%|    def register_parameter(self, name: str, param: Optional[Parameter]) -> None:\n",
      "   325|         0|            0|            0|  0.00%|        r\"\"\"Adds a parameter to the module.\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|        The parameter can be accessed as an attribute using given name.\n",
      "   328|         0|            0|            0|  0.00%|\n",
      "   329|         0|            0|            0|  0.00%|        Args:\n",
      "   330|         0|            0|            0|  0.00%|            name (string): name of the parameter. The parameter can be accessed\n",
      "   331|         0|            0|            0|  0.00%|                from this module using the given name\n",
      "   332|         0|            0|            0|  0.00%|            param (Parameter or None): parameter to be added to the module. If\n",
      "   333|         0|            0|            0|  0.00%|                ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      "   334|         0|            0|            0|  0.00%|                are ignored. If ``None``, the parameter is **not** included in the\n",
      "   335|         0|            0|            0|  0.00%|                module's :attr:`state_dict`.\n",
      "   336|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   337|         0|            0|            0|  0.00%|        if '_parameters' not in self.__dict__:\n",
      "   338|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   339|         0|            0|            0|  0.00%|                \"cannot assign parameter before Module.__init__() call\")\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   342|         0|            0|            0|  0.00%|            raise TypeError(\"parameter name should be a string. \"\n",
      "   343|         0|            0|            0|  0.00%|                            \"Got {}\".format(torch.typename(name)))\n",
      "   344|         0|            0|            0|  0.00%|        elif '.' in name:\n",
      "   345|         0|            0|            0|  0.00%|            raise KeyError(\"parameter name can't contain \\\".\\\"\")\n",
      "   346|         0|            0|            0|  0.00%|        elif name == '':\n",
      "   347|         0|            0|            0|  0.00%|            raise KeyError(\"parameter name can't be empty string \\\"\\\"\")\n",
      "   348|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._parameters:\n",
      "   349|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|        if param is None:\n",
      "   352|         0|            0|            0|  0.00%|            self._parameters[name] = None\n",
      "   353|         0|            0|            0|  0.00%|        elif not isinstance(param, Parameter):\n",
      "   354|         0|            0|            0|  0.00%|            raise TypeError(\"cannot assign '{}' object to parameter '{}' \"\n",
      "   355|         0|            0|            0|  0.00%|                            \"(torch.nn.Parameter or None required)\"\n",
      "   356|         0|            0|            0|  0.00%|                            .format(torch.typename(param), name))\n",
      "   357|         0|            0|            0|  0.00%|        elif param.grad_fn:\n",
      "   358|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   359|         0|            0|            0|  0.00%|                \"Cannot assign non-leaf Tensor to parameter '{0}'. Model \"\n",
      "   360|         0|            0|            0|  0.00%|                \"parameters must be created explicitly. To express '{0}' \"\n",
      "   361|         0|            0|            0|  0.00%|                \"as a function of another Tensor, compute the value in \"\n",
      "   362|         0|            0|            0|  0.00%|                \"the forward() method.\".format(name))\n",
      "   363|         0|            0|            0|  0.00%|        else:\n",
      "   364|         0|            0|            0|  0.00%|            self._parameters[name] = param\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    def add_module(self, name: str, module: Optional['Module']) -> None:\n",
      "   367|         0|            0|            0|  0.00%|        r\"\"\"Adds a child module to the current module.\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|        The module can be accessed as an attribute using the given name.\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|        Args:\n",
      "   372|         0|            0|            0|  0.00%|            name (string): name of the child module. The child module can be\n",
      "   373|         0|            0|            0|  0.00%|                accessed from this module using the given name\n",
      "   374|         0|            0|            0|  0.00%|            module (Module): child module to be added to the module.\n",
      "   375|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   376|         0|            0|            0|  0.00%|        if not isinstance(module, Module) and module is not None:\n",
      "   377|         0|            0|            0|  0.00%|            raise TypeError(\"{} is not a Module subclass\".format(\n",
      "   378|         0|            0|            0|  0.00%|                torch.typename(module)))\n",
      "   379|         0|            0|            0|  0.00%|        elif not isinstance(name, torch._six.string_classes):\n",
      "   380|         0|            0|            0|  0.00%|            raise TypeError(\"module name should be a string. Got {}\".format(\n",
      "   381|         0|            0|            0|  0.00%|                torch.typename(name)))\n",
      "   382|         0|            0|            0|  0.00%|        elif hasattr(self, name) and name not in self._modules:\n",
      "   383|         0|            0|            0|  0.00%|            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
      "   384|         0|            0|            0|  0.00%|        elif '.' in name:\n",
      "   385|         0|            0|            0|  0.00%|            raise KeyError(\"module name can't contain \\\".\\\", got: {}\".format(name))\n",
      "   386|         0|            0|            0|  0.00%|        elif name == '':\n",
      "   387|         0|            0|            0|  0.00%|            raise KeyError(\"module name can't be empty string \\\"\\\"\")\n",
      "   388|         0|            0|            0|  0.00%|        self._modules[name] = module\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    def get_submodule(self, target: str) -> \"Module\":\n",
      "   391|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   392|         0|            0|            0|  0.00%|        Returns the submodule given by ``target`` if it exists,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   393|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   394|         0|            0|            0|  0.00%|\n",
      "   395|         0|            0|            0|  0.00%|        For example, let's say you have an ``nn.Module`` ``A`` that\n",
      "   396|         0|            0|            0|  0.00%|        looks like this:\n",
      "   397|         0|            0|            0|  0.00%|\n",
      "   398|         0|            0|            0|  0.00%|        .. code-block::text\n",
      "   399|         0|            0|            0|  0.00%|\n",
      "   400|         0|            0|            0|  0.00%|            A(\n",
      "   401|         0|            0|            0|  0.00%|                (net_b): Module(\n",
      "   402|         0|            0|            0|  0.00%|                    (net_c): Module(\n",
      "   403|         0|            0|            0|  0.00%|                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      "   404|         0|            0|            0|  0.00%|                    )\n",
      "   405|         0|            0|            0|  0.00%|                    (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      "   406|         0|            0|            0|  0.00%|                )\n",
      "   407|         0|            0|            0|  0.00%|            )\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      "   410|         0|            0|            0|  0.00%|        submodule ``net_b``, which itself has two submodules ``net_c``\n",
      "   411|         0|            0|            0|  0.00%|        and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      "   412|         0|            0|            0|  0.00%|\n",
      "   413|         0|            0|            0|  0.00%|        To check whether or not we have the ``linear`` submodule, we\n",
      "   414|         0|            0|            0|  0.00%|        would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      "   415|         0|            0|            0|  0.00%|        we have the ``conv`` submodule, we would call\n",
      "   416|         0|            0|            0|  0.00%|        ``get_submodule(\"net_b.net_c.conv\")``.\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|        The runtime of ``get_submodule`` is bounded by the degree\n",
      "   419|         0|            0|            0|  0.00%|        of module nesting in ``target``. A query against\n",
      "   420|         0|            0|            0|  0.00%|        ``named_modules`` achieves the same result, but it is O(N) in\n",
      "   421|         0|            0|            0|  0.00%|        the number of transitive modules. So, for a simple check to see\n",
      "   422|         0|            0|            0|  0.00%|        if some submodule exists, ``get_submodule`` should always be\n",
      "   423|         0|            0|            0|  0.00%|        used.\n",
      "   424|         0|            0|            0|  0.00%|\n",
      "   425|         0|            0|            0|  0.00%|        Args:\n",
      "   426|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the submodule\n",
      "   427|         0|            0|            0|  0.00%|                to look for. (See above example for how to specify a\n",
      "   428|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   429|         0|            0|            0|  0.00%|\n",
      "   430|         0|            0|            0|  0.00%|        Returns:\n",
      "   431|         0|            0|            0|  0.00%|            torch.nn.Module: The submodule referenced by ``target``\n",
      "   432|         0|            0|            0|  0.00%|\n",
      "   433|         0|            0|            0|  0.00%|        Raises:\n",
      "   434|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   435|         0|            0|            0|  0.00%|                path or resolves to something that is not an\n",
      "   436|         0|            0|            0|  0.00%|                ``nn.Module``\n",
      "   437|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   438|         0|            0|            0|  0.00%|        if target == \"\":\n",
      "   439|         0|            0|            0|  0.00%|            return self\n",
      "   440|         0|            0|            0|  0.00%|\n",
      "   441|         0|            0|            0|  0.00%|        atoms: List[str] = target.split(\".\")\n",
      "   442|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|        for item in atoms:\n",
      "   445|         0|            0|            0|  0.00%|\n",
      "   446|         0|            0|            0|  0.00%|            if not hasattr(mod, item):\n",
      "   447|         0|            0|            0|  0.00%|                raise AttributeError(mod._get_name() + \" has no \"\n",
      "   448|         0|            0|            0|  0.00%|                                     \"attribute `\" + item + \"`\")\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|            mod = getattr(mod, item)\n",
      "   451|         0|            0|            0|  0.00%|\n",
      "   452|         0|            0|            0|  0.00%|            if not isinstance(mod, torch.nn.Module):\n",
      "   453|         0|            0|            0|  0.00%|                raise AttributeError(\"`\" + item + \"` is not \"\n",
      "   454|         0|            0|            0|  0.00%|                                     \"an nn.Module\")\n",
      "   455|         0|            0|            0|  0.00%|\n",
      "   456|         0|            0|            0|  0.00%|        return mod\n",
      "   457|         0|            0|            0|  0.00%|\n",
      "   458|         0|            0|            0|  0.00%|    def get_parameter(self, target: str) -> \"Parameter\":\n",
      "   459|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   460|         0|            0|            0|  0.00%|        Returns the parameter given by ``target`` if it exists,\n",
      "   461|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   462|         0|            0|            0|  0.00%|\n",
      "   463|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed\n",
      "   464|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to\n",
      "   465|         0|            0|            0|  0.00%|        correctly specify ``target``.\n",
      "   466|         0|            0|            0|  0.00%|\n",
      "   467|         0|            0|            0|  0.00%|        Args:\n",
      "   468|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the Parameter\n",
      "   469|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a\n",
      "   470|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   471|         0|            0|            0|  0.00%|\n",
      "   472|         0|            0|            0|  0.00%|        Returns:\n",
      "   473|         0|            0|            0|  0.00%|            torch.nn.Parameter: The Parameter referenced by ``target``\n",
      "   474|         0|            0|            0|  0.00%|\n",
      "   475|         0|            0|            0|  0.00%|        Raises:\n",
      "   476|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   477|         0|            0|            0|  0.00%|                path or resolves to something that is not an\n",
      "   478|         0|            0|            0|  0.00%|                ``nn.Parameter``\n",
      "   479|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   480|         0|            0|            0|  0.00%|        module_path, _, param_name = target.rpartition(\".\")\n",
      "   481|         0|            0|            0|  0.00%|\n",
      "   482|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)\n",
      "   483|         0|            0|            0|  0.00%|\n",
      "   484|         0|            0|            0|  0.00%|        if not hasattr(mod, param_name):\n",
      "   485|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + \" has no attribute `\"\n",
      "   486|         0|            0|            0|  0.00%|                                 + param_name + \"`\")\n",
      "   487|         0|            0|            0|  0.00%|\n",
      "   488|         0|            0|            0|  0.00%|        param: torch.nn.Parameter = getattr(mod, param_name)\n",
      "   489|         0|            0|            0|  0.00%|\n",
      "   490|         0|            0|            0|  0.00%|        if not isinstance(param, torch.nn.Parameter):\n",
      "   491|         0|            0|            0|  0.00%|            raise AttributeError(\"`\" + param_name + \"` is not an \"\n",
      "   492|         0|            0|            0|  0.00%|                                 \"nn.Parameter\")\n",
      "   493|         0|            0|            0|  0.00%|\n",
      "   494|         0|            0|            0|  0.00%|        return param\n",
      "   495|         0|            0|            0|  0.00%|\n",
      "   496|         0|            0|            0|  0.00%|    def get_buffer(self, target: str) -> \"Tensor\":\n",
      "   497|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   498|         0|            0|            0|  0.00%|        Returns the buffer given by ``target`` if it exists,\n",
      "   499|         0|            0|            0|  0.00%|        otherwise throws an error.\n",
      "   500|         0|            0|            0|  0.00%|\n",
      "   501|         0|            0|            0|  0.00%|        See the docstring for ``get_submodule`` for a more detailed\n",
      "   502|         0|            0|            0|  0.00%|        explanation of this method's functionality as well as how to\n",
      "   503|         0|            0|            0|  0.00%|        correctly specify ``target``.\n",
      "   504|         0|            0|            0|  0.00%|\n",
      "   505|         0|            0|            0|  0.00%|        Args:\n",
      "   506|         0|            0|            0|  0.00%|            target: The fully-qualified string name of the buffer\n",
      "   507|         0|            0|            0|  0.00%|                to look for. (See ``get_submodule`` for how to specify a\n",
      "   508|         0|            0|            0|  0.00%|                fully-qualified string.)\n",
      "   509|         0|            0|            0|  0.00%|\n",
      "   510|         0|            0|            0|  0.00%|        Returns:\n",
      "   511|         0|            0|            0|  0.00%|            torch.Tensor: The buffer referenced by ``target``\n",
      "   512|         0|            0|            0|  0.00%|\n",
      "   513|         0|            0|            0|  0.00%|        Raises:\n",
      "   514|         0|            0|            0|  0.00%|            AttributeError: If the target string references an invalid\n",
      "   515|         0|            0|            0|  0.00%|                path or resolves to something that is not a\n",
      "   516|         0|            0|            0|  0.00%|                buffer\n",
      "   517|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   518|         0|            0|            0|  0.00%|        module_path, _, buffer_name = target.rpartition(\".\")\n",
      "   519|         0|            0|            0|  0.00%|\n",
      "   520|         0|            0|            0|  0.00%|        mod: torch.nn.Module = self.get_submodule(module_path)\n",
      "   521|         0|            0|            0|  0.00%|\n",
      "   522|         0|            0|            0|  0.00%|        if not hasattr(mod, buffer_name):\n",
      "   523|         0|            0|            0|  0.00%|            raise AttributeError(mod._get_name() + \" has no attribute `\"\n",
      "   524|         0|            0|            0|  0.00%|                                 + buffer_name + \"`\")\n",
      "   525|         0|            0|            0|  0.00%|\n",
      "   526|         0|            0|            0|  0.00%|        buffer: torch.Tensor = getattr(mod, buffer_name)\n",
      "   527|         0|            0|            0|  0.00%|\n",
      "   528|         0|            0|            0|  0.00%|        if buffer_name not in mod._buffers:\n",
      "   529|         0|            0|            0|  0.00%|            raise AttributeError(\"`\" + buffer_name + \"` is not a buffer\")\n",
      "   530|         0|            0|            0|  0.00%|\n",
      "   531|         0|            0|            0|  0.00%|        return buffer\n",
      "   532|         0|            0|            0|  0.00%|\n",
      "   533|         0|            0|            0|  0.00%|    def get_extra_state(self) -> Any:\n",
      "   534|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   535|         0|            0|            0|  0.00%|        Returns any extra state to include in the module's state_dict.\n",
      "   536|         0|            0|            0|  0.00%|        Implement this and a corresponding :func:`set_extra_state` for your module\n",
      "   537|         0|            0|            0|  0.00%|        if you need to store extra state. This function is called when building the\n",
      "   538|         0|            0|            0|  0.00%|        module's `state_dict()`.\n",
      "   539|         0|            0|            0|  0.00%|\n",
      "   540|         0|            0|            0|  0.00%|        Note that extra state should be pickleable to ensure working serialization\n",
      "   541|         0|            0|            0|  0.00%|        of the state_dict. We only provide provide backwards compatibility guarantees\n",
      "   542|         0|            0|            0|  0.00%|        for serializing Tensors; other objects may break backwards compatibility if\n",
      "   543|         0|            0|            0|  0.00%|        their serialized pickled form changes.\n",
      "   544|         0|            0|            0|  0.00%|\n",
      "   545|         0|            0|            0|  0.00%|        Returns:\n",
      "   546|         0|            0|            0|  0.00%|            object: Any extra state to store in the module's state_dict\n",
      "   547|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   548|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   549|         0|            0|            0|  0.00%|            \"Reached a code path in Module.get_extra_state() that should never be called. \"\n",
      "   550|         0|            0|            0|  0.00%|            \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   551|         0|            0|            0|  0.00%|            \"to report this bug.\")\n",
      "   552|         0|            0|            0|  0.00%|\n",
      "   553|         0|            0|            0|  0.00%|    def set_extra_state(self, state: Any):\n",
      "   554|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   555|         0|            0|            0|  0.00%|        This function is called from :func:`load_state_dict` to handle any extra state\n",
      "   556|         0|            0|            0|  0.00%|        found within the `state_dict`. Implement this function and a corresponding\n",
      "   557|         0|            0|            0|  0.00%|        :func:`get_extra_state` for your module if you need to store extra state within its\n",
      "   558|         0|            0|            0|  0.00%|        `state_dict`.\n",
      "   559|         0|            0|            0|  0.00%|\n",
      "   560|         0|            0|            0|  0.00%|        Args:\n",
      "   561|         0|            0|            0|  0.00%|            state (dict): Extra state from the `state_dict`\n",
      "   562|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   563|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   564|         0|            0|            0|  0.00%|            \"Reached a code path in Module.set_extra_state() that should never be called. \"\n",
      "   565|         0|            0|            0|  0.00%|            \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   566|         0|            0|            0|  0.00%|            \"to report this bug.\")\n",
      "   567|         0|            0|            0|  0.00%|\n",
      "   568|         0|            0|            0|  0.00%|    def _apply(self, fn):\n",
      "   569|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "   570|         0|            0|            0|  0.00%|            module._apply(fn)\n",
      "   571|         0|            0|            0|  0.00%|\n",
      "   572|         0|            0|            0|  0.00%|        def compute_should_use_set_data(tensor, tensor_applied):\n",
      "   573|         0|            0|            0|  0.00%|            if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
      "   574|         0|            0|            0|  0.00%|                # If the new tensor has compatible tensor type as the existing tensor,\n",
      "   575|         0|            0|            0|  0.00%|                # the current behavior is to change the tensor in-place using `.data =`,\n",
      "   576|         0|            0|            0|  0.00%|                # and the future behavior is to overwrite the existing tensor. However,\n",
      "   577|         0|            0|            0|  0.00%|                # changing the current behavior is a BC-breaking change, and we want it\n",
      "   578|         0|            0|            0|  0.00%|                # to happen in future releases. So for now we introduce the\n",
      "   579|         0|            0|            0|  0.00%|                # `torch.__future__.get_overwrite_module_params_on_conversion()`\n",
      "   580|         0|            0|            0|  0.00%|                # global flag to let the user control whether they want the future\n",
      "   581|         0|            0|            0|  0.00%|                # behavior of overwriting the existing tensor or not.\n",
      "   582|         0|            0|            0|  0.00%|                return not torch.__future__.get_overwrite_module_params_on_conversion()\n",
      "   583|         0|            0|            0|  0.00%|            else:\n",
      "   584|         0|            0|            0|  0.00%|                return False\n",
      "   585|         0|            0|            0|  0.00%|\n",
      "   586|         0|            0|            0|  0.00%|        for key, param in self._parameters.items():\n",
      "   587|         0|            0|            0|  0.00%|            if param is None:\n",
      "   588|         0|            0|            0|  0.00%|                continue\n",
      "   589|         0|            0|            0|  0.00%|            # Tensors stored in modules are graph leaves, and we don't want to\n",
      "   590|         0|            0|            0|  0.00%|            # track autograd history of `param_applied`, so we have to use\n",
      "   591|         0|            0|            0|  0.00%|            # `with torch.no_grad():`\n",
      "   592|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   593|         0|            0|            0|  0.00%|                param_applied = fn(param)\n",
      "   594|         0|            0|            0|  0.00%|            should_use_set_data = compute_should_use_set_data(param, param_applied)\n",
      "   595|         0|            0|            0|  0.00%|            if should_use_set_data:\n",
      "   596|         0|            0|            0|  0.00%|                param.data = param_applied\n",
      "   597|         0|            0|            0|  0.00%|                out_param = param\n",
      "   598|         0|            0|            0|  0.00%|            else:\n",
      "   599|         0|            0|            0|  0.00%|                assert isinstance(param, Parameter)\n",
      "   600|         0|            0|            0|  0.00%|                assert param.is_leaf\n",
      "   601|         0|            0|            0|  0.00%|                out_param = Parameter(param_applied, param.requires_grad)\n",
      "   602|         0|            0|            0|  0.00%|                self._parameters[key] = out_param\n",
      "   603|         0|            0|            0|  0.00%|\n",
      "   604|         0|            0|            0|  0.00%|            if param.grad is not None:\n",
      "   605|         0|            0|            0|  0.00%|                with torch.no_grad():\n",
      "   606|         0|            0|            0|  0.00%|                    grad_applied = fn(param.grad)\n",
      "   607|         0|            0|            0|  0.00%|                should_use_set_data = compute_should_use_set_data(param.grad, grad_applied)\n",
      "   608|         0|            0|            0|  0.00%|                if should_use_set_data:\n",
      "   609|         0|            0|            0|  0.00%|                    out_param.grad.data = grad_applied\n",
      "   610|         0|            0|            0|  0.00%|                else:\n",
      "   611|         0|            0|            0|  0.00%|                    assert param.grad.is_leaf\n",
      "   612|         0|            0|            0|  0.00%|                    out_param.grad = grad_applied.requires_grad_(param.grad.requires_grad)\n",
      "   613|         0|            0|            0|  0.00%|\n",
      "   614|         0|            0|            0|  0.00%|        for key, buf in self._buffers.items():\n",
      "   615|         0|            0|            0|  0.00%|            if buf is not None:\n",
      "   616|         0|            0|            0|  0.00%|                self._buffers[key] = fn(buf)\n",
      "   617|         0|            0|            0|  0.00%|\n",
      "   618|         0|            0|            0|  0.00%|        return self\n",
      "   619|         0|            0|            0|  0.00%|\n",
      "   620|         0|            0|            0|  0.00%|    def apply(self: T, fn: Callable[['Module'], None]) -> T:\n",
      "   621|         0|            0|            0|  0.00%|        r\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      "   622|         0|            0|            0|  0.00%|        as well as self. Typical use includes initializing the parameters of a model\n",
      "   623|         0|            0|            0|  0.00%|        (see also :ref:`nn-init-doc`).\n",
      "   624|         0|            0|            0|  0.00%|\n",
      "   625|         0|            0|            0|  0.00%|        Args:\n",
      "   626|         0|            0|            0|  0.00%|            fn (:class:`Module` -> None): function to be applied to each submodule\n",
      "   627|         0|            0|            0|  0.00%|\n",
      "   628|         0|            0|            0|  0.00%|        Returns:\n",
      "   629|         0|            0|            0|  0.00%|            Module: self\n",
      "   630|         0|            0|            0|  0.00%|\n",
      "   631|         0|            0|            0|  0.00%|        Example::\n",
      "   632|         0|            0|            0|  0.00%|\n",
      "   633|         0|            0|            0|  0.00%|            >>> @torch.no_grad()\n",
      "   634|         0|            0|            0|  0.00%|            >>> def init_weights(m):\n",
      "   635|         0|            0|            0|  0.00%|            >>>     print(m)\n",
      "   636|         0|            0|            0|  0.00%|            >>>     if type(m) == nn.Linear:\n",
      "   637|         0|            0|            0|  0.00%|            >>>         m.weight.fill_(1.0)\n",
      "   638|         0|            0|            0|  0.00%|            >>>         print(m.weight)\n",
      "   639|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      "   640|         0|            0|            0|  0.00%|            >>> net.apply(init_weights)\n",
      "   641|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   642|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   643|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],\n",
      "   644|         0|            0|            0|  0.00%|                    [ 1.,  1.]])\n",
      "   645|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   646|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   647|         0|            0|            0|  0.00%|            tensor([[ 1.,  1.],\n",
      "   648|         0|            0|            0|  0.00%|                    [ 1.,  1.]])\n",
      "   649|         0|            0|            0|  0.00%|            Sequential(\n",
      "   650|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "   651|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "   652|         0|            0|            0|  0.00%|            )\n",
      "   653|         0|            0|            0|  0.00%|            Sequential(\n",
      "   654|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "   655|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "   656|         0|            0|            0|  0.00%|            )\n",
      "   657|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   658|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "   659|         0|            0|            0|  0.00%|            module.apply(fn)\n",
      "   660|         0|            0|            0|  0.00%|        fn(self)\n",
      "   661|         0|            0|            0|  0.00%|        return self\n",
      "   662|         0|            0|            0|  0.00%|\n",
      "   663|         0|            0|            0|  0.00%|    def cuda(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
      "   664|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the GPU.\n",
      "   665|         0|            0|            0|  0.00%|\n",
      "   666|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So\n",
      "   667|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will\n",
      "   668|         0|            0|            0|  0.00%|        live on GPU while being optimized.\n",
      "   669|         0|            0|            0|  0.00%|\n",
      "   670|         0|            0|            0|  0.00%|        .. note::\n",
      "   671|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   672|         0|            0|            0|  0.00%|\n",
      "   673|         0|            0|            0|  0.00%|        Args:\n",
      "   674|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be\n",
      "   675|         0|            0|            0|  0.00%|                copied to that device\n",
      "   676|         0|            0|            0|  0.00%|\n",
      "   677|         0|            0|            0|  0.00%|        Returns:\n",
      "   678|         0|            0|            0|  0.00%|            Module: self\n",
      "   679|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   680|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cuda(device))\n",
      "   681|         0|            0|            0|  0.00%|\n",
      "   682|         0|            0|            0|  0.00%|    def xpu(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
      "   683|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the XPU.\n",
      "   684|         0|            0|            0|  0.00%|\n",
      "   685|         0|            0|            0|  0.00%|        This also makes associated parameters and buffers different objects. So\n",
      "   686|         0|            0|            0|  0.00%|        it should be called before constructing optimizer if the module will\n",
      "   687|         0|            0|            0|  0.00%|        live on XPU while being optimized.\n",
      "   688|         0|            0|            0|  0.00%|\n",
      "   689|         0|            0|            0|  0.00%|        .. note::\n",
      "   690|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   691|         0|            0|            0|  0.00%|\n",
      "   692|         0|            0|            0|  0.00%|        Arguments:\n",
      "   693|         0|            0|            0|  0.00%|            device (int, optional): if specified, all parameters will be\n",
      "   694|         0|            0|            0|  0.00%|                copied to that device\n",
      "   695|         0|            0|            0|  0.00%|\n",
      "   696|         0|            0|            0|  0.00%|        Returns:\n",
      "   697|         0|            0|            0|  0.00%|            Module: self\n",
      "   698|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   699|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.xpu(device))\n",
      "   700|         0|            0|            0|  0.00%|\n",
      "   701|         0|            0|            0|  0.00%|    def cpu(self: T) -> T:\n",
      "   702|         0|            0|            0|  0.00%|        r\"\"\"Moves all model parameters and buffers to the CPU.\n",
      "   703|         0|            0|            0|  0.00%|\n",
      "   704|         0|            0|            0|  0.00%|        .. note::\n",
      "   705|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   706|         0|            0|            0|  0.00%|\n",
      "   707|         0|            0|            0|  0.00%|        Returns:\n",
      "   708|         0|            0|            0|  0.00%|            Module: self\n",
      "   709|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   710|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.cpu())\n",
      "   711|         0|            0|            0|  0.00%|\n",
      "   712|         0|            0|            0|  0.00%|    def type(self: T, dst_type: Union[dtype, str]) -> T:\n",
      "   713|         0|            0|            0|  0.00%|        r\"\"\"Casts all parameters and buffers to :attr:`dst_type`.\n",
      "   714|         0|            0|            0|  0.00%|\n",
      "   715|         0|            0|            0|  0.00%|        .. note::\n",
      "   716|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   717|         0|            0|            0|  0.00%|\n",
      "   718|         0|            0|            0|  0.00%|        Args:\n",
      "   719|         0|            0|            0|  0.00%|            dst_type (type or string): the desired type\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|        Returns:\n",
      "   722|         0|            0|            0|  0.00%|            Module: self\n",
      "   723|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   724|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.type(dst_type))\n",
      "   725|         0|            0|            0|  0.00%|\n",
      "   726|         0|            0|            0|  0.00%|    def float(self: T) -> T:\n",
      "   727|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``float`` datatype.\n",
      "   728|         0|            0|            0|  0.00%|\n",
      "   729|         0|            0|            0|  0.00%|        .. note::\n",
      "   730|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   731|         0|            0|            0|  0.00%|\n",
      "   732|         0|            0|            0|  0.00%|        Returns:\n",
      "   733|         0|            0|            0|  0.00%|            Module: self\n",
      "   734|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   735|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.float() if t.is_floating_point() else t)\n",
      "   736|         0|            0|            0|  0.00%|\n",
      "   737|         0|            0|            0|  0.00%|    def double(self: T) -> T:\n",
      "   738|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``double`` datatype.\n",
      "   739|         0|            0|            0|  0.00%|\n",
      "   740|         0|            0|            0|  0.00%|        .. note::\n",
      "   741|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   742|         0|            0|            0|  0.00%|\n",
      "   743|         0|            0|            0|  0.00%|        Returns:\n",
      "   744|         0|            0|            0|  0.00%|            Module: self\n",
      "   745|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   746|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.double() if t.is_floating_point() else t)\n",
      "   747|         0|            0|            0|  0.00%|\n",
      "   748|         0|            0|            0|  0.00%|    def half(self: T) -> T:\n",
      "   749|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``half`` datatype.\n",
      "   750|         0|            0|            0|  0.00%|\n",
      "   751|         0|            0|            0|  0.00%|        .. note::\n",
      "   752|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   753|         0|            0|            0|  0.00%|\n",
      "   754|         0|            0|            0|  0.00%|        Returns:\n",
      "   755|         0|            0|            0|  0.00%|            Module: self\n",
      "   756|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   757|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.half() if t.is_floating_point() else t)\n",
      "   758|         0|            0|            0|  0.00%|\n",
      "   759|         0|            0|            0|  0.00%|    def bfloat16(self: T) -> T:\n",
      "   760|         0|            0|            0|  0.00%|        r\"\"\"Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|        .. note::\n",
      "   763|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   764|         0|            0|            0|  0.00%|\n",
      "   765|         0|            0|            0|  0.00%|        Returns:\n",
      "   766|         0|            0|            0|  0.00%|            Module: self\n",
      "   767|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   768|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.bfloat16() if t.is_floating_point() else t)\n",
      "   769|         0|            0|            0|  0.00%|\n",
      "   770|         0|            0|            0|  0.00%|    def to_empty(self: T, *, device: Union[str, device]) -> T:\n",
      "   771|         0|            0|            0|  0.00%|        r\"\"\"Moves the parameters and buffers to the specified device without copying storage.\n",
      "   772|         0|            0|            0|  0.00%|\n",
      "   773|         0|            0|            0|  0.00%|        Args:\n",
      "   774|         0|            0|            0|  0.00%|            device (:class:`torch.device`): The desired device of the parameters\n",
      "   775|         0|            0|            0|  0.00%|                and buffers in this module.\n",
      "   776|         0|            0|            0|  0.00%|\n",
      "   777|         0|            0|            0|  0.00%|        Returns:\n",
      "   778|         0|            0|            0|  0.00%|            Module: self\n",
      "   779|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   780|         0|            0|            0|  0.00%|        return self._apply(lambda t: torch.empty_like(t, device=device))\n",
      "   781|         0|            0|            0|  0.00%|\n",
      "   782|         0|            0|            0|  0.00%|    @overload\n",
      "   783|         0|            0|            0|  0.00%|    def to(self: T, device: Optional[Union[int, device]] = ..., dtype: Optional[Union[dtype, str]] = ...,\n",
      "   784|         0|            0|            0|  0.00%|           non_blocking: bool = ...) -> T:\n",
      "   785|         0|            0|            0|  0.00%|        ...\n",
      "   786|         0|            0|            0|  0.00%|\n",
      "   787|         0|            0|            0|  0.00%|    @overload\n",
      "   788|         0|            0|            0|  0.00%|    def to(self: T, dtype: Union[dtype, str], non_blocking: bool = ...) -> T:\n",
      "   789|         0|            0|            0|  0.00%|        ...\n",
      "   790|         0|            0|            0|  0.00%|\n",
      "   791|         0|            0|            0|  0.00%|    @overload\n",
      "   792|         0|            0|            0|  0.00%|    def to(self: T, tensor: Tensor, non_blocking: bool = ...) -> T:\n",
      "   793|         0|            0|            0|  0.00%|        ...\n",
      "   794|         0|            0|            0|  0.00%|\n",
      "   795|         0|            0|            0|  0.00%|    def to(self, *args, **kwargs):\n",
      "   796|         0|            0|            0|  0.00%|        r\"\"\"Moves and/or casts the parameters and buffers.\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|        This can be called as\n",
      "   799|         0|            0|            0|  0.00%|\n",
      "   800|         0|            0|            0|  0.00%|        .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      "   801|         0|            0|            0|  0.00%|           :noindex:\n",
      "   802|         0|            0|            0|  0.00%|\n",
      "   803|         0|            0|            0|  0.00%|        .. function:: to(dtype, non_blocking=False)\n",
      "   804|         0|            0|            0|  0.00%|           :noindex:\n",
      "   805|         0|            0|            0|  0.00%|\n",
      "   806|         0|            0|            0|  0.00%|        .. function:: to(tensor, non_blocking=False)\n",
      "   807|         0|            0|            0|  0.00%|           :noindex:\n",
      "   808|         0|            0|            0|  0.00%|\n",
      "   809|         0|            0|            0|  0.00%|        .. function:: to(memory_format=torch.channels_last)\n",
      "   810|         0|            0|            0|  0.00%|           :noindex:\n",
      "   811|         0|            0|            0|  0.00%|\n",
      "   812|         0|            0|            0|  0.00%|        Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      "   813|         0|            0|            0|  0.00%|        floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      "   814|         0|            0|            0|  0.00%|        only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      "   815|         0|            0|            0|  0.00%|        (if given). The integral parameters and buffers will be moved\n",
      "   816|         0|            0|            0|  0.00%|        :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      "   817|         0|            0|            0|  0.00%|        :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      "   818|         0|            0|            0|  0.00%|        with respect to the host if possible, e.g., moving CPU Tensors with\n",
      "   819|         0|            0|            0|  0.00%|        pinned memory to CUDA devices.\n",
      "   820|         0|            0|            0|  0.00%|\n",
      "   821|         0|            0|            0|  0.00%|        See below for examples.\n",
      "   822|         0|            0|            0|  0.00%|\n",
      "   823|         0|            0|            0|  0.00%|        .. note::\n",
      "   824|         0|            0|            0|  0.00%|            This method modifies the module in-place.\n",
      "   825|         0|            0|            0|  0.00%|\n",
      "   826|         0|            0|            0|  0.00%|        Args:\n",
      "   827|         0|            0|            0|  0.00%|            device (:class:`torch.device`): the desired device of the parameters\n",
      "   828|         0|            0|            0|  0.00%|                and buffers in this module\n",
      "   829|         0|            0|            0|  0.00%|            dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      "   830|         0|            0|            0|  0.00%|                the parameters and buffers in this module\n",
      "   831|         0|            0|            0|  0.00%|            tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      "   832|         0|            0|            0|  0.00%|                dtype and device for all parameters and buffers in this module\n",
      "   833|         0|            0|            0|  0.00%|            memory_format (:class:`torch.memory_format`): the desired memory\n",
      "   834|         0|            0|            0|  0.00%|                format for 4D parameters and buffers in this module (keyword\n",
      "   835|         0|            0|            0|  0.00%|                only argument)\n",
      "   836|         0|            0|            0|  0.00%|\n",
      "   837|         0|            0|            0|  0.00%|        Returns:\n",
      "   838|         0|            0|            0|  0.00%|            Module: self\n",
      "   839|         0|            0|            0|  0.00%|\n",
      "   840|         0|            0|            0|  0.00%|        Examples::\n",
      "   841|         0|            0|            0|  0.00%|\n",
      "   842|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2)\n",
      "   843|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   844|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   845|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],\n",
      "   846|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]])\n",
      "   847|         0|            0|            0|  0.00%|            >>> linear.to(torch.double)\n",
      "   848|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   849|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   850|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   851|         0|            0|            0|  0.00%|            tensor([[ 0.1913, -0.3420],\n",
      "   852|         0|            0|            0|  0.00%|                    [-0.5113, -0.2325]], dtype=torch.float64)\n",
      "   853|         0|            0|            0|  0.00%|            >>> gpu1 = torch.device(\"cuda:1\")\n",
      "   854|         0|            0|            0|  0.00%|            >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      "   855|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   856|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   857|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   858|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],\n",
      "   859|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      "   860|         0|            0|            0|  0.00%|            >>> cpu = torch.device(\"cpu\")\n",
      "   861|         0|            0|            0|  0.00%|            >>> linear.to(cpu)\n",
      "   862|         0|            0|            0|  0.00%|            Linear(in_features=2, out_features=2, bias=True)\n",
      "   863|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   864|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   865|         0|            0|            0|  0.00%|            tensor([[ 0.1914, -0.3420],\n",
      "   866|         0|            0|            0|  0.00%|                    [-0.5112, -0.2324]], dtype=torch.float16)\n",
      "   867|         0|            0|            0|  0.00%|\n",
      "   868|         0|            0|            0|  0.00%|            >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      "   869|         0|            0|            0|  0.00%|            >>> linear.weight\n",
      "   870|         0|            0|            0|  0.00%|            Parameter containing:\n",
      "   871|         0|            0|            0|  0.00%|            tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      "   872|         0|            0|            0|  0.00%|                    [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      "   873|         0|            0|            0|  0.00%|            >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      "   874|         0|            0|            0|  0.00%|            tensor([[0.6122+0.j, 0.1150+0.j],\n",
      "   875|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j],\n",
      "   876|         0|            0|            0|  0.00%|                    [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      "   877|         0|            0|            0|  0.00%|\n",
      "   878|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   879|         0|            0|            0|  0.00%|\n",
      "   880|         0|            0|            0|  0.00%|        device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n",
      "   881|         0|            0|            0|  0.00%|\n",
      "   882|         0|            0|            0|  0.00%|        if dtype is not None:\n",
      "   883|         0|            0|            0|  0.00%|            if not (dtype.is_floating_point or dtype.is_complex):\n",
      "   884|         0|            0|            0|  0.00%|                raise TypeError('nn.Module.to only accepts floating point or complex '\n",
      "   885|         0|            0|            0|  0.00%|                                'dtypes, but got desired dtype={}'.format(dtype))\n",
      "   886|         0|            0|            0|  0.00%|            if dtype.is_complex:\n",
      "   887|         0|            0|            0|  0.00%|                warnings.warn(\n",
      "   888|         0|            0|            0|  0.00%|                    \"Complex modules are a new feature under active development whose design may change, \"\n",
      "   889|         0|            0|            0|  0.00%|                    \"and some modules might not work as expected when using complex tensors as parameters or buffers. \"\n",
      "   890|         0|            0|            0|  0.00%|                    \"Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md \"\n",
      "   891|         0|            0|            0|  0.00%|                    \"if a complex module does not work as expected.\")\n",
      "   892|         0|            0|            0|  0.00%|\n",
      "   893|         0|            0|            0|  0.00%|        def convert(t):\n",
      "   894|         0|            0|            0|  0.00%|            if convert_to_format is not None and t.dim() in (4, 5):\n",
      "   895|         0|            0|            0|  0.00%|                return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n",
      "   896|         0|            0|            0|  0.00%|                            non_blocking, memory_format=convert_to_format)\n",
      "   897|         0|            0|            0|  0.00%|            return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|        return self._apply(convert)\n",
      "   900|         0|            0|            0|  0.00%|\n",
      "   901|         0|            0|            0|  0.00%|    def register_backward_hook(\n",
      "   902|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   903|         0|            0|            0|  0.00%|    ) -> RemovableHandle:\n",
      "   904|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook on the module.\n",
      "   905|         0|            0|            0|  0.00%|\n",
      "   906|         0|            0|            0|  0.00%|        This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      "   907|         0|            0|            0|  0.00%|        the behavior of this function will change in future versions.\n",
      "   908|         0|            0|            0|  0.00%|\n",
      "   909|         0|            0|            0|  0.00%|        Returns:\n",
      "   910|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   911|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "   912|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "   913|         0|            0|            0|  0.00%|\n",
      "   914|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   915|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is True:\n",
      "   916|         0|            0|            0|  0.00%|            raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n",
      "   917|         0|            0|            0|  0.00%|                               \"single Module. Please use only one of them.\")\n",
      "   918|         0|            0|            0|  0.00%|\n",
      "   919|         0|            0|            0|  0.00%|        self._is_full_backward_hook = False\n",
      "   920|         0|            0|            0|  0.00%|\n",
      "   921|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   922|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   923|         0|            0|            0|  0.00%|        return handle\n",
      "   924|         0|            0|            0|  0.00%|\n",
      "   925|         0|            0|            0|  0.00%|    def register_full_backward_hook(\n",
      "   926|         0|            0|            0|  0.00%|        self, hook: Callable[['Module', _grad_t, _grad_t], Union[None, Tensor]]\n",
      "   927|         0|            0|            0|  0.00%|    ) -> RemovableHandle:\n",
      "   928|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook on the module.\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|        The hook will be called every time the gradients with respect to module\n",
      "   931|         0|            0|            0|  0.00%|        inputs are computed. The hook should have the following signature::\n",
      "   932|         0|            0|            0|  0.00%|\n",
      "   933|         0|            0|            0|  0.00%|            hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      "   934|         0|            0|            0|  0.00%|\n",
      "   935|         0|            0|            0|  0.00%|        The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      "   936|         0|            0|            0|  0.00%|        with respect to the inputs and outputs respectively. The hook should\n",
      "   937|         0|            0|            0|  0.00%|        not modify its arguments, but it can optionally return a new gradient with\n",
      "   938|         0|            0|            0|  0.00%|        respect to the input that will be used in place of :attr:`grad_input` in\n",
      "   939|         0|            0|            0|  0.00%|        subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      "   940|         0|            0|            0|  0.00%|        as positional arguments and all kwarg arguments are ignored. Entries\n",
      "   941|         0|            0|            0|  0.00%|        in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      "   942|         0|            0|            0|  0.00%|        arguments.\n",
      "   943|         0|            0|            0|  0.00%|\n",
      "   944|         0|            0|            0|  0.00%|        For technical reasons, when this hook is applied to a Module, its forward function will\n",
      "   945|         0|            0|            0|  0.00%|        receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      "   946|         0|            0|            0|  0.00%|        of each Tensor returned by the Module's forward function.\n",
      "   947|         0|            0|            0|  0.00%|\n",
      "   948|         0|            0|            0|  0.00%|        .. warning ::\n",
      "   949|         0|            0|            0|  0.00%|            Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      "   950|         0|            0|            0|  0.00%|            will raise an error.\n",
      "   951|         0|            0|            0|  0.00%|\n",
      "   952|         0|            0|            0|  0.00%|        Returns:\n",
      "   953|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "   954|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "   955|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "   956|         0|            0|            0|  0.00%|\n",
      "   957|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   958|         0|            0|            0|  0.00%|        if self._is_full_backward_hook is False:\n",
      "   959|         0|            0|            0|  0.00%|            raise RuntimeError(\"Cannot use both regular backward hooks and full backward hooks on a \"\n",
      "   960|         0|            0|            0|  0.00%|                               \"single Module. Please use only one of them.\")\n",
      "   961|         0|            0|            0|  0.00%|\n",
      "   962|         0|            0|            0|  0.00%|        self._is_full_backward_hook = True\n",
      "   963|         0|            0|            0|  0.00%|\n",
      "   964|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   965|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   966|         0|            0|            0|  0.00%|        return handle\n",
      "   967|         0|            0|            0|  0.00%|\n",
      "   968|         0|            0|            0|  0.00%|    def _get_backward_hooks(self):\n",
      "   969|         0|            0|            0|  0.00%|        r\"\"\"Returns the backward hooks for use in the call function.\n",
      "   970|         0|            0|            0|  0.00%|        It returns two lists, one with the full backward hooks and one with the non-full\n",
      "   971|         0|            0|            0|  0.00%|        backward hooks.\n",
      "   972|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   973|         0|            0|            0|  0.00%|        full_backward_hooks: List[Callable] = []\n",
      "   974|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is True):\n",
      "   975|         0|            0|            0|  0.00%|            full_backward_hooks += _global_backward_hooks.values()\n",
      "   976|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is True):\n",
      "   977|         0|            0|            0|  0.00%|            full_backward_hooks += self._backward_hooks.values()\n",
      "   978|         0|            0|            0|  0.00%|\n",
      "   979|         0|            0|            0|  0.00%|        non_full_backward_hooks: List[Callable] = []\n",
      "   980|         0|            0|            0|  0.00%|        if (_global_is_full_backward_hook is False):\n",
      "   981|         0|            0|            0|  0.00%|            non_full_backward_hooks += _global_backward_hooks.values()\n",
      "   982|         0|            0|            0|  0.00%|        if (self._is_full_backward_hook is False):\n",
      "   983|         0|            0|            0|  0.00%|            non_full_backward_hooks += self._backward_hooks.values()\n",
      "   984|         0|            0|            0|  0.00%|\n",
      "   985|         0|            0|            0|  0.00%|        return full_backward_hooks, non_full_backward_hooks\n",
      "   986|         0|            0|            0|  0.00%|\n",
      "   987|         0|            0|            0|  0.00%|    def _maybe_warn_non_full_backward_hook(self, inputs, result, grad_fn):\n",
      "   988|         0|            0|            0|  0.00%|        if not isinstance(result, torch.Tensor):\n",
      "   989|         0|            0|            0|  0.00%|            if not (isinstance(result, tuple) and all([isinstance(r, torch.Tensor) for r in result])):\n",
      "   990|         0|            0|            0|  0.00%|                warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "   991|         0|            0|            0|  0.00%|                              \"single Tensor or a tuple of Tensors is deprecated and will be removed \"\n",
      "   992|         0|            0|            0|  0.00%|                              \"in future versions. This hook will be missing some of the grad_output. \"\n",
      "   993|         0|            0|            0|  0.00%|                              \"Please use register_full_backward_hook to get the documented behavior.\")\n",
      "   994|         0|            0|            0|  0.00%|                return\n",
      "   995|         0|            0|            0|  0.00%|        else:\n",
      "   996|         0|            0|            0|  0.00%|            result = (result,)\n",
      "   997|         0|            0|            0|  0.00%|\n",
      "   998|         0|            0|            0|  0.00%|        if not isinstance(inputs, torch.Tensor):\n",
      "   999|         0|            0|            0|  0.00%|            if not (isinstance(inputs, tuple) and all([isinstance(i, torch.Tensor) for i in inputs])):\n",
      "  1000|         0|            0|            0|  0.00%|                warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "  1001|         0|            0|            0|  0.00%|                              \"single Tensor or a tuple of Tensors is deprecated and will be removed \"\n",
      "  1002|         0|            0|            0|  0.00%|                              \"in future versions. This hook will be missing some of the grad_input. \"\n",
      "  1003|         0|            0|            0|  0.00%|                              \"Please use register_full_backward_hook to get the documented behavior.\")\n",
      "  1004|         0|            0|            0|  0.00%|                return\n",
      "  1005|         0|            0|            0|  0.00%|        else:\n",
      "  1006|         0|            0|            0|  0.00%|            inputs = (inputs,)\n",
      "  1007|         0|            0|            0|  0.00%|\n",
      "  1008|         0|            0|            0|  0.00%|        # At this point we are sure that inputs and result are tuple of Tensors\n",
      "  1009|         0|            0|            0|  0.00%|        out_grad_fn = {r.grad_fn for r in result if r.grad_fn is not None}\n",
      "  1010|         0|            0|            0|  0.00%|        if len(out_grad_fn) == 0 or (len(out_grad_fn) == 1 and grad_fn not in out_grad_fn):\n",
      "  1011|         0|            0|            0|  0.00%|            warnings.warn(\"Using a non-full backward hook when outputs are nested in python data structure \"\n",
      "  1012|         0|            0|            0|  0.00%|                          \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1013|         0|            0|            0|  0.00%|                          \"some grad_output.\")\n",
      "  1014|         0|            0|            0|  0.00%|        elif len(out_grad_fn) > 1:\n",
      "  1015|         0|            0|            0|  0.00%|            warnings.warn(\"Using a non-full backward hook when outputs are generated by different autograd Nodes \"\n",
      "  1016|         0|            0|            0|  0.00%|                          \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1017|         0|            0|            0|  0.00%|                          \"some grad_output. Please use register_full_backward_hook to get the documented behavior.\")\n",
      "  1018|         0|            0|            0|  0.00%|        else:\n",
      "  1019|         0|            0|            0|  0.00%|            # At this point the grad_ouput part of the hook will most likely be correct\n",
      "  1020|         0|            0|            0|  0.00%|            inputs_grad_fn = {i.grad_fn for i in inputs if i.grad_fn is not None}\n",
      "  1021|         0|            0|            0|  0.00%|\n",
      "  1022|         0|            0|            0|  0.00%|            next_functions = {n[0] for n in grad_fn.next_functions}\n",
      "  1023|         0|            0|            0|  0.00%|\n",
      "  1024|         0|            0|            0|  0.00%|            if inputs_grad_fn != next_functions:\n",
      "  1025|         0|            0|            0|  0.00%|                warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "  1026|         0|            0|            0|  0.00%|                              \"is deprecated and will be removed in future versions. This hook will be missing \"\n",
      "  1027|         0|            0|            0|  0.00%|                              \"some grad_input. Please use register_full_backward_hook to get the documented \"\n",
      "  1028|         0|            0|            0|  0.00%|                              \"behavior.\")\n",
      "  1029|         0|            0|            0|  0.00%|\n",
      "  1030|         0|            0|            0|  0.00%|    def register_forward_pre_hook(self, hook: Callable[..., None]) -> RemovableHandle:\n",
      "  1031|         0|            0|            0|  0.00%|        r\"\"\"Registers a forward pre-hook on the module.\n",
      "  1032|         0|            0|            0|  0.00%|\n",
      "  1033|         0|            0|            0|  0.00%|        The hook will be called every time before :func:`forward` is invoked.\n",
      "  1034|         0|            0|            0|  0.00%|        It should have the following signature::\n",
      "  1035|         0|            0|            0|  0.00%|\n",
      "  1036|         0|            0|            0|  0.00%|            hook(module, input) -> None or modified input\n",
      "  1037|         0|            0|            0|  0.00%|\n",
      "  1038|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.\n",
      "  1039|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "  1040|         0|            0|            0|  0.00%|        The hook can modify the input. User can either return a tuple or a\n",
      "  1041|         0|            0|            0|  0.00%|        single modified value in the hook. We will wrap the value into a tuple\n",
      "  1042|         0|            0|            0|  0.00%|        if a single value is returned(unless that value is already a tuple).\n",
      "  1043|         0|            0|            0|  0.00%|\n",
      "  1044|         0|            0|            0|  0.00%|        Returns:\n",
      "  1045|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "  1046|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "  1047|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "  1048|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1049|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_pre_hooks)\n",
      "  1050|         0|            0|            0|  0.00%|        self._forward_pre_hooks[handle.id] = hook\n",
      "  1051|         0|            0|            0|  0.00%|        return handle\n",
      "  1052|         0|            0|            0|  0.00%|\n",
      "  1053|         0|            0|            0|  0.00%|    def register_forward_hook(self, hook: Callable[..., None]) -> RemovableHandle:\n",
      "  1054|         0|            0|            0|  0.00%|        r\"\"\"Registers a forward hook on the module.\n",
      "  1055|         0|            0|            0|  0.00%|\n",
      "  1056|         0|            0|            0|  0.00%|        The hook will be called every time after :func:`forward` has computed an output.\n",
      "  1057|         0|            0|            0|  0.00%|        It should have the following signature::\n",
      "  1058|         0|            0|            0|  0.00%|\n",
      "  1059|         0|            0|            0|  0.00%|            hook(module, input, output) -> None or modified output\n",
      "  1060|         0|            0|            0|  0.00%|\n",
      "  1061|         0|            0|            0|  0.00%|        The input contains only the positional arguments given to the module.\n",
      "  1062|         0|            0|            0|  0.00%|        Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      "  1063|         0|            0|            0|  0.00%|        The hook can modify the output. It can modify the input inplace but\n",
      "  1064|         0|            0|            0|  0.00%|        it will not have effect on forward since this is called after\n",
      "  1065|         0|            0|            0|  0.00%|        :func:`forward` is called.\n",
      "  1066|         0|            0|            0|  0.00%|\n",
      "  1067|         0|            0|            0|  0.00%|        Returns:\n",
      "  1068|         0|            0|            0|  0.00%|            :class:`torch.utils.hooks.RemovableHandle`:\n",
      "  1069|         0|            0|            0|  0.00%|                a handle that can be used to remove the added hook by calling\n",
      "  1070|         0|            0|            0|  0.00%|                ``handle.remove()``\n",
      "  1071|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1072|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._forward_hooks)\n",
      "  1073|         0|            0|            0|  0.00%|        self._forward_hooks[handle.id] = hook\n",
      "  1074|         0|            0|            0|  0.00%|        return handle\n",
      "  1075|         0|            0|            0|  0.00%|\n",
      "  1076|         0|            0|            0|  0.00%|    def _slow_forward(self, *input, **kwargs):\n",
      "  1077|         0|            0|            0|  0.00%|        tracing_state = torch._C._get_tracing_state()\n",
      "  1078|         0|            0|            0|  0.00%|        if not tracing_state or isinstance(self.forward, torch._C.ScriptMethod):\n",
      "  1079|         0|            0|            0|  0.00%|            return self.forward(*input, **kwargs)\n",
      "  1080|         0|            0|            0|  0.00%|        recording_scopes = torch.jit._trace._trace_module_map is not None\n",
      "  1081|         0|            0|            0|  0.00%|        if recording_scopes:\n",
      "  1082|         0|            0|            0|  0.00%|            # type ignore was added because at this point one knows that\n",
      "  1083|         0|            0|            0|  0.00%|            # torch.jit._trace._trace_module_map is not Optional and has type Dict[Any, Any]\n",
      "  1084|         0|            0|            0|  0.00%|            name = torch.jit._trace._trace_module_map[self] if self in torch.jit._trace._trace_module_map else None  # type: ignore[index, operator] # noqa: B950\n",
      "  1085|         0|            0|            0|  0.00%|            if name:\n",
      "  1086|         0|            0|            0|  0.00%|                tracing_state.push_scope(name)\n",
      "  1087|         0|            0|            0|  0.00%|            else:\n",
      "  1088|         0|            0|            0|  0.00%|                recording_scopes = False\n",
      "  1089|         0|            0|            0|  0.00%|        try:\n",
      "  1090|         0|            0|            0|  0.00%|            result = self.forward(*input, **kwargs)\n",
      "  1091|         0|            0|            0|  0.00%|        finally:\n",
      "  1092|         0|            0|            0|  0.00%|            if recording_scopes:\n",
      "  1093|         0|            0|            0|  0.00%|                tracing_state.pop_scope()\n",
      "  1094|         0|            0|            0|  0.00%|        return result\n",
      "  1095|         0|            0|            0|  0.00%|\n",
      "  1096|        53|  0.000202179|   3.8147e-06|  0.00%|    def _call_impl(self, *input, **kwargs):\n",
      "  1097|        53|  0.000305414|  5.76253e-06|  0.00%|        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "  1098|         0|            0|            0|  0.00%|        # If we don't have any hooks, we want to skip the rest of the logic in\n",
      "  1099|         0|            0|            0|  0.00%|        # this function, and just call forward.\n",
      "  1100|        53|  0.000225782|  4.26005e-06|  0.00%|        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n",
      "  1101|        53|  0.000186443|   3.5178e-06|  0.00%|                or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "  1102|        53|  0.000654221|  1.23438e-05|  0.01%|            return forward_call(*input, **kwargs)\n",
      "(call)|         9|   0.00129366|   0.00014374|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/sparse.py:157 forward\n",
      "(call)|         9|    0.0180247|   0.00200274|  0.23%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/rnn.py:824 forward\n",
      "(call)|         1|     0.014082|     0.014082|  0.18%|# <ipython-input-176-5d68b8565542>:22 forward\n",
      "(call)|         8|    0.0517087|   0.00646359|  0.65%|# <ipython-input-176-5d68b8565542>:39 forward\n",
      "(call)|        16|   0.00264001|  0.000165001|  0.03%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/linear.py:102 forward\n",
      "(call)|         8|    0.0668242|   0.00835302|  0.84%|# <ipython-input-176-5d68b8565542>:25 forward\n",
      "(call)|         1|    0.0828261|    0.0828261|  1.04%|# <ipython-input-176-5d68b8565542>:19 forward\n",
      "(call)|         1|   0.00437307|   0.00437307|  0.05%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:1149 forward\n",
      "  1103|         0|            0|            0|  0.00%|        # Do not call functions when jit is used\n",
      "  1104|         0|            0|            0|  0.00%|        full_backward_hooks, non_full_backward_hooks = [], []\n",
      "  1105|         0|            0|            0|  0.00%|        if self._backward_hooks or _global_backward_hooks:\n",
      "  1106|         0|            0|            0|  0.00%|            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()\n",
      "  1107|         0|            0|            0|  0.00%|        if _global_forward_pre_hooks or self._forward_pre_hooks:\n",
      "  1108|         0|            0|            0|  0.00%|            for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()):\n",
      "  1109|         0|            0|            0|  0.00%|                result = hook(self, input)\n",
      "  1110|         0|            0|            0|  0.00%|                if result is not None:\n",
      "  1111|         0|            0|            0|  0.00%|                    if not isinstance(result, tuple):\n",
      "  1112|         0|            0|            0|  0.00%|                        result = (result,)\n",
      "  1113|         0|            0|            0|  0.00%|                    input = result\n",
      "  1114|         0|            0|            0|  0.00%|\n",
      "  1115|         0|            0|            0|  0.00%|        bw_hook = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1116|         0|            0|            0|  0.00%|        if full_backward_hooks:\n",
      "  1117|         0|            0|            0|  0.00%|            bw_hook = hooks.BackwardHook(self, full_backward_hooks)\n",
      "  1118|         0|            0|            0|  0.00%|            input = bw_hook.setup_input_hook(input)\n",
      "  1119|         0|            0|            0|  0.00%|\n",
      "  1120|         0|            0|            0|  0.00%|        result = forward_call(*input, **kwargs)\n",
      "  1121|         0|            0|            0|  0.00%|        if _global_forward_hooks or self._forward_hooks:\n",
      "  1122|         0|            0|            0|  0.00%|            for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):\n",
      "  1123|         0|            0|            0|  0.00%|                hook_result = hook(self, input, result)\n",
      "  1124|         0|            0|            0|  0.00%|                if hook_result is not None:\n",
      "  1125|         0|            0|            0|  0.00%|                    result = hook_result\n",
      "  1126|         0|            0|            0|  0.00%|\n",
      "  1127|         0|            0|            0|  0.00%|        if bw_hook:\n",
      "  1128|         0|            0|            0|  0.00%|            result = bw_hook.setup_output_hook(result)\n",
      "  1129|         0|            0|            0|  0.00%|\n",
      "  1130|         0|            0|            0|  0.00%|        # Handle the non-full backward hooks\n",
      "  1131|         0|            0|            0|  0.00%|        if non_full_backward_hooks:\n",
      "  1132|         0|            0|            0|  0.00%|            var = result\n",
      "  1133|         0|            0|            0|  0.00%|            while not isinstance(var, torch.Tensor):\n",
      "  1134|         0|            0|            0|  0.00%|                if isinstance(var, dict):\n",
      "  1135|         0|            0|            0|  0.00%|                    var = next((v for v in var.values() if isinstance(v, torch.Tensor)))\n",
      "  1136|         0|            0|            0|  0.00%|                else:\n",
      "  1137|         0|            0|            0|  0.00%|                    var = var[0]\n",
      "  1138|         0|            0|            0|  0.00%|            grad_fn = var.grad_fn\n",
      "  1139|         0|            0|            0|  0.00%|            if grad_fn is not None:\n",
      "  1140|         0|            0|            0|  0.00%|                for hook in non_full_backward_hooks:\n",
      "  1141|         0|            0|            0|  0.00%|                    wrapper = functools.partial(hook, self)\n",
      "  1142|         0|            0|            0|  0.00%|                    functools.update_wrapper(wrapper, hook)\n",
      "  1143|         0|            0|            0|  0.00%|                    grad_fn.register_hook(wrapper)\n",
      "  1144|         0|            0|            0|  0.00%|                self._maybe_warn_non_full_backward_hook(input, result, grad_fn)\n",
      "  1145|         0|            0|            0|  0.00%|\n",
      "  1146|         0|            0|            0|  0.00%|        return result\n",
      "  1147|         0|            0|            0|  0.00%|\n",
      "  1148|         0|            0|            0|  0.00%|    __call__ : Callable[..., Any] = _call_impl\n",
      "  1149|         0|            0|            0|  0.00%|\n",
      "  1150|         0|            0|            0|  0.00%|    def __setstate__(self, state):\n",
      "  1151|         0|            0|            0|  0.00%|        self.__dict__.update(state)\n",
      "  1152|         0|            0|            0|  0.00%|        # Support loading old checkpoints that don't have the following attrs:\n",
      "  1153|         0|            0|            0|  0.00%|        if '_forward_pre_hooks' not in self.__dict__:\n",
      "  1154|         0|            0|            0|  0.00%|            self._forward_pre_hooks = OrderedDict()\n",
      "  1155|         0|            0|            0|  0.00%|        if '_state_dict_hooks' not in self.__dict__:\n",
      "  1156|         0|            0|            0|  0.00%|            self._state_dict_hooks = OrderedDict()\n",
      "  1157|         0|            0|            0|  0.00%|        if '_load_state_dict_pre_hooks' not in self.__dict__:\n",
      "  1158|         0|            0|            0|  0.00%|            self._load_state_dict_pre_hooks = OrderedDict()\n",
      "  1159|         0|            0|            0|  0.00%|        if '_non_persistent_buffers_set' not in self.__dict__:\n",
      "  1160|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set = set()\n",
      "  1161|         0|            0|            0|  0.00%|        if '_is_full_backward_hook' not in self.__dict__:\n",
      "  1162|         0|            0|            0|  0.00%|            self._is_full_backward_hook = None\n",
      "  1163|         0|            0|            0|  0.00%|\n",
      "  1164|        94|  0.000243902|   2.5947e-06|  0.00%|    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:\n",
      "  1165|        94|  0.000275373|   2.9295e-06|  0.00%|        if '_parameters' in self.__dict__:\n",
      "  1166|        94|  0.000237703|  2.52876e-06|  0.00%|            _parameters = self.__dict__['_parameters']\n",
      "  1167|        94|  0.000222921|   2.3715e-06|  0.00%|            if name in _parameters:\n",
      "  1168|        41|  0.000100374|  2.44815e-06|  0.00%|                return _parameters[name]\n",
      "  1169|        53|   0.00013113|  2.47416e-06|  0.00%|        if '_buffers' in self.__dict__:\n",
      "  1170|        53|  0.000124454|   2.3482e-06|  0.00%|            _buffers = self.__dict__['_buffers']\n",
      "  1171|        53|  0.000126123|  2.37969e-06|  0.00%|            if name in _buffers:\n",
      "  1172|         1|  1.90735e-06|  1.90735e-06|  0.00%|                return _buffers[name]\n",
      "  1173|        52|  0.000118971|   2.2879e-06|  0.00%|        if '_modules' in self.__dict__:\n",
      "  1174|        52|  0.000120163|  2.31083e-06|  0.00%|            modules = self.__dict__['_modules']\n",
      "  1175|        52|  0.000111103|   2.1366e-06|  0.00%|            if name in modules:\n",
      "  1176|        51|  0.000119448|  2.34211e-06|  0.00%|                return modules[name]\n",
      "  1177|         1|   3.8147e-06|   3.8147e-06|  0.00%|        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "  1178|         1|  7.15256e-06|  7.15256e-06|  0.00%|            type(self).__name__, name))\n",
      "  1179|         0|            0|            0|  0.00%|\n",
      "  1180|        14|  5.00679e-05|  3.57628e-06|  0.00%|    def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -> None:\n",
      "  1181|        14|    4.673e-05|  3.33786e-06|  0.00%|        def remove_from(*dicts_or_sets):\n",
      "  1182|         0|            0|            0|  0.00%|            for d in dicts_or_sets:\n",
      "  1183|         0|            0|            0|  0.00%|                if name in d:\n",
      "  1184|         0|            0|            0|  0.00%|                    if isinstance(d, dict):\n",
      "  1185|         0|            0|            0|  0.00%|                        del d[name]\n",
      "  1186|         0|            0|            0|  0.00%|                    else:\n",
      "  1187|         0|            0|            0|  0.00%|                        d.discard(name)\n",
      "  1188|         0|            0|            0|  0.00%|\n",
      "  1189|        14|  4.74453e-05|  3.38895e-06|  0.00%|        params = self.__dict__.get('_parameters')\n",
      "  1190|        14|  4.52995e-05|  3.23568e-06|  0.00%|        if isinstance(value, Parameter):\n",
      "  1191|         0|            0|            0|  0.00%|            if params is None:\n",
      "  1192|         0|            0|            0|  0.00%|                raise AttributeError(\n",
      "  1193|         0|            0|            0|  0.00%|                    \"cannot assign parameters before Module.__init__() call\")\n",
      "  1194|         0|            0|            0|  0.00%|            remove_from(self.__dict__, self._buffers, self._modules, self._non_persistent_buffers_set)\n",
      "  1195|         0|            0|            0|  0.00%|            self.register_parameter(name, value)\n",
      "  1196|        14|  4.31538e-05|  3.08241e-06|  0.00%|        elif params is not None and name in params:\n",
      "  1197|         0|            0|            0|  0.00%|            if value is not None:\n",
      "  1198|         0|            0|            0|  0.00%|                raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n",
      "  1199|         0|            0|            0|  0.00%|                                \"(torch.nn.Parameter or None expected)\"\n",
      "  1200|         0|            0|            0|  0.00%|                                .format(torch.typename(value), name))\n",
      "  1201|         0|            0|            0|  0.00%|            self.register_parameter(name, value)\n",
      "  1202|         0|            0|            0|  0.00%|        else:\n",
      "  1203|        14|  4.45843e-05|  3.18459e-06|  0.00%|            modules = self.__dict__.get('_modules')\n",
      "  1204|        14|  4.33922e-05|  3.09944e-06|  0.00%|            if isinstance(value, Module):\n",
      "  1205|         0|            0|            0|  0.00%|                if modules is None:\n",
      "  1206|         0|            0|            0|  0.00%|                    raise AttributeError(\n",
      "  1207|         0|            0|            0|  0.00%|                        \"cannot assign module before Module.__init__() call\")\n",
      "  1208|         0|            0|            0|  0.00%|                remove_from(self.__dict__, self._parameters, self._buffers, self._non_persistent_buffers_set)\n",
      "  1209|         0|            0|            0|  0.00%|                modules[name] = value\n",
      "  1210|        14|  3.71933e-05|  2.65666e-06|  0.00%|            elif modules is not None and name in modules:\n",
      "  1211|         0|            0|            0|  0.00%|                if value is not None:\n",
      "  1212|         0|            0|            0|  0.00%|                    raise TypeError(\"cannot assign '{}' as child module '{}' \"\n",
      "  1213|         0|            0|            0|  0.00%|                                    \"(torch.nn.Module or None expected)\"\n",
      "  1214|         0|            0|            0|  0.00%|                                    .format(torch.typename(value), name))\n",
      "  1215|         0|            0|            0|  0.00%|                modules[name] = value\n",
      "  1216|         0|            0|            0|  0.00%|            else:\n",
      "  1217|        14|   4.1008e-05|  2.92914e-06|  0.00%|                buffers = self.__dict__.get('_buffers')\n",
      "  1218|        14|  3.93391e-05|  2.80993e-06|  0.00%|                if buffers is not None and name in buffers:\n",
      "  1219|         0|            0|            0|  0.00%|                    if value is not None and not isinstance(value, torch.Tensor):\n",
      "  1220|         0|            0|            0|  0.00%|                        raise TypeError(\"cannot assign '{}' as buffer '{}' \"\n",
      "  1221|         0|            0|            0|  0.00%|                                        \"(torch.Tensor or None expected)\"\n",
      "  1222|         0|            0|            0|  0.00%|                                        .format(torch.typename(value), name))\n",
      "  1223|         0|            0|            0|  0.00%|                    buffers[name] = value\n",
      "  1224|         0|            0|            0|  0.00%|                else:\n",
      "  1225|        14|  5.22137e-05|  3.72955e-06|  0.00%|                    object.__setattr__(self, name, value)\n",
      "  1226|         0|            0|            0|  0.00%|\n",
      "  1227|         0|            0|            0|  0.00%|    def __delattr__(self, name):\n",
      "  1228|         0|            0|            0|  0.00%|        if name in self._parameters:\n",
      "  1229|         0|            0|            0|  0.00%|            del self._parameters[name]\n",
      "  1230|         0|            0|            0|  0.00%|        elif name in self._buffers:\n",
      "  1231|         0|            0|            0|  0.00%|            del self._buffers[name]\n",
      "  1232|         0|            0|            0|  0.00%|            self._non_persistent_buffers_set.discard(name)\n",
      "  1233|         0|            0|            0|  0.00%|        elif name in self._modules:\n",
      "  1234|         0|            0|            0|  0.00%|            del self._modules[name]\n",
      "  1235|         0|            0|            0|  0.00%|        else:\n",
      "  1236|         0|            0|            0|  0.00%|            object.__delattr__(self, name)\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    def _register_state_dict_hook(self, hook):\n",
      "  1239|         0|            0|            0|  0.00%|        r\"\"\"These hooks will be called with arguments: `self`, `state_dict`,\n",
      "  1240|         0|            0|            0|  0.00%|        `prefix`, `local_metadata`, after the `state_dict` of `self` is set.\n",
      "  1241|         0|            0|            0|  0.00%|        Note that only parameters and buffers of `self` or its children are\n",
      "  1242|         0|            0|            0|  0.00%|        guaranteed to exist in `state_dict`. The hooks may modify `state_dict`\n",
      "  1243|         0|            0|            0|  0.00%|        inplace or return a new one.\n",
      "  1244|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1245|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._state_dict_hooks)\n",
      "  1246|         0|            0|            0|  0.00%|        self._state_dict_hooks[handle.id] = hook\n",
      "  1247|         0|            0|            0|  0.00%|        return handle\n",
      "  1248|         0|            0|            0|  0.00%|\n",
      "  1249|         0|            0|            0|  0.00%|    def _save_to_state_dict(self, destination, prefix, keep_vars):\n",
      "  1250|         0|            0|            0|  0.00%|        r\"\"\"Saves module state to `destination` dictionary, containing a state\n",
      "  1251|         0|            0|            0|  0.00%|        of the module, but not its descendants. This is called on every\n",
      "  1252|         0|            0|            0|  0.00%|        submodule in :meth:`~torch.nn.Module.state_dict`.\n",
      "  1253|         0|            0|            0|  0.00%|\n",
      "  1254|         0|            0|            0|  0.00%|        In rare cases, subclasses can achieve class-specific behavior by\n",
      "  1255|         0|            0|            0|  0.00%|        overriding this method with custom logic.\n",
      "  1256|         0|            0|            0|  0.00%|\n",
      "  1257|         0|            0|            0|  0.00%|        Args:\n",
      "  1258|         0|            0|            0|  0.00%|            destination (dict): a dict where state will be stored\n",
      "  1259|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this\n",
      "  1260|         0|            0|            0|  0.00%|                module\n",
      "  1261|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1262|         0|            0|            0|  0.00%|        for name, param in self._parameters.items():\n",
      "  1263|         0|            0|            0|  0.00%|            if param is not None:\n",
      "  1264|         0|            0|            0|  0.00%|                destination[prefix + name] = param if keep_vars else param.detach()\n",
      "  1265|         0|            0|            0|  0.00%|        for name, buf in self._buffers.items():\n",
      "  1266|         0|            0|            0|  0.00%|            if buf is not None and name not in self._non_persistent_buffers_set:\n",
      "  1267|         0|            0|            0|  0.00%|                destination[prefix + name] = buf if keep_vars else buf.detach()\n",
      "  1268|         0|            0|            0|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
      "  1269|         0|            0|            0|  0.00%|        if getattr(self.__class__, \"get_extra_state\", Module.get_extra_state) is not Module.get_extra_state:\n",
      "  1270|         0|            0|            0|  0.00%|            destination[extra_state_key] = self.get_extra_state()\n",
      "  1271|         0|            0|            0|  0.00%|\n",
      "  1272|         0|            0|            0|  0.00%|    # The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns\n",
      "  1273|         0|            0|            0|  0.00%|    # back that same object. But if they pass nothing, an `OrederedDict` is created and returned.\n",
      "  1274|         0|            0|            0|  0.00%|    T_destination = TypeVar('T_destination', bound=Mapping[str, Tensor])\n",
      "  1275|         0|            0|            0|  0.00%|\n",
      "  1276|         0|            0|            0|  0.00%|    @overload\n",
      "  1277|         0|            0|            0|  0.00%|    def state_dict(self, destination: T_destination, prefix: str = ..., keep_vars: bool = ...) -> T_destination:\n",
      "  1278|         0|            0|            0|  0.00%|        ...\n",
      "  1279|         0|            0|            0|  0.00%|\n",
      "  1280|         0|            0|            0|  0.00%|    # TODO: Remove string escape once Python-3.6 no longer supported\n",
      "  1281|         0|            0|            0|  0.00%|    # See https://github.com/python/mypy/issues/6904#issuecomment-496207426\n",
      "  1282|         0|            0|            0|  0.00%|    @overload\n",
      "  1283|         0|            0|            0|  0.00%|    def state_dict(self, prefix: str = ..., keep_vars: bool = ...) -> 'OrderedDict[str, Tensor]':\n",
      "  1284|         0|            0|            0|  0.00%|        ...\n",
      "  1285|         0|            0|            0|  0.00%|\n",
      "  1286|         0|            0|            0|  0.00%|    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
      "  1287|         0|            0|            0|  0.00%|        r\"\"\"Returns a dictionary containing a whole state of the module.\n",
      "  1288|         0|            0|            0|  0.00%|\n",
      "  1289|         0|            0|            0|  0.00%|        Both parameters and persistent buffers (e.g. running averages) are\n",
      "  1290|         0|            0|            0|  0.00%|        included. Keys are corresponding parameter and buffer names.\n",
      "  1291|         0|            0|            0|  0.00%|        Parameters and buffers set to ``None`` are not included.\n",
      "  1292|         0|            0|            0|  0.00%|\n",
      "  1293|         0|            0|            0|  0.00%|        Returns:\n",
      "  1294|         0|            0|            0|  0.00%|            dict:\n",
      "  1295|         0|            0|            0|  0.00%|                a dictionary containing a whole state of the module\n",
      "  1296|         0|            0|            0|  0.00%|\n",
      "  1297|         0|            0|            0|  0.00%|        Example::\n",
      "  1298|         0|            0|            0|  0.00%|\n",
      "  1299|         0|            0|            0|  0.00%|            >>> module.state_dict().keys()\n",
      "  1300|         0|            0|            0|  0.00%|            ['bias', 'weight']\n",
      "  1301|         0|            0|            0|  0.00%|\n",
      "  1302|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1303|         0|            0|            0|  0.00%|        if destination is None:\n",
      "  1304|         0|            0|            0|  0.00%|            destination = OrderedDict()\n",
      "  1305|         0|            0|            0|  0.00%|            destination._metadata = OrderedDict()\n",
      "  1306|         0|            0|            0|  0.00%|        destination._metadata[prefix[:-1]] = local_metadata = dict(version=self._version)\n",
      "  1307|         0|            0|            0|  0.00%|        self._save_to_state_dict(destination, prefix, keep_vars)\n",
      "  1308|         0|            0|            0|  0.00%|        for name, module in self._modules.items():\n",
      "  1309|         0|            0|            0|  0.00%|            if module is not None:\n",
      "  1310|         0|            0|            0|  0.00%|                module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)\n",
      "  1311|         0|            0|            0|  0.00%|        for hook in self._state_dict_hooks.values():\n",
      "  1312|         0|            0|            0|  0.00%|            hook_result = hook(self, destination, prefix, local_metadata)\n",
      "  1313|         0|            0|            0|  0.00%|            if hook_result is not None:\n",
      "  1314|         0|            0|            0|  0.00%|                destination = hook_result\n",
      "  1315|         0|            0|            0|  0.00%|        return destination\n",
      "  1316|         0|            0|            0|  0.00%|\n",
      "  1317|         0|            0|            0|  0.00%|    def _register_load_state_dict_pre_hook(self, hook, with_module=False):\n",
      "  1318|         0|            0|            0|  0.00%|        r\"\"\"These hooks will be called with arguments: `state_dict`, `prefix`,\n",
      "  1319|         0|            0|            0|  0.00%|        `local_metadata`, `strict`, `missing_keys`, `unexpected_keys`,\n",
      "  1320|         0|            0|            0|  0.00%|        `error_msgs`, before loading `state_dict` into `self`. These arguments\n",
      "  1321|         0|            0|            0|  0.00%|        are exactly the same as those of `_load_from_state_dict`.\n",
      "  1322|         0|            0|            0|  0.00%|\n",
      "  1323|         0|            0|            0|  0.00%|        If ``with_module`` is ``True``, then the first argument to the hook is\n",
      "  1324|         0|            0|            0|  0.00%|        an instance of the module.\n",
      "  1325|         0|            0|            0|  0.00%|\n",
      "  1326|         0|            0|            0|  0.00%|        Arguments:\n",
      "  1327|         0|            0|            0|  0.00%|            hook (Callable): Callable hook that will be invoked before\n",
      "  1328|         0|            0|            0|  0.00%|                loading the state dict.\n",
      "  1329|         0|            0|            0|  0.00%|            with_module (bool, optional): Whether or not to pass the module\n",
      "  1330|         0|            0|            0|  0.00%|                instance to the hook as the first parameter.\n",
      "  1331|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1332|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._load_state_dict_pre_hooks)\n",
      "  1333|         0|            0|            0|  0.00%|        if with_module:\n",
      "  1334|         0|            0|            0|  0.00%|            hook = functools.partial(hook, self)\n",
      "  1335|         0|            0|            0|  0.00%|        self._load_state_dict_pre_hooks[handle.id] = hook\n",
      "  1336|         0|            0|            0|  0.00%|        return handle\n",
      "  1337|         0|            0|            0|  0.00%|\n",
      "  1338|         0|            0|            0|  0.00%|    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,\n",
      "  1339|         0|            0|            0|  0.00%|                              missing_keys, unexpected_keys, error_msgs):\n",
      "  1340|         0|            0|            0|  0.00%|        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\n",
      "  1341|         0|            0|            0|  0.00%|        this module, but not its descendants. This is called on every submodule\n",
      "  1342|         0|            0|            0|  0.00%|        in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\n",
      "  1343|         0|            0|            0|  0.00%|        module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\n",
      "  1344|         0|            0|            0|  0.00%|        For state dicts without metadata, :attr:`local_metadata` is empty.\n",
      "  1345|         0|            0|            0|  0.00%|        Subclasses can achieve class-specific backward compatible loading using\n",
      "  1346|         0|            0|            0|  0.00%|        the version number at `local_metadata.get(\"version\", None)`.\n",
      "  1347|         0|            0|            0|  0.00%|\n",
      "  1348|         0|            0|            0|  0.00%|        .. note::\n",
      "  1349|         0|            0|            0|  0.00%|            :attr:`state_dict` is not the same object as the input\n",
      "  1350|         0|            0|            0|  0.00%|            :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\n",
      "  1351|         0|            0|            0|  0.00%|            it can be modified.\n",
      "  1352|         0|            0|            0|  0.00%|\n",
      "  1353|         0|            0|            0|  0.00%|        Args:\n",
      "  1354|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and\n",
      "  1355|         0|            0|            0|  0.00%|                persistent buffers.\n",
      "  1356|         0|            0|            0|  0.00%|            prefix (str): the prefix for parameters and buffers used in this\n",
      "  1357|         0|            0|            0|  0.00%|                module\n",
      "  1358|         0|            0|            0|  0.00%|            local_metadata (dict): a dict containing the metadata for this module.\n",
      "  1359|         0|            0|            0|  0.00%|                See\n",
      "  1360|         0|            0|            0|  0.00%|            strict (bool): whether to strictly enforce that the keys in\n",
      "  1361|         0|            0|            0|  0.00%|                :attr:`state_dict` with :attr:`prefix` match the names of\n",
      "  1362|         0|            0|            0|  0.00%|                parameters and buffers in this module\n",
      "  1363|         0|            0|            0|  0.00%|            missing_keys (list of str): if ``strict=True``, add missing keys to\n",
      "  1364|         0|            0|            0|  0.00%|                this list\n",
      "  1365|         0|            0|            0|  0.00%|            unexpected_keys (list of str): if ``strict=True``, add unexpected\n",
      "  1366|         0|            0|            0|  0.00%|                keys to this list\n",
      "  1367|         0|            0|            0|  0.00%|            error_msgs (list of str): error messages should be added to this\n",
      "  1368|         0|            0|            0|  0.00%|                list, and will be reported together in\n",
      "  1369|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.load_state_dict`\n",
      "  1370|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1371|         0|            0|            0|  0.00%|        for hook in self._load_state_dict_pre_hooks.values():\n",
      "  1372|         0|            0|            0|  0.00%|            hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
      "  1373|         0|            0|            0|  0.00%|\n",
      "  1374|         0|            0|            0|  0.00%|        persistent_buffers = {k: v for k, v in self._buffers.items() if k not in self._non_persistent_buffers_set}\n",
      "  1375|         0|            0|            0|  0.00%|        local_name_params = itertools.chain(self._parameters.items(), persistent_buffers.items())\n",
      "  1376|         0|            0|            0|  0.00%|        local_state = {k: v for k, v in local_name_params if v is not None}\n",
      "  1377|         0|            0|            0|  0.00%|\n",
      "  1378|         0|            0|            0|  0.00%|        for name, param in local_state.items():\n",
      "  1379|         0|            0|            0|  0.00%|            key = prefix + name\n",
      "  1380|         0|            0|            0|  0.00%|            if key in state_dict:\n",
      "  1381|         0|            0|            0|  0.00%|                input_param = state_dict[key]\n",
      "  1382|         0|            0|            0|  0.00%|                # This is used to avoid copying uninitialized parameters into\n",
      "  1383|         0|            0|            0|  0.00%|                # non-lazy modules, since they dont have the hook to do the checks\n",
      "  1384|         0|            0|            0|  0.00%|                # in such case, it will error when accessing the .shape attribute.\n",
      "  1385|         0|            0|            0|  0.00%|                is_param_lazy = torch.nn.parameter.is_lazy(param)\n",
      "  1386|         0|            0|            0|  0.00%|                # Backward compatibility: loading 1-dim tensor from 0.3.* to version 0.4+\n",
      "  1387|         0|            0|            0|  0.00%|                if not is_param_lazy and len(param.shape) == 0 and len(input_param.shape) == 1:\n",
      "  1388|         0|            0|            0|  0.00%|                    input_param = input_param[0]\n",
      "  1389|         0|            0|            0|  0.00%|\n",
      "  1390|         0|            0|            0|  0.00%|                if not is_param_lazy and input_param.shape != param.shape:\n",
      "  1391|         0|            0|            0|  0.00%|                    # local shape should match the one in checkpoint\n",
      "  1392|         0|            0|            0|  0.00%|                    error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '\n",
      "  1393|         0|            0|            0|  0.00%|                                      'the shape in current model is {}.'\n",
      "  1394|         0|            0|            0|  0.00%|                                      .format(key, input_param.shape, param.shape))\n",
      "  1395|         0|            0|            0|  0.00%|                    continue\n",
      "  1396|         0|            0|            0|  0.00%|                try:\n",
      "  1397|         0|            0|            0|  0.00%|                    with torch.no_grad():\n",
      "  1398|         0|            0|            0|  0.00%|                        param.copy_(input_param)\n",
      "  1399|         0|            0|            0|  0.00%|                except Exception as ex:\n",
      "  1400|         0|            0|            0|  0.00%|                    error_msgs.append('While copying the parameter named \"{}\", '\n",
      "  1401|         0|            0|            0|  0.00%|                                      'whose dimensions in the model are {} and '\n",
      "  1402|         0|            0|            0|  0.00%|                                      'whose dimensions in the checkpoint are {}, '\n",
      "  1403|         0|            0|            0|  0.00%|                                      'an exception occurred : {}.'\n",
      "  1404|         0|            0|            0|  0.00%|                                      .format(key, param.size(), input_param.size(), ex.args))\n",
      "  1405|         0|            0|            0|  0.00%|            elif strict:\n",
      "  1406|         0|            0|            0|  0.00%|                missing_keys.append(key)\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
      "  1409|         0|            0|            0|  0.00%|        if getattr(self.__class__, \"set_extra_state\", Module.set_extra_state) is not Module.set_extra_state:\n",
      "  1410|         0|            0|            0|  0.00%|            if extra_state_key in state_dict:\n",
      "  1411|         0|            0|            0|  0.00%|                self.set_extra_state(state_dict[extra_state_key])\n",
      "  1412|         0|            0|            0|  0.00%|            elif strict:\n",
      "  1413|         0|            0|            0|  0.00%|                missing_keys.append(extra_state_key)\n",
      "  1414|         0|            0|            0|  0.00%|        elif strict and (extra_state_key in state_dict):\n",
      "  1415|         0|            0|            0|  0.00%|            unexpected_keys.append(extra_state_key)\n",
      "  1416|         0|            0|            0|  0.00%|\n",
      "  1417|         0|            0|            0|  0.00%|        if strict:\n",
      "  1418|         0|            0|            0|  0.00%|            for key in state_dict.keys():\n",
      "  1419|         0|            0|            0|  0.00%|                if key.startswith(prefix) and key != extra_state_key:\n",
      "  1420|         0|            0|            0|  0.00%|                    input_name = key[len(prefix):]\n",
      "  1421|         0|            0|            0|  0.00%|                    input_name = input_name.split('.', 1)[0]  # get the name of param/buffer/child\n",
      "  1422|         0|            0|            0|  0.00%|                    if input_name not in self._modules and input_name not in local_state:\n",
      "  1423|         0|            0|            0|  0.00%|                        unexpected_keys.append(key)\n",
      "  1424|         0|            0|            0|  0.00%|\n",
      "  1425|         0|            0|            0|  0.00%|    def load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]',\n",
      "  1426|         0|            0|            0|  0.00%|                        strict: bool = True):\n",
      "  1427|         0|            0|            0|  0.00%|        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into\n",
      "  1428|         0|            0|            0|  0.00%|        this module and its descendants. If :attr:`strict` is ``True``, then\n",
      "  1429|         0|            0|            0|  0.00%|        the keys of :attr:`state_dict` must exactly match the keys returned\n",
      "  1430|         0|            0|            0|  0.00%|        by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      "  1431|         0|            0|            0|  0.00%|\n",
      "  1432|         0|            0|            0|  0.00%|        Args:\n",
      "  1433|         0|            0|            0|  0.00%|            state_dict (dict): a dict containing parameters and\n",
      "  1434|         0|            0|            0|  0.00%|                persistent buffers.\n",
      "  1435|         0|            0|            0|  0.00%|            strict (bool, optional): whether to strictly enforce that the keys\n",
      "  1436|         0|            0|            0|  0.00%|                in :attr:`state_dict` match the keys returned by this module's\n",
      "  1437|         0|            0|            0|  0.00%|                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      "  1438|         0|            0|            0|  0.00%|\n",
      "  1439|         0|            0|            0|  0.00%|        Returns:\n",
      "  1440|         0|            0|            0|  0.00%|            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      "  1441|         0|            0|            0|  0.00%|                * **missing_keys** is a list of str containing the missing keys\n",
      "  1442|         0|            0|            0|  0.00%|                * **unexpected_keys** is a list of str containing the unexpected keys\n",
      "  1443|         0|            0|            0|  0.00%|\n",
      "  1444|         0|            0|            0|  0.00%|        Note:\n",
      "  1445|         0|            0|            0|  0.00%|            If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      "  1446|         0|            0|            0|  0.00%|            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      "  1447|         0|            0|            0|  0.00%|            ``RuntimeError``.\n",
      "  1448|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1449|         0|            0|            0|  0.00%|        missing_keys: List[str] = []\n",
      "  1450|         0|            0|            0|  0.00%|        unexpected_keys: List[str] = []\n",
      "  1451|         0|            0|            0|  0.00%|        error_msgs: List[str] = []\n",
      "  1452|         0|            0|            0|  0.00%|\n",
      "  1453|         0|            0|            0|  0.00%|        # copy state_dict so _load_from_state_dict can modify it\n",
      "  1454|         0|            0|            0|  0.00%|        metadata = getattr(state_dict, '_metadata', None)\n",
      "  1455|         0|            0|            0|  0.00%|        state_dict = state_dict.copy()\n",
      "  1456|         0|            0|            0|  0.00%|        if metadata is not None:\n",
      "  1457|         0|            0|            0|  0.00%|            # mypy isn't aware that \"_metadata\" exists in state_dict\n",
      "  1458|         0|            0|            0|  0.00%|            state_dict._metadata = metadata  # type: ignore[attr-defined]\n",
      "  1459|         0|            0|            0|  0.00%|\n",
      "  1460|         0|            0|            0|  0.00%|        def load(module, prefix=''):\n",
      "  1461|         0|            0|            0|  0.00%|            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
      "  1462|         0|            0|            0|  0.00%|            module._load_from_state_dict(\n",
      "  1463|         0|            0|            0|  0.00%|                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
      "  1464|         0|            0|            0|  0.00%|            for name, child in module._modules.items():\n",
      "  1465|         0|            0|            0|  0.00%|                if child is not None:\n",
      "  1466|         0|            0|            0|  0.00%|                    load(child, prefix + name + '.')\n",
      "  1467|         0|            0|            0|  0.00%|\n",
      "  1468|         0|            0|            0|  0.00%|        load(self)\n",
      "  1469|         0|            0|            0|  0.00%|        del load\n",
      "  1470|         0|            0|            0|  0.00%|\n",
      "  1471|         0|            0|            0|  0.00%|        if strict:\n",
      "  1472|         0|            0|            0|  0.00%|            if len(unexpected_keys) > 0:\n",
      "  1473|         0|            0|            0|  0.00%|                error_msgs.insert(\n",
      "  1474|         0|            0|            0|  0.00%|                    0, 'Unexpected key(s) in state_dict: {}. '.format(\n",
      "  1475|         0|            0|            0|  0.00%|                        ', '.join('\"{}\"'.format(k) for k in unexpected_keys)))\n",
      "  1476|         0|            0|            0|  0.00%|            if len(missing_keys) > 0:\n",
      "  1477|         0|            0|            0|  0.00%|                error_msgs.insert(\n",
      "  1478|         0|            0|            0|  0.00%|                    0, 'Missing key(s) in state_dict: {}. '.format(\n",
      "  1479|         0|            0|            0|  0.00%|                        ', '.join('\"{}\"'.format(k) for k in missing_keys)))\n",
      "  1480|         0|            0|            0|  0.00%|\n",
      "  1481|         0|            0|            0|  0.00%|        if len(error_msgs) > 0:\n",
      "  1482|         0|            0|            0|  0.00%|            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "  1483|         0|            0|            0|  0.00%|                               self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
      "  1484|         0|            0|            0|  0.00%|        return _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "  1485|         0|            0|            0|  0.00%|\n",
      "  1486|         0|            0|            0|  0.00%|    def _named_members(self, get_members_fn, prefix='', recurse=True):\n",
      "  1487|         0|            0|            0|  0.00%|        r\"\"\"Helper method for yielding various names + members of modules.\"\"\"\n",
      "  1488|         0|            0|            0|  0.00%|        memo = set()\n",
      "  1489|         0|            0|            0|  0.00%|        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)]\n",
      "  1490|         0|            0|            0|  0.00%|        for module_prefix, module in modules:\n",
      "  1491|         0|            0|            0|  0.00%|            members = get_members_fn(module)\n",
      "  1492|         0|            0|            0|  0.00%|            for k, v in members:\n",
      "  1493|         0|            0|            0|  0.00%|                if v is None or v in memo:\n",
      "  1494|         0|            0|            0|  0.00%|                    continue\n",
      "  1495|         0|            0|            0|  0.00%|                memo.add(v)\n",
      "  1496|         0|            0|            0|  0.00%|                name = module_prefix + ('.' if module_prefix else '') + k\n",
      "  1497|         0|            0|            0|  0.00%|                yield name, v\n",
      "  1498|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1499|         0|            0|            0|  0.00%|    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
      "  1500|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module parameters.\n",
      "  1501|         0|            0|            0|  0.00%|\n",
      "  1502|         0|            0|            0|  0.00%|        This is typically passed to an optimizer.\n",
      "  1503|         0|            0|            0|  0.00%|\n",
      "  1504|         0|            0|            0|  0.00%|        Args:\n",
      "  1505|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module\n",
      "  1506|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that\n",
      "  1507|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1508|         0|            0|            0|  0.00%|\n",
      "  1509|         0|            0|            0|  0.00%|        Yields:\n",
      "  1510|         0|            0|            0|  0.00%|            Parameter: module parameter\n",
      "  1511|         0|            0|            0|  0.00%|\n",
      "  1512|         0|            0|            0|  0.00%|        Example::\n",
      "  1513|         0|            0|            0|  0.00%|\n",
      "  1514|         0|            0|            0|  0.00%|            >>> for param in model.parameters():\n",
      "  1515|         0|            0|            0|  0.00%|            >>>     print(type(param), param.size())\n",
      "  1516|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)\n",
      "  1517|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      "  1518|         0|            0|            0|  0.00%|\n",
      "  1519|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1520|         0|            0|            0|  0.00%|        for name, param in self.named_parameters(recurse=recurse):\n",
      "  1521|         0|            0|            0|  0.00%|            yield param\n",
      "  1522|         0|            0|            0|  0.00%|\n",
      "  1523|         0|            0|            0|  0.00%|    def named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Parameter]]:\n",
      "  1524|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module parameters, yielding both the\n",
      "  1525|         0|            0|            0|  0.00%|        name of the parameter as well as the parameter itself.\n",
      "  1526|         0|            0|            0|  0.00%|\n",
      "  1527|         0|            0|            0|  0.00%|        Args:\n",
      "  1528|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all parameter names.\n",
      "  1529|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields parameters of this module\n",
      "  1530|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only parameters that\n",
      "  1531|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1532|         0|            0|            0|  0.00%|\n",
      "  1533|         0|            0|            0|  0.00%|        Yields:\n",
      "  1534|         0|            0|            0|  0.00%|            (string, Parameter): Tuple containing the name and parameter\n",
      "  1535|         0|            0|            0|  0.00%|\n",
      "  1536|         0|            0|            0|  0.00%|        Example::\n",
      "  1537|         0|            0|            0|  0.00%|\n",
      "  1538|         0|            0|            0|  0.00%|            >>> for name, param in self.named_parameters():\n",
      "  1539|         0|            0|            0|  0.00%|            >>>    if name in ['bias']:\n",
      "  1540|         0|            0|            0|  0.00%|            >>>        print(param.size())\n",
      "  1541|         0|            0|            0|  0.00%|\n",
      "  1542|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1543|         0|            0|            0|  0.00%|        gen = self._named_members(\n",
      "  1544|         0|            0|            0|  0.00%|            lambda module: module._parameters.items(),\n",
      "  1545|         0|            0|            0|  0.00%|            prefix=prefix, recurse=recurse)\n",
      "  1546|         0|            0|            0|  0.00%|        for elem in gen:\n",
      "  1547|         0|            0|            0|  0.00%|            yield elem\n",
      "  1548|         0|            0|            0|  0.00%|\n",
      "  1549|         0|            0|            0|  0.00%|    def buffers(self, recurse: bool = True) -> Iterator[Tensor]:\n",
      "  1550|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module buffers.\n",
      "  1551|         0|            0|            0|  0.00%|\n",
      "  1552|         0|            0|            0|  0.00%|        Args:\n",
      "  1553|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module\n",
      "  1554|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that\n",
      "  1555|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1556|         0|            0|            0|  0.00%|\n",
      "  1557|         0|            0|            0|  0.00%|        Yields:\n",
      "  1558|         0|            0|            0|  0.00%|            torch.Tensor: module buffer\n",
      "  1559|         0|            0|            0|  0.00%|\n",
      "  1560|         0|            0|            0|  0.00%|        Example::\n",
      "  1561|         0|            0|            0|  0.00%|\n",
      "  1562|         0|            0|            0|  0.00%|            >>> for buf in model.buffers():\n",
      "  1563|         0|            0|            0|  0.00%|            >>>     print(type(buf), buf.size())\n",
      "  1564|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L,)\n",
      "  1565|         0|            0|            0|  0.00%|            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      "  1566|         0|            0|            0|  0.00%|\n",
      "  1567|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1568|         0|            0|            0|  0.00%|        for _, buf in self.named_buffers(recurse=recurse):\n",
      "  1569|         0|            0|            0|  0.00%|            yield buf\n",
      "  1570|         0|            0|            0|  0.00%|\n",
      "  1571|         0|            0|            0|  0.00%|    def named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Tensor]]:\n",
      "  1572|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over module buffers, yielding both the\n",
      "  1573|         0|            0|            0|  0.00%|        name of the buffer as well as the buffer itself.\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|        Args:\n",
      "  1576|         0|            0|            0|  0.00%|            prefix (str): prefix to prepend to all buffer names.\n",
      "  1577|         0|            0|            0|  0.00%|            recurse (bool): if True, then yields buffers of this module\n",
      "  1578|         0|            0|            0|  0.00%|                and all submodules. Otherwise, yields only buffers that\n",
      "  1579|         0|            0|            0|  0.00%|                are direct members of this module.\n",
      "  1580|         0|            0|            0|  0.00%|\n",
      "  1581|         0|            0|            0|  0.00%|        Yields:\n",
      "  1582|         0|            0|            0|  0.00%|            (string, torch.Tensor): Tuple containing the name and buffer\n",
      "  1583|         0|            0|            0|  0.00%|\n",
      "  1584|         0|            0|            0|  0.00%|        Example::\n",
      "  1585|         0|            0|            0|  0.00%|\n",
      "  1586|         0|            0|            0|  0.00%|            >>> for name, buf in self.named_buffers():\n",
      "  1587|         0|            0|            0|  0.00%|            >>>    if name in ['running_var']:\n",
      "  1588|         0|            0|            0|  0.00%|            >>>        print(buf.size())\n",
      "  1589|         0|            0|            0|  0.00%|\n",
      "  1590|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1591|         0|            0|            0|  0.00%|        gen = self._named_members(\n",
      "  1592|         0|            0|            0|  0.00%|            lambda module: module._buffers.items(),\n",
      "  1593|         0|            0|            0|  0.00%|            prefix=prefix, recurse=recurse)\n",
      "  1594|         0|            0|            0|  0.00%|        for elem in gen:\n",
      "  1595|         0|            0|            0|  0.00%|            yield elem\n",
      "  1596|         0|            0|            0|  0.00%|\n",
      "  1597|         0|            0|            0|  0.00%|    def children(self) -> Iterator['Module']:\n",
      "  1598|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over immediate children modules.\n",
      "  1599|         0|            0|            0|  0.00%|\n",
      "  1600|         0|            0|            0|  0.00%|        Yields:\n",
      "  1601|         0|            0|            0|  0.00%|            Module: a child module\n",
      "  1602|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1603|         0|            0|            0|  0.00%|        for name, module in self.named_children():\n",
      "  1604|         0|            0|            0|  0.00%|            yield module\n",
      "  1605|         0|            0|            0|  0.00%|\n",
      "  1606|         0|            0|            0|  0.00%|    def named_children(self) -> Iterator[Tuple[str, 'Module']]:\n",
      "  1607|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over immediate children modules, yielding both\n",
      "  1608|         0|            0|            0|  0.00%|        the name of the module as well as the module itself.\n",
      "  1609|         0|            0|            0|  0.00%|\n",
      "  1610|         0|            0|            0|  0.00%|        Yields:\n",
      "  1611|         0|            0|            0|  0.00%|            (string, Module): Tuple containing a name and child module\n",
      "  1612|         0|            0|            0|  0.00%|\n",
      "  1613|         0|            0|            0|  0.00%|        Example::\n",
      "  1614|         0|            0|            0|  0.00%|\n",
      "  1615|         0|            0|            0|  0.00%|            >>> for name, module in model.named_children():\n",
      "  1616|         0|            0|            0|  0.00%|            >>>     if name in ['conv4', 'conv5']:\n",
      "  1617|         0|            0|            0|  0.00%|            >>>         print(module)\n",
      "  1618|         0|            0|            0|  0.00%|\n",
      "  1619|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1620|         0|            0|            0|  0.00%|        memo = set()\n",
      "  1621|         0|            0|            0|  0.00%|        for name, module in self._modules.items():\n",
      "  1622|         0|            0|            0|  0.00%|            if module is not None and module not in memo:\n",
      "  1623|         0|            0|            0|  0.00%|                memo.add(module)\n",
      "  1624|         0|            0|            0|  0.00%|                yield name, module\n",
      "  1625|         0|            0|            0|  0.00%|\n",
      "  1626|         0|            0|            0|  0.00%|    def modules(self) -> Iterator['Module']:\n",
      "  1627|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over all modules in the network.\n",
      "  1628|         0|            0|            0|  0.00%|\n",
      "  1629|         0|            0|            0|  0.00%|        Yields:\n",
      "  1630|         0|            0|            0|  0.00%|            Module: a module in the network\n",
      "  1631|         0|            0|            0|  0.00%|\n",
      "  1632|         0|            0|            0|  0.00%|        Note:\n",
      "  1633|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following\n",
      "  1634|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.\n",
      "  1635|         0|            0|            0|  0.00%|\n",
      "  1636|         0|            0|            0|  0.00%|        Example::\n",
      "  1637|         0|            0|            0|  0.00%|\n",
      "  1638|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)\n",
      "  1639|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)\n",
      "  1640|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.modules()):\n",
      "  1641|         0|            0|            0|  0.00%|                    print(idx, '->', m)\n",
      "  1642|         0|            0|            0|  0.00%|\n",
      "  1643|         0|            0|            0|  0.00%|            0 -> Sequential(\n",
      "  1644|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1645|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1646|         0|            0|            0|  0.00%|            )\n",
      "  1647|         0|            0|            0|  0.00%|            1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      "  1648|         0|            0|            0|  0.00%|\n",
      "  1649|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1650|         0|            0|            0|  0.00%|        for _, module in self.named_modules():\n",
      "  1651|         0|            0|            0|  0.00%|            yield module\n",
      "  1652|         0|            0|            0|  0.00%|\n",
      "  1653|         0|            0|            0|  0.00%|    def named_modules(self, memo: Optional[Set['Module']] = None, prefix: str = '', remove_duplicate: bool = True):\n",
      "  1654|         0|            0|            0|  0.00%|        r\"\"\"Returns an iterator over all modules in the network, yielding\n",
      "  1655|         0|            0|            0|  0.00%|        both the name of the module as well as the module itself.\n",
      "  1656|         0|            0|            0|  0.00%|\n",
      "  1657|         0|            0|            0|  0.00%|        Args:\n",
      "  1658|         0|            0|            0|  0.00%|            memo: a memo to store the set of modules already added to the result\n",
      "  1659|         0|            0|            0|  0.00%|            prefix: a prefix that will be added to the name of the module\n",
      "  1660|         0|            0|            0|  0.00%|            remove_duplicate: whether to remove the duplicated module instances in the result\n",
      "  1661|         0|            0|            0|  0.00%|            or not\n",
      "  1662|         0|            0|            0|  0.00%|\n",
      "  1663|         0|            0|            0|  0.00%|        Yields:\n",
      "  1664|         0|            0|            0|  0.00%|            (string, Module): Tuple of name and module\n",
      "  1665|         0|            0|            0|  0.00%|\n",
      "  1666|         0|            0|            0|  0.00%|        Note:\n",
      "  1667|         0|            0|            0|  0.00%|            Duplicate modules are returned only once. In the following\n",
      "  1668|         0|            0|            0|  0.00%|            example, ``l`` will be returned only once.\n",
      "  1669|         0|            0|            0|  0.00%|\n",
      "  1670|         0|            0|            0|  0.00%|        Example::\n",
      "  1671|         0|            0|            0|  0.00%|\n",
      "  1672|         0|            0|            0|  0.00%|            >>> l = nn.Linear(2, 2)\n",
      "  1673|         0|            0|            0|  0.00%|            >>> net = nn.Sequential(l, l)\n",
      "  1674|         0|            0|            0|  0.00%|            >>> for idx, m in enumerate(net.named_modules()):\n",
      "  1675|         0|            0|            0|  0.00%|                    print(idx, '->', m)\n",
      "  1676|         0|            0|            0|  0.00%|\n",
      "  1677|         0|            0|            0|  0.00%|            0 -> ('', Sequential(\n",
      "  1678|         0|            0|            0|  0.00%|              (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1679|         0|            0|            0|  0.00%|              (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  1680|         0|            0|            0|  0.00%|            ))\n",
      "  1681|         0|            0|            0|  0.00%|            1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      "  1682|         0|            0|            0|  0.00%|\n",
      "  1683|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1684|         0|            0|            0|  0.00%|\n",
      "  1685|         0|            0|            0|  0.00%|        if memo is None:\n",
      "  1686|         0|            0|            0|  0.00%|            memo = set()\n",
      "  1687|         0|            0|            0|  0.00%|        if self not in memo:\n",
      "  1688|         0|            0|            0|  0.00%|            if remove_duplicate:\n",
      "  1689|         0|            0|            0|  0.00%|                memo.add(self)\n",
      "  1690|         0|            0|            0|  0.00%|            yield prefix, self\n",
      "  1691|         0|            0|            0|  0.00%|            for name, module in self._modules.items():\n",
      "  1692|         0|            0|            0|  0.00%|                if module is None:\n",
      "  1693|         0|            0|            0|  0.00%|                    continue\n",
      "  1694|         0|            0|            0|  0.00%|                submodule_prefix = prefix + ('.' if prefix else '') + name\n",
      "  1695|         0|            0|            0|  0.00%|                for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n",
      "  1696|         0|            0|            0|  0.00%|                    yield m\n",
      "  1697|         0|            0|            0|  0.00%|\n",
      "  1698|         0|            0|            0|  0.00%|    def train(self: T, mode: bool = True) -> T:\n",
      "  1699|         0|            0|            0|  0.00%|        r\"\"\"Sets the module in training mode.\n",
      "  1700|         0|            0|            0|  0.00%|\n",
      "  1701|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of\n",
      "  1702|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation\n",
      "  1703|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "  1704|         0|            0|            0|  0.00%|        etc.\n",
      "  1705|         0|            0|            0|  0.00%|\n",
      "  1706|         0|            0|            0|  0.00%|        Args:\n",
      "  1707|         0|            0|            0|  0.00%|            mode (bool): whether to set training mode (``True``) or evaluation\n",
      "  1708|         0|            0|            0|  0.00%|                         mode (``False``). Default: ``True``.\n",
      "  1709|         0|            0|            0|  0.00%|\n",
      "  1710|         0|            0|            0|  0.00%|        Returns:\n",
      "  1711|         0|            0|            0|  0.00%|            Module: self\n",
      "  1712|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1713|         0|            0|            0|  0.00%|        if not isinstance(mode, bool):\n",
      "  1714|         0|            0|            0|  0.00%|            raise ValueError(\"training mode is expected to be boolean\")\n",
      "  1715|         0|            0|            0|  0.00%|        self.training = mode\n",
      "  1716|         0|            0|            0|  0.00%|        for module in self.children():\n",
      "  1717|         0|            0|            0|  0.00%|            module.train(mode)\n",
      "  1718|         0|            0|            0|  0.00%|        return self\n",
      "  1719|         0|            0|            0|  0.00%|\n",
      "  1720|         0|            0|            0|  0.00%|    def eval(self: T) -> T:\n",
      "  1721|         0|            0|            0|  0.00%|        r\"\"\"Sets the module in evaluation mode.\n",
      "  1722|         0|            0|            0|  0.00%|\n",
      "  1723|         0|            0|            0|  0.00%|        This has any effect only on certain modules. See documentations of\n",
      "  1724|         0|            0|            0|  0.00%|        particular modules for details of their behaviors in training/evaluation\n",
      "  1725|         0|            0|            0|  0.00%|        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "  1726|         0|            0|            0|  0.00%|        etc.\n",
      "  1727|         0|            0|            0|  0.00%|\n",
      "  1728|         0|            0|            0|  0.00%|        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      "  1729|         0|            0|            0|  0.00%|\n",
      "  1730|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between\n",
      "  1731|         0|            0|            0|  0.00%|        `.eval()` and several similar mechanisms that may be confused with it.\n",
      "  1732|         0|            0|            0|  0.00%|\n",
      "  1733|         0|            0|            0|  0.00%|        Returns:\n",
      "  1734|         0|            0|            0|  0.00%|            Module: self\n",
      "  1735|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1736|         0|            0|            0|  0.00%|        return self.train(False)\n",
      "  1737|         0|            0|            0|  0.00%|\n",
      "  1738|         0|            0|            0|  0.00%|    def requires_grad_(self: T, requires_grad: bool = True) -> T:\n",
      "  1739|         0|            0|            0|  0.00%|        r\"\"\"Change if autograd should record operations on parameters in this\n",
      "  1740|         0|            0|            0|  0.00%|        module.\n",
      "  1741|         0|            0|            0|  0.00%|\n",
      "  1742|         0|            0|            0|  0.00%|        This method sets the parameters' :attr:`requires_grad` attributes\n",
      "  1743|         0|            0|            0|  0.00%|        in-place.\n",
      "  1744|         0|            0|            0|  0.00%|\n",
      "  1745|         0|            0|            0|  0.00%|        This method is helpful for freezing part of the module for finetuning\n",
      "  1746|         0|            0|            0|  0.00%|        or training parts of a model individually (e.g., GAN training).\n",
      "  1747|         0|            0|            0|  0.00%|\n",
      "  1748|         0|            0|            0|  0.00%|        See :ref:`locally-disable-grad-doc` for a comparison between\n",
      "  1749|         0|            0|            0|  0.00%|        `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      "  1750|         0|            0|            0|  0.00%|\n",
      "  1751|         0|            0|            0|  0.00%|        Args:\n",
      "  1752|         0|            0|            0|  0.00%|            requires_grad (bool): whether autograd should record operations on\n",
      "  1753|         0|            0|            0|  0.00%|                                  parameters in this module. Default: ``True``.\n",
      "  1754|         0|            0|            0|  0.00%|\n",
      "  1755|         0|            0|            0|  0.00%|        Returns:\n",
      "  1756|         0|            0|            0|  0.00%|            Module: self\n",
      "  1757|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1758|         0|            0|            0|  0.00%|        for p in self.parameters():\n",
      "  1759|         0|            0|            0|  0.00%|            p.requires_grad_(requires_grad)\n",
      "  1760|         0|            0|            0|  0.00%|        return self\n",
      "  1761|         0|            0|            0|  0.00%|\n",
      "  1762|         0|            0|            0|  0.00%|    def zero_grad(self, set_to_none: bool = False) -> None:\n",
      "  1763|         0|            0|            0|  0.00%|        r\"\"\"Sets gradients of all model parameters to zero. See similar function\n",
      "  1764|         0|            0|            0|  0.00%|        under :class:`torch.optim.Optimizer` for more context.\n",
      "  1765|         0|            0|            0|  0.00%|\n",
      "  1766|         0|            0|            0|  0.00%|        Args:\n",
      "  1767|         0|            0|            0|  0.00%|            set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      "  1768|         0|            0|            0|  0.00%|                See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      "  1769|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1770|         0|            0|            0|  0.00%|        if getattr(self, '_is_replica', False):\n",
      "  1771|         0|            0|            0|  0.00%|            warnings.warn(\n",
      "  1772|         0|            0|            0|  0.00%|                \"Calling .zero_grad() from a module created with nn.DataParallel() has no effect. \"\n",
      "  1773|         0|            0|            0|  0.00%|                \"The parameters are copied (in a differentiable manner) from the original module. \"\n",
      "  1774|         0|            0|            0|  0.00%|                \"This means they are not leaf nodes in autograd and so don't accumulate gradients. \"\n",
      "  1775|         0|            0|            0|  0.00%|                \"If you need gradients in your forward method, consider using autograd.grad instead.\")\n",
      "  1776|         0|            0|            0|  0.00%|\n",
      "  1777|         0|            0|            0|  0.00%|        for p in self.parameters():\n",
      "  1778|         0|            0|            0|  0.00%|            if p.grad is not None:\n",
      "  1779|         0|            0|            0|  0.00%|                if set_to_none:\n",
      "  1780|         0|            0|            0|  0.00%|                    p.grad = None\n",
      "  1781|         0|            0|            0|  0.00%|                else:\n",
      "  1782|         0|            0|            0|  0.00%|                    if p.grad.grad_fn is not None:\n",
      "  1783|         0|            0|            0|  0.00%|                        p.grad.detach_()\n",
      "  1784|         0|            0|            0|  0.00%|                    else:\n",
      "  1785|         0|            0|            0|  0.00%|                        p.grad.requires_grad_(False)\n",
      "  1786|         0|            0|            0|  0.00%|                    p.grad.zero_()\n",
      "  1787|         0|            0|            0|  0.00%|\n",
      "  1788|         0|            0|            0|  0.00%|    def share_memory(self: T) -> T:\n",
      "  1789|         0|            0|            0|  0.00%|        r\"\"\"See :meth:`torch.Tensor.share_memory_`\"\"\"\n",
      "  1790|         0|            0|            0|  0.00%|        return self._apply(lambda t: t.share_memory_())\n",
      "  1791|         0|            0|            0|  0.00%|\n",
      "  1792|         0|            0|            0|  0.00%|    def _get_name(self):\n",
      "  1793|         0|            0|            0|  0.00%|        return self.__class__.__name__\n",
      "  1794|         0|            0|            0|  0.00%|\n",
      "  1795|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "  1796|         0|            0|            0|  0.00%|        r\"\"\"Set the extra representation of the module\n",
      "  1797|         0|            0|            0|  0.00%|\n",
      "  1798|         0|            0|            0|  0.00%|        To print customized extra information, you should re-implement\n",
      "  1799|         0|            0|            0|  0.00%|        this method in your own modules. Both single-line and multi-line\n",
      "  1800|         0|            0|            0|  0.00%|        strings are acceptable.\n",
      "  1801|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1802|         0|            0|            0|  0.00%|        return ''\n",
      "  1803|         0|            0|            0|  0.00%|\n",
      "  1804|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "  1805|         0|            0|            0|  0.00%|        # We treat the extra repr like the sub-module, one item per line\n",
      "  1806|         0|            0|            0|  0.00%|        extra_lines = []\n",
      "  1807|         0|            0|            0|  0.00%|        extra_repr = self.extra_repr()\n",
      "  1808|         0|            0|            0|  0.00%|        # empty string will be split into list ['']\n",
      "  1809|         0|            0|            0|  0.00%|        if extra_repr:\n",
      "  1810|         0|            0|            0|  0.00%|            extra_lines = extra_repr.split('\\n')\n",
      "  1811|         0|            0|            0|  0.00%|        child_lines = []\n",
      "  1812|         0|            0|            0|  0.00%|        for key, module in self._modules.items():\n",
      "  1813|         0|            0|            0|  0.00%|            mod_str = repr(module)\n",
      "  1814|         0|            0|            0|  0.00%|            mod_str = _addindent(mod_str, 2)\n",
      "  1815|         0|            0|            0|  0.00%|            child_lines.append('(' + key + '): ' + mod_str)\n",
      "  1816|         0|            0|            0|  0.00%|        lines = extra_lines + child_lines\n",
      "  1817|         0|            0|            0|  0.00%|\n",
      "  1818|         0|            0|            0|  0.00%|        main_str = self._get_name() + '('\n",
      "  1819|         0|            0|            0|  0.00%|        if lines:\n",
      "  1820|         0|            0|            0|  0.00%|            # simple one-liner info, which most builtin Modules will use\n",
      "  1821|         0|            0|            0|  0.00%|            if len(extra_lines) == 1 and not child_lines:\n",
      "  1822|         0|            0|            0|  0.00%|                main_str += extra_lines[0]\n",
      "  1823|         0|            0|            0|  0.00%|            else:\n",
      "  1824|         0|            0|            0|  0.00%|                main_str += '\\n  ' + '\\n  '.join(lines) + '\\n'\n",
      "  1825|         0|            0|            0|  0.00%|\n",
      "  1826|         0|            0|            0|  0.00%|        main_str += ')'\n",
      "  1827|         0|            0|            0|  0.00%|        return main_str\n",
      "  1828|         0|            0|            0|  0.00%|\n",
      "  1829|         0|            0|            0|  0.00%|    def __dir__(self):\n",
      "  1830|         0|            0|            0|  0.00%|        module_attrs = dir(self.__class__)\n",
      "  1831|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())\n",
      "  1832|         0|            0|            0|  0.00%|        parameters = list(self._parameters.keys())\n",
      "  1833|         0|            0|            0|  0.00%|        modules = list(self._modules.keys())\n",
      "  1834|         0|            0|            0|  0.00%|        buffers = list(self._buffers.keys())\n",
      "  1835|         0|            0|            0|  0.00%|        keys = module_attrs + attrs + parameters + modules + buffers\n",
      "  1836|         0|            0|            0|  0.00%|\n",
      "  1837|         0|            0|            0|  0.00%|        # Eliminate attrs that are not legal Python variable names\n",
      "  1838|         0|            0|            0|  0.00%|        keys = [key for key in keys if not key[0].isdigit()]\n",
      "  1839|         0|            0|            0|  0.00%|\n",
      "  1840|         0|            0|            0|  0.00%|        return sorted(keys)\n",
      "  1841|         0|            0|            0|  0.00%|\n",
      "  1842|         0|            0|            0|  0.00%|    def _replicate_for_data_parallel(self):\n",
      "  1843|         0|            0|            0|  0.00%|        replica = self.__new__(type(self))\n",
      "  1844|         0|            0|            0|  0.00%|        replica.__dict__ = self.__dict__.copy()\n",
      "  1845|         0|            0|            0|  0.00%|\n",
      "  1846|         0|            0|            0|  0.00%|        # replicas do not have parameters themselves, the replicas reference the original\n",
      "  1847|         0|            0|            0|  0.00%|        # module.\n",
      "  1848|         0|            0|            0|  0.00%|        replica._parameters = OrderedDict()\n",
      "  1849|         0|            0|            0|  0.00%|        replica._buffers = replica._buffers.copy()\n",
      "  1850|         0|            0|            0|  0.00%|        replica._modules = replica._modules.copy()\n",
      "  1851|         0|            0|            0|  0.00%|        replica._is_replica = True\n",
      "  1852|         0|            0|            0|  0.00%|\n",
      "  1853|         0|            0|            0|  0.00%|        return replica\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py\n",
      "File duration: 0.00078249s (0.01%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import namedtuple\n",
      "     2|         0|            0|            0|  0.00%|import warnings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|import torch\n",
      "     5|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     6|         0|            0|            0|  0.00%|from ... import _VF\n",
      "     7|         0|            0|            0|  0.00%|from ..._jit_internal import Optional\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|from typing import List, Tuple\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|\n",
      "    13|         0|            0|            0|  0.00%|PackedSequence_ = namedtuple('PackedSequence_',\n",
      "    14|         0|            0|            0|  0.00%|                             ['data', 'batch_sizes', 'sorted_indices', 'unsorted_indices'])\n",
      "    15|         0|            0|            0|  0.00%|\n",
      "    16|         0|            0|            0|  0.00%|# type annotation for PackedSequence_ to make it compatible with TorchScript\n",
      "    17|         0|            0|            0|  0.00%|PackedSequence_.__annotations__ = {'data': torch.Tensor, 'batch_sizes': torch.Tensor,\n",
      "    18|         0|            0|            0|  0.00%|                                   'sorted_indices': Optional[torch.Tensor],\n",
      "    19|         0|            0|            0|  0.00%|                                   'unsorted_indices': Optional[torch.Tensor]}\n",
      "    20|         0|            0|            0|  0.00%|\n",
      "    21|         0|            0|            0|  0.00%|def bind(optional, fn):\n",
      "    22|         0|            0|            0|  0.00%|    if optional is None:\n",
      "    23|         0|            0|            0|  0.00%|        return None\n",
      "    24|         0|            0|            0|  0.00%|    return fn(optional)\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|\n",
      "    27|         0|            0|            0|  0.00%|class PackedSequence(PackedSequence_):\n",
      "    28|         0|            0|            0|  0.00%|    r\"\"\"Holds the data and list of :attr:`batch_sizes` of a packed sequence.\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|    All RNN modules accept packed sequences as inputs.\n",
      "    31|         0|            0|            0|  0.00%|\n",
      "    32|         0|            0|            0|  0.00%|    Note:\n",
      "    33|         0|            0|            0|  0.00%|        Instances of this class should never be created manually. They are meant\n",
      "    34|         0|            0|            0|  0.00%|        to be instantiated by functions like :func:`pack_padded_sequence`.\n",
      "    35|         0|            0|            0|  0.00%|\n",
      "    36|         0|            0|            0|  0.00%|        Batch sizes represent the number elements at each sequence step in\n",
      "    37|         0|            0|            0|  0.00%|        the batch, not the varying sequence lengths passed to\n",
      "    38|         0|            0|            0|  0.00%|        :func:`pack_padded_sequence`.  For instance, given data ``abc`` and ``x``\n",
      "    39|         0|            0|            0|  0.00%|        the :class:`PackedSequence` would contain data ``axbc`` with\n",
      "    40|         0|            0|            0|  0.00%|        ``batch_sizes=[2,1,1]``.\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|    Attributes:\n",
      "    43|         0|            0|            0|  0.00%|        data (Tensor): Tensor containing packed sequence\n",
      "    44|         0|            0|            0|  0.00%|        batch_sizes (Tensor): Tensor of integers holding\n",
      "    45|         0|            0|            0|  0.00%|            information about the batch size at each sequence step\n",
      "    46|         0|            0|            0|  0.00%|        sorted_indices (Tensor, optional): Tensor of integers holding how this\n",
      "    47|         0|            0|            0|  0.00%|            :class:`PackedSequence` is constructed from sequences.\n",
      "    48|         0|            0|            0|  0.00%|        unsorted_indices (Tensor, optional): Tensor of integers holding how this\n",
      "    49|         0|            0|            0|  0.00%|            to recover the original sequences with correct order.\n",
      "    50|         0|            0|            0|  0.00%|\n",
      "    51|         0|            0|            0|  0.00%|    .. note::\n",
      "    52|         0|            0|            0|  0.00%|        :attr:`data` can be on arbitrary device and of arbitrary dtype.\n",
      "    53|         0|            0|            0|  0.00%|        :attr:`sorted_indices` and :attr:`unsorted_indices` must be ``torch.int64``\n",
      "    54|         0|            0|            0|  0.00%|        tensors on the same device as :attr:`data`.\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|        However, :attr:`batch_sizes` should always be a CPU ``torch.int64`` tensor.\n",
      "    57|         0|            0|            0|  0.00%|\n",
      "    58|         0|            0|            0|  0.00%|        This invariant is maintained throughout :class:`PackedSequence` class,\n",
      "    59|         0|            0|            0|  0.00%|        and all functions that construct a `:class:PackedSequence` in PyTorch\n",
      "    60|         0|            0|            0|  0.00%|        (i.e., they only pass in tensors conforming to this constraint).\n",
      "    61|         0|            0|            0|  0.00%|\n",
      "    62|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    63|         2|  0.000118017|  5.90086e-05|  0.00%|    def __new__(cls, data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "    64|         2|  1.38283e-05|  6.91414e-06|  0.00%|        return super(PackedSequence, cls).__new__(\n",
      "    65|         2|  7.15256e-06|  3.57628e-06|  0.00%|            cls,\n",
      "    66|         2|  5.24521e-06|   2.6226e-06|  0.00%|            *_packed_sequence_init_args(data, batch_sizes, sorted_indices,\n",
      "    67|         2|   3.6478e-05|   1.8239e-05|  0.00%|                                        unsorted_indices))\n",
      "(call)|         2|  3.40939e-05|  1.70469e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:156 _packed_sequence_init_args\n",
      "(call)|         2|  2.02656e-05|  1.01328e-05|  0.00%|# <string>:12 __new__\n",
      "    68|         0|            0|            0|  0.00%|\n",
      "    69|         0|            0|            0|  0.00%|    # NOTE [ device and dtype of a PackedSequence ]\n",
      "    70|         0|            0|            0|  0.00%|    #\n",
      "    71|         0|            0|            0|  0.00%|    # See the note above in doc string (starting with \":attr:`data` can be on\n",
      "    72|         0|            0|            0|  0.00%|    # arbitrary device...\").\n",
      "    73|         0|            0|            0|  0.00%|    def pin_memory(self):\n",
      "    74|         0|            0|            0|  0.00%|        # Why not convert `batch_sizes`?\n",
      "    75|         0|            0|            0|  0.00%|        # See NOTE [ device and dtype of a PackedSequence ]\n",
      "    76|         0|            0|            0|  0.00%|        return type(self)(self.data.pin_memory(), self.batch_sizes,\n",
      "    77|         0|            0|            0|  0.00%|                          bind(self.sorted_indices, lambda t: t.pin_memory()),\n",
      "    78|         0|            0|            0|  0.00%|                          bind(self.unsorted_indices, lambda t: t.pin_memory()))\n",
      "    79|         0|            0|            0|  0.00%|\n",
      "    80|         0|            0|            0|  0.00%|    def cuda(self, *args, **kwargs):\n",
      "    81|         0|            0|            0|  0.00%|        # Tests to see if 'cuda' should be added to kwargs\n",
      "    82|         0|            0|            0|  0.00%|        ex = torch.tensor((), dtype=self.data.dtype, device=self.data.device).to(*args, **kwargs)\n",
      "    83|         0|            0|            0|  0.00%|        if ex.is_cuda:\n",
      "    84|         0|            0|            0|  0.00%|            return self.to(*args, **kwargs)\n",
      "    85|         0|            0|            0|  0.00%|        return self.to(*args, device='cuda', **kwargs)\n",
      "    86|         0|            0|            0|  0.00%|\n",
      "    87|         0|            0|            0|  0.00%|    def cpu(self, *args, **kwargs):\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|        ex = torch.tensor((), dtype=self.data.dtype, device=self.data.device).to(*args, **kwargs)\n",
      "    90|         0|            0|            0|  0.00%|        if ex.device.type == 'cpu':\n",
      "    91|         0|            0|            0|  0.00%|            return self.to(*args, **kwargs)\n",
      "    92|         0|            0|            0|  0.00%|        return self.to(*args, device='cpu', **kwargs)\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|    def double(self):\n",
      "    95|         0|            0|            0|  0.00%|        return self.to(dtype=torch.double)\n",
      "    96|         0|            0|            0|  0.00%|\n",
      "    97|         0|            0|            0|  0.00%|    def float(self):\n",
      "    98|         0|            0|            0|  0.00%|        return self.to(dtype=torch.float)\n",
      "    99|         0|            0|            0|  0.00%|\n",
      "   100|         0|            0|            0|  0.00%|    def half(self):\n",
      "   101|         0|            0|            0|  0.00%|        return self.to(dtype=torch.half)\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    def long(self):\n",
      "   104|         0|            0|            0|  0.00%|        return self.to(dtype=torch.long)\n",
      "   105|         0|            0|            0|  0.00%|\n",
      "   106|         0|            0|            0|  0.00%|    def int(self):\n",
      "   107|         0|            0|            0|  0.00%|        return self.to(dtype=torch.int)\n",
      "   108|         0|            0|            0|  0.00%|\n",
      "   109|         0|            0|            0|  0.00%|    def short(self):\n",
      "   110|         0|            0|            0|  0.00%|        return self.to(dtype=torch.short)\n",
      "   111|         0|            0|            0|  0.00%|\n",
      "   112|         0|            0|            0|  0.00%|    def char(self):\n",
      "   113|         0|            0|            0|  0.00%|        return self.to(dtype=torch.int8)\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|    def byte(self):\n",
      "   116|         0|            0|            0|  0.00%|        return self.to(dtype=torch.uint8)\n",
      "   117|         0|            0|            0|  0.00%|\n",
      "   118|         0|            0|            0|  0.00%|    def to(self, *args, **kwargs):\n",
      "   119|         0|            0|            0|  0.00%|        r\"\"\"Performs dtype and/or device conversion on `self.data`.\n",
      "   120|         0|            0|            0|  0.00%|\n",
      "   121|         0|            0|            0|  0.00%|        It has similar signature as :meth:`torch.Tensor.to`, except optional\n",
      "   122|         0|            0|            0|  0.00%|        arguments like `non_blocking` and `copy` should be passed as kwargs,\n",
      "   123|         0|            0|            0|  0.00%|        not args, or they will not apply to the index tensors.\n",
      "   124|         0|            0|            0|  0.00%|\n",
      "   125|         0|            0|            0|  0.00%|        .. note::\n",
      "   126|         0|            0|            0|  0.00%|\n",
      "   127|         0|            0|            0|  0.00%|            If the ``self.data`` Tensor already has the correct :class:`torch.dtype`\n",
      "   128|         0|            0|            0|  0.00%|            and :class:`torch.device`, then ``self`` is returned.\n",
      "   129|         0|            0|            0|  0.00%|            Otherwise, returns a copy with the desired configuration.\n",
      "   130|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   131|         0|            0|            0|  0.00%|\n",
      "   132|         0|            0|            0|  0.00%|        # Why not convert `batch_sizes`?\n",
      "   133|         0|            0|            0|  0.00%|        # See NOTE [ device and dtype of a PackedSequence ]\n",
      "   134|         0|            0|            0|  0.00%|        data = self.data.to(*args, **kwargs)\n",
      "   135|         0|            0|            0|  0.00%|        if data is self.data:\n",
      "   136|         0|            0|            0|  0.00%|            return self\n",
      "   137|         0|            0|            0|  0.00%|        else:\n",
      "   138|         0|            0|            0|  0.00%|            # Does not forward device or dtype arg/kwargs, device is set from data.device\n",
      "   139|         0|            0|            0|  0.00%|            kwargs = {k : v for k, v in filter(lambda t: t[0] != 'device' and t[0] != 'dtype', kwargs.items())}\n",
      "   140|         0|            0|            0|  0.00%|            sorted_indices = bind(self.sorted_indices, lambda t: t.to(data.device, **kwargs))\n",
      "   141|         0|            0|            0|  0.00%|            unsorted_indices = bind(self.unsorted_indices, lambda t: t.to(data.device, **kwargs))\n",
      "   142|         0|            0|            0|  0.00%|            return type(self)(data, self.batch_sizes, sorted_indices, unsorted_indices)\n",
      "   143|         0|            0|            0|  0.00%|\n",
      "   144|         0|            0|            0|  0.00%|    @property\n",
      "   145|         0|            0|            0|  0.00%|    def is_cuda(self):\n",
      "   146|         0|            0|            0|  0.00%|        r\"\"\"Returns true if `self.data` stored on a gpu\"\"\"\n",
      "   147|         0|            0|            0|  0.00%|        return self.data.is_cuda\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         0|            0|            0|  0.00%|    def is_pinned(self):\n",
      "   150|         0|            0|            0|  0.00%|        r\"\"\"Returns true if `self.data` stored on in pinned memory\"\"\"\n",
      "   151|         0|            0|            0|  0.00%|        return self.data.is_pinned()\n",
      "   152|         0|            0|            0|  0.00%|\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|# TorchScript doesn't support constructors on named tuples, so we use this helper\n",
      "   155|         0|            0|            0|  0.00%|# method to construct PackedSequence\n",
      "   156|         3|  1.23978e-05|  4.13259e-06|  0.00%|def _packed_sequence_init_args(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "   157|         0|            0|            0|  0.00%|    # type: (Tensor, Optional[Tensor], Optional[Tensor], Optional[Tensor]) -> Tuple[Tensor, Tensor, Optional[Tensor], Optional[Tensor]]  # noqa: B950\n",
      "   158|         0|            0|            0|  0.00%|    # NB: if unsorted_indices is provided, it should be the inverse permutation\n",
      "   159|         0|            0|            0|  0.00%|    # to sorted_indices. Don't assert it here because the PackedSequence ctor\n",
      "   160|         0|            0|            0|  0.00%|    # should only be used internally.\n",
      "   161|         0|            0|            0|  0.00%|\n",
      "   162|         3|  9.05991e-06|  3.01997e-06|  0.00%|    if unsorted_indices is None:\n",
      "   163|         1|  1.28746e-05|  1.28746e-05|  0.00%|        unsorted_indices = invert_permutation(sorted_indices)\n",
      "(call)|         1|  5.10216e-05|  5.10216e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:190 invert_permutation\n",
      "   164|         0|            0|            0|  0.00%|\n",
      "   165|         0|            0|            0|  0.00%|    # support being called as `PackedSequence(data, batch_sizes, sorted_indices)`\n",
      "   166|         3|  8.34465e-06|  2.78155e-06|  0.00%|    if batch_sizes is not None:\n",
      "   167|         0|            0|            0|  0.00%|        # TODO: Re-enable this check (.type isn't supported in TorchScript)\n",
      "   168|         3|  2.16961e-05|  7.23203e-06|  0.00%|        if batch_sizes.device.type != 'cpu':\n",
      "   169|         0|            0|            0|  0.00%|            raise ValueError(\n",
      "   170|         0|            0|            0|  0.00%|                \"batch_sizes should always be on CPU. \"\n",
      "   171|         0|            0|            0|  0.00%|                \"Instances of PackedSequence should never be created manually. \"\n",
      "   172|         0|            0|            0|  0.00%|                \"They should be instantiated by functions like pack_sequence \"\n",
      "   173|         0|            0|            0|  0.00%|                \"and pack_padded_sequences in nn.utils.rnn. \"\n",
      "   174|         0|            0|            0|  0.00%|                \"https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence\")\n",
      "   175|         3|  1.07288e-05|  3.57628e-06|  0.00%|        return data, batch_sizes, sorted_indices, unsorted_indices\n",
      "   176|         0|            0|            0|  0.00%|\n",
      "   177|         0|            0|            0|  0.00%|    # support being called as `PackedSequence((data, batch_sizes), *, sorted_indices)`\n",
      "   178|         0|            0|            0|  0.00%|    else:\n",
      "   179|         0|            0|            0|  0.00%|        assert isinstance(data, (list, tuple)) and len(data) == 2\n",
      "   180|         0|            0|            0|  0.00%|        return data[0], data[1], sorted_indices, unsorted_indices\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|\n",
      "   183|         1|  3.09944e-06|  3.09944e-06|  0.00%|def _packed_sequence_init(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None):\n",
      "   184|         0|            0|            0|  0.00%|    # type: (Tensor, Optional[Tensor], Optional[Tensor], Optional[Tensor]) -> PackedSequence\n",
      "   185|         1|  4.05312e-06|  4.05312e-06|  0.00%|    data, batch_sizes, sorted_indices, unsorted_indices = _packed_sequence_init_args(\n",
      "   186|         1|  1.07288e-05|  1.07288e-05|  0.00%|        data, batch_sizes, sorted_indices, unsorted_indices)\n",
      "(call)|         1|  9.20296e-05|  9.20296e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:156 _packed_sequence_init_args\n",
      "   187|         1|  1.28746e-05|  1.28746e-05|  0.00%|    return PackedSequence(data, batch_sizes, sorted_indices, unsorted_indices)\n",
      "(call)|         1|  6.22272e-05|  6.22272e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:63 __new__\n",
      "   188|         0|            0|            0|  0.00%|\n",
      "   189|         0|            0|            0|  0.00%|\n",
      "   190|         1|  4.76837e-06|  4.76837e-06|  0.00%|def invert_permutation(permutation):\n",
      "   191|         0|            0|            0|  0.00%|    # type: (Optional[Tensor]) -> Optional[Tensor]\n",
      "   192|         1|  4.29153e-06|  4.29153e-06|  0.00%|    if permutation is None:\n",
      "   193|         0|            0|            0|  0.00%|        return None\n",
      "   194|         1|  8.82149e-06|  8.82149e-06|  0.00%|    output = torch.empty_like(permutation, memory_format=torch.legacy_contiguous_format)\n",
      "   195|         1|  5.24521e-06|  5.24521e-06|  0.00%|    output.scatter_(0, permutation,\n",
      "   196|         1|  2.28882e-05|  2.28882e-05|  0.00%|                    torch.arange(0, permutation.numel(), device=permutation.device))\n",
      "   197|         1|  5.00679e-06|  5.00679e-06|  0.00%|    return output\n",
      "   198|         0|            0|            0|  0.00%|\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         1|  1.57356e-05|  1.57356e-05|  0.00%|def pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True):\n",
      "   201|         0|            0|            0|  0.00%|    # type: (Tensor, Tensor, bool, bool) -> PackedSequence\n",
      "   202|         0|            0|            0|  0.00%|    r\"\"\"Packs a Tensor containing padded sequences of variable length.\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|    :attr:`input` can be of size ``T x B x *`` where `T` is the length of the\n",
      "   205|         0|            0|            0|  0.00%|    longest sequence (equal to ``lengths[0]``), ``B`` is the batch size, and\n",
      "   206|         0|            0|            0|  0.00%|    ``*`` is any number of dimensions (including 0). If ``batch_first`` is\n",
      "   207|         0|            0|            0|  0.00%|    ``True``, ``B x T x *`` :attr:`input` is expected.\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|    For unsorted sequences, use `enforce_sorted = False`. If :attr:`enforce_sorted` is\n",
      "   210|         0|            0|            0|  0.00%|    ``True``, the sequences should be sorted by length in a decreasing order, i.e.\n",
      "   211|         0|            0|            0|  0.00%|    ``input[:,0]`` should be the longest sequence, and ``input[:,B-1]`` the shortest\n",
      "   212|         0|            0|            0|  0.00%|    one. `enforce_sorted = True` is only necessary for ONNX export.\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|    Note:\n",
      "   215|         0|            0|            0|  0.00%|        This function accepts any input that has at least two dimensions. You\n",
      "   216|         0|            0|            0|  0.00%|        can apply it to pack the labels, and use the output of the RNN with\n",
      "   217|         0|            0|            0|  0.00%|        them to compute the loss directly. A Tensor can be retrieved from\n",
      "   218|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object by accessing its ``.data`` attribute.\n",
      "   219|         0|            0|            0|  0.00%|\n",
      "   220|         0|            0|            0|  0.00%|    Args:\n",
      "   221|         0|            0|            0|  0.00%|        input (Tensor): padded batch of variable length sequences.\n",
      "   222|         0|            0|            0|  0.00%|        lengths (Tensor or list(int)): list of sequence lengths of each batch\n",
      "   223|         0|            0|            0|  0.00%|            element (must be on the CPU if provided as a tensor).\n",
      "   224|         0|            0|            0|  0.00%|        batch_first (bool, optional): if ``True``, the input is expected in ``B x T x *``\n",
      "   225|         0|            0|            0|  0.00%|            format.\n",
      "   226|         0|            0|            0|  0.00%|        enforce_sorted (bool, optional): if ``True``, the input is expected to\n",
      "   227|         0|            0|            0|  0.00%|            contain sequences sorted by length in a decreasing order. If\n",
      "   228|         0|            0|            0|  0.00%|            ``False``, the input will get sorted unconditionally. Default: ``True``.\n",
      "   229|         0|            0|            0|  0.00%|\n",
      "   230|         0|            0|            0|  0.00%|    Returns:\n",
      "   231|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object\n",
      "   232|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   233|         1|  1.43051e-05|  1.43051e-05|  0.00%|    if torch._C._get_tracing_state() and not isinstance(lengths, torch.Tensor):\n",
      "   234|         0|            0|            0|  0.00%|        warnings.warn('pack_padded_sequence has been called with a Python list of '\n",
      "   235|         0|            0|            0|  0.00%|                      'sequence lengths. The tracer cannot track the data flow of Python '\n",
      "   236|         0|            0|            0|  0.00%|                      'values, and it will treat them as constants, likely rendering '\n",
      "   237|         0|            0|            0|  0.00%|                      'the trace incorrect for any other combination of lengths.',\n",
      "   238|         0|            0|            0|  0.00%|                      stacklevel=2)\n",
      "   239|         1|  1.88351e-05|  1.88351e-05|  0.00%|    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
      "   240|         1|  5.00679e-06|  5.00679e-06|  0.00%|    if enforce_sorted:\n",
      "   241|         0|            0|            0|  0.00%|        sorted_indices = None\n",
      "   242|         0|            0|            0|  0.00%|    else:\n",
      "   243|         1|  3.50475e-05|  3.50475e-05|  0.00%|        lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
      "   244|         1|  8.82149e-06|  8.82149e-06|  0.00%|        sorted_indices = sorted_indices.to(input.device)\n",
      "   245|         1|  5.24521e-06|  5.24521e-06|  0.00%|        batch_dim = 0 if batch_first else 1\n",
      "   246|         1|  3.98159e-05|  3.98159e-05|  0.00%|        input = input.index_select(batch_dim, sorted_indices)\n",
      "   247|         0|            0|            0|  0.00%|\n",
      "   248|         0|            0|            0|  0.00%|    data, batch_sizes = \\\n",
      "   249|         1|  6.91414e-05|  6.91414e-05|  0.00%|        _VF._pack_padded_sequence(input, lengths, batch_first)\n",
      "(call)|         1|  1.88351e-05|  1.88351e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   250|         1|   1.5974e-05|   1.5974e-05|  0.00%|    return _packed_sequence_init(data, batch_sizes, sorted_indices, None)\n",
      "(call)|         1|  0.000185013|  0.000185013|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/utils/rnn.py:183 _packed_sequence_init\n",
      "   251|         0|            0|            0|  0.00%|\n",
      "   252|         0|            0|            0|  0.00%|\n",
      "   253|         1|  1.09673e-05|  1.09673e-05|  0.00%|def pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None):\n",
      "   254|         0|            0|            0|  0.00%|    # type: (PackedSequence, bool, float, Optional[int]) -> Tuple[Tensor, Tensor]\n",
      "   255|         0|            0|            0|  0.00%|    r\"\"\"Pads a packed batch of variable length sequences.\n",
      "   256|         0|            0|            0|  0.00%|\n",
      "   257|         0|            0|            0|  0.00%|    It is an inverse operation to :func:`pack_padded_sequence`.\n",
      "   258|         0|            0|            0|  0.00%|\n",
      "   259|         0|            0|            0|  0.00%|    The returned Tensor's data will be of size ``T x B x *``, where `T` is the length\n",
      "   260|         0|            0|            0|  0.00%|    of the longest sequence and `B` is the batch size. If ``batch_first`` is True,\n",
      "   261|         0|            0|            0|  0.00%|    the data will be transposed into ``B x T x *`` format.\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|    Example:\n",
      "   264|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
      "   265|         0|            0|            0|  0.00%|        >>> seq = torch.tensor([[1,2,0], [3,0,0], [4,5,6]])\n",
      "   266|         0|            0|            0|  0.00%|        >>> lens = [2, 1, 3]\n",
      "   267|         0|            0|            0|  0.00%|        >>> packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)\n",
      "   268|         0|            0|            0|  0.00%|        >>> packed\n",
      "   269|         0|            0|            0|  0.00%|        PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]),\n",
      "   270|         0|            0|            0|  0.00%|                       sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
      "   271|         0|            0|            0|  0.00%|        >>> seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
      "   272|         0|            0|            0|  0.00%|        >>> seq_unpacked\n",
      "   273|         0|            0|            0|  0.00%|        tensor([[1, 2, 0],\n",
      "   274|         0|            0|            0|  0.00%|                [3, 0, 0],\n",
      "   275|         0|            0|            0|  0.00%|                [4, 5, 6]])\n",
      "   276|         0|            0|            0|  0.00%|        >>> lens_unpacked\n",
      "   277|         0|            0|            0|  0.00%|        tensor([2, 1, 3])\n",
      "   278|         0|            0|            0|  0.00%|\n",
      "   279|         0|            0|            0|  0.00%|    .. note::\n",
      "   280|         0|            0|            0|  0.00%|        :attr:`total_length` is useful to implement the\n",
      "   281|         0|            0|            0|  0.00%|        ``pack sequence -> recurrent network -> unpack sequence`` pattern in a\n",
      "   282|         0|            0|            0|  0.00%|        :class:`~torch.nn.Module` wrapped in :class:`~torch.nn.DataParallel`.\n",
      "   283|         0|            0|            0|  0.00%|        See :ref:`this FAQ section <pack-rnn-unpack-with-data-parallelism>` for\n",
      "   284|         0|            0|            0|  0.00%|        details.\n",
      "   285|         0|            0|            0|  0.00%|\n",
      "   286|         0|            0|            0|  0.00%|    Args:\n",
      "   287|         0|            0|            0|  0.00%|        sequence (PackedSequence): batch to pad\n",
      "   288|         0|            0|            0|  0.00%|        batch_first (bool, optional): if ``True``, the output will be in ``B x T x *``\n",
      "   289|         0|            0|            0|  0.00%|            format.\n",
      "   290|         0|            0|            0|  0.00%|        padding_value (float, optional): values for padded elements.\n",
      "   291|         0|            0|            0|  0.00%|        total_length (int, optional): if not ``None``, the output will be padded to\n",
      "   292|         0|            0|            0|  0.00%|            have length :attr:`total_length`. This method will throw :class:`ValueError`\n",
      "   293|         0|            0|            0|  0.00%|            if :attr:`total_length` is less than the max sequence length in\n",
      "   294|         0|            0|            0|  0.00%|            :attr:`sequence`.\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|    Returns:\n",
      "   297|         0|            0|            0|  0.00%|        Tuple of Tensor containing the padded sequence, and a Tensor\n",
      "   298|         0|            0|            0|  0.00%|        containing the list of lengths of each sequence in the batch.\n",
      "   299|         0|            0|            0|  0.00%|        Batch elements will be re-ordered as they were ordered originally when\n",
      "   300|         0|            0|            0|  0.00%|        the batch was passed to ``pack_padded_sequence`` or ``pack_sequence``.\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|\n",
      "   303|         0|            0|            0|  0.00%|\n",
      "   304|         0|            0|            0|  0.00%|\n",
      "   305|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   306|         1|  7.86781e-06|  7.86781e-06|  0.00%|    max_seq_length = sequence.batch_sizes.size(0)\n",
      "   307|         1|  5.24521e-06|  5.24521e-06|  0.00%|    if total_length is not None:\n",
      "   308|         0|            0|            0|  0.00%|        if total_length < max_seq_length:\n",
      "   309|         0|            0|            0|  0.00%|            raise ValueError(\"Expected total_length to be at least the length \"\n",
      "   310|         0|            0|            0|  0.00%|                             \"of the longest sequence in input, but got \"\n",
      "   311|         0|            0|            0|  0.00%|                             \"total_length={} and max sequence length being {}\"\n",
      "   312|         0|            0|            0|  0.00%|                             .format(total_length, max_seq_length))\n",
      "   313|         0|            0|            0|  0.00%|        max_seq_length = total_length\n",
      "   314|         1|  1.62125e-05|  1.62125e-05|  0.00%|    padded_output, lengths = _VF._pad_packed_sequence(\n",
      "(call)|         1|  6.91414e-06|  6.91414e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py:25 __getattr__\n",
      "   315|         1|  0.000125885|  0.000125885|  0.00%|        sequence.data, sequence.batch_sizes, batch_first, padding_value, max_seq_length)\n",
      "   316|         1|  7.86781e-06|  7.86781e-06|  0.00%|    unsorted_indices = sequence.unsorted_indices\n",
      "   317|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if unsorted_indices is not None:\n",
      "   318|         1|   3.8147e-06|   3.8147e-06|  0.00%|        batch_dim = 0 if batch_first else 1\n",
      "   319|         1|  3.50475e-05|  3.50475e-05|  0.00%|        return padded_output.index_select(batch_dim, unsorted_indices), lengths[unsorted_indices]\n",
      "   320|         0|            0|            0|  0.00%|    return padded_output, lengths\n",
      "   321|         0|            0|            0|  0.00%|\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|def pad_sequence(sequences, batch_first=False, padding_value=0.0):\n",
      "   324|         0|            0|            0|  0.00%|    # type: (List[Tensor], bool, float) -> Tensor\n",
      "   325|         0|            0|            0|  0.00%|    r\"\"\"Pad a list of variable length Tensors with ``padding_value``\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|    ``pad_sequence`` stacks a list of Tensors along a new dimension,\n",
      "   328|         0|            0|            0|  0.00%|    and pads them to equal length. For example, if the input is list of\n",
      "   329|         0|            0|            0|  0.00%|    sequences with size ``L x *`` and if batch_first is False, and ``T x B x *``\n",
      "   330|         0|            0|            0|  0.00%|    otherwise.\n",
      "   331|         0|            0|            0|  0.00%|\n",
      "   332|         0|            0|            0|  0.00%|    `B` is batch size. It is equal to the number of elements in ``sequences``.\n",
      "   333|         0|            0|            0|  0.00%|    `T` is length of the longest sequence.\n",
      "   334|         0|            0|            0|  0.00%|    `L` is length of the sequence.\n",
      "   335|         0|            0|            0|  0.00%|    `*` is any number of trailing dimensions, including none.\n",
      "   336|         0|            0|            0|  0.00%|\n",
      "   337|         0|            0|            0|  0.00%|    Example:\n",
      "   338|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pad_sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   339|         0|            0|            0|  0.00%|        >>> a = torch.ones(25, 300)\n",
      "   340|         0|            0|            0|  0.00%|        >>> b = torch.ones(22, 300)\n",
      "   341|         0|            0|            0|  0.00%|        >>> c = torch.ones(15, 300)\n",
      "   342|         0|            0|            0|  0.00%|        >>> pad_sequence([a, b, c]).size()\n",
      "   343|         0|            0|            0|  0.00%|        torch.Size([25, 3, 300])\n",
      "   344|         0|            0|            0|  0.00%|\n",
      "   345|         0|            0|            0|  0.00%|    Note:\n",
      "   346|         0|            0|            0|  0.00%|        This function returns a Tensor of size ``T x B x *`` or ``B x T x *``\n",
      "   347|         0|            0|            0|  0.00%|        where `T` is the length of the longest sequence. This function assumes\n",
      "   348|         0|            0|            0|  0.00%|        trailing dimensions and type of all the Tensors in sequences are same.\n",
      "   349|         0|            0|            0|  0.00%|\n",
      "   350|         0|            0|            0|  0.00%|    Args:\n",
      "   351|         0|            0|            0|  0.00%|        sequences (list[Tensor]): list of variable length sequences.\n",
      "   352|         0|            0|            0|  0.00%|        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
      "   353|         0|            0|            0|  0.00%|            ``T x B x *`` otherwise\n",
      "   354|         0|            0|            0|  0.00%|        padding_value (float, optional): value for padded elements. Default: 0.\n",
      "   355|         0|            0|            0|  0.00%|\n",
      "   356|         0|            0|            0|  0.00%|    Returns:\n",
      "   357|         0|            0|            0|  0.00%|        Tensor of size ``T x B x *`` if :attr:`batch_first` is ``False``.\n",
      "   358|         0|            0|            0|  0.00%|        Tensor of size ``B x T x *`` otherwise\n",
      "   359|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|    # assuming trailing dimensions and type of all the Tensors\n",
      "   362|         0|            0|            0|  0.00%|    # in sequences are same and fetching those from sequences[0]\n",
      "   363|         0|            0|            0|  0.00%|    return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
      "   364|         0|            0|            0|  0.00%|\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|def pack_sequence(sequences, enforce_sorted=True):\n",
      "   367|         0|            0|            0|  0.00%|    # type: (List[Tensor], bool) -> PackedSequence\n",
      "   368|         0|            0|            0|  0.00%|    r\"\"\"Packs a list of variable length Tensors\n",
      "   369|         0|            0|            0|  0.00%|\n",
      "   370|         0|            0|            0|  0.00%|    ``sequences`` should be a list of Tensors of size ``L x *``, where `L` is\n",
      "   371|         0|            0|            0|  0.00%|    the length of a sequence and `*` is any number of trailing dimensions,\n",
      "   372|         0|            0|            0|  0.00%|    including zero.\n",
      "   373|         0|            0|            0|  0.00%|\n",
      "   374|         0|            0|            0|  0.00%|    For unsorted sequences, use `enforce_sorted = False`. If ``enforce_sorted``\n",
      "   375|         0|            0|            0|  0.00%|    is ``True``, the sequences should be sorted in the order of decreasing length.\n",
      "   376|         0|            0|            0|  0.00%|    ``enforce_sorted = True`` is only necessary for ONNX export.\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|\n",
      "   379|         0|            0|            0|  0.00%|    Example:\n",
      "   380|         0|            0|            0|  0.00%|        >>> from torch.nn.utils.rnn import pack_sequence\n",
      "   381|         0|            0|            0|  0.00%|        >>> a = torch.tensor([1,2,3])\n",
      "   382|         0|            0|            0|  0.00%|        >>> b = torch.tensor([4,5])\n",
      "   383|         0|            0|            0|  0.00%|        >>> c = torch.tensor([6])\n",
      "   384|         0|            0|            0|  0.00%|        >>> pack_sequence([a, b, c])\n",
      "   385|         0|            0|            0|  0.00%|        PackedSequence(data=tensor([ 1,  4,  6,  2,  5,  3]), batch_sizes=tensor([ 3,  2,  1]))\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|\n",
      "   388|         0|            0|            0|  0.00%|    Args:\n",
      "   389|         0|            0|            0|  0.00%|        sequences (list[Tensor]): A list of sequences of decreasing length.\n",
      "   390|         0|            0|            0|  0.00%|        enforce_sorted (bool, optional): if ``True``, checks that the input\n",
      "   391|         0|            0|            0|  0.00%|            contains sequences sorted by length in a decreasing order. If\n",
      "   392|         0|            0|            0|  0.00%|            ``False``, this condition is not checked. Default: ``True``.\n",
      "   393|         0|            0|            0|  0.00%|\n",
      "   394|         0|            0|            0|  0.00%|    Returns:\n",
      "   395|         0|            0|            0|  0.00%|        a :class:`PackedSequence` object\n",
      "   396|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   397|         0|            0|            0|  0.00%|    lengths = torch.as_tensor([v.size(0) for v in sequences])\n",
      "   398|         0|            0|            0|  0.00%|    return pack_padded_sequence(pad_sequence(sequences), lengths, enforce_sorted=enforce_sorted)\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/linear.py\n",
      "File duration: 0.000382662s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|import math\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|import torch\n",
      "     4|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     5|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter, UninitializedParameter\n",
      "     6|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     7|         0|            0|            0|  0.00%|from .. import init\n",
      "     8|         0|            0|            0|  0.00%|from .module import Module\n",
      "     9|         0|            0|            0|  0.00%|from .lazy import LazyModuleMixin\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class Identity(Module):\n",
      "    13|         0|            0|            0|  0.00%|    r\"\"\"A placeholder identity operator that is argument-insensitive.\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|    Args:\n",
      "    16|         0|            0|            0|  0.00%|        args: any argument (unused)\n",
      "    17|         0|            0|            0|  0.00%|        kwargs: any keyword argument (unused)\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|    Shape:\n",
      "    20|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "    21|         0|            0|            0|  0.00%|        - Output: :math:`(*)`, same shape as the input.\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|    Examples::\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|        >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)\n",
      "    26|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)\n",
      "    27|         0|            0|            0|  0.00%|        >>> output = m(input)\n",
      "    28|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "    29|         0|            0|            0|  0.00%|        torch.Size([128, 20])\n",
      "    30|         0|            0|            0|  0.00%|\n",
      "    31|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    32|         0|            0|            0|  0.00%|    def __init__(self, *args, **kwargs):\n",
      "    33|         0|            0|            0|  0.00%|        super(Identity, self).__init__()\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    def forward(self, input: Tensor) -> Tensor:\n",
      "    36|         0|            0|            0|  0.00%|        return input\n",
      "    37|         0|            0|            0|  0.00%|\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|         0|            0|            0|  0.00%|class Linear(Module):\n",
      "    40|         0|            0|            0|  0.00%|    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "    43|         0|            0|            0|  0.00%|\n",
      "    44|         0|            0|            0|  0.00%|    Args:\n",
      "    45|         0|            0|            0|  0.00%|        in_features: size of each input sample\n",
      "    46|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "    47|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "    48|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "    49|         0|            0|            0|  0.00%|\n",
      "    50|         0|            0|            0|  0.00%|    Shape:\n",
      "    51|         0|            0|            0|  0.00%|        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
      "    52|         0|            0|            0|  0.00%|          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
      "    53|         0|            0|            0|  0.00%|        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
      "    54|         0|            0|            0|  0.00%|          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|    Attributes:\n",
      "    57|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "    58|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "    59|         0|            0|            0|  0.00%|            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "    60|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    61|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "    62|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "    63|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "    64|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    65|         0|            0|            0|  0.00%|\n",
      "    66|         0|            0|            0|  0.00%|    Examples::\n",
      "    67|         0|            0|            0|  0.00%|\n",
      "    68|         0|            0|            0|  0.00%|        >>> m = nn.Linear(20, 30)\n",
      "    69|         0|            0|            0|  0.00%|        >>> input = torch.randn(128, 20)\n",
      "    70|         0|            0|            0|  0.00%|        >>> output = m(input)\n",
      "    71|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "    72|         0|            0|            0|  0.00%|        torch.Size([128, 30])\n",
      "    73|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    74|         0|            0|            0|  0.00%|    __constants__ = ['in_features', 'out_features']\n",
      "    75|         0|            0|            0|  0.00%|    in_features: int\n",
      "    76|         0|            0|            0|  0.00%|    out_features: int\n",
      "    77|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "    78|         0|            0|            0|  0.00%|\n",
      "    79|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
      "    80|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "    81|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "    82|         0|            0|            0|  0.00%|        super(Linear, self).__init__()\n",
      "    83|         0|            0|            0|  0.00%|        self.in_features = in_features\n",
      "    84|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "    85|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
      "    86|         0|            0|            0|  0.00%|        if bias:\n",
      "    87|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "    88|         0|            0|            0|  0.00%|        else:\n",
      "    89|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)\n",
      "    90|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "    93|         0|            0|            0|  0.00%|        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
      "    94|         0|            0|            0|  0.00%|        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
      "    95|         0|            0|            0|  0.00%|        # https://github.com/pytorch/pytorch/issues/57109\n",
      "    96|         0|            0|            0|  0.00%|        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
      "    97|         0|            0|            0|  0.00%|        if self.bias is not None:\n",
      "    98|         0|            0|            0|  0.00%|            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
      "    99|         0|            0|            0|  0.00%|            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
      "   100|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)\n",
      "   101|         0|            0|            0|  0.00%|\n",
      "   102|        16|  3.29018e-05|  2.05636e-06|  0.00%|    def forward(self, input: Tensor) -> Tensor:\n",
      "   103|        16|   0.00034976|    2.186e-05|  0.00%|        return F.linear(input, self.weight, self.bias)\n",
      "(call)|        32|  0.000377893|  1.18092e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "(call)|        16|   0.00187945|  0.000117466|  0.02%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:1832 linear\n",
      "   104|         0|            0|            0|  0.00%|\n",
      "   105|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   106|         0|            0|            0|  0.00%|        return 'in_features={}, out_features={}, bias={}'.format(\n",
      "   107|         0|            0|            0|  0.00%|            self.in_features, self.out_features, self.bias is not None\n",
      "   108|         0|            0|            0|  0.00%|        )\n",
      "   109|         0|            0|            0|  0.00%|\n",
      "   110|         0|            0|            0|  0.00%|\n",
      "   111|         0|            0|            0|  0.00%|# This class exists solely to avoid triggering an obscure error when scripting\n",
      "   112|         0|            0|            0|  0.00%|# an improperly quantized attention layer. See this issue for details:\n",
      "   113|         0|            0|            0|  0.00%|# https://github.com/pytorch/pytorch/issues/58969\n",
      "   114|         0|            0|            0|  0.00%|# TODO: fail fast on quantization API usage error, then remove this class\n",
      "   115|         0|            0|            0|  0.00%|# and replace uses of it with plain Linear\n",
      "   116|         0|            0|            0|  0.00%|class NonDynamicallyQuantizableLinear(Linear):\n",
      "   117|         0|            0|            0|  0.00%|    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
      "   118|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   119|         0|            0|            0|  0.00%|        super().__init__(in_features, out_features, bias=bias,\n",
      "   120|         0|            0|            0|  0.00%|                         device=device, dtype=dtype)\n",
      "   121|         0|            0|            0|  0.00%|\n",
      "   122|         0|            0|            0|  0.00%|\n",
      "   123|         0|            0|            0|  0.00%|class Bilinear(Module):\n",
      "   124|         0|            0|            0|  0.00%|    r\"\"\"Applies a bilinear transformation to the incoming data:\n",
      "   125|         0|            0|            0|  0.00%|    :math:`y = x_1^T A x_2 + b`\n",
      "   126|         0|            0|            0|  0.00%|\n",
      "   127|         0|            0|            0|  0.00%|    Args:\n",
      "   128|         0|            0|            0|  0.00%|        in1_features: size of each first input sample\n",
      "   129|         0|            0|            0|  0.00%|        in2_features: size of each second input sample\n",
      "   130|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "   131|         0|            0|            0|  0.00%|        bias: If set to False, the layer will not learn an additive bias.\n",
      "   132|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   133|         0|            0|            0|  0.00%|\n",
      "   134|         0|            0|            0|  0.00%|    Shape:\n",
      "   135|         0|            0|            0|  0.00%|        - Input1: :math:`(N, *, H_{in1})` where :math:`H_{in1}=\\text{in1\\_features}` and\n",
      "   136|         0|            0|            0|  0.00%|          :math:`*` means any number of additional dimensions. All but the last dimension\n",
      "   137|         0|            0|            0|  0.00%|          of the inputs should be the same.\n",
      "   138|         0|            0|            0|  0.00%|        - Input2: :math:`(N, *, H_{in2})` where :math:`H_{in2}=\\text{in2\\_features}`.\n",
      "   139|         0|            0|            0|  0.00%|        - Output: :math:`(N, *, H_{out})` where :math:`H_{out}=\\text{out\\_features}`\n",
      "   140|         0|            0|            0|  0.00%|          and all but the last dimension are the same shape as the input.\n",
      "   141|         0|            0|            0|  0.00%|\n",
      "   142|         0|            0|            0|  0.00%|    Attributes:\n",
      "   143|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "   144|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in1\\_features}, \\text{in2\\_features})`.\n",
      "   145|         0|            0|            0|  0.00%|            The values are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   146|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in1\\_features}}`\n",
      "   147|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "   148|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "   149|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   150|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in1\\_features}}`\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    Examples::\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|        >>> m = nn.Bilinear(20, 30, 40)\n",
      "   155|         0|            0|            0|  0.00%|        >>> input1 = torch.randn(128, 20)\n",
      "   156|         0|            0|            0|  0.00%|        >>> input2 = torch.randn(128, 30)\n",
      "   157|         0|            0|            0|  0.00%|        >>> output = m(input1, input2)\n",
      "   158|         0|            0|            0|  0.00%|        >>> print(output.size())\n",
      "   159|         0|            0|            0|  0.00%|        torch.Size([128, 40])\n",
      "   160|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   161|         0|            0|            0|  0.00%|    __constants__ = ['in1_features', 'in2_features', 'out_features']\n",
      "   162|         0|            0|            0|  0.00%|    in1_features: int\n",
      "   163|         0|            0|            0|  0.00%|    in2_features: int\n",
      "   164|         0|            0|            0|  0.00%|    out_features: int\n",
      "   165|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|    def __init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True,\n",
      "   168|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   169|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   170|         0|            0|            0|  0.00%|        super(Bilinear, self).__init__()\n",
      "   171|         0|            0|            0|  0.00%|        self.in1_features = in1_features\n",
      "   172|         0|            0|            0|  0.00%|        self.in2_features = in2_features\n",
      "   173|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "   174|         0|            0|            0|  0.00%|        self.weight = Parameter(torch.empty((out_features, in1_features, in2_features), **factory_kwargs))\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|        if bias:\n",
      "   177|         0|            0|            0|  0.00%|            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
      "   178|         0|            0|            0|  0.00%|        else:\n",
      "   179|         0|            0|            0|  0.00%|            self.register_parameter('bias', None)\n",
      "   180|         0|            0|            0|  0.00%|        self.reset_parameters()\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   183|         0|            0|            0|  0.00%|        bound = 1 / math.sqrt(self.weight.size(1))\n",
      "   184|         0|            0|            0|  0.00%|        init.uniform_(self.weight, -bound, bound)\n",
      "   185|         0|            0|            0|  0.00%|        if self.bias is not None:\n",
      "   186|         0|            0|            0|  0.00%|            init.uniform_(self.bias, -bound, bound)\n",
      "   187|         0|            0|            0|  0.00%|\n",
      "   188|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor) -> Tensor:\n",
      "   189|         0|            0|            0|  0.00%|        return F.bilinear(input1, input2, self.weight, self.bias)\n",
      "   190|         0|            0|            0|  0.00%|\n",
      "   191|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   192|         0|            0|            0|  0.00%|        return 'in1_features={}, in2_features={}, out_features={}, bias={}'.format(\n",
      "   193|         0|            0|            0|  0.00%|            self.in1_features, self.in2_features, self.out_features, self.bias is not None\n",
      "   194|         0|            0|            0|  0.00%|        )\n",
      "   195|         0|            0|            0|  0.00%|\n",
      "   196|         0|            0|            0|  0.00%|\n",
      "   197|         0|            0|            0|  0.00%|class LazyLinear(LazyModuleMixin, Linear):\n",
      "   198|         0|            0|            0|  0.00%|    r\"\"\"A :class:`torch.nn.Linear` module where `in_features` is inferred.\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         0|            0|            0|  0.00%|    In this module, the `weight` and `bias` are of :class:`torch.nn.UninitializedParameter`\n",
      "   201|         0|            0|            0|  0.00%|    class. They will be initialized after the first call to ``forward`` is done and the\n",
      "   202|         0|            0|            0|  0.00%|    module will become a regular :class:`torch.nn.Linear` module. The ``in_features`` argument\n",
      "   203|         0|            0|            0|  0.00%|    of the :class:`Linear` is inferred from the ``input.shape[-1]``.\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|    Check the :class:`torch.nn.modules.lazy.LazyModuleMixin` for further documentation\n",
      "   206|         0|            0|            0|  0.00%|    on lazy modules and their limitations.\n",
      "   207|         0|            0|            0|  0.00%|\n",
      "   208|         0|            0|            0|  0.00%|    Args:\n",
      "   209|         0|            0|            0|  0.00%|        out_features: size of each output sample\n",
      "   210|         0|            0|            0|  0.00%|        bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "   211|         0|            0|            0|  0.00%|            Default: ``True``\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|    Attributes:\n",
      "   214|         0|            0|            0|  0.00%|        weight: the learnable weights of the module of shape\n",
      "   215|         0|            0|            0|  0.00%|            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "   216|         0|            0|            0|  0.00%|            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "   217|         0|            0|            0|  0.00%|            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "   218|         0|            0|            0|  0.00%|        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "   219|         0|            0|            0|  0.00%|                If :attr:`bias` is ``True``, the values are initialized from\n",
      "   220|         0|            0|            0|  0.00%|                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "   221|         0|            0|            0|  0.00%|                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|\n",
      "   224|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    cls_to_become = Linear  # type: ignore[assignment]\n",
      "   227|         0|            0|            0|  0.00%|    weight: UninitializedParameter\n",
      "   228|         0|            0|            0|  0.00%|    bias: UninitializedParameter  # type: ignore[assignment]\n",
      "   229|         0|            0|            0|  0.00%|\n",
      "   230|         0|            0|            0|  0.00%|    def __init__(self, out_features: int, bias: bool = True,\n",
      "   231|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   232|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   233|         0|            0|            0|  0.00%|        # bias is hardcoded to False to avoid creating tensor\n",
      "   234|         0|            0|            0|  0.00%|        # that will soon be overwritten.\n",
      "   235|         0|            0|            0|  0.00%|        super().__init__(0, 0, False)\n",
      "   236|         0|            0|            0|  0.00%|        self.weight = UninitializedParameter(**factory_kwargs)\n",
      "   237|         0|            0|            0|  0.00%|        self.out_features = out_features\n",
      "   238|         0|            0|            0|  0.00%|        if bias:\n",
      "   239|         0|            0|            0|  0.00%|            self.bias = UninitializedParameter(**factory_kwargs)\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   242|         0|            0|            0|  0.00%|        if not self.has_uninitialized_params() and self.in_features != 0:\n",
      "   243|         0|            0|            0|  0.00%|            super().reset_parameters()\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    def initialize_parameters(self, input) -> None:  # type: ignore[override]\n",
      "   246|         0|            0|            0|  0.00%|        if self.has_uninitialized_params():\n",
      "   247|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   248|         0|            0|            0|  0.00%|                self.in_features = input.shape[-1]\n",
      "   249|         0|            0|            0|  0.00%|                self.weight.materialize((self.out_features, self.in_features))\n",
      "   250|         0|            0|            0|  0.00%|                if self.bias is not None:\n",
      "   251|         0|            0|            0|  0.00%|                    self.bias.materialize((self.out_features,))\n",
      "   252|         0|            0|            0|  0.00%|                self.reset_parameters()\n",
      "   253|         0|            0|            0|  0.00%|# TODO: PartialLinear - maybe in sparse?\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/sparse.py\n",
      "File duration: 0.000254869s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from typing import Optional\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|import torch\n",
      "     4|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     5|         0|            0|            0|  0.00%|from torch.nn.parameter import Parameter\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|from .module import Module\n",
      "     8|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     9|         0|            0|            0|  0.00%|from .. import init\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class Embedding(Module):\n",
      "    13|         0|            0|            0|  0.00%|    r\"\"\"A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|    This module is often used to store word embeddings and retrieve them using indices.\n",
      "    16|         0|            0|            0|  0.00%|    The input to the module is a list of indices, and the output is the corresponding\n",
      "    17|         0|            0|            0|  0.00%|    word embeddings.\n",
      "    18|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19|         0|            0|            0|  0.00%|    Args:\n",
      "    20|         0|            0|            0|  0.00%|        num_embeddings (int): size of the dictionary of embeddings\n",
      "    21|         0|            0|            0|  0.00%|        embedding_dim (int): the size of each embedding vector\n",
      "    22|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "    23|         0|            0|            0|  0.00%|                                     therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "    24|         0|            0|            0|  0.00%|                                     i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\n",
      "    25|         0|            0|            0|  0.00%|                                     the embedding vector at :attr:`padding_idx` will default to all zeros,\n",
      "    26|         0|            0|            0|  0.00%|                                     but can be updated to another value to be used as the padding vector.\n",
      "    27|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "    28|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "    29|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "    30|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): If given, this will scale gradients by the inverse of frequency of\n",
      "    31|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "    32|         0|            0|            0|  0.00%|        sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
      "    33|         0|            0|            0|  0.00%|                                 See Notes for more details regarding sparse gradients.\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    Attributes:\n",
      "    36|         0|            0|            0|  0.00%|        weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      "    37|         0|            0|            0|  0.00%|                         initialized from :math:`\\mathcal{N}(0, 1)`\n",
      "    38|         0|            0|            0|  0.00%|\n",
      "    39|         0|            0|            0|  0.00%|    Shape:\n",
      "    40|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n",
      "    41|         0|            0|            0|  0.00%|        - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n",
      "    42|         0|            0|            0|  0.00%|\n",
      "    43|         0|            0|            0|  0.00%|    .. note::\n",
      "    44|         0|            0|            0|  0.00%|        Keep in mind that only a limited number of optimizers support\n",
      "    45|         0|            0|            0|  0.00%|        sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
      "    46|         0|            0|            0|  0.00%|        :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
      "    47|         0|            0|            0|  0.00%|\n",
      "    48|         0|            0|            0|  0.00%|    .. note::\n",
      "    49|         0|            0|            0|  0.00%|        When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\n",
      "    50|         0|            0|            0|  0.00%|        :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n",
      "    51|         0|            0|            0|  0.00%|        modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n",
      "    52|         0|            0|            0|  0.00%|        calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\n",
      "    53|         0|            0|            0|  0.00%|        :attr:`max_norm` is not ``None``. For example::\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|            n, d, m = 3, 5, 7\n",
      "    56|         0|            0|            0|  0.00%|            embedding = nn.Embedding(n, d, max_norm=True)\n",
      "    57|         0|            0|            0|  0.00%|            W = torch.randn((m, d), requires_grad=True)\n",
      "    58|         0|            0|            0|  0.00%|            idx = torch.tensor([1, 2])\n",
      "    59|         0|            0|            0|  0.00%|            a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
      "    60|         0|            0|            0|  0.00%|            b = embedding(idx) @ W.t()  # modifies weight in-place\n",
      "    61|         0|            0|            0|  0.00%|            out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
      "    62|         0|            0|            0|  0.00%|            loss = out.sigmoid().prod()\n",
      "    63|         0|            0|            0|  0.00%|            loss.backward()\n",
      "    64|         0|            0|            0|  0.00%|\n",
      "    65|         0|            0|            0|  0.00%|    Examples::\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|        >>> # an Embedding module containing 10 tensors of size 3\n",
      "    68|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3)\n",
      "    69|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "    70|         0|            0|            0|  0.00%|        >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
      "    71|         0|            0|            0|  0.00%|        >>> embedding(input)\n",
      "    72|         0|            0|            0|  0.00%|        tensor([[[-0.0251, -1.6902,  0.7172],\n",
      "    73|         0|            0|            0|  0.00%|                 [-0.6431,  0.0748,  0.6969],\n",
      "    74|         0|            0|            0|  0.00%|                 [ 1.4970,  1.3448, -0.9685],\n",
      "    75|         0|            0|            0|  0.00%|                 [-0.3677, -2.7265, -0.1685]],\n",
      "    76|         0|            0|            0|  0.00%|\n",
      "    77|         0|            0|            0|  0.00%|                [[ 1.4970,  1.3448, -0.9685],\n",
      "    78|         0|            0|            0|  0.00%|                 [ 0.4362, -0.4004,  0.9400],\n",
      "    79|         0|            0|            0|  0.00%|                 [-0.6431,  0.0748,  0.6969],\n",
      "    80|         0|            0|            0|  0.00%|                 [ 0.9124, -2.3616,  1.1151]]])\n",
      "    81|         0|            0|            0|  0.00%|\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|        >>> # example with padding_idx\n",
      "    84|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      "    85|         0|            0|            0|  0.00%|        >>> input = torch.LongTensor([[0,2,0,5]])\n",
      "    86|         0|            0|            0|  0.00%|        >>> embedding(input)\n",
      "    87|         0|            0|            0|  0.00%|        tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      "    88|         0|            0|            0|  0.00%|                 [ 0.1535, -2.0309,  0.9315],\n",
      "    89|         0|            0|            0|  0.00%|                 [ 0.0000,  0.0000,  0.0000],\n",
      "    90|         0|            0|            0|  0.00%|                 [-0.1655,  0.9897,  0.0635]]])\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|        >>> # example of changing `pad` vector\n",
      "    93|         0|            0|            0|  0.00%|        >>> padding_idx = 0\n",
      "    94|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
      "    95|         0|            0|            0|  0.00%|        >>> embedding.weight\n",
      "    96|         0|            0|            0|  0.00%|        Parameter containing:\n",
      "    97|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "    98|         0|            0|            0|  0.00%|                [-0.7895, -0.7089, -0.0364],\n",
      "    99|         0|            0|            0|  0.00%|                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      "   100|         0|            0|            0|  0.00%|        >>> with torch.no_grad():\n",
      "   101|         0|            0|            0|  0.00%|        ...     embedding.weight[padding_idx] = torch.ones(3)\n",
      "   102|         0|            0|            0|  0.00%|        >>> embedding.weight\n",
      "   103|         0|            0|            0|  0.00%|        Parameter containing:\n",
      "   104|         0|            0|            0|  0.00%|        tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "   105|         0|            0|            0|  0.00%|                [-0.7895, -0.7089, -0.0364],\n",
      "   106|         0|            0|            0|  0.00%|                [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      "   107|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   108|         0|            0|            0|  0.00%|    __constants__ = ['num_embeddings', 'embedding_dim', 'padding_idx', 'max_norm',\n",
      "   109|         0|            0|            0|  0.00%|                     'norm_type', 'scale_grad_by_freq', 'sparse']\n",
      "   110|         0|            0|            0|  0.00%|\n",
      "   111|         0|            0|            0|  0.00%|    num_embeddings: int\n",
      "   112|         0|            0|            0|  0.00%|    embedding_dim: int\n",
      "   113|         0|            0|            0|  0.00%|    padding_idx: Optional[int]\n",
      "   114|         0|            0|            0|  0.00%|    max_norm: Optional[float]\n",
      "   115|         0|            0|            0|  0.00%|    norm_type: float\n",
      "   116|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool\n",
      "   117|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   118|         0|            0|            0|  0.00%|    sparse: bool\n",
      "   119|         0|            0|            0|  0.00%|\n",
      "   120|         0|            0|            0|  0.00%|    def __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None,\n",
      "   121|         0|            0|            0|  0.00%|                 max_norm: Optional[float] = None, norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   122|         0|            0|            0|  0.00%|                 sparse: bool = False, _weight: Optional[Tensor] = None,\n",
      "   123|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   124|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   125|         0|            0|            0|  0.00%|        super(Embedding, self).__init__()\n",
      "   126|         0|            0|            0|  0.00%|        self.num_embeddings = num_embeddings\n",
      "   127|         0|            0|            0|  0.00%|        self.embedding_dim = embedding_dim\n",
      "   128|         0|            0|            0|  0.00%|        if padding_idx is not None:\n",
      "   129|         0|            0|            0|  0.00%|            if padding_idx > 0:\n",
      "   130|         0|            0|            0|  0.00%|                assert padding_idx < self.num_embeddings, 'Padding_idx must be within num_embeddings'\n",
      "   131|         0|            0|            0|  0.00%|            elif padding_idx < 0:\n",
      "   132|         0|            0|            0|  0.00%|                assert padding_idx >= -self.num_embeddings, 'Padding_idx must be within num_embeddings'\n",
      "   133|         0|            0|            0|  0.00%|                padding_idx = self.num_embeddings + padding_idx\n",
      "   134|         0|            0|            0|  0.00%|        self.padding_idx = padding_idx\n",
      "   135|         0|            0|            0|  0.00%|        self.max_norm = max_norm\n",
      "   136|         0|            0|            0|  0.00%|        self.norm_type = norm_type\n",
      "   137|         0|            0|            0|  0.00%|        self.scale_grad_by_freq = scale_grad_by_freq\n",
      "   138|         0|            0|            0|  0.00%|        if _weight is None:\n",
      "   139|         0|            0|            0|  0.00%|            self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs))\n",
      "   140|         0|            0|            0|  0.00%|            self.reset_parameters()\n",
      "   141|         0|            0|            0|  0.00%|        else:\n",
      "   142|         0|            0|            0|  0.00%|            assert list(_weight.shape) == [num_embeddings, embedding_dim], \\\n",
      "   143|         0|            0|            0|  0.00%|                'Shape of weight does not match num_embeddings and embedding_dim'\n",
      "   144|         0|            0|            0|  0.00%|            self.weight = Parameter(_weight)\n",
      "   145|         0|            0|            0|  0.00%|\n",
      "   146|         0|            0|            0|  0.00%|        self.sparse = sparse\n",
      "   147|         0|            0|            0|  0.00%|\n",
      "   148|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   149|         0|            0|            0|  0.00%|        init.normal_(self.weight)\n",
      "   150|         0|            0|            0|  0.00%|        self._fill_padding_idx_with_zero()\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    def _fill_padding_idx_with_zero(self) -> None:\n",
      "   153|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   154|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   155|         0|            0|            0|  0.00%|                self.weight[self.padding_idx].fill_(0)\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         9|  2.28882e-05|  2.54313e-06|  0.00%|    def forward(self, input: Tensor) -> Tensor:\n",
      "   158|         9|  3.21865e-05|  3.57628e-06|  0.00%|        return F.embedding(\n",
      "   159|         9|   7.7486e-05|  8.60956e-06|  0.00%|            input, self.weight, self.padding_idx, self.max_norm,\n",
      "(call)|         9|  0.000108004|  1.20004e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "   160|         9|  0.000122309|  1.35899e-05|  0.00%|            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "(call)|         9|  0.000930786|  0.000103421|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:1950 embedding\n",
      "   161|         0|            0|            0|  0.00%|\n",
      "   162|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   163|         0|            0|            0|  0.00%|        s = '{num_embeddings}, {embedding_dim}'\n",
      "   164|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   165|         0|            0|            0|  0.00%|            s += ', padding_idx={padding_idx}'\n",
      "   166|         0|            0|            0|  0.00%|        if self.max_norm is not None:\n",
      "   167|         0|            0|            0|  0.00%|            s += ', max_norm={max_norm}'\n",
      "   168|         0|            0|            0|  0.00%|        if self.norm_type != 2:\n",
      "   169|         0|            0|            0|  0.00%|            s += ', norm_type={norm_type}'\n",
      "   170|         0|            0|            0|  0.00%|        if self.scale_grad_by_freq is not False:\n",
      "   171|         0|            0|            0|  0.00%|            s += ', scale_grad_by_freq={scale_grad_by_freq}'\n",
      "   172|         0|            0|            0|  0.00%|        if self.sparse is not False:\n",
      "   173|         0|            0|            0|  0.00%|            s += ', sparse=True'\n",
      "   174|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|    @classmethod\n",
      "   177|         0|            0|            0|  0.00%|    def from_pretrained(cls, embeddings, freeze=True, padding_idx=None,\n",
      "   178|         0|            0|            0|  0.00%|                        max_norm=None, norm_type=2., scale_grad_by_freq=False,\n",
      "   179|         0|            0|            0|  0.00%|                        sparse=False):\n",
      "   180|         0|            0|            0|  0.00%|        r\"\"\"Creates Embedding instance from given 2-dimensional FloatTensor.\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|        Args:\n",
      "   183|         0|            0|            0|  0.00%|            embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
      "   184|         0|            0|            0|  0.00%|                First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\n",
      "   185|         0|            0|            0|  0.00%|            freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      "   186|         0|            0|            0|  0.00%|                Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
      "   187|         0|            0|            0|  0.00%|            padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      "   188|         0|            0|            0|  0.00%|                                         therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      "   189|         0|            0|            0|  0.00%|                                         i.e. it remains as a fixed \"pad\".\n",
      "   190|         0|            0|            0|  0.00%|            max_norm (float, optional): See module initialization documentation.\n",
      "   191|         0|            0|            0|  0.00%|            norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      "   192|         0|            0|            0|  0.00%|            scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\n",
      "   193|         0|            0|            0|  0.00%|            sparse (bool, optional): See module initialization documentation.\n",
      "   194|         0|            0|            0|  0.00%|\n",
      "   195|         0|            0|            0|  0.00%|        Examples::\n",
      "   196|         0|            0|            0|  0.00%|\n",
      "   197|         0|            0|            0|  0.00%|            >>> # FloatTensor containing pretrained weights\n",
      "   198|         0|            0|            0|  0.00%|            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      "   199|         0|            0|            0|  0.00%|            >>> embedding = nn.Embedding.from_pretrained(weight)\n",
      "   200|         0|            0|            0|  0.00%|            >>> # Get embeddings for index 1\n",
      "   201|         0|            0|            0|  0.00%|            >>> input = torch.LongTensor([1])\n",
      "   202|         0|            0|            0|  0.00%|            >>> embedding(input)\n",
      "   203|         0|            0|            0|  0.00%|            tensor([[ 4.0000,  5.1000,  6.3000]])\n",
      "   204|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   205|         0|            0|            0|  0.00%|        assert embeddings.dim() == 2, \\\n",
      "   206|         0|            0|            0|  0.00%|            'Embeddings parameter is expected to be 2-dimensional'\n",
      "   207|         0|            0|            0|  0.00%|        rows, cols = embeddings.shape\n",
      "   208|         0|            0|            0|  0.00%|        embedding = cls(\n",
      "   209|         0|            0|            0|  0.00%|            num_embeddings=rows,\n",
      "   210|         0|            0|            0|  0.00%|            embedding_dim=cols,\n",
      "   211|         0|            0|            0|  0.00%|            _weight=embeddings,\n",
      "   212|         0|            0|            0|  0.00%|            padding_idx=padding_idx,\n",
      "   213|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "   214|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "   215|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "   216|         0|            0|            0|  0.00%|            sparse=sparse)\n",
      "   217|         0|            0|            0|  0.00%|        embedding.weight.requires_grad = not freeze\n",
      "   218|         0|            0|            0|  0.00%|        return embedding\n",
      "   219|         0|            0|            0|  0.00%|\n",
      "   220|         0|            0|            0|  0.00%|\n",
      "   221|         0|            0|            0|  0.00%|class EmbeddingBag(Module):\n",
      "   222|         0|            0|            0|  0.00%|    r\"\"\"Computes sums or means of 'bags' of embeddings, without instantiating the\n",
      "   223|         0|            0|            0|  0.00%|    intermediate embeddings.\n",
      "   224|         0|            0|            0|  0.00%|\n",
      "   225|         0|            0|            0|  0.00%|    For bags of constant length, no :attr:`per_sample_weights`, no indices equal to :attr:`padding_idx`,\n",
      "   226|         0|            0|            0|  0.00%|    and with 2D inputs, this class\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|        * with ``mode=\"sum\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=1)``,\n",
      "   229|         0|            0|            0|  0.00%|        * with ``mode=\"mean\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.mean(dim=1)``,\n",
      "   230|         0|            0|            0|  0.00%|        * with ``mode=\"max\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.max(dim=1)``.\n",
      "   231|         0|            0|            0|  0.00%|\n",
      "   232|         0|            0|            0|  0.00%|    However, :class:`~torch.nn.EmbeddingBag` is much more time and memory efficient than using a chain of these\n",
      "   233|         0|            0|            0|  0.00%|    operations.\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    EmbeddingBag also supports per-sample weights as an argument to the forward\n",
      "   236|         0|            0|            0|  0.00%|    pass. This scales the output of the Embedding before performing a weighted\n",
      "   237|         0|            0|            0|  0.00%|    reduction as specified by ``mode``. If :attr:`per_sample_weights` is passed, the\n",
      "   238|         0|            0|            0|  0.00%|    only supported ``mode`` is ``\"sum\"``, which computes a weighted sum according to\n",
      "   239|         0|            0|            0|  0.00%|    :attr:`per_sample_weights`.\n",
      "   240|         0|            0|            0|  0.00%|\n",
      "   241|         0|            0|            0|  0.00%|    Args:\n",
      "   242|         0|            0|            0|  0.00%|        num_embeddings (int): size of the dictionary of embeddings\n",
      "   243|         0|            0|            0|  0.00%|        embedding_dim (int): the size of each embedding vector\n",
      "   244|         0|            0|            0|  0.00%|        max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      "   245|         0|            0|            0|  0.00%|                                    is renormalized to have norm :attr:`max_norm`.\n",
      "   246|         0|            0|            0|  0.00%|        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      "   247|         0|            0|            0|  0.00%|        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
      "   248|         0|            0|            0|  0.00%|                                                the words in the mini-batch. Default ``False``.\n",
      "   249|         0|            0|            0|  0.00%|                                                Note: this option is not supported when ``mode=\"max\"``.\n",
      "   250|         0|            0|            0|  0.00%|        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
      "   251|         0|            0|            0|  0.00%|                                 ``\"sum\"`` computes the weighted sum, taking :attr:`per_sample_weights`\n",
      "   252|         0|            0|            0|  0.00%|                                 into consideration. ``\"mean\"`` computes the average of the values\n",
      "   253|         0|            0|            0|  0.00%|                                 in the bag, ``\"max\"`` computes the max value over each bag.\n",
      "   254|         0|            0|            0|  0.00%|                                 Default: ``\"mean\"``\n",
      "   255|         0|            0|            0|  0.00%|        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See\n",
      "   256|         0|            0|            0|  0.00%|                                 Notes for more details regarding sparse gradients. Note: this option is not\n",
      "   257|         0|            0|            0|  0.00%|                                 supported when ``mode=\"max\"``.\n",
      "   258|         0|            0|            0|  0.00%|        include_last_offset (bool, optional): if ``True``, :attr:`offsets` has one additional element, where the last element\n",
      "   259|         0|            0|            0|  0.00%|                                      is equivalent to the size of `indices`. This matches the CSR format.\n",
      "   260|         0|            0|            0|  0.00%|        padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the\n",
      "   261|         0|            0|            0|  0.00%|                                     gradient; therefore, the embedding vector at :attr:`padding_idx` is not updated\n",
      "   262|         0|            0|            0|  0.00%|                                     during training, i.e. it remains as a fixed \"pad\". For a newly constructed\n",
      "   263|         0|            0|            0|  0.00%|                                     EmbeddingBag, the embedding vector at :attr:`padding_idx` will default to all\n",
      "   264|         0|            0|            0|  0.00%|                                     zeros, but can be updated to another value to be used as the padding vector.\n",
      "   265|         0|            0|            0|  0.00%|                                     Note that the embedding vector at :attr:`padding_idx` is excluded from the\n",
      "   266|         0|            0|            0|  0.00%|                                     reduction.\n",
      "   267|         0|            0|            0|  0.00%|\n",
      "   268|         0|            0|            0|  0.00%|    Attributes:\n",
      "   269|         0|            0|            0|  0.00%|        weight (Tensor): the learnable weights of the module of shape `(num_embeddings, embedding_dim)`\n",
      "   270|         0|            0|            0|  0.00%|                         initialized from :math:`\\mathcal{N}(0, 1)`.\n",
      "   271|         0|            0|            0|  0.00%|\n",
      "   272|         0|            0|            0|  0.00%|    Examples::\n",
      "   273|         0|            0|            0|  0.00%|\n",
      "   274|         0|            0|            0|  0.00%|        >>> # an EmbeddingBag module containing 10 tensors of size 3\n",
      "   275|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum')\n",
      "   276|         0|            0|            0|  0.00%|        >>> # a batch of 2 samples of 4 indices each\n",
      "   277|         0|            0|            0|  0.00%|        >>> input = torch.tensor([1,2,4,5,4,3,2,9], dtype=torch.long)\n",
      "   278|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4], dtype=torch.long)\n",
      "   279|         0|            0|            0|  0.00%|        >>> embedding_sum(input, offsets)\n",
      "   280|         0|            0|            0|  0.00%|        tensor([[-0.8861, -5.4350, -0.0523],\n",
      "   281|         0|            0|            0|  0.00%|                [ 1.1306, -2.5798, -1.0044]])\n",
      "   282|         0|            0|            0|  0.00%|\n",
      "   283|         0|            0|            0|  0.00%|        >>> # Example with padding_idx\n",
      "   284|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum', padding_idx=2)\n",
      "   285|         0|            0|            0|  0.00%|        >>> input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9], dtype=torch.long)\n",
      "   286|         0|            0|            0|  0.00%|        >>> offsets = torch.tensor([0,4], dtype=torch.long)\n",
      "   287|         0|            0|            0|  0.00%|        >>> embedding_sum(input, offsets)\n",
      "   288|         0|            0|            0|  0.00%|        tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "   289|         0|            0|            0|  0.00%|                [-0.7082,  3.2145, -2.6251]])\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|        >>> # An EmbeddingBag can be loaded from an Embedding like so\n",
      "   292|         0|            0|            0|  0.00%|        >>> embedding = nn.Embedding(10, 3, padding_idx=2)\n",
      "   293|         0|            0|            0|  0.00%|        >>> embedding_sum = nn.EmbeddingBag.from_pretrained(\n",
      "   294|         0|            0|            0|  0.00%|                embedding.weight,\n",
      "   295|         0|            0|            0|  0.00%|                padding_idx=embedding.padding_idx,\n",
      "   296|         0|            0|            0|  0.00%|                mode='sum')\n",
      "   297|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   298|         0|            0|            0|  0.00%|    __constants__ = ['num_embeddings', 'embedding_dim', 'max_norm', 'norm_type',\n",
      "   299|         0|            0|            0|  0.00%|                     'scale_grad_by_freq', 'mode', 'sparse', 'include_last_offset',\n",
      "   300|         0|            0|            0|  0.00%|                     'padding_idx']\n",
      "   301|         0|            0|            0|  0.00%|\n",
      "   302|         0|            0|            0|  0.00%|    num_embeddings: int\n",
      "   303|         0|            0|            0|  0.00%|    embedding_dim: int\n",
      "   304|         0|            0|            0|  0.00%|    max_norm: Optional[float]\n",
      "   305|         0|            0|            0|  0.00%|    norm_type: float\n",
      "   306|         0|            0|            0|  0.00%|    scale_grad_by_freq: bool\n",
      "   307|         0|            0|            0|  0.00%|    weight: Tensor\n",
      "   308|         0|            0|            0|  0.00%|    mode: str\n",
      "   309|         0|            0|            0|  0.00%|    sparse: bool\n",
      "   310|         0|            0|            0|  0.00%|    include_last_offset: bool\n",
      "   311|         0|            0|            0|  0.00%|    padding_idx: Optional[int]\n",
      "   312|         0|            0|            0|  0.00%|\n",
      "   313|         0|            0|            0|  0.00%|    def __init__(self, num_embeddings: int, embedding_dim: int,\n",
      "   314|         0|            0|            0|  0.00%|                 max_norm: Optional[float] = None, norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   315|         0|            0|            0|  0.00%|                 mode: str = 'mean', sparse: bool = False, _weight: Optional[Tensor] = None,\n",
      "   316|         0|            0|            0|  0.00%|                 include_last_offset: bool = False, padding_idx: Optional[int] = None,\n",
      "   317|         0|            0|            0|  0.00%|                 device=None, dtype=None) -> None:\n",
      "   318|         0|            0|            0|  0.00%|        factory_kwargs = {'device': device, 'dtype': dtype}\n",
      "   319|         0|            0|            0|  0.00%|        super(EmbeddingBag, self).__init__()\n",
      "   320|         0|            0|            0|  0.00%|        self.num_embeddings = num_embeddings\n",
      "   321|         0|            0|            0|  0.00%|        self.embedding_dim = embedding_dim\n",
      "   322|         0|            0|            0|  0.00%|        self.max_norm = max_norm\n",
      "   323|         0|            0|            0|  0.00%|        self.norm_type = norm_type\n",
      "   324|         0|            0|            0|  0.00%|        self.scale_grad_by_freq = scale_grad_by_freq\n",
      "   325|         0|            0|            0|  0.00%|        if padding_idx is not None:\n",
      "   326|         0|            0|            0|  0.00%|            if padding_idx > 0:\n",
      "   327|         0|            0|            0|  0.00%|                assert padding_idx < self.num_embeddings, 'padding_idx must be within num_embeddings'\n",
      "   328|         0|            0|            0|  0.00%|            elif padding_idx < 0:\n",
      "   329|         0|            0|            0|  0.00%|                assert padding_idx >= -self.num_embeddings, 'padding_idx must be within num_embeddings'\n",
      "   330|         0|            0|            0|  0.00%|                padding_idx = self.num_embeddings + padding_idx\n",
      "   331|         0|            0|            0|  0.00%|        self.padding_idx = padding_idx\n",
      "   332|         0|            0|            0|  0.00%|        if _weight is None:\n",
      "   333|         0|            0|            0|  0.00%|            self.weight = Parameter(torch.empty((num_embeddings, embedding_dim), **factory_kwargs))\n",
      "   334|         0|            0|            0|  0.00%|            self.reset_parameters()\n",
      "   335|         0|            0|            0|  0.00%|        else:\n",
      "   336|         0|            0|            0|  0.00%|            assert list(_weight.shape) == [num_embeddings, embedding_dim], \\\n",
      "   337|         0|            0|            0|  0.00%|                'Shape of weight does not match num_embeddings and embedding_dim'\n",
      "   338|         0|            0|            0|  0.00%|            self.weight = Parameter(_weight)\n",
      "   339|         0|            0|            0|  0.00%|        self.mode = mode\n",
      "   340|         0|            0|            0|  0.00%|        self.sparse = sparse\n",
      "   341|         0|            0|            0|  0.00%|        self.include_last_offset = include_last_offset\n",
      "   342|         0|            0|            0|  0.00%|\n",
      "   343|         0|            0|            0|  0.00%|    def reset_parameters(self) -> None:\n",
      "   344|         0|            0|            0|  0.00%|        init.normal_(self.weight)\n",
      "   345|         0|            0|            0|  0.00%|        self._fill_padding_idx_with_zero()\n",
      "   346|         0|            0|            0|  0.00%|\n",
      "   347|         0|            0|            0|  0.00%|    def _fill_padding_idx_with_zero(self) -> None:\n",
      "   348|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   349|         0|            0|            0|  0.00%|            with torch.no_grad():\n",
      "   350|         0|            0|            0|  0.00%|                self.weight[self.padding_idx].fill_(0)\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, offsets: Optional[Tensor] = None, per_sample_weights: Optional[Tensor] = None) -> Tensor:\n",
      "   353|         0|            0|            0|  0.00%|        \"\"\"Forward pass of EmbeddingBag.\n",
      "   354|         0|            0|            0|  0.00%|\n",
      "   355|         0|            0|            0|  0.00%|        Args:\n",
      "   356|         0|            0|            0|  0.00%|            input (Tensor): Tensor containing bags of indices into the embedding matrix.\n",
      "   357|         0|            0|            0|  0.00%|            offsets (Tensor, optional): Only used when :attr:`input` is 1D. :attr:`offsets` determines\n",
      "   358|         0|            0|            0|  0.00%|                the starting index position of each bag (sequence) in :attr:`input`.\n",
      "   359|         0|            0|            0|  0.00%|            per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
      "   360|         0|            0|            0|  0.00%|                to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`\n",
      "   361|         0|            0|            0|  0.00%|                must have exactly the same shape as input and is treated as having the same\n",
      "   362|         0|            0|            0|  0.00%|                :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.\n",
      "   363|         0|            0|            0|  0.00%|\n",
      "   364|         0|            0|            0|  0.00%|        Returns:\n",
      "   365|         0|            0|            0|  0.00%|            Tensor output shape of `(B, embedding_dim)`.\n",
      "   366|         0|            0|            0|  0.00%|\n",
      "   367|         0|            0|            0|  0.00%|        .. note::\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|            A few notes about ``input`` and ``offsets``:\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|            - :attr:`input` and :attr:`offsets` have to be of the same type, either int or long\n",
      "   372|         0|            0|            0|  0.00%|\n",
      "   373|         0|            0|            0|  0.00%|            - If :attr:`input` is 2D of shape `(B, N)`, it will be treated as ``B`` bags (sequences)\n",
      "   374|         0|            0|            0|  0.00%|              each of fixed length ``N``, and this will return ``B`` values aggregated in a way\n",
      "   375|         0|            0|            0|  0.00%|              depending on the :attr:`mode`. :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
      "   376|         0|            0|            0|  0.00%|\n",
      "   377|         0|            0|            0|  0.00%|            - If :attr:`input` is 1D of shape `(N)`, it will be treated as a concatenation of\n",
      "   378|         0|            0|            0|  0.00%|              multiple bags (sequences).  :attr:`offsets` is required to be a 1D tensor containing the\n",
      "   379|         0|            0|            0|  0.00%|              starting index positions of each bag in :attr:`input`. Therefore, for :attr:`offsets` of shape `(B)`,\n",
      "   380|         0|            0|            0|  0.00%|              :attr:`input` will be viewed as having ``B`` bags. Empty bags (i.e., having 0-length) will have\n",
      "   381|         0|            0|            0|  0.00%|              returned vectors filled by zeros.\n",
      "   382|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   383|         0|            0|            0|  0.00%|        return F.embedding_bag(input, self.weight, offsets,\n",
      "   384|         0|            0|            0|  0.00%|                               self.max_norm, self.norm_type,\n",
      "   385|         0|            0|            0|  0.00%|                               self.scale_grad_by_freq, self.mode, self.sparse,\n",
      "   386|         0|            0|            0|  0.00%|                               per_sample_weights, self.include_last_offset,\n",
      "   387|         0|            0|            0|  0.00%|                               self.padding_idx)\n",
      "   388|         0|            0|            0|  0.00%|\n",
      "   389|         0|            0|            0|  0.00%|    def extra_repr(self) -> str:\n",
      "   390|         0|            0|            0|  0.00%|        s = '{num_embeddings}, {embedding_dim}'\n",
      "   391|         0|            0|            0|  0.00%|        if self.max_norm is not None:\n",
      "   392|         0|            0|            0|  0.00%|            s += ', max_norm={max_norm}'\n",
      "   393|         0|            0|            0|  0.00%|        if self.norm_type != 2:\n",
      "   394|         0|            0|            0|  0.00%|            s += ', norm_type={norm_type}'\n",
      "   395|         0|            0|            0|  0.00%|        if self.scale_grad_by_freq is not False:\n",
      "   396|         0|            0|            0|  0.00%|            s += ', scale_grad_by_freq={scale_grad_by_freq}'\n",
      "   397|         0|            0|            0|  0.00%|        s += ', mode={mode}'\n",
      "   398|         0|            0|            0|  0.00%|        if self.padding_idx is not None:\n",
      "   399|         0|            0|            0|  0.00%|            s += ', padding_idx={padding_idx}'\n",
      "   400|         0|            0|            0|  0.00%|        return s.format(**self.__dict__)\n",
      "   401|         0|            0|            0|  0.00%|\n",
      "   402|         0|            0|            0|  0.00%|    @classmethod\n",
      "   403|         0|            0|            0|  0.00%|    def from_pretrained(cls, embeddings: Tensor, freeze: bool = True, max_norm: Optional[float] = None,\n",
      "   404|         0|            0|            0|  0.00%|                        norm_type: float = 2., scale_grad_by_freq: bool = False,\n",
      "   405|         0|            0|            0|  0.00%|                        mode: str = 'mean', sparse: bool = False, include_last_offset: bool = False,\n",
      "   406|         0|            0|            0|  0.00%|                        padding_idx: Optional[int] = None) -> 'EmbeddingBag':\n",
      "   407|         0|            0|            0|  0.00%|        r\"\"\"Creates EmbeddingBag instance from given 2-dimensional FloatTensor.\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|        Args:\n",
      "   410|         0|            0|            0|  0.00%|            embeddings (Tensor): FloatTensor containing weights for the EmbeddingBag.\n",
      "   411|         0|            0|            0|  0.00%|                First dimension is being passed to EmbeddingBag as 'num_embeddings', second as 'embedding_dim'.\n",
      "   412|         0|            0|            0|  0.00%|            freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      "   413|         0|            0|            0|  0.00%|                Equivalent to ``embeddingbag.weight.requires_grad = False``. Default: ``True``\n",
      "   414|         0|            0|            0|  0.00%|            max_norm (float, optional): See module initialization documentation. Default: ``None``\n",
      "   415|         0|            0|            0|  0.00%|            norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      "   416|         0|            0|            0|  0.00%|            scale_grad_by_freq (boolean, optional): See module initialization documentation. Default ``False``.\n",
      "   417|         0|            0|            0|  0.00%|            mode (string, optional): See module initialization documentation. Default: ``\"mean\"``\n",
      "   418|         0|            0|            0|  0.00%|            sparse (bool, optional): See module initialization documentation. Default: ``False``.\n",
      "   419|         0|            0|            0|  0.00%|            include_last_offset (bool, optional): See module initialization documentation. Default: ``False``.\n",
      "   420|         0|            0|            0|  0.00%|            padding_idx (int, optional): See module initialization documentation. Default: ``None``.\n",
      "   421|         0|            0|            0|  0.00%|\n",
      "   422|         0|            0|            0|  0.00%|        Examples::\n",
      "   423|         0|            0|            0|  0.00%|\n",
      "   424|         0|            0|            0|  0.00%|            >>> # FloatTensor containing pretrained weights\n",
      "   425|         0|            0|            0|  0.00%|            >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      "   426|         0|            0|            0|  0.00%|            >>> embeddingbag = nn.EmbeddingBag.from_pretrained(weight)\n",
      "   427|         0|            0|            0|  0.00%|            >>> # Get embeddings for index 1\n",
      "   428|         0|            0|            0|  0.00%|            >>> input = torch.LongTensor([[1, 0]])\n",
      "   429|         0|            0|            0|  0.00%|            >>> embeddingbag(input)\n",
      "   430|         0|            0|            0|  0.00%|            tensor([[ 2.5000,  3.7000,  4.6500]])\n",
      "   431|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   432|         0|            0|            0|  0.00%|        assert embeddings.dim() == 2, \\\n",
      "   433|         0|            0|            0|  0.00%|            'Embeddings parameter is expected to be 2-dimensional'\n",
      "   434|         0|            0|            0|  0.00%|        rows, cols = embeddings.shape\n",
      "   435|         0|            0|            0|  0.00%|        embeddingbag = cls(\n",
      "   436|         0|            0|            0|  0.00%|            num_embeddings=rows,\n",
      "   437|         0|            0|            0|  0.00%|            embedding_dim=cols,\n",
      "   438|         0|            0|            0|  0.00%|            _weight=embeddings,\n",
      "   439|         0|            0|            0|  0.00%|            max_norm=max_norm,\n",
      "   440|         0|            0|            0|  0.00%|            norm_type=norm_type,\n",
      "   441|         0|            0|            0|  0.00%|            scale_grad_by_freq=scale_grad_by_freq,\n",
      "   442|         0|            0|            0|  0.00%|            mode=mode,\n",
      "   443|         0|            0|            0|  0.00%|            sparse=sparse,\n",
      "   444|         0|            0|            0|  0.00%|            include_last_offset=include_last_offset,\n",
      "   445|         0|            0|            0|  0.00%|            padding_idx=padding_idx)\n",
      "   446|         0|            0|            0|  0.00%|        embeddingbag.weight.requires_grad = not freeze\n",
      "   447|         0|            0|            0|  0.00%|        return embeddingbag\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py\n",
      "File duration: 0.00017643s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|import warnings\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|from .distance import PairwiseDistance\n",
      "     4|         0|            0|            0|  0.00%|from .module import Module\n",
      "     5|         0|            0|            0|  0.00%|from .. import functional as F\n",
      "     6|         0|            0|            0|  0.00%|from .. import _reduction as _Reduction\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|from torch import Tensor\n",
      "     9|         0|            0|            0|  0.00%|from typing import Callable, Optional\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|class _Loss(Module):\n",
      "    13|         0|            0|            0|  0.00%|    reduction: str\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         1|  2.86102e-06|  2.86102e-06|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    16|         1|  1.33514e-05|  1.33514e-05|  0.00%|        super(_Loss, self).__init__()\n",
      "(call)|         1|  0.000537872|  0.000537872|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:250 __init__\n",
      "    17|         1|   3.8147e-06|   3.8147e-06|  0.00%|        if size_average is not None or reduce is not None:\n",
      "    18|         0|            0|            0|  0.00%|            self.reduction: str = _Reduction.legacy_get_string(size_average, reduce)\n",
      "    19|         0|            0|            0|  0.00%|        else:\n",
      "    20|         1|  1.00136e-05|  1.00136e-05|  0.00%|            self.reduction = reduction\n",
      "(call)|         1|  3.40939e-05|  3.40939e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|class _WeightedLoss(_Loss):\n",
      "    24|         1|   3.8147e-06|   3.8147e-06|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    25|         1|  1.38283e-05|  1.38283e-05|  0.00%|        super(_WeightedLoss, self).__init__(size_average, reduce, reduction)\n",
      "(call)|         1|  0.000602007|  0.000602007|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:15 __init__\n",
      "    26|         1|  1.33514e-05|  1.33514e-05|  0.00%|        self.register_buffer('weight', weight)\n",
      "(call)|         1|  0.000112772|  0.000112772|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:270 register_buffer\n",
      "    27|         1|  2.86102e-06|  2.86102e-06|  0.00%|        self.weight: Optional[Tensor]\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|class L1Loss(_Loss):\n",
      "    31|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the mean absolute error (MAE) between each element in\n",
      "    32|         0|            0|            0|  0.00%|    the input :math:`x` and target :math:`y`.\n",
      "    33|         0|            0|            0|  0.00%|\n",
      "    34|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "    35|         0|            0|            0|  0.00%|\n",
      "    36|         0|            0|            0|  0.00%|    .. math::\n",
      "    37|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "    38|         0|            0|            0|  0.00%|        l_n = \\left| x_n - y_n \\right|,\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "    41|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "    42|         0|            0|            0|  0.00%|\n",
      "    43|         0|            0|            0|  0.00%|    .. math::\n",
      "    44|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "    45|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "    46|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "    47|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "    48|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "    49|         0|            0|            0|  0.00%|\n",
      "    50|         0|            0|            0|  0.00%|    :math:`x` and :math:`y` are tensors of arbitrary shapes with a total\n",
      "    51|         0|            0|            0|  0.00%|    of :math:`n` elements each.\n",
      "    52|         0|            0|            0|  0.00%|\n",
      "    53|         0|            0|            0|  0.00%|    The sum operation still operates over all the elements, and divides by :math:`n`.\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|    The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.\n",
      "    56|         0|            0|            0|  0.00%|\n",
      "    57|         0|            0|            0|  0.00%|    Supports real-valued and complex-valued inputs.\n",
      "    58|         0|            0|            0|  0.00%|\n",
      "    59|         0|            0|            0|  0.00%|    Args:\n",
      "    60|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "    61|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "    62|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "    63|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "    64|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "    65|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "    66|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "    67|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "    68|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    69|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "    70|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "    71|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "    72|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "    73|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "    74|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    75|         0|            0|            0|  0.00%|\n",
      "    76|         0|            0|            0|  0.00%|    Shape:\n",
      "    77|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "    78|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "    79|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then\n",
      "    80|         0|            0|            0|  0.00%|          :math:`(*)`, same shape as the input.\n",
      "    81|         0|            0|            0|  0.00%|\n",
      "    82|         0|            0|            0|  0.00%|    Examples::\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|        >>> loss = nn.L1Loss()\n",
      "    85|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    86|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5)\n",
      "    87|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "    88|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "    89|         0|            0|            0|  0.00%|    \"\"\"\n",
      "    90|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "    93|         0|            0|            0|  0.00%|        super(L1Loss, self).__init__(size_average, reduce, reduction)\n",
      "    94|         0|            0|            0|  0.00%|\n",
      "    95|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "    96|         0|            0|            0|  0.00%|        return F.l1_loss(input, target, reduction=self.reduction)\n",
      "    97|         0|            0|            0|  0.00%|\n",
      "    98|         0|            0|            0|  0.00%|\n",
      "    99|         0|            0|            0|  0.00%|class NLLLoss(_WeightedLoss):\n",
      "   100|         0|            0|            0|  0.00%|    r\"\"\"The negative log likelihood loss. It is useful to train a classification\n",
      "   101|         0|            0|            0|  0.00%|    problem with `C` classes.\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|    If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning\n",
      "   104|         0|            0|            0|  0.00%|    weight to each of the classes. This is particularly useful when you have an\n",
      "   105|         0|            0|            0|  0.00%|    unbalanced training set.\n",
      "   106|         0|            0|            0|  0.00%|\n",
      "   107|         0|            0|            0|  0.00%|    The `input` given through a forward call is expected to contain\n",
      "   108|         0|            0|            0|  0.00%|    log-probabilities of each class. `input` has to be a Tensor of size either\n",
      "   109|         0|            0|            0|  0.00%|    :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`\n",
      "   110|         0|            0|            0|  0.00%|    with :math:`K \\geq 1` for the `K`-dimensional case. The latter is useful for\n",
      "   111|         0|            0|            0|  0.00%|    higher dimension inputs, such as computing NLL loss per-pixel for 2D images.\n",
      "   112|         0|            0|            0|  0.00%|\n",
      "   113|         0|            0|            0|  0.00%|    Obtaining log-probabilities in a neural network is easily achieved by\n",
      "   114|         0|            0|            0|  0.00%|    adding a  `LogSoftmax`  layer in the last layer of your network.\n",
      "   115|         0|            0|            0|  0.00%|    You may use `CrossEntropyLoss` instead, if you prefer not to add an extra\n",
      "   116|         0|            0|            0|  0.00%|    layer.\n",
      "   117|         0|            0|            0|  0.00%|\n",
      "   118|         0|            0|            0|  0.00%|    The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`\n",
      "   119|         0|            0|            0|  0.00%|    where `C = number of classes`; if `ignore_index` is specified, this loss also accepts\n",
      "   120|         0|            0|            0|  0.00%|    this class index (this index may not necessarily be in the class range).\n",
      "   121|         0|            0|            0|  0.00%|\n",
      "   122|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   123|         0|            0|            0|  0.00%|\n",
      "   124|         0|            0|            0|  0.00%|    .. math::\n",
      "   125|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   126|         0|            0|            0|  0.00%|        l_n = - w_{y_n} x_{n,y_n}, \\quad\n",
      "   127|         0|            0|            0|  0.00%|        w_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|    where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and\n",
      "   130|         0|            0|            0|  0.00%|    :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   131|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   132|         0|            0|            0|  0.00%|\n",
      "   133|         0|            0|            0|  0.00%|    .. math::\n",
      "   134|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   135|         0|            0|            0|  0.00%|            \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &\n",
      "   136|         0|            0|            0|  0.00%|            \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   137|         0|            0|            0|  0.00%|            \\sum_{n=1}^N l_n,  &\n",
      "   138|         0|            0|            0|  0.00%|            \\text{if reduction} = \\text{`sum'.}\n",
      "   139|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   140|         0|            0|            0|  0.00%|\n",
      "   141|         0|            0|            0|  0.00%|    Args:\n",
      "   142|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "   143|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "   144|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "   145|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   146|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   147|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   148|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   149|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   150|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "   151|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When\n",
      "   152|         0|            0|            0|  0.00%|            :attr:`size_average` is ``True``, the loss is averaged over\n",
      "   153|         0|            0|            0|  0.00%|            non-ignored targets.\n",
      "   154|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   155|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   156|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   157|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   158|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   159|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "   160|         0|            0|            0|  0.00%|            be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "   161|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   162|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in\n",
      "   163|         0|            0|            0|  0.00%|            the meantime, specifying either of those two args will override\n",
      "   164|         0|            0|            0|  0.00%|            :attr:`reduction`. Default: ``'mean'``\n",
      "   165|         0|            0|            0|  0.00%|\n",
      "   166|         0|            0|            0|  0.00%|    Shape:\n",
      "   167|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, or\n",
      "   168|         0|            0|            0|  0.00%|          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "   169|         0|            0|            0|  0.00%|          in the case of `K`-dimensional loss.\n",
      "   170|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`, where each value is\n",
      "   171|         0|            0|            0|  0.00%|          :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n",
      "   172|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of\n",
      "   173|         0|            0|            0|  0.00%|          K-dimensional loss.\n",
      "   174|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n",
      "   175|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n",
      "   176|         0|            0|            0|  0.00%|          Otherwise, scalar.\n",
      "   177|         0|            0|            0|  0.00%|\n",
      "   178|         0|            0|            0|  0.00%|    Examples::\n",
      "   179|         0|            0|            0|  0.00%|\n",
      "   180|         0|            0|            0|  0.00%|        >>> m = nn.LogSoftmax(dim=1)\n",
      "   181|         0|            0|            0|  0.00%|        >>> loss = nn.NLLLoss()\n",
      "   182|         0|            0|            0|  0.00%|        >>> # input is of size N x C = 3 x 5\n",
      "   183|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "   184|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "   185|         0|            0|            0|  0.00%|        >>> target = torch.tensor([1, 0, 4])\n",
      "   186|         0|            0|            0|  0.00%|        >>> output = loss(m(input), target)\n",
      "   187|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   188|         0|            0|            0|  0.00%|        >>>\n",
      "   189|         0|            0|            0|  0.00%|        >>>\n",
      "   190|         0|            0|            0|  0.00%|        >>> # 2D loss example (used, for example, with image inputs)\n",
      "   191|         0|            0|            0|  0.00%|        >>> N, C = 5, 4\n",
      "   192|         0|            0|            0|  0.00%|        >>> loss = nn.NLLLoss()\n",
      "   193|         0|            0|            0|  0.00%|        >>> # input is of size N x C x height x width\n",
      "   194|         0|            0|            0|  0.00%|        >>> data = torch.randn(N, 16, 10, 10)\n",
      "   195|         0|            0|            0|  0.00%|        >>> conv = nn.Conv2d(16, C, (3, 3))\n",
      "   196|         0|            0|            0|  0.00%|        >>> m = nn.LogSoftmax(dim=1)\n",
      "   197|         0|            0|            0|  0.00%|        >>> # each element in target has to have 0 <= value < C\n",
      "   198|         0|            0|            0|  0.00%|        >>> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
      "   199|         0|            0|            0|  0.00%|        >>> output = loss(m(conv(data)), target)\n",
      "   200|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   201|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   202|         0|            0|            0|  0.00%|    __constants__ = ['ignore_index', 'reduction']\n",
      "   203|         0|            0|            0|  0.00%|    ignore_index: int\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "   206|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "   207|         0|            0|            0|  0.00%|        super(NLLLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "   208|         0|            0|            0|  0.00%|        self.ignore_index = ignore_index\n",
      "   209|         0|            0|            0|  0.00%|\n",
      "   210|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   211|         0|            0|            0|  0.00%|        return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)\n",
      "   212|         0|            0|            0|  0.00%|\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|class NLLLoss2d(NLLLoss):\n",
      "   215|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "   216|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "   217|         0|            0|            0|  0.00%|        warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "   218|         0|            0|            0|  0.00%|                      \"Please use NLLLoss instead as a drop-in replacement and see \"\n",
      "   219|         0|            0|            0|  0.00%|                      \"https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\")\n",
      "   220|         0|            0|            0|  0.00%|        super(NLLLoss2d, self).__init__(weight, size_average, ignore_index, reduce, reduction)\n",
      "   221|         0|            0|            0|  0.00%|\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|class PoissonNLLLoss(_Loss):\n",
      "   224|         0|            0|            0|  0.00%|    r\"\"\"Negative log likelihood loss with Poisson distribution of target.\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    The loss can be described as:\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    .. math::\n",
      "   229|         0|            0|            0|  0.00%|        \\text{target} \\sim \\mathrm{Poisson}(\\text{input})\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|        \\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input})\n",
      "   232|         0|            0|            0|  0.00%|                                    + \\log(\\text{target!})\n",
      "   233|         0|            0|            0|  0.00%|\n",
      "   234|         0|            0|            0|  0.00%|    The last term can be omitted or approximated with Stirling formula. The\n",
      "   235|         0|            0|            0|  0.00%|    approximation is used for target values more than 1. For targets less or\n",
      "   236|         0|            0|            0|  0.00%|    equal to 1 zeros are added to the loss.\n",
      "   237|         0|            0|            0|  0.00%|\n",
      "   238|         0|            0|            0|  0.00%|    Args:\n",
      "   239|         0|            0|            0|  0.00%|        log_input (bool, optional): if ``True`` the loss is computed as\n",
      "   240|         0|            0|            0|  0.00%|            :math:`\\exp(\\text{input}) - \\text{target}*\\text{input}`, if ``False`` the loss is\n",
      "   241|         0|            0|            0|  0.00%|            :math:`\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})`.\n",
      "   242|         0|            0|            0|  0.00%|        full (bool, optional): whether to compute full loss, i. e. to add the\n",
      "   243|         0|            0|            0|  0.00%|            Stirling approximation term\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|            .. math::\n",
      "   246|         0|            0|            0|  0.00%|                \\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\n",
      "   247|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   248|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   249|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   250|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   251|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   252|         0|            0|            0|  0.00%|        eps (float, optional): Small value to avoid evaluation of :math:`\\log(0)` when\n",
      "   253|         0|            0|            0|  0.00%|            :attr:`log_input = False`. Default: 1e-8\n",
      "   254|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   255|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   256|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   257|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   258|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   259|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   260|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   261|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   262|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   263|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   264|         0|            0|            0|  0.00%|\n",
      "   265|         0|            0|            0|  0.00%|    Examples::\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|        >>> loss = nn.PoissonNLLLoss()\n",
      "   268|         0|            0|            0|  0.00%|        >>> log_input = torch.randn(5, 2, requires_grad=True)\n",
      "   269|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   270|         0|            0|            0|  0.00%|        >>> output = loss(log_input, target)\n",
      "   271|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|    Shape:\n",
      "   274|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   275|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   276|         0|            0|            0|  0.00%|        - Output: scalar by default. If :attr:`reduction` is ``'none'``, then :math:`(*)`,\n",
      "   277|         0|            0|            0|  0.00%|          the same shape as the input.\n",
      "   278|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   279|         0|            0|            0|  0.00%|    __constants__ = ['log_input', 'full', 'eps', 'reduction']\n",
      "   280|         0|            0|            0|  0.00%|    log_input: bool\n",
      "   281|         0|            0|            0|  0.00%|    full: bool\n",
      "   282|         0|            0|            0|  0.00%|    eps: float\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|    def __init__(self, log_input: bool = True, full: bool = False, size_average=None,\n",
      "   285|         0|            0|            0|  0.00%|                 eps: float = 1e-8, reduce=None, reduction: str = 'mean') -> None:\n",
      "   286|         0|            0|            0|  0.00%|        super(PoissonNLLLoss, self).__init__(size_average, reduce, reduction)\n",
      "   287|         0|            0|            0|  0.00%|        self.log_input = log_input\n",
      "   288|         0|            0|            0|  0.00%|        self.full = full\n",
      "   289|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|    def forward(self, log_input: Tensor, target: Tensor) -> Tensor:\n",
      "   292|         0|            0|            0|  0.00%|        return F.poisson_nll_loss(log_input, target, log_input=self.log_input, full=self.full,\n",
      "   293|         0|            0|            0|  0.00%|                                  eps=self.eps, reduction=self.reduction)\n",
      "   294|         0|            0|            0|  0.00%|\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|class GaussianNLLLoss(_Loss):\n",
      "   297|         0|            0|            0|  0.00%|    r\"\"\"Gaussian negative log likelihood loss.\n",
      "   298|         0|            0|            0|  0.00%|\n",
      "   299|         0|            0|            0|  0.00%|    The targets are treated as samples from Gaussian distributions with\n",
      "   300|         0|            0|            0|  0.00%|    expectations and variances predicted by the neural network. For a\n",
      "   301|         0|            0|            0|  0.00%|    ``target`` tensor modelled as having Gaussian distribution with a tensor\n",
      "   302|         0|            0|            0|  0.00%|    of expectations ``input`` and a tensor of positive variances ``var`` the loss is:\n",
      "   303|         0|            0|            0|  0.00%|\n",
      "   304|         0|            0|            0|  0.00%|    .. math::\n",
      "   305|         0|            0|            0|  0.00%|        \\text{loss} = \\frac{1}{2}\\left(\\log\\left(\\text{max}\\left(\\text{var},\n",
      "   306|         0|            0|            0|  0.00%|        \\ \\text{eps}\\right)\\right) + \\frac{\\left(\\text{input} - \\text{target}\\right)^2}\n",
      "   307|         0|            0|            0|  0.00%|        {\\text{max}\\left(\\text{var}, \\ \\text{eps}\\right)}\\right) + \\text{const.}\n",
      "   308|         0|            0|            0|  0.00%|\n",
      "   309|         0|            0|            0|  0.00%|    where :attr:`eps` is used for stability. By default, the constant term of\n",
      "   310|         0|            0|            0|  0.00%|    the loss function is omitted unless :attr:`full` is ``True``. If ``var`` is not the same\n",
      "   311|         0|            0|            0|  0.00%|    size as ``input`` (due to a homoscedastic assumption), it must either have a final dimension\n",
      "   312|         0|            0|            0|  0.00%|    of 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting.\n",
      "   313|         0|            0|            0|  0.00%|\n",
      "   314|         0|            0|            0|  0.00%|    Args:\n",
      "   315|         0|            0|            0|  0.00%|        full (bool, optional): include the constant term in the loss\n",
      "   316|         0|            0|            0|  0.00%|            calculation. Default: ``False``.\n",
      "   317|         0|            0|            0|  0.00%|        eps (float, optional): value used to clamp ``var`` (see note below), for\n",
      "   318|         0|            0|            0|  0.00%|            stability. Default: 1e-6.\n",
      "   319|         0|            0|            0|  0.00%|        reduction (string, optional): specifies the reduction to apply to the\n",
      "   320|         0|            0|            0|  0.00%|            output:``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction\n",
      "   321|         0|            0|            0|  0.00%|            will be applied, ``'mean'``: the output is the average of all batch\n",
      "   322|         0|            0|            0|  0.00%|            member losses, ``'sum'``: the output is the sum of all batch member\n",
      "   323|         0|            0|            0|  0.00%|            losses. Default: ``'mean'``.\n",
      "   324|         0|            0|            0|  0.00%|\n",
      "   325|         0|            0|            0|  0.00%|    Shape:\n",
      "   326|         0|            0|            0|  0.00%|        - Input: :math:`(N, *)` where :math:`*` means any number of additional\n",
      "   327|         0|            0|            0|  0.00%|          dimensions\n",
      "   328|         0|            0|            0|  0.00%|        - Target: :math:`(N, *)`, same shape as the input, or same shape as the input\n",
      "   329|         0|            0|            0|  0.00%|          but with one dimension equal to 1 (to allow for broadcasting)\n",
      "   330|         0|            0|            0|  0.00%|        - Var: :math:`(N, *)`, same shape as the input, or same shape as the input but\n",
      "   331|         0|            0|            0|  0.00%|          with one dimension equal to 1, or same shape as the input but with one fewer\n",
      "   332|         0|            0|            0|  0.00%|          dimension (to allow for broadcasting)\n",
      "   333|         0|            0|            0|  0.00%|        - Output: scalar if :attr:`reduction` is ``'mean'`` (default) or\n",
      "   334|         0|            0|            0|  0.00%|          ``'sum'``. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n",
      "   335|         0|            0|            0|  0.00%|          shape as the input\n",
      "   336|         0|            0|            0|  0.00%|\n",
      "   337|         0|            0|            0|  0.00%|    Examples::\n",
      "   338|         0|            0|            0|  0.00%|        >>> loss = nn.GaussianNLLLoss()\n",
      "   339|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 2, requires_grad=True)\n",
      "   340|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   341|         0|            0|            0|  0.00%|        >>> var = torch.ones(5, 2, requires_grad=True) #heteroscedastic\n",
      "   342|         0|            0|            0|  0.00%|        >>> output = loss(input, target, var)\n",
      "   343|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   344|         0|            0|            0|  0.00%|\n",
      "   345|         0|            0|            0|  0.00%|        >>> loss = nn.GaussianNLLLoss()\n",
      "   346|         0|            0|            0|  0.00%|        >>> input = torch.randn(5, 2, requires_grad=True)\n",
      "   347|         0|            0|            0|  0.00%|        >>> target = torch.randn(5, 2)\n",
      "   348|         0|            0|            0|  0.00%|        >>> var = torch.ones(5, 1, requires_grad=True) #homoscedastic\n",
      "   349|         0|            0|            0|  0.00%|        >>> output = loss(input, target, var)\n",
      "   350|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   351|         0|            0|            0|  0.00%|\n",
      "   352|         0|            0|            0|  0.00%|    Note:\n",
      "   353|         0|            0|            0|  0.00%|        The clamping of ``var`` is ignored with respect to autograd, and so the\n",
      "   354|         0|            0|            0|  0.00%|        gradients are unaffected by it.\n",
      "   355|         0|            0|            0|  0.00%|\n",
      "   356|         0|            0|            0|  0.00%|    Reference:\n",
      "   357|         0|            0|            0|  0.00%|        Nix, D. A. and Weigend, A. S., \"Estimating the mean and variance of the\n",
      "   358|         0|            0|            0|  0.00%|        target probability distribution\", Proceedings of 1994 IEEE International\n",
      "   359|         0|            0|            0|  0.00%|        Conference on Neural Networks (ICNN'94), Orlando, FL, USA, 1994, pp. 55-60\n",
      "   360|         0|            0|            0|  0.00%|        vol.1, doi: 10.1109/ICNN.1994.374138.\n",
      "   361|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   362|         0|            0|            0|  0.00%|    __constants__ = ['full', 'eps', 'reduction']\n",
      "   363|         0|            0|            0|  0.00%|    full: bool\n",
      "   364|         0|            0|            0|  0.00%|    eps: float\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    def __init__(self, *, full: bool = False, eps: float = 1e-6, reduction: str = 'mean') -> None:\n",
      "   367|         0|            0|            0|  0.00%|        super(GaussianNLLLoss, self).__init__(None, None, reduction)\n",
      "   368|         0|            0|            0|  0.00%|        self.full = full\n",
      "   369|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "   370|         0|            0|            0|  0.00%|\n",
      "   371|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor, var: Tensor) -> Tensor:\n",
      "   372|         0|            0|            0|  0.00%|        return F.gaussian_nll_loss(input, target, var, full=self.full, eps=self.eps, reduction=self.reduction)\n",
      "   373|         0|            0|            0|  0.00%|\n",
      "   374|         0|            0|            0|  0.00%|\n",
      "   375|         0|            0|            0|  0.00%|class KLDivLoss(_Loss):\n",
      "   376|         0|            0|            0|  0.00%|    r\"\"\"The Kullback-Leibler divergence loss measure\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|    `Kullback-Leibler divergence`_ is a useful distance measure for continuous\n",
      "   379|         0|            0|            0|  0.00%|    distributions and is often useful when performing direct regression over\n",
      "   380|         0|            0|            0|  0.00%|    the space of (discretely sampled) continuous output distributions.\n",
      "   381|         0|            0|            0|  0.00%|\n",
      "   382|         0|            0|            0|  0.00%|    As with :class:`~torch.nn.NLLLoss`, the `input` given is expected to contain\n",
      "   383|         0|            0|            0|  0.00%|    *log-probabilities* and is not restricted to a 2D Tensor.\n",
      "   384|         0|            0|            0|  0.00%|    The targets are interpreted as *probabilities* by default, but could be considered\n",
      "   385|         0|            0|            0|  0.00%|    as *log-probabilities* with :attr:`log_target` set to ``True``.\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|    This criterion expects a `target` `Tensor` of the same size as the\n",
      "   388|         0|            0|            0|  0.00%|    `input` `Tensor`.\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   391|         0|            0|            0|  0.00%|\n",
      "   392|         0|            0|            0|  0.00%|    .. math::\n",
      "   393|         0|            0|            0|  0.00%|        l(x,y) = L = \\{ l_1,\\dots,l_N \\}, \\quad\n",
      "   394|         0|            0|            0|  0.00%|        l_n = y_n \\cdot \\left( \\log y_n - x_n \\right)\n",
      "   395|         0|            0|            0|  0.00%|\n",
      "   396|         0|            0|            0|  0.00%|    where the index :math:`N` spans all dimensions of ``input`` and :math:`L` has the same\n",
      "   397|         0|            0|            0|  0.00%|    shape as ``input``. If :attr:`reduction` is not ``'none'`` (default ``'mean'``), then:\n",
      "   398|         0|            0|            0|  0.00%|\n",
      "   399|         0|            0|            0|  0.00%|    .. math::\n",
      "   400|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   401|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';} \\\\\n",
      "   402|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   403|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   404|         0|            0|            0|  0.00%|\n",
      "   405|         0|            0|            0|  0.00%|    In default :attr:`reduction` mode ``'mean'``, the losses are averaged for each minibatch over observations\n",
      "   406|         0|            0|            0|  0.00%|    **as well as** over dimensions. ``'batchmean'`` mode gives the correct KL divergence where losses\n",
      "   407|         0|            0|            0|  0.00%|    are averaged over batch dimension only. ``'mean'`` mode's behavior will be changed to the same as\n",
      "   408|         0|            0|            0|  0.00%|    ``'batchmean'`` in the next major release.\n",
      "   409|         0|            0|            0|  0.00%|\n",
      "   410|         0|            0|            0|  0.00%|    .. _`kullback-leibler divergence`: https://en.wikipedia.org/wiki/Kullback-Leibler_divergence\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|    Args:\n",
      "   413|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   414|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   415|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   416|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   417|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   418|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   419|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   420|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   421|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   422|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   423|         0|            0|            0|  0.00%|            ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.\n",
      "   424|         0|            0|            0|  0.00%|            ``'none'``: no reduction will be applied.\n",
      "   425|         0|            0|            0|  0.00%|            ``'batchmean'``: the sum of the output will be divided by batchsize.\n",
      "   426|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed.\n",
      "   427|         0|            0|            0|  0.00%|            ``'mean'``: the output will be divided by the number of elements in the output.\n",
      "   428|         0|            0|            0|  0.00%|            Default: ``'mean'``\n",
      "   429|         0|            0|            0|  0.00%|        log_target (bool, optional): Specifies whether `target` is passed in the log space.\n",
      "   430|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "   431|         0|            0|            0|  0.00%|\n",
      "   432|         0|            0|            0|  0.00%|    .. note::\n",
      "   433|         0|            0|            0|  0.00%|        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,\n",
      "   434|         0|            0|            0|  0.00%|        and in the meantime, specifying either of those two args will override :attr:`reduction`.\n",
      "   435|         0|            0|            0|  0.00%|\n",
      "   436|         0|            0|            0|  0.00%|    .. note::\n",
      "   437|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use\n",
      "   438|         0|            0|            0|  0.00%|        :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.\n",
      "   439|         0|            0|            0|  0.00%|        In the next major release, ``'mean'`` will be changed to be the same as ``'batchmean'``.\n",
      "   440|         0|            0|            0|  0.00%|\n",
      "   441|         0|            0|            0|  0.00%|    Shape:\n",
      "   442|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   443|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   444|         0|            0|            0|  0.00%|        - Output: scalar by default. If :attr:``reduction`` is ``'none'``, then :math:`(*)`,\n",
      "   445|         0|            0|            0|  0.00%|          same shape as the input.\n",
      "   446|         0|            0|            0|  0.00%|\n",
      "   447|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   448|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False) -> None:\n",
      "   451|         0|            0|            0|  0.00%|        super(KLDivLoss, self).__init__(size_average, reduce, reduction)\n",
      "   452|         0|            0|            0|  0.00%|        self.log_target = log_target\n",
      "   453|         0|            0|            0|  0.00%|\n",
      "   454|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   455|         0|            0|            0|  0.00%|        return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)\n",
      "   456|         0|            0|            0|  0.00%|\n",
      "   457|         0|            0|            0|  0.00%|\n",
      "   458|         0|            0|            0|  0.00%|class MSELoss(_Loss):\n",
      "   459|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the mean squared error (squared L2 norm) between\n",
      "   460|         0|            0|            0|  0.00%|    each element in the input :math:`x` and target :math:`y`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   461|         0|            0|            0|  0.00%|\n",
      "   462|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   463|         0|            0|            0|  0.00%|\n",
      "   464|         0|            0|            0|  0.00%|    .. math::\n",
      "   465|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   466|         0|            0|            0|  0.00%|        l_n = \\left( x_n - y_n \\right)^2,\n",
      "   467|         0|            0|            0|  0.00%|\n",
      "   468|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   469|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "   470|         0|            0|            0|  0.00%|\n",
      "   471|         0|            0|            0|  0.00%|    .. math::\n",
      "   472|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   473|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   474|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   475|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   476|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   477|         0|            0|            0|  0.00%|\n",
      "   478|         0|            0|            0|  0.00%|    :math:`x` and :math:`y` are tensors of arbitrary shapes with a total\n",
      "   479|         0|            0|            0|  0.00%|    of :math:`n` elements each.\n",
      "   480|         0|            0|            0|  0.00%|\n",
      "   481|         0|            0|            0|  0.00%|    The mean operation still operates over all the elements, and divides by :math:`n`.\n",
      "   482|         0|            0|            0|  0.00%|\n",
      "   483|         0|            0|            0|  0.00%|    The division by :math:`n` can be avoided if one sets ``reduction = 'sum'``.\n",
      "   484|         0|            0|            0|  0.00%|\n",
      "   485|         0|            0|            0|  0.00%|    Args:\n",
      "   486|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   487|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   488|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   489|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   490|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   491|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   492|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   493|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   494|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   495|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   496|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   497|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   498|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   499|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   500|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   501|         0|            0|            0|  0.00%|\n",
      "   502|         0|            0|            0|  0.00%|    Shape:\n",
      "   503|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   504|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   505|         0|            0|            0|  0.00%|\n",
      "   506|         0|            0|            0|  0.00%|    Examples::\n",
      "   507|         0|            0|            0|  0.00%|\n",
      "   508|         0|            0|            0|  0.00%|        >>> loss = nn.MSELoss()\n",
      "   509|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "   510|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5)\n",
      "   511|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "   512|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   513|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   514|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   515|         0|            0|            0|  0.00%|\n",
      "   516|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   517|         0|            0|            0|  0.00%|        super(MSELoss, self).__init__(size_average, reduce, reduction)\n",
      "   518|         0|            0|            0|  0.00%|\n",
      "   519|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   520|         0|            0|            0|  0.00%|        return F.mse_loss(input, target, reduction=self.reduction)\n",
      "   521|         0|            0|            0|  0.00%|\n",
      "   522|         0|            0|            0|  0.00%|\n",
      "   523|         0|            0|            0|  0.00%|class BCELoss(_WeightedLoss):\n",
      "   524|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the Binary Cross Entropy between the target and\n",
      "   525|         0|            0|            0|  0.00%|    the input probabilities:\n",
      "   526|         0|            0|            0|  0.00%|\n",
      "   527|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   528|         0|            0|            0|  0.00%|\n",
      "   529|         0|            0|            0|  0.00%|    .. math::\n",
      "   530|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   531|         0|            0|            0|  0.00%|        l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
      "   532|         0|            0|            0|  0.00%|\n",
      "   533|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   534|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   535|         0|            0|            0|  0.00%|\n",
      "   536|         0|            0|            0|  0.00%|    .. math::\n",
      "   537|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   538|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   539|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   540|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   541|         0|            0|            0|  0.00%|\n",
      "   542|         0|            0|            0|  0.00%|    This is used for measuring the error of a reconstruction in for example\n",
      "   543|         0|            0|            0|  0.00%|    an auto-encoder. Note that the targets :math:`y` should be numbers\n",
      "   544|         0|            0|            0|  0.00%|    between 0 and 1.\n",
      "   545|         0|            0|            0|  0.00%|\n",
      "   546|         0|            0|            0|  0.00%|    Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be\n",
      "   547|         0|            0|            0|  0.00%|    mathematically undefined in the above loss equation. PyTorch chooses to set\n",
      "   548|         0|            0|            0|  0.00%|    :math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\n",
      "   549|         0|            0|            0|  0.00%|    However, an infinite term in the loss equation is not desirable for several reasons.\n",
      "   550|         0|            0|            0|  0.00%|\n",
      "   551|         0|            0|            0|  0.00%|    For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\n",
      "   552|         0|            0|            0|  0.00%|    multiplying 0 with infinity. Secondly, if we have an infinite loss value, then\n",
      "   553|         0|            0|            0|  0.00%|    we would also have an infinite term in our gradient, since\n",
      "   554|         0|            0|            0|  0.00%|    :math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\n",
      "   555|         0|            0|            0|  0.00%|    This would make BCELoss's backward method nonlinear with respect to :math:`x_n`,\n",
      "   556|         0|            0|            0|  0.00%|    and using it for things like linear regression would not be straight-forward.\n",
      "   557|         0|            0|            0|  0.00%|\n",
      "   558|         0|            0|            0|  0.00%|    Our solution is that BCELoss clamps its log function outputs to be greater than\n",
      "   559|         0|            0|            0|  0.00%|    or equal to -100. This way, we can always have a finite loss value and a linear\n",
      "   560|         0|            0|            0|  0.00%|    backward method.\n",
      "   561|         0|            0|            0|  0.00%|\n",
      "   562|         0|            0|            0|  0.00%|\n",
      "   563|         0|            0|            0|  0.00%|    Args:\n",
      "   564|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to the loss\n",
      "   565|         0|            0|            0|  0.00%|            of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
      "   566|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   567|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   568|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   569|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   570|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   571|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   572|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   573|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   574|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   575|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   576|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   577|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   578|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   579|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   580|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   581|         0|            0|            0|  0.00%|\n",
      "   582|         0|            0|            0|  0.00%|    Shape:\n",
      "   583|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   584|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   585|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "   586|         0|            0|            0|  0.00%|          shape as input.\n",
      "   587|         0|            0|            0|  0.00%|\n",
      "   588|         0|            0|            0|  0.00%|    Examples::\n",
      "   589|         0|            0|            0|  0.00%|\n",
      "   590|         0|            0|            0|  0.00%|        >>> m = nn.Sigmoid()\n",
      "   591|         0|            0|            0|  0.00%|        >>> loss = nn.BCELoss()\n",
      "   592|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, requires_grad=True)\n",
      "   593|         0|            0|            0|  0.00%|        >>> target = torch.empty(3).random_(2)\n",
      "   594|         0|            0|            0|  0.00%|        >>> output = loss(m(input), target)\n",
      "   595|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   596|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   597|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   598|         0|            0|            0|  0.00%|\n",
      "   599|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   600|         0|            0|            0|  0.00%|        super(BCELoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "   601|         0|            0|            0|  0.00%|\n",
      "   602|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   603|         0|            0|            0|  0.00%|        return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "   604|         0|            0|            0|  0.00%|\n",
      "   605|         0|            0|            0|  0.00%|\n",
      "   606|         0|            0|            0|  0.00%|class BCEWithLogitsLoss(_Loss):\n",
      "   607|         0|            0|            0|  0.00%|    r\"\"\"This loss combines a `Sigmoid` layer and the `BCELoss` in one single\n",
      "   608|         0|            0|            0|  0.00%|    class. This version is more numerically stable than using a plain `Sigmoid`\n",
      "   609|         0|            0|            0|  0.00%|    followed by a `BCELoss` as, by combining the operations into one layer,\n",
      "   610|         0|            0|            0|  0.00%|    we take advantage of the log-sum-exp trick for numerical stability.\n",
      "   611|         0|            0|            0|  0.00%|\n",
      "   612|         0|            0|            0|  0.00%|    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
      "   613|         0|            0|            0|  0.00%|\n",
      "   614|         0|            0|            0|  0.00%|    .. math::\n",
      "   615|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "   616|         0|            0|            0|  0.00%|        l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\n",
      "   617|         0|            0|            0|  0.00%|        + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\n",
      "   618|         0|            0|            0|  0.00%|\n",
      "   619|         0|            0|            0|  0.00%|    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
      "   620|         0|            0|            0|  0.00%|    (default ``'mean'``), then\n",
      "   621|         0|            0|            0|  0.00%|\n",
      "   622|         0|            0|            0|  0.00%|    .. math::\n",
      "   623|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   624|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   625|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   626|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   627|         0|            0|            0|  0.00%|\n",
      "   628|         0|            0|            0|  0.00%|    This is used for measuring the error of a reconstruction in for example\n",
      "   629|         0|            0|            0|  0.00%|    an auto-encoder. Note that the targets `t[i]` should be numbers\n",
      "   630|         0|            0|            0|  0.00%|    between 0 and 1.\n",
      "   631|         0|            0|            0|  0.00%|\n",
      "   632|         0|            0|            0|  0.00%|    It's possible to trade off recall and precision by adding weights to positive examples.\n",
      "   633|         0|            0|            0|  0.00%|    In the case of multi-label classification the loss can be described as:\n",
      "   634|         0|            0|            0|  0.00%|\n",
      "   635|         0|            0|            0|  0.00%|    .. math::\n",
      "   636|         0|            0|            0|  0.00%|        \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\n",
      "   637|         0|            0|            0|  0.00%|        l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\n",
      "   638|         0|            0|            0|  0.00%|        + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\n",
      "   639|         0|            0|            0|  0.00%|\n",
      "   640|         0|            0|            0|  0.00%|    where :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,\n",
      "   641|         0|            0|            0|  0.00%|    :math:`c = 1` for single-label binary classification),\n",
      "   642|         0|            0|            0|  0.00%|    :math:`n` is the number of the sample in the batch and\n",
      "   643|         0|            0|            0|  0.00%|    :math:`p_c` is the weight of the positive answer for the class :math:`c`.\n",
      "   644|         0|            0|            0|  0.00%|\n",
      "   645|         0|            0|            0|  0.00%|    :math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.\n",
      "   646|         0|            0|            0|  0.00%|\n",
      "   647|         0|            0|            0|  0.00%|    For example, if a dataset contains 100 positive and 300 negative examples of a single class,\n",
      "   648|         0|            0|            0|  0.00%|    then `pos_weight` for the class should be equal to :math:`\\frac{300}{100}=3`.\n",
      "   649|         0|            0|            0|  0.00%|    The loss would act as if the dataset contains :math:`3\\times 100=300` positive examples.\n",
      "   650|         0|            0|            0|  0.00%|\n",
      "   651|         0|            0|            0|  0.00%|    Examples::\n",
      "   652|         0|            0|            0|  0.00%|\n",
      "   653|         0|            0|            0|  0.00%|        >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n",
      "   654|         0|            0|            0|  0.00%|        >>> output = torch.full([10, 64], 1.5)  # A prediction (logit)\n",
      "   655|         0|            0|            0|  0.00%|        >>> pos_weight = torch.ones([64])  # All weights are equal to 1\n",
      "   656|         0|            0|            0|  0.00%|        >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
      "   657|         0|            0|            0|  0.00%|        >>> criterion(output, target)  # -log(sigmoid(1.5))\n",
      "   658|         0|            0|            0|  0.00%|        tensor(0.2014)\n",
      "   659|         0|            0|            0|  0.00%|\n",
      "   660|         0|            0|            0|  0.00%|    Args:\n",
      "   661|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to the loss\n",
      "   662|         0|            0|            0|  0.00%|            of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
      "   663|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   664|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   665|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   666|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   667|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   668|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   669|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   670|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   671|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   672|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   673|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   674|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   675|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   676|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   677|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   678|         0|            0|            0|  0.00%|        pos_weight (Tensor, optional): a weight of positive examples.\n",
      "   679|         0|            0|            0|  0.00%|                Must be a vector with length equal to the number of classes.\n",
      "   680|         0|            0|            0|  0.00%|\n",
      "   681|         0|            0|            0|  0.00%|    Shape:\n",
      "   682|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   683|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   684|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "   685|         0|            0|            0|  0.00%|          shape as input.\n",
      "   686|         0|            0|            0|  0.00%|\n",
      "   687|         0|            0|            0|  0.00%|     Examples::\n",
      "   688|         0|            0|            0|  0.00%|\n",
      "   689|         0|            0|            0|  0.00%|        >>> loss = nn.BCEWithLogitsLoss()\n",
      "   690|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, requires_grad=True)\n",
      "   691|         0|            0|            0|  0.00%|        >>> target = torch.empty(3).random_(2)\n",
      "   692|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "   693|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "   694|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   695|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean',\n",
      "   696|         0|            0|            0|  0.00%|                 pos_weight: Optional[Tensor] = None) -> None:\n",
      "   697|         0|            0|            0|  0.00%|        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
      "   698|         0|            0|            0|  0.00%|        self.register_buffer('weight', weight)\n",
      "   699|         0|            0|            0|  0.00%|        self.register_buffer('pos_weight', pos_weight)\n",
      "   700|         0|            0|            0|  0.00%|        self.weight: Optional[Tensor]\n",
      "   701|         0|            0|            0|  0.00%|        self.pos_weight: Optional[Tensor]\n",
      "   702|         0|            0|            0|  0.00%|\n",
      "   703|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   704|         0|            0|            0|  0.00%|        return F.binary_cross_entropy_with_logits(input, target,\n",
      "   705|         0|            0|            0|  0.00%|                                                  self.weight,\n",
      "   706|         0|            0|            0|  0.00%|                                                  pos_weight=self.pos_weight,\n",
      "   707|         0|            0|            0|  0.00%|                                                  reduction=self.reduction)\n",
      "   708|         0|            0|            0|  0.00%|\n",
      "   709|         0|            0|            0|  0.00%|\n",
      "   710|         0|            0|            0|  0.00%|class HingeEmbeddingLoss(_Loss):\n",
      "   711|         0|            0|            0|  0.00%|    r\"\"\"Measures the loss given an input tensor :math:`x` and a labels tensor :math:`y`\n",
      "   712|         0|            0|            0|  0.00%|    (containing 1 or -1).\n",
      "   713|         0|            0|            0|  0.00%|    This is usually used for measuring whether two inputs are similar or\n",
      "   714|         0|            0|            0|  0.00%|    dissimilar, e.g. using the L1 pairwise distance as :math:`x`, and is typically\n",
      "   715|         0|            0|            0|  0.00%|    used for learning nonlinear embeddings or semi-supervised learning.\n",
      "   716|         0|            0|            0|  0.00%|\n",
      "   717|         0|            0|            0|  0.00%|    The loss function for :math:`n`-th sample in the mini-batch is\n",
      "   718|         0|            0|            0|  0.00%|\n",
      "   719|         0|            0|            0|  0.00%|    .. math::\n",
      "   720|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   721|         0|            0|            0|  0.00%|            x_n, & \\text{if}\\; y_n = 1,\\\\\n",
      "   722|         0|            0|            0|  0.00%|            \\max \\{0, \\Delta - x_n\\}, & \\text{if}\\; y_n = -1,\n",
      "   723|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   724|         0|            0|            0|  0.00%|\n",
      "   725|         0|            0|            0|  0.00%|    and the total loss functions is\n",
      "   726|         0|            0|            0|  0.00%|\n",
      "   727|         0|            0|            0|  0.00%|    .. math::\n",
      "   728|         0|            0|            0|  0.00%|        \\ell(x, y) = \\begin{cases}\n",
      "   729|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   730|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n",
      "   731|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   732|         0|            0|            0|  0.00%|\n",
      "   733|         0|            0|            0|  0.00%|    where :math:`L = \\{l_1,\\dots,l_N\\}^\\top`.\n",
      "   734|         0|            0|            0|  0.00%|\n",
      "   735|         0|            0|            0|  0.00%|    Args:\n",
      "   736|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of `1`.\n",
      "   737|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   738|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   739|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   740|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   741|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   742|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   743|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   744|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   745|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   746|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   747|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   748|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   749|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   750|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   751|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   752|         0|            0|            0|  0.00%|\n",
      "   753|         0|            0|            0|  0.00%|    Shape:\n",
      "   754|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where :math:`*` means, any number of dimensions. The sum operation\n",
      "   755|         0|            0|            0|  0.00%|          operates over all the elements.\n",
      "   756|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input\n",
      "   757|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the input\n",
      "   758|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   759|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "   760|         0|            0|            0|  0.00%|    margin: float\n",
      "   761|         0|            0|            0|  0.00%|\n",
      "   762|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   763|         0|            0|            0|  0.00%|        super(HingeEmbeddingLoss, self).__init__(size_average, reduce, reduction)\n",
      "   764|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "   765|         0|            0|            0|  0.00%|\n",
      "   766|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   767|         0|            0|            0|  0.00%|        return F.hinge_embedding_loss(input, target, margin=self.margin, reduction=self.reduction)\n",
      "   768|         0|            0|            0|  0.00%|\n",
      "   769|         0|            0|            0|  0.00%|\n",
      "   770|         0|            0|            0|  0.00%|class MultiLabelMarginLoss(_Loss):\n",
      "   771|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-class multi-classification\n",
      "   772|         0|            0|            0|  0.00%|    hinge loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`)\n",
      "   773|         0|            0|            0|  0.00%|    and output :math:`y` (which is a 2D `Tensor` of target class indices).\n",
      "   774|         0|            0|            0|  0.00%|    For each sample in the mini-batch:\n",
      "   775|         0|            0|            0|  0.00%|\n",
      "   776|         0|            0|            0|  0.00%|    .. math::\n",
      "   777|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)}\n",
      "   778|         0|            0|            0|  0.00%|\n",
      "   779|         0|            0|            0|  0.00%|    where :math:`x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`, \\\n",
      "   780|         0|            0|            0|  0.00%|    :math:`y \\in \\left\\{0, \\; \\cdots , \\; \\text{y.size}(0) - 1\\right\\}`, \\\n",
      "   781|         0|            0|            0|  0.00%|    :math:`0 \\leq y[j] \\leq \\text{x.size}(0)-1`, \\\n",
      "   782|         0|            0|            0|  0.00%|    and :math:`i \\neq y[j]` for all :math:`i` and :math:`j`.\n",
      "   783|         0|            0|            0|  0.00%|\n",
      "   784|         0|            0|            0|  0.00%|    :math:`y` and :math:`x` must have the same size.\n",
      "   785|         0|            0|            0|  0.00%|\n",
      "   786|         0|            0|            0|  0.00%|    The criterion only considers a contiguous block of non-negative targets that\n",
      "   787|         0|            0|            0|  0.00%|    starts at the front.\n",
      "   788|         0|            0|            0|  0.00%|\n",
      "   789|         0|            0|            0|  0.00%|    This allows for different samples to have variable amounts of target classes.\n",
      "   790|         0|            0|            0|  0.00%|\n",
      "   791|         0|            0|            0|  0.00%|    Args:\n",
      "   792|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   793|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   794|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   795|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   796|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   797|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   798|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   799|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   800|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   801|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   802|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   803|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   804|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   805|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   806|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   807|         0|            0|            0|  0.00%|\n",
      "   808|         0|            0|            0|  0.00%|    Shape:\n",
      "   809|         0|            0|            0|  0.00%|        - Input: :math:`(C)` or :math:`(N, C)` where `N` is the batch size and `C`\n",
      "   810|         0|            0|            0|  0.00%|          is the number of classes.\n",
      "   811|         0|            0|            0|  0.00%|        - Target: :math:`(C)` or :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.\n",
      "   812|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "   813|         0|            0|            0|  0.00%|\n",
      "   814|         0|            0|            0|  0.00%|    Examples::\n",
      "   815|         0|            0|            0|  0.00%|\n",
      "   816|         0|            0|            0|  0.00%|        >>> loss = nn.MultiLabelMarginLoss()\n",
      "   817|         0|            0|            0|  0.00%|        >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n",
      "   818|         0|            0|            0|  0.00%|        >>> # for target y, only consider labels 3 and 0, not after label -1\n",
      "   819|         0|            0|            0|  0.00%|        >>> y = torch.LongTensor([[3, 0, -1, 1]])\n",
      "   820|         0|            0|            0|  0.00%|        >>> loss(x, y)\n",
      "   821|         0|            0|            0|  0.00%|        >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n",
      "   822|         0|            0|            0|  0.00%|        tensor(0.8500)\n",
      "   823|         0|            0|            0|  0.00%|\n",
      "   824|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   825|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   826|         0|            0|            0|  0.00%|\n",
      "   827|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "   828|         0|            0|            0|  0.00%|        super(MultiLabelMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "   829|         0|            0|            0|  0.00%|\n",
      "   830|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   831|         0|            0|            0|  0.00%|        return F.multilabel_margin_loss(input, target, reduction=self.reduction)\n",
      "   832|         0|            0|            0|  0.00%|\n",
      "   833|         0|            0|            0|  0.00%|\n",
      "   834|         0|            0|            0|  0.00%|class SmoothL1Loss(_Loss):\n",
      "   835|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that uses a squared term if the absolute\n",
      "   836|         0|            0|            0|  0.00%|    element-wise error falls below beta and an L1 term otherwise.\n",
      "   837|         0|            0|            0|  0.00%|    It is less sensitive to outliers than :class:`torch.nn.MSELoss` and in some cases\n",
      "   838|         0|            0|            0|  0.00%|    prevents exploding gradients (e.g. see the paper `Fast R-CNN`_ by Ross Girshick).\n",
      "   839|         0|            0|            0|  0.00%|\n",
      "   840|         0|            0|            0|  0.00%|    For a batch of size :math:`N`, the unreduced loss can be described as:\n",
      "   841|         0|            0|            0|  0.00%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   842|         0|            0|            0|  0.00%|    .. math::\n",
      "   843|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n",
      "   844|         0|            0|            0|  0.00%|\n",
      "   845|         0|            0|            0|  0.00%|    with\n",
      "   846|         0|            0|            0|  0.00%|\n",
      "   847|         0|            0|            0|  0.00%|    .. math::\n",
      "   848|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   849|         0|            0|            0|  0.00%|        0.5 (x_n - y_n)^2 / beta, & \\text{if } |x_n - y_n| < beta \\\\\n",
      "   850|         0|            0|            0|  0.00%|        |x_n - y_n| - 0.5 * beta, & \\text{otherwise }\n",
      "   851|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   852|         0|            0|            0|  0.00%|\n",
      "   853|         0|            0|            0|  0.00%|    If `reduction` is not `none`, then:\n",
      "   854|         0|            0|            0|  0.00%|\n",
      "   855|         0|            0|            0|  0.00%|    .. math::\n",
      "   856|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   857|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   858|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   859|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   860|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   861|         0|            0|            0|  0.00%|\n",
      "   862|         0|            0|            0|  0.00%|    .. note::\n",
      "   863|         0|            0|            0|  0.00%|        Smooth L1 loss can be seen as exactly :class:`L1Loss`, but with the :math:`|x - y| < beta`\n",
      "   864|         0|            0|            0|  0.00%|        portion replaced with a quadratic function such that its slope is 1 at :math:`|x - y| = beta`.\n",
      "   865|         0|            0|            0|  0.00%|        The quadratic segment smooths the L1 loss near :math:`|x - y| = 0`.\n",
      "   866|         0|            0|            0|  0.00%|\n",
      "   867|         0|            0|            0|  0.00%|    .. note::\n",
      "   868|         0|            0|            0|  0.00%|        Smooth L1 loss is closely related to :class:`HuberLoss`, being\n",
      "   869|         0|            0|            0|  0.00%|        equivalent to :math:`huber(x, y) / beta` (note that Smooth L1's beta hyper-parameter is\n",
      "   870|         0|            0|            0|  0.00%|        also known as delta for Huber). This leads to the following differences:\n",
      "   871|         0|            0|            0|  0.00%|\n",
      "   872|         0|            0|            0|  0.00%|        * As beta -> 0, Smooth L1 loss converges to :class:`L1Loss`, while :class:`HuberLoss`\n",
      "   873|         0|            0|            0|  0.00%|          converges to a constant 0 loss.\n",
      "   874|         0|            0|            0|  0.00%|        * As beta -> :math:`+\\infty`, Smooth L1 loss converges to a constant 0 loss, while\n",
      "   875|         0|            0|            0|  0.00%|          :class:`HuberLoss` converges to :class:`MSELoss`.\n",
      "   876|         0|            0|            0|  0.00%|        * For Smooth L1 loss, as beta varies, the L1 segment of the loss has a constant slope of 1.\n",
      "   877|         0|            0|            0|  0.00%|          For :class:`HuberLoss`, the slope of the L1 segment is beta.\n",
      "   878|         0|            0|            0|  0.00%|\n",
      "   879|         0|            0|            0|  0.00%|    .. _`Fast R-CNN`: https://arxiv.org/abs/1504.08083\n",
      "   880|         0|            0|            0|  0.00%|\n",
      "   881|         0|            0|            0|  0.00%|    Args:\n",
      "   882|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   883|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   884|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   885|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   886|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   887|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   888|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   889|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   890|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   891|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   892|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   893|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   894|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   895|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   896|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   897|         0|            0|            0|  0.00%|        beta (float, optional): Specifies the threshold at which to change between L1 and L2 loss.\n",
      "   898|         0|            0|            0|  0.00%|            The value must be non-negative. Default: 1.0\n",
      "   899|         0|            0|            0|  0.00%|\n",
      "   900|         0|            0|            0|  0.00%|    Shape:\n",
      "   901|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "   902|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   903|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.\n",
      "   904|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   905|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "   906|         0|            0|            0|  0.00%|\n",
      "   907|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0) -> None:\n",
      "   908|         0|            0|            0|  0.00%|        super(SmoothL1Loss, self).__init__(size_average, reduce, reduction)\n",
      "   909|         0|            0|            0|  0.00%|        self.beta = beta\n",
      "   910|         0|            0|            0|  0.00%|\n",
      "   911|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   912|         0|            0|            0|  0.00%|        return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "   913|         0|            0|            0|  0.00%|\n",
      "   914|         0|            0|            0|  0.00%|\n",
      "   915|         0|            0|            0|  0.00%|class HuberLoss(_Loss):\n",
      "   916|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that uses a squared term if the absolute\n",
      "   917|         0|            0|            0|  0.00%|    element-wise error falls below delta and a delta-scaled L1 term otherwise.\n",
      "   918|         0|            0|            0|  0.00%|    This loss combines advantages of both :class:`L1Loss` and :class:`MSELoss`; the\n",
      "   919|         0|            0|            0|  0.00%|    delta-scaled L1 region makes the loss less sensitive to outliers than :class:`MSELoss`,\n",
      "   920|         0|            0|            0|  0.00%|    while the L2 region provides smoothness over :class:`L1Loss` near 0. See\n",
      "   921|         0|            0|            0|  0.00%|    `Huber loss <https://en.wikipedia.org/wiki/Huber_loss>`_ for more information.\n",
      "   922|         0|            0|            0|  0.00%|\n",
      "   923|         0|            0|            0|  0.00%|    For a batch of size :math:`N`, the unreduced loss can be described as:\n",
      "   924|         0|            0|            0|  0.00%|\n",
      "   925|         0|            0|            0|  0.00%|    .. math::\n",
      "   926|         0|            0|            0|  0.00%|        \\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\n",
      "   927|         0|            0|            0|  0.00%|\n",
      "   928|         0|            0|            0|  0.00%|    with\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|    .. math::\n",
      "   931|         0|            0|            0|  0.00%|        l_n = \\begin{cases}\n",
      "   932|         0|            0|            0|  0.00%|        0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| < delta \\\\\n",
      "   933|         0|            0|            0|  0.00%|        delta * (|x_n - y_n| - 0.5 * delta), & \\text{otherwise }\n",
      "   934|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   935|         0|            0|            0|  0.00%|\n",
      "   936|         0|            0|            0|  0.00%|    If `reduction` is not `none`, then:\n",
      "   937|         0|            0|            0|  0.00%|\n",
      "   938|         0|            0|            0|  0.00%|    .. math::\n",
      "   939|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "   940|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "   941|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "   942|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "   943|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "   944|         0|            0|            0|  0.00%|\n",
      "   945|         0|            0|            0|  0.00%|    .. note::\n",
      "   946|         0|            0|            0|  0.00%|        When delta is set to 1, this loss is equivalent to :class:`SmoothL1Loss`.\n",
      "   947|         0|            0|            0|  0.00%|        In general, this loss differs from :class:`SmoothL1Loss` by a factor of delta (AKA beta\n",
      "   948|         0|            0|            0|  0.00%|        in Smooth L1).\n",
      "   949|         0|            0|            0|  0.00%|        See :class:`SmoothL1Loss` for additional discussion on the differences in behavior\n",
      "   950|         0|            0|            0|  0.00%|        between the two losses.\n",
      "   951|         0|            0|            0|  0.00%|\n",
      "   952|         0|            0|            0|  0.00%|    Args:\n",
      "   953|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   954|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   955|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   956|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n",
      "   957|         0|            0|            0|  0.00%|        delta (float, optional): Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\n",
      "   958|         0|            0|            0|  0.00%|            The value must be positive.  Default: 1.0\n",
      "   959|         0|            0|            0|  0.00%|\n",
      "   960|         0|            0|            0|  0.00%|    Shape:\n",
      "   961|         0|            0|            0|  0.00%|        - Input: :math:`(*)` where :math:`*` means any number of dimensions.\n",
      "   962|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "   963|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same shape as the input.\n",
      "   964|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   965|         0|            0|            0|  0.00%|    __constants__ = ['reduction', 'delta']\n",
      "   966|         0|            0|            0|  0.00%|\n",
      "   967|         0|            0|            0|  0.00%|    def __init__(self, reduction: str = 'mean', delta: float = 1.0) -> None:\n",
      "   968|         0|            0|            0|  0.00%|        super().__init__(reduction=reduction)\n",
      "   969|         0|            0|            0|  0.00%|        self.delta = delta\n",
      "   970|         0|            0|            0|  0.00%|\n",
      "   971|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "   972|         0|            0|            0|  0.00%|        return F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)\n",
      "   973|         0|            0|            0|  0.00%|\n",
      "   974|         0|            0|            0|  0.00%|\n",
      "   975|         0|            0|            0|  0.00%|class SoftMarginLoss(_Loss):\n",
      "   976|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a two-class classification\n",
      "   977|         0|            0|            0|  0.00%|    logistic loss between input tensor :math:`x` and target tensor :math:`y`\n",
      "   978|         0|            0|            0|  0.00%|    (containing 1 or -1).\n",
      "   979|         0|            0|            0|  0.00%|\n",
      "   980|         0|            0|            0|  0.00%|    .. math::\n",
      "   981|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()}\n",
      "   982|         0|            0|            0|  0.00%|\n",
      "   983|         0|            0|            0|  0.00%|    Args:\n",
      "   984|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "   985|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "   986|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "   987|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "   988|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "   989|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "   990|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "   991|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "   992|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "   993|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "   994|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "   995|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "   996|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "   997|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "   998|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "   999|         0|            0|            0|  0.00%|\n",
      "  1000|         0|            0|            0|  0.00%|    Shape:\n",
      "  1001|         0|            0|            0|  0.00%|        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      "  1002|         0|            0|            0|  0.00%|        - Target: :math:`(*)`, same shape as the input.\n",
      "  1003|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(*)`, same\n",
      "  1004|         0|            0|            0|  0.00%|          shape as input.\n",
      "  1005|         0|            0|            0|  0.00%|\n",
      "  1006|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1007|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "  1008|         0|            0|            0|  0.00%|\n",
      "  1009|         0|            0|            0|  0.00%|    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1010|         0|            0|            0|  0.00%|        super(SoftMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1011|         0|            0|            0|  0.00%|\n",
      "  1012|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1013|         0|            0|            0|  0.00%|        return F.soft_margin_loss(input, target, reduction=self.reduction)\n",
      "  1014|         0|            0|            0|  0.00%|\n",
      "  1015|         0|            0|            0|  0.00%|\n",
      "  1016|         0|            0|            0|  0.00%|class CrossEntropyLoss(_WeightedLoss):\n",
      "  1017|         0|            0|            0|  0.00%|    r\"\"\"This criterion computes the cross entropy loss between input and target.\n",
      "  1018|         0|            0|            0|  0.00%|\n",
      "  1019|         0|            0|            0|  0.00%|    It is useful when training a classification problem with `C` classes.\n",
      "  1020|         0|            0|            0|  0.00%|    If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
      "  1021|         0|            0|            0|  0.00%|    assigning weight to each of the classes.\n",
      "  1022|         0|            0|            0|  0.00%|    This is particularly useful when you have an unbalanced training set.\n",
      "  1023|         0|            0|            0|  0.00%|\n",
      "  1024|         0|            0|            0|  0.00%|    The `input` is expected to contain raw, unnormalized scores for each class.\n",
      "  1025|         0|            0|            0|  0.00%|    `input` has to be a Tensor of size either :math:`(minibatch, C)` or\n",
      "  1026|         0|            0|            0|  0.00%|    :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` for the\n",
      "  1027|         0|            0|            0|  0.00%|    `K`-dimensional case. The latter is useful for higher dimension inputs, such\n",
      "  1028|         0|            0|            0|  0.00%|    as computing cross entropy loss per-pixel for 2D images.\n",
      "  1029|         0|            0|            0|  0.00%|\n",
      "  1030|         0|            0|            0|  0.00%|    The `target` that this criterion expects should contain either:\n",
      "  1031|         0|            0|            0|  0.00%|\n",
      "  1032|         0|            0|            0|  0.00%|    - Class indices in the range :math:`[0, C-1]` where :math:`C` is the number of classes; if\n",
      "  1033|         0|            0|            0|  0.00%|      `ignore_index` is specified, this loss also accepts this class index (this index\n",
      "  1034|         0|            0|            0|  0.00%|      may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`\n",
      "  1035|         0|            0|            0|  0.00%|      set to ``'none'``) loss for this case can be described as:\n",
      "  1036|         0|            0|            0|  0.00%|\n",
      "  1037|         0|            0|            0|  0.00%|      .. math::\n",
      "  1038|         0|            0|            0|  0.00%|          \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1039|         0|            0|            0|  0.00%|          l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
      "  1040|         0|            0|            0|  0.00%|          \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
      "  1041|         0|            0|            0|  0.00%|\n",
      "  1042|         0|            0|            0|  0.00%|      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  1043|         0|            0|            0|  0.00%|      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  1044|         0|            0|            0|  0.00%|      :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  1045|         0|            0|            0|  0.00%|      :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "  1046|         0|            0|            0|  0.00%|\n",
      "  1047|         0|            0|            0|  0.00%|      .. math::\n",
      "  1048|         0|            0|            0|  0.00%|          \\ell(x, y) = \\begin{cases}\n",
      "  1049|         0|            0|            0|  0.00%|              \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n",
      "  1050|         0|            0|            0|  0.00%|               \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1051|         0|            0|            0|  0.00%|                \\sum_{n=1}^N l_n,  &\n",
      "  1052|         0|            0|            0|  0.00%|                \\text{if reduction} = \\text{`sum'.}\n",
      "  1053|         0|            0|            0|  0.00%|            \\end{cases}\n",
      "  1054|         0|            0|            0|  0.00%|\n",
      "  1055|         0|            0|            0|  0.00%|      Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and\n",
      "  1056|         0|            0|            0|  0.00%|      :class:`~torch.nn.NLLLoss`.\n",
      "  1057|         0|            0|            0|  0.00%|\n",
      "  1058|         0|            0|            0|  0.00%|    - Probabilities for each class; useful when labels beyond a single class per minibatch item\n",
      "  1059|         0|            0|            0|  0.00%|      are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\n",
      "  1060|         0|            0|            0|  0.00%|      :attr:`reduction` set to ``'none'``) loss for this case can be described as:\n",
      "  1061|         0|            0|            0|  0.00%|\n",
      "  1062|         0|            0|            0|  0.00%|      .. math::\n",
      "  1063|         0|            0|            0|  0.00%|          \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1064|         0|            0|            0|  0.00%|          l_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\exp(\\sum_{i=1}^C x_{n,i})} y_{n,c}\n",
      "  1065|         0|            0|            0|  0.00%|\n",
      "  1066|         0|            0|            0|  0.00%|      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,\n",
      "  1067|         0|            0|            0|  0.00%|      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as\n",
      "  1068|         0|            0|            0|  0.00%|      :math:`d_1, ..., d_k` for the `K`-dimensional case. If\n",
      "  1069|         0|            0|            0|  0.00%|      :attr:`reduction` is not ``'none'`` (default ``'mean'``), then\n",
      "  1070|         0|            0|            0|  0.00%|\n",
      "  1071|         0|            0|            0|  0.00%|      .. math::\n",
      "  1072|         0|            0|            0|  0.00%|          \\ell(x, y) = \\begin{cases}\n",
      "  1073|         0|            0|            0|  0.00%|              \\frac{\\sum_{n=1}^N l_n}{N}, &\n",
      "  1074|         0|            0|            0|  0.00%|               \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1075|         0|            0|            0|  0.00%|                \\sum_{n=1}^N l_n,  &\n",
      "  1076|         0|            0|            0|  0.00%|                \\text{if reduction} = \\text{`sum'.}\n",
      "  1077|         0|            0|            0|  0.00%|            \\end{cases}\n",
      "  1078|         0|            0|            0|  0.00%|\n",
      "  1079|         0|            0|            0|  0.00%|    .. note::\n",
      "  1080|         0|            0|            0|  0.00%|        The performance of this criterion is generally better when `target` contains class\n",
      "  1081|         0|            0|            0|  0.00%|        indices, as this allows for optimized computation. Consider providing `target` as\n",
      "  1082|         0|            0|            0|  0.00%|        class probabilities only when a single class label per minibatch item is too restrictive.\n",
      "  1083|         0|            0|            0|  0.00%|\n",
      "  1084|         0|            0|            0|  0.00%|    Args:\n",
      "  1085|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each class.\n",
      "  1086|         0|            0|            0|  0.00%|            If given, has to be a Tensor of size `C`\n",
      "  1087|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1088|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1089|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1090|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1091|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1092|         0|            0|            0|  0.00%|        ignore_index (int, optional): Specifies a target value that is ignored\n",
      "  1093|         0|            0|            0|  0.00%|            and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "  1094|         0|            0|            0|  0.00%|            ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "  1095|         0|            0|            0|  0.00%|            :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "  1096|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1097|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1098|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1099|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1100|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1101|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
      "  1102|         0|            0|            0|  0.00%|            be applied, ``'mean'``: the weighted mean of the output is taken,\n",
      "  1103|         0|            0|            0|  0.00%|            ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1104|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in\n",
      "  1105|         0|            0|            0|  0.00%|            the meantime, specifying either of those two args will override\n",
      "  1106|         0|            0|            0|  0.00%|            :attr:`reduction`. Default: ``'mean'``\n",
      "  1107|         0|            0|            0|  0.00%|        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "  1108|         0|            0|            0|  0.00%|            of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "  1109|         0|            0|            0|  0.00%|            become a mixture of the original ground truth and a uniform distribution as described in\n",
      "  1110|         0|            0|            0|  0.00%|            `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "  1111|         0|            0|            0|  0.00%|\n",
      "  1112|         0|            0|            0|  0.00%|    Shape:\n",
      "  1113|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` where `C = number of classes`, or\n",
      "  1114|         0|            0|            0|  0.00%|          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "  1115|         0|            0|            0|  0.00%|          in the case of `K`-dimensional loss.\n",
      "  1116|         0|            0|            0|  0.00%|        - Target: If containing class indices, shape :math:`(N)` where each value is\n",
      "  1117|         0|            0|            0|  0.00%|          :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "  1118|         0|            0|            0|  0.00%|          :math:`K \\geq 1` in the case of K-dimensional loss. If containing class probabilities,\n",
      "  1119|         0|            0|            0|  0.00%|          same shape as the input.\n",
      "  1120|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, shape :math:`(N)` or\n",
      "  1121|         0|            0|            0|  0.00%|          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of K-dimensional loss.\n",
      "  1122|         0|            0|            0|  0.00%|          Otherwise, scalar.\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    Examples::\n",
      "  1125|         0|            0|            0|  0.00%|\n",
      "  1126|         0|            0|            0|  0.00%|        >>> # Example of target with class indices\n",
      "  1127|         0|            0|            0|  0.00%|        >>> loss = nn.CrossEntropyLoss()\n",
      "  1128|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  1129|         0|            0|            0|  0.00%|        >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
      "  1130|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "  1131|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1132|         0|            0|            0|  0.00%|        >>>\n",
      "  1133|         0|            0|            0|  0.00%|        >>> # Example of target with class probabilities\n",
      "  1134|         0|            0|            0|  0.00%|        >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "  1135|         0|            0|            0|  0.00%|        >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "  1136|         0|            0|            0|  0.00%|        >>> output = loss(input, target)\n",
      "  1137|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1138|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1139|         0|            0|            0|  0.00%|    __constants__ = ['ignore_index', 'reduction', 'label_smoothing']\n",
      "  1140|         0|            0|            0|  0.00%|    ignore_index: int\n",
      "  1141|         0|            0|            0|  0.00%|    label_smoothing: float\n",
      "  1142|         0|            0|            0|  0.00%|\n",
      "  1143|         1|  5.00679e-06|  5.00679e-06|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
      "  1144|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n",
      "  1145|         1|  1.93119e-05|  1.93119e-05|  0.00%|        super(CrossEntropyLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "(call)|         1|  0.000748634|  0.000748634|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:24 __init__\n",
      "  1146|         1|  1.19209e-05|  1.19209e-05|  0.00%|        self.ignore_index = ignore_index\n",
      "(call)|         1|  3.60012e-05|  3.60012e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "  1147|         1|   1.3113e-05|   1.3113e-05|  0.00%|        self.label_smoothing = label_smoothing\n",
      "(call)|         1|  3.19481e-05|  3.19481e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1180 __setattr__\n",
      "  1148|         0|            0|            0|  0.00%|\n",
      "  1149|         1|  4.05312e-06|  4.05312e-06|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1150|         1|  1.40667e-05|  1.40667e-05|  0.00%|        return F.cross_entropy(input, target, weight=self.weight,\n",
      "(call)|         1|  1.97887e-05|  1.97887e-05|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1164 __getattr__\n",
      "  1151|         1|  3.09944e-06|  3.09944e-06|  0.00%|                               ignore_index=self.ignore_index, reduction=self.reduction,\n",
      "  1152|         1|  4.19617e-05|  4.19617e-05|  0.00%|                               label_smoothing=self.label_smoothing)\n",
      "(call)|         1|    0.0042901|    0.0042901|  0.05%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/functional.py:2767 cross_entropy\n",
      "  1153|         0|            0|            0|  0.00%|\n",
      "  1154|         0|            0|            0|  0.00%|\n",
      "  1155|         0|            0|            0|  0.00%|class MultiLabelSoftMarginLoss(_WeightedLoss):\n",
      "  1156|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-label one-versus-all\n",
      "  1157|         0|            0|            0|  0.00%|    loss based on max-entropy, between input :math:`x` and target :math:`y` of size\n",
      "  1158|         0|            0|            0|  0.00%|    :math:`(N, C)`.\n",
      "  1159|         0|            0|            0|  0.00%|    For each sample in the minibatch:\n",
      "  1160|         0|            0|            0|  0.00%|\n",
      "  1161|         0|            0|            0|  0.00%|    .. math::\n",
      "  1162|         0|            0|            0|  0.00%|        loss(x, y) = - \\frac{1}{C} * \\sum_i y[i] * \\log((1 + \\exp(-x[i]))^{-1})\n",
      "  1163|         0|            0|            0|  0.00%|                         + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right)\n",
      "  1164|         0|            0|            0|  0.00%|\n",
      "  1165|         0|            0|            0|  0.00%|    where :math:`i \\in \\left\\{0, \\; \\cdots , \\; \\text{x.nElement}() - 1\\right\\}`,\n",
      "  1166|         0|            0|            0|  0.00%|    :math:`y[i] \\in \\left\\{0, \\; 1\\right\\}`.\n",
      "  1167|         0|            0|            0|  0.00%|\n",
      "  1168|         0|            0|            0|  0.00%|    Args:\n",
      "  1169|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  1170|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "  1171|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "  1172|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1173|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1174|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1175|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1176|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1177|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1178|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1179|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1180|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1181|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1182|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1183|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1184|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1185|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1186|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1187|         0|            0|            0|  0.00%|\n",
      "  1188|         0|            0|            0|  0.00%|    Shape:\n",
      "  1189|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` where `N` is the batch size and `C` is the number of classes.\n",
      "  1190|         0|            0|            0|  0.00%|        - Target: :math:`(N, C)`, label targets padded by -1 ensuring same shape as the input.\n",
      "  1191|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "  1192|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1193|         0|            0|            0|  0.00%|    __constants__ = ['reduction']\n",
      "  1194|         0|            0|            0|  0.00%|\n",
      "  1195|         0|            0|            0|  0.00%|    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1196|         0|            0|            0|  0.00%|        super(MultiLabelSoftMarginLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "  1197|         0|            0|            0|  0.00%|\n",
      "  1198|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1199|         0|            0|            0|  0.00%|        return F.multilabel_soft_margin_loss(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1200|         0|            0|            0|  0.00%|\n",
      "  1201|         0|            0|            0|  0.00%|\n",
      "  1202|         0|            0|            0|  0.00%|class CosineEmbeddingLoss(_Loss):\n",
      "  1203|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the loss given input tensors\n",
      "  1204|         0|            0|            0|  0.00%|    :math:`x_1`, :math:`x_2` and a `Tensor` label :math:`y` with values 1 or -1.\n",
      "  1205|         0|            0|            0|  0.00%|    This is used for measuring whether two inputs are similar or dissimilar,\n",
      "  1206|         0|            0|            0|  0.00%|    using the cosine distance, and is typically used for learning nonlinear\n",
      "  1207|         0|            0|            0|  0.00%|    embeddings or semi-supervised learning.\n",
      "  1208|         0|            0|            0|  0.00%|\n",
      "  1209|         0|            0|            0|  0.00%|    The loss function for each sample is:\n",
      "  1210|         0|            0|            0|  0.00%|\n",
      "  1211|         0|            0|            0|  0.00%|    .. math::\n",
      "  1212|         0|            0|            0|  0.00%|        \\text{loss}(x, y) =\n",
      "  1213|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "  1214|         0|            0|            0|  0.00%|        1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\\n",
      "  1215|         0|            0|            0|  0.00%|        \\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1\n",
      "  1216|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1217|         0|            0|            0|  0.00%|\n",
      "  1218|         0|            0|            0|  0.00%|    Args:\n",
      "  1219|         0|            0|            0|  0.00%|        margin (float, optional): Should be a number from :math:`-1` to :math:`1`,\n",
      "  1220|         0|            0|            0|  0.00%|            :math:`0` to :math:`0.5` is suggested. If :attr:`margin` is missing, the\n",
      "  1221|         0|            0|            0|  0.00%|            default value is :math:`0`.\n",
      "  1222|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1223|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1224|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1225|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1226|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1227|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1228|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1229|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1230|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1231|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1232|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1233|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1234|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1235|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1236|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1237|         0|            0|            0|  0.00%|\n",
      "  1238|         0|            0|            0|  0.00%|    Shape:\n",
      "  1239|         0|            0|            0|  0.00%|        - Input1: :math:`(N, D)` or :math:`(D)`, where `N` is the batch size and `D` is the embedding dimension.\n",
      "  1240|         0|            0|            0|  0.00%|        - Input2: :math:`(N, D)` or :math:`(D)`, same shape as Input1.\n",
      "  1241|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`.\n",
      "  1242|         0|            0|            0|  0.00%|        - Output: If :attr:`reduction` is ``'none'``, then :math:`(N)`, otherwise scalar.\n",
      "  1243|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1244|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "  1245|         0|            0|            0|  0.00%|    margin: float\n",
      "  1246|         0|            0|            0|  0.00%|\n",
      "  1247|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 0., size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1248|         0|            0|            0|  0.00%|        super(CosineEmbeddingLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1249|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1250|         0|            0|            0|  0.00%|\n",
      "  1251|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n",
      "  1252|         0|            0|            0|  0.00%|        return F.cosine_embedding_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)\n",
      "  1253|         0|            0|            0|  0.00%|\n",
      "  1254|         0|            0|            0|  0.00%|\n",
      "  1255|         0|            0|            0|  0.00%|class MarginRankingLoss(_Loss):\n",
      "  1256|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the loss given\n",
      "  1257|         0|            0|            0|  0.00%|    inputs :math:`x1`, :math:`x2`, two 1D mini-batch `Tensors`,\n",
      "  1258|         0|            0|            0|  0.00%|    and a label 1D mini-batch tensor :math:`y` (containing 1 or -1).\n",
      "  1259|         0|            0|            0|  0.00%|\n",
      "  1260|         0|            0|            0|  0.00%|    If :math:`y = 1` then it assumed the first input should be ranked higher\n",
      "  1261|         0|            0|            0|  0.00%|    (have a larger value) than the second input, and vice-versa for :math:`y = -1`.\n",
      "  1262|         0|            0|            0|  0.00%|\n",
      "  1263|         0|            0|            0|  0.00%|    The loss function for each pair of samples in the mini-batch is:\n",
      "  1264|         0|            0|            0|  0.00%|\n",
      "  1265|         0|            0|            0|  0.00%|    .. math::\n",
      "  1266|         0|            0|            0|  0.00%|        \\text{loss}(x1, x2, y) = \\max(0, -y * (x1 - x2) + \\text{margin})\n",
      "  1267|         0|            0|            0|  0.00%|\n",
      "  1268|         0|            0|            0|  0.00%|    Args:\n",
      "  1269|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of :math:`0`.\n",
      "  1270|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1271|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1272|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1273|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1274|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1275|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1276|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1277|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1278|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1279|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1280|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1281|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1282|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1283|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1284|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1285|         0|            0|            0|  0.00%|\n",
      "  1286|         0|            0|            0|  0.00%|    Shape:\n",
      "  1287|         0|            0|            0|  0.00%|        - Input1: :math:`(N)` where `N` is the batch size.\n",
      "  1288|         0|            0|            0|  0.00%|        - Input2: :math:`(N)`, same shape as the Input1.\n",
      "  1289|         0|            0|            0|  0.00%|        - Target: :math:`(N)`, same shape as the inputs.\n",
      "  1290|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N)`.\n",
      "  1291|         0|            0|            0|  0.00%|\n",
      "  1292|         0|            0|            0|  0.00%|    Examples::\n",
      "  1293|         0|            0|            0|  0.00%|\n",
      "  1294|         0|            0|            0|  0.00%|        >>> loss = nn.MarginRankingLoss()\n",
      "  1295|         0|            0|            0|  0.00%|        >>> input1 = torch.randn(3, requires_grad=True)\n",
      "  1296|         0|            0|            0|  0.00%|        >>> input2 = torch.randn(3, requires_grad=True)\n",
      "  1297|         0|            0|            0|  0.00%|        >>> target = torch.randn(3).sign()\n",
      "  1298|         0|            0|            0|  0.00%|        >>> output = loss(input1, input2, target)\n",
      "  1299|         0|            0|            0|  0.00%|        >>> output.backward()\n",
      "  1300|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1301|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'reduction']\n",
      "  1302|         0|            0|            0|  0.00%|    margin: float\n",
      "  1303|         0|            0|            0|  0.00%|\n",
      "  1304|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 0., size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
      "  1305|         0|            0|            0|  0.00%|        super(MarginRankingLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1306|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1307|         0|            0|            0|  0.00%|\n",
      "  1308|         0|            0|            0|  0.00%|    def forward(self, input1: Tensor, input2: Tensor, target: Tensor) -> Tensor:\n",
      "  1309|         0|            0|            0|  0.00%|        return F.margin_ranking_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)\n",
      "  1310|         0|            0|            0|  0.00%|\n",
      "  1311|         0|            0|            0|  0.00%|\n",
      "  1312|         0|            0|            0|  0.00%|class MultiMarginLoss(_WeightedLoss):\n",
      "  1313|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that optimizes a multi-class classification hinge\n",
      "  1314|         0|            0|            0|  0.00%|    loss (margin-based loss) between input :math:`x` (a 2D mini-batch `Tensor`) and\n",
      "  1315|         0|            0|            0|  0.00%|    output :math:`y` (which is a 1D tensor of target class indices,\n",
      "  1316|         0|            0|            0|  0.00%|    :math:`0 \\leq y \\leq \\text{x.size}(1)-1`):\n",
      "  1317|         0|            0|            0|  0.00%|\n",
      "  1318|         0|            0|            0|  0.00%|    For each mini-batch sample, the loss in terms of the 1D input :math:`x` and scalar\n",
      "  1319|         0|            0|            0|  0.00%|    output :math:`y` is:\n",
      "  1320|         0|            0|            0|  0.00%|\n",
      "  1321|         0|            0|            0|  0.00%|    .. math::\n",
      "  1322|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\n",
      "  1323|         0|            0|            0|  0.00%|\n",
      "  1324|         0|            0|            0|  0.00%|    where :math:`x \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}`\n",
      "  1325|         0|            0|            0|  0.00%|    and :math:`i \\neq y`.\n",
      "  1326|         0|            0|            0|  0.00%|\n",
      "  1327|         0|            0|            0|  0.00%|    Optionally, you can give non-equal weighting on the classes by passing\n",
      "  1328|         0|            0|            0|  0.00%|    a 1D :attr:`weight` tensor into the constructor.\n",
      "  1329|         0|            0|            0|  0.00%|\n",
      "  1330|         0|            0|            0|  0.00%|    The loss function then becomes:\n",
      "  1331|         0|            0|            0|  0.00%|\n",
      "  1332|         0|            0|            0|  0.00%|    .. math::\n",
      "  1333|         0|            0|            0|  0.00%|        \\text{loss}(x, y) = \\frac{\\sum_i \\max(0, w[y] * (\\text{margin} - x[y] + x[i]))^p}{\\text{x.size}(0)}\n",
      "  1334|         0|            0|            0|  0.00%|\n",
      "  1335|         0|            0|            0|  0.00%|    Args:\n",
      "  1336|         0|            0|            0|  0.00%|        p (int, optional): Has a default value of :math:`1`. :math:`1` and :math:`2`\n",
      "  1337|         0|            0|            0|  0.00%|            are the only supported values.\n",
      "  1338|         0|            0|            0|  0.00%|        margin (float, optional): Has a default value of :math:`1`.\n",
      "  1339|         0|            0|            0|  0.00%|        weight (Tensor, optional): a manual rescaling weight given to each\n",
      "  1340|         0|            0|            0|  0.00%|            class. If given, it has to be a Tensor of size `C`. Otherwise, it is\n",
      "  1341|         0|            0|            0|  0.00%|            treated as if having all ones.\n",
      "  1342|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1343|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1344|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1345|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1346|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1347|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1348|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1349|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1350|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1351|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1352|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1353|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1354|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1355|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1356|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1357|         0|            0|            0|  0.00%|\n",
      "  1358|         0|            0|            0|  0.00%|    Shape:\n",
      "  1359|         0|            0|            0|  0.00%|        - Input: :math:`(N, C)` or :math:`(C)`, where :math:`N` is the batch size and :math:`C` is the number of classes.\n",
      "  1360|         0|            0|            0|  0.00%|        - Target: :math:`(N)` or :math:`()`, where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`.\n",
      "  1361|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then same shape as the target.\n",
      "  1362|         0|            0|            0|  0.00%|\n",
      "  1363|         0|            0|            0|  0.00%|    Examples::\n",
      "  1364|         0|            0|            0|  0.00%|\n",
      "  1365|         0|            0|            0|  0.00%|        >>> loss = nn.MultiMarginLoss()\n",
      "  1366|         0|            0|            0|  0.00%|        >>> x = torch.tensor([[0.1, 0.2, 0.4, 0.8]])\n",
      "  1367|         0|            0|            0|  0.00%|        >>> y = torch.tensor([3])\n",
      "  1368|         0|            0|            0|  0.00%|        >>> loss(x, y)\n",
      "  1369|         0|            0|            0|  0.00%|        >>> # 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n",
      "  1370|         0|            0|            0|  0.00%|        tensor(0.3250)\n",
      "  1371|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1372|         0|            0|            0|  0.00%|    __constants__ = ['p', 'margin', 'reduction']\n",
      "  1373|         0|            0|            0|  0.00%|    margin: float\n",
      "  1374|         0|            0|            0|  0.00%|    p: int\n",
      "  1375|         0|            0|            0|  0.00%|\n",
      "  1376|         0|            0|            0|  0.00%|    def __init__(self, p: int = 1, margin: float = 1., weight: Optional[Tensor] = None, size_average=None,\n",
      "  1377|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean') -> None:\n",
      "  1378|         0|            0|            0|  0.00%|        super(MultiMarginLoss, self).__init__(weight, size_average, reduce, reduction)\n",
      "  1379|         0|            0|            0|  0.00%|        if p != 1 and p != 2:\n",
      "  1380|         0|            0|            0|  0.00%|            raise ValueError(\"only p == 1 and p == 2 supported\")\n",
      "  1381|         0|            0|            0|  0.00%|        assert weight is None or weight.dim() == 1\n",
      "  1382|         0|            0|            0|  0.00%|        self.p = p\n",
      "  1383|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1384|         0|            0|            0|  0.00%|\n",
      "  1385|         0|            0|            0|  0.00%|    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
      "  1386|         0|            0|            0|  0.00%|        return F.multi_margin_loss(input, target, p=self.p, margin=self.margin,\n",
      "  1387|         0|            0|            0|  0.00%|                                   weight=self.weight, reduction=self.reduction)\n",
      "  1388|         0|            0|            0|  0.00%|\n",
      "  1389|         0|            0|            0|  0.00%|\n",
      "  1390|         0|            0|            0|  0.00%|class TripletMarginLoss(_Loss):\n",
      "  1391|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the triplet loss given an input\n",
      "  1392|         0|            0|            0|  0.00%|    tensors :math:`x1`, :math:`x2`, :math:`x3` and a margin with a value greater than :math:`0`.\n",
      "  1393|         0|            0|            0|  0.00%|    This is used for measuring a relative similarity between samples. A triplet\n",
      "  1394|         0|            0|            0|  0.00%|    is composed by `a`, `p` and `n` (i.e., `anchor`, `positive examples` and `negative\n",
      "  1395|         0|            0|            0|  0.00%|    examples` respectively). The shapes of all input tensors should be\n",
      "  1396|         0|            0|            0|  0.00%|    :math:`(N, D)`.\n",
      "  1397|         0|            0|            0|  0.00%|\n",
      "  1398|         0|            0|            0|  0.00%|    The distance swap is described in detail in the paper `Learning shallow\n",
      "  1399|         0|            0|            0|  0.00%|    convolutional feature descriptors with triplet losses`_ by\n",
      "  1400|         0|            0|            0|  0.00%|    V. Balntas, E. Riba et al.\n",
      "  1401|         0|            0|            0|  0.00%|\n",
      "  1402|         0|            0|            0|  0.00%|    The loss function for each sample in the mini-batch is:\n",
      "  1403|         0|            0|            0|  0.00%|\n",
      "  1404|         0|            0|            0|  0.00%|    .. math::\n",
      "  1405|         0|            0|            0|  0.00%|        L(a, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n",
      "  1406|         0|            0|            0|  0.00%|\n",
      "  1407|         0|            0|            0|  0.00%|\n",
      "  1408|         0|            0|            0|  0.00%|    where\n",
      "  1409|         0|            0|            0|  0.00%|\n",
      "  1410|         0|            0|            0|  0.00%|    .. math::\n",
      "  1411|         0|            0|            0|  0.00%|        d(x_i, y_i) = \\left\\lVert {\\bf x}_i - {\\bf y}_i \\right\\rVert_p\n",
      "  1412|         0|            0|            0|  0.00%|\n",
      "  1413|         0|            0|            0|  0.00%|    See also :class:`~torch.nn.TripletMarginWithDistanceLoss`, which computes the\n",
      "  1414|         0|            0|            0|  0.00%|    triplet margin loss for input tensors using a custom distance function.\n",
      "  1415|         0|            0|            0|  0.00%|\n",
      "  1416|         0|            0|            0|  0.00%|    Args:\n",
      "  1417|         0|            0|            0|  0.00%|        margin (float, optional): Default: :math:`1`.\n",
      "  1418|         0|            0|            0|  0.00%|        p (int, optional): The norm degree for pairwise distance. Default: :math:`2`.\n",
      "  1419|         0|            0|            0|  0.00%|        swap (bool, optional): The distance swap is described in detail in the paper\n",
      "  1420|         0|            0|            0|  0.00%|            `Learning shallow convolutional feature descriptors with triplet losses` by\n",
      "  1421|         0|            0|            0|  0.00%|            V. Balntas, E. Riba et al. Default: ``False``.\n",
      "  1422|         0|            0|            0|  0.00%|        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "  1423|         0|            0|            0|  0.00%|            the losses are averaged over each loss element in the batch. Note that for\n",
      "  1424|         0|            0|            0|  0.00%|            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
      "  1425|         0|            0|            0|  0.00%|            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "  1426|         0|            0|            0|  0.00%|            when :attr:`reduce` is ``False``. Default: ``True``\n",
      "  1427|         0|            0|            0|  0.00%|        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "  1428|         0|            0|            0|  0.00%|            losses are averaged or summed over observations for each minibatch depending\n",
      "  1429|         0|            0|            0|  0.00%|            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "  1430|         0|            0|            0|  0.00%|            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "  1431|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1432|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1433|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1434|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "  1435|         0|            0|            0|  0.00%|            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "  1436|         0|            0|            0|  0.00%|            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "  1437|         0|            0|            0|  0.00%|\n",
      "  1438|         0|            0|            0|  0.00%|    Shape:\n",
      "  1439|         0|            0|            0|  0.00%|        - Input: :math:`(N, D)` or :math`(D)` where :math:`D` is the vector dimension.\n",
      "  1440|         0|            0|            0|  0.00%|        - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'`` and\n",
      "  1441|         0|            0|            0|  0.00%|                  input shape is :math`(N, D)`; a scalar otherwise.\n",
      "  1442|         0|            0|            0|  0.00%|\n",
      "  1443|         0|            0|            0|  0.00%|    Examples::\n",
      "  1444|         0|            0|            0|  0.00%|\n",
      "  1445|         0|            0|            0|  0.00%|    >>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
      "  1446|         0|            0|            0|  0.00%|    >>> anchor = torch.randn(100, 128, requires_grad=True)\n",
      "  1447|         0|            0|            0|  0.00%|    >>> positive = torch.randn(100, 128, requires_grad=True)\n",
      "  1448|         0|            0|            0|  0.00%|    >>> negative = torch.randn(100, 128, requires_grad=True)\n",
      "  1449|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1450|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1451|         0|            0|            0|  0.00%|\n",
      "  1452|         0|            0|            0|  0.00%|    .. _Learning shallow convolutional feature descriptors with triplet losses:\n",
      "  1453|         0|            0|            0|  0.00%|        http://www.bmva.org/bmvc/2016/papers/paper119/index.html\n",
      "  1454|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1455|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'p', 'eps', 'swap', 'reduction']\n",
      "  1456|         0|            0|            0|  0.00%|    margin: float\n",
      "  1457|         0|            0|            0|  0.00%|    p: float\n",
      "  1458|         0|            0|            0|  0.00%|    eps: float\n",
      "  1459|         0|            0|            0|  0.00%|    swap: bool\n",
      "  1460|         0|            0|            0|  0.00%|\n",
      "  1461|         0|            0|            0|  0.00%|    def __init__(self, margin: float = 1.0, p: float = 2., eps: float = 1e-6, swap: bool = False, size_average=None,\n",
      "  1462|         0|            0|            0|  0.00%|                 reduce=None, reduction: str = 'mean'):\n",
      "  1463|         0|            0|            0|  0.00%|        super(TripletMarginLoss, self).__init__(size_average, reduce, reduction)\n",
      "  1464|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1465|         0|            0|            0|  0.00%|        self.p = p\n",
      "  1466|         0|            0|            0|  0.00%|        self.eps = eps\n",
      "  1467|         0|            0|            0|  0.00%|        self.swap = swap\n",
      "  1468|         0|            0|            0|  0.00%|\n",
      "  1469|         0|            0|            0|  0.00%|    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n",
      "  1470|         0|            0|            0|  0.00%|        return F.triplet_margin_loss(anchor, positive, negative, margin=self.margin, p=self.p,\n",
      "  1471|         0|            0|            0|  0.00%|                                     eps=self.eps, swap=self.swap, reduction=self.reduction)\n",
      "  1472|         0|            0|            0|  0.00%|\n",
      "  1473|         0|            0|            0|  0.00%|\n",
      "  1474|         0|            0|            0|  0.00%|class TripletMarginWithDistanceLoss(_Loss):\n",
      "  1475|         0|            0|            0|  0.00%|    r\"\"\"Creates a criterion that measures the triplet loss given input\n",
      "  1476|         0|            0|            0|  0.00%|    tensors :math:`a`, :math:`p`, and :math:`n` (representing anchor,\n",
      "  1477|         0|            0|            0|  0.00%|    positive, and negative examples, respectively), and a nonnegative,\n",
      "  1478|         0|            0|            0|  0.00%|    real-valued function (\"distance function\") used to compute the relationship\n",
      "  1479|         0|            0|            0|  0.00%|    between the anchor and positive example (\"positive distance\") and the\n",
      "  1480|         0|            0|            0|  0.00%|    anchor and negative example (\"negative distance\").\n",
      "  1481|         0|            0|            0|  0.00%|\n",
      "  1482|         0|            0|            0|  0.00%|    The unreduced loss (i.e., with :attr:`reduction` set to ``'none'``)\n",
      "  1483|         0|            0|            0|  0.00%|    can be described as:\n",
      "  1484|         0|            0|            0|  0.00%|\n",
      "  1485|         0|            0|            0|  0.00%|    .. math::\n",
      "  1486|         0|            0|            0|  0.00%|        \\ell(a, p, n) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
      "  1487|         0|            0|            0|  0.00%|        l_i = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\n",
      "  1488|         0|            0|            0|  0.00%|\n",
      "  1489|         0|            0|            0|  0.00%|    where :math:`N` is the batch size; :math:`d` is a nonnegative, real-valued function\n",
      "  1490|         0|            0|            0|  0.00%|    quantifying the closeness of two tensors, referred to as the :attr:`distance_function`;\n",
      "  1491|         0|            0|            0|  0.00%|    and :math:`margin` is a nonnegative margin representing the minimum difference\n",
      "  1492|         0|            0|            0|  0.00%|    between the positive and negative distances that is required for the loss to\n",
      "  1493|         0|            0|            0|  0.00%|    be 0.  The input tensors have :math:`N` elements each and can be of any shape\n",
      "  1494|         0|            0|            0|  0.00%|    that the distance function can handle.\n",
      "  1495|         0|            0|            0|  0.00%|\n",
      "  1496|         0|            0|            0|  0.00%|    If :attr:`reduction` is not ``'none'``\n",
      "  1497|         0|            0|            0|  0.00%|    (default ``'mean'``), then:\n",
      "  1498|         0|            0|            0|  0.00%|\n",
      "  1499|         0|            0|            0|  0.00%|    .. math::\n",
      "  1500|         0|            0|            0|  0.00%|        \\ell(x, y) =\n",
      "  1501|         0|            0|            0|  0.00%|        \\begin{cases}\n",
      "  1502|         0|            0|            0|  0.00%|            \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n",
      "  1503|         0|            0|            0|  0.00%|            \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n",
      "  1504|         0|            0|            0|  0.00%|        \\end{cases}\n",
      "  1505|         0|            0|            0|  0.00%|\n",
      "  1506|         0|            0|            0|  0.00%|    See also :class:`~torch.nn.TripletMarginLoss`, which computes the triplet\n",
      "  1507|         0|            0|            0|  0.00%|    loss for input tensors using the :math:`l_p` distance as the distance function.\n",
      "  1508|         0|            0|            0|  0.00%|\n",
      "  1509|         0|            0|            0|  0.00%|    Args:\n",
      "  1510|         0|            0|            0|  0.00%|        distance_function (callable, optional): A nonnegative, real-valued function that\n",
      "  1511|         0|            0|            0|  0.00%|            quantifies the closeness of two tensors. If not specified,\n",
      "  1512|         0|            0|            0|  0.00%|            `nn.PairwiseDistance` will be used.  Default: ``None``\n",
      "  1513|         0|            0|            0|  0.00%|        margin (float, optional): A nonnegative margin representing the minimum difference\n",
      "  1514|         0|            0|            0|  0.00%|            between the positive and negative distances required for the loss to be 0. Larger\n",
      "  1515|         0|            0|            0|  0.00%|            margins penalize cases where the negative examples are not distant enough from the\n",
      "  1516|         0|            0|            0|  0.00%|            anchors, relative to the positives. Default: :math:`1`.\n",
      "  1517|         0|            0|            0|  0.00%|        swap (bool, optional): Whether to use the distance swap described in the paper\n",
      "  1518|         0|            0|            0|  0.00%|            `Learning shallow convolutional feature descriptors with triplet losses` by\n",
      "  1519|         0|            0|            0|  0.00%|            V. Balntas, E. Riba et al. If True, and if the positive example is closer to the\n",
      "  1520|         0|            0|            0|  0.00%|            negative example than the anchor is, swaps the positive example and the anchor in\n",
      "  1521|         0|            0|            0|  0.00%|            the loss computation. Default: ``False``.\n",
      "  1522|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the (optional) reduction to apply to the output:\n",
      "  1523|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1524|         0|            0|            0|  0.00%|            ``'mean'``: the sum of the output will be divided by the number of\n",
      "  1525|         0|            0|            0|  0.00%|            elements in the output, ``'sum'``: the output will be summed. Default: ``'mean'``\n",
      "  1526|         0|            0|            0|  0.00%|\n",
      "  1527|         0|            0|            0|  0.00%|\n",
      "  1528|         0|            0|            0|  0.00%|    Shape:\n",
      "  1529|         0|            0|            0|  0.00%|        - Input: :math:`(N, *)` where :math:`*` represents any number of additional dimensions\n",
      "  1530|         0|            0|            0|  0.00%|          as supported by the distance function.\n",
      "  1531|         0|            0|            0|  0.00%|        - Output: A Tensor of shape :math:`(N)` if :attr:`reduction` is ``'none'``, or a scalar\n",
      "  1532|         0|            0|            0|  0.00%|          otherwise.\n",
      "  1533|         0|            0|            0|  0.00%|\n",
      "  1534|         0|            0|            0|  0.00%|    Examples::\n",
      "  1535|         0|            0|            0|  0.00%|\n",
      "  1536|         0|            0|            0|  0.00%|    >>> # Initialize embeddings\n",
      "  1537|         0|            0|            0|  0.00%|    >>> embedding = nn.Embedding(1000, 128)\n",
      "  1538|         0|            0|            0|  0.00%|    >>> anchor_ids = torch.randint(0, 1000, (1,))\n",
      "  1539|         0|            0|            0|  0.00%|    >>> positive_ids = torch.randint(0, 1000, (1,))\n",
      "  1540|         0|            0|            0|  0.00%|    >>> negative_ids = torch.randint(0, 1000, (1,))\n",
      "  1541|         0|            0|            0|  0.00%|    >>> anchor = embedding(anchor_ids)\n",
      "  1542|         0|            0|            0|  0.00%|    >>> positive = embedding(positive_ids)\n",
      "  1543|         0|            0|            0|  0.00%|    >>> negative = embedding(negative_ids)\n",
      "  1544|         0|            0|            0|  0.00%|    >>>\n",
      "  1545|         0|            0|            0|  0.00%|    >>> # Built-in Distance Function\n",
      "  1546|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1547|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())\n",
      "  1548|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1549|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1550|         0|            0|            0|  0.00%|    >>>\n",
      "  1551|         0|            0|            0|  0.00%|    >>> # Custom Distance Function\n",
      "  1552|         0|            0|            0|  0.00%|    >>> def l_infinity(x1, x2):\n",
      "  1553|         0|            0|            0|  0.00%|    >>>     return torch.max(torch.abs(x1 - x2), dim=1).values\n",
      "  1554|         0|            0|            0|  0.00%|    >>>\n",
      "  1555|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1556|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5)\n",
      "  1557|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1558|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1559|         0|            0|            0|  0.00%|    >>>\n",
      "  1560|         0|            0|            0|  0.00%|    >>> # Custom Distance Function (Lambda)\n",
      "  1561|         0|            0|            0|  0.00%|    >>> triplet_loss = \\\n",
      "  1562|         0|            0|            0|  0.00%|    >>>     nn.TripletMarginWithDistanceLoss(\n",
      "  1563|         0|            0|            0|  0.00%|    >>>         distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
      "  1564|         0|            0|            0|  0.00%|    >>> output = triplet_loss(anchor, positive, negative)\n",
      "  1565|         0|            0|            0|  0.00%|    >>> output.backward()\n",
      "  1566|         0|            0|            0|  0.00%|\n",
      "  1567|         0|            0|            0|  0.00%|    Reference:\n",
      "  1568|         0|            0|            0|  0.00%|        V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1569|         0|            0|            0|  0.00%|        http://www.bmva.org/bmvc/2016/papers/paper119/index.html\n",
      "  1570|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1571|         0|            0|            0|  0.00%|    __constants__ = ['margin', 'swap', 'reduction']\n",
      "  1572|         0|            0|            0|  0.00%|    margin: float\n",
      "  1573|         0|            0|            0|  0.00%|    swap: bool\n",
      "  1574|         0|            0|            0|  0.00%|\n",
      "  1575|         0|            0|            0|  0.00%|    def __init__(self, *, distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = None,\n",
      "  1576|         0|            0|            0|  0.00%|                 margin: float = 1.0, swap: bool = False, reduction: str = 'mean'):\n",
      "  1577|         0|            0|            0|  0.00%|        super(TripletMarginWithDistanceLoss, self).__init__(size_average=None, reduce=None, reduction=reduction)\n",
      "  1578|         0|            0|            0|  0.00%|        self.distance_function: Optional[Callable[[Tensor, Tensor], Tensor]] = \\\n",
      "  1579|         0|            0|            0|  0.00%|            distance_function if distance_function is not None else PairwiseDistance()\n",
      "  1580|         0|            0|            0|  0.00%|        self.margin = margin\n",
      "  1581|         0|            0|            0|  0.00%|        self.swap = swap\n",
      "  1582|         0|            0|            0|  0.00%|\n",
      "  1583|         0|            0|            0|  0.00%|    def forward(self, anchor: Tensor, positive: Tensor, negative: Tensor) -> Tensor:\n",
      "  1584|         0|            0|            0|  0.00%|        return F.triplet_margin_with_distance_loss(anchor, positive, negative,\n",
      "  1585|         0|            0|            0|  0.00%|                                                   distance_function=self.distance_function,\n",
      "  1586|         0|            0|            0|  0.00%|                                                   margin=self.margin, swap=self.swap, reduction=self.reduction)\n",
      "  1587|         0|            0|            0|  0.00%|\n",
      "  1588|         0|            0|            0|  0.00%|\n",
      "  1589|         0|            0|            0|  0.00%|class CTCLoss(_Loss):\n",
      "  1590|         0|            0|            0|  0.00%|    r\"\"\"The Connectionist Temporal Classification loss.\n",
      "  1591|         0|            0|            0|  0.00%|\n",
      "  1592|         0|            0|            0|  0.00%|    Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the\n",
      "  1593|         0|            0|            0|  0.00%|    probability of possible alignments of input to target, producing a loss value which is differentiable\n",
      "  1594|         0|            0|            0|  0.00%|    with respect to each input node. The alignment of input to target is assumed to be \"many-to-one\", which\n",
      "  1595|         0|            0|            0|  0.00%|    limits the length of the target sequence such that it must be :math:`\\leq` the input length.\n",
      "  1596|         0|            0|            0|  0.00%|\n",
      "  1597|         0|            0|            0|  0.00%|    Args:\n",
      "  1598|         0|            0|            0|  0.00%|        blank (int, optional): blank label. Default :math:`0`.\n",
      "  1599|         0|            0|            0|  0.00%|        reduction (string, optional): Specifies the reduction to apply to the output:\n",
      "  1600|         0|            0|            0|  0.00%|            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "  1601|         0|            0|            0|  0.00%|            ``'mean'``: the output losses will be divided by the target lengths and\n",
      "  1602|         0|            0|            0|  0.00%|            then the mean over the batch is taken. Default: ``'mean'``\n",
      "  1603|         0|            0|            0|  0.00%|        zero_infinity (bool, optional):\n",
      "  1604|         0|            0|            0|  0.00%|            Whether to zero infinite losses and the associated gradients.\n",
      "  1605|         0|            0|            0|  0.00%|            Default: ``False``\n",
      "  1606|         0|            0|            0|  0.00%|            Infinite losses mainly occur when the inputs are too short\n",
      "  1607|         0|            0|            0|  0.00%|            to be aligned to the targets.\n",
      "  1608|         0|            0|            0|  0.00%|\n",
      "  1609|         0|            0|            0|  0.00%|    Shape:\n",
      "  1610|         0|            0|            0|  0.00%|        - Log_probs: Tensor of size :math:`(T, N, C)`,\n",
      "  1611|         0|            0|            0|  0.00%|          where :math:`T = \\text{input length}`,\n",
      "  1612|         0|            0|            0|  0.00%|          :math:`N = \\text{batch size}`, and\n",
      "  1613|         0|            0|            0|  0.00%|          :math:`C = \\text{number of classes (including blank)}`.\n",
      "  1614|         0|            0|            0|  0.00%|          The logarithmized probabilities of the outputs (e.g. obtained with\n",
      "  1615|         0|            0|            0|  0.00%|          :func:`torch.nn.functional.log_softmax`).\n",
      "  1616|         0|            0|            0|  0.00%|        - Targets: Tensor of size :math:`(N, S)` or\n",
      "  1617|         0|            0|            0|  0.00%|          :math:`(\\operatorname{sum}(\\text{target\\_lengths}))`,\n",
      "  1618|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}` and\n",
      "  1619|         0|            0|            0|  0.00%|          :math:`S = \\text{max target length, if shape is } (N, S)`.\n",
      "  1620|         0|            0|            0|  0.00%|          It represent the target sequences. Each element in the target\n",
      "  1621|         0|            0|            0|  0.00%|          sequence is a class index. And the target index cannot be blank (default=0).\n",
      "  1622|         0|            0|            0|  0.00%|          In the :math:`(N, S)` form, targets are padded to the\n",
      "  1623|         0|            0|            0|  0.00%|          length of the longest sequence, and stacked.\n",
      "  1624|         0|            0|            0|  0.00%|          In the :math:`(\\operatorname{sum}(\\text{target\\_lengths}))` form,\n",
      "  1625|         0|            0|            0|  0.00%|          the targets are assumed to be un-padded and\n",
      "  1626|         0|            0|            0|  0.00%|          concatenated within 1 dimension.\n",
      "  1627|         0|            0|            0|  0.00%|        - Input_lengths: Tuple or tensor of size :math:`(N)`,\n",
      "  1628|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}`. It represent the lengths of the\n",
      "  1629|         0|            0|            0|  0.00%|          inputs (must each be :math:`\\leq T`). And the lengths are specified\n",
      "  1630|         0|            0|            0|  0.00%|          for each sequence to achieve masking under the assumption that sequences\n",
      "  1631|         0|            0|            0|  0.00%|          are padded to equal lengths.\n",
      "  1632|         0|            0|            0|  0.00%|        - Target_lengths: Tuple or tensor of size :math:`(N)`,\n",
      "  1633|         0|            0|            0|  0.00%|          where :math:`N = \\text{batch size}`. It represent lengths of the targets.\n",
      "  1634|         0|            0|            0|  0.00%|          Lengths are specified for each sequence to achieve masking under the\n",
      "  1635|         0|            0|            0|  0.00%|          assumption that sequences are padded to equal lengths. If target shape is\n",
      "  1636|         0|            0|            0|  0.00%|          :math:`(N,S)`, target_lengths are effectively the stop index\n",
      "  1637|         0|            0|            0|  0.00%|          :math:`s_n` for each target sequence, such that ``target_n = targets[n,0:s_n]`` for\n",
      "  1638|         0|            0|            0|  0.00%|          each target in a batch. Lengths must each be :math:`\\leq S`\n",
      "  1639|         0|            0|            0|  0.00%|          If the targets are given as a 1d tensor that is the concatenation of individual\n",
      "  1640|         0|            0|            0|  0.00%|          targets, the target_lengths must add up to the total length of the tensor.\n",
      "  1641|         0|            0|            0|  0.00%|        - Output: scalar. If :attr:`reduction` is ``'none'``, then\n",
      "  1642|         0|            0|            0|  0.00%|          :math:`(N)`, where :math:`N = \\text{batch size}`.\n",
      "  1643|         0|            0|            0|  0.00%|\n",
      "  1644|         0|            0|            0|  0.00%|    Examples::\n",
      "  1645|         0|            0|            0|  0.00%|\n",
      "  1646|         0|            0|            0|  0.00%|        >>> # Target are to be padded\n",
      "  1647|         0|            0|            0|  0.00%|        >>> T = 50      # Input sequence length\n",
      "  1648|         0|            0|            0|  0.00%|        >>> C = 20      # Number of classes (including blank)\n",
      "  1649|         0|            0|            0|  0.00%|        >>> N = 16      # Batch size\n",
      "  1650|         0|            0|            0|  0.00%|        >>> S = 30      # Target sequence length of longest target in batch (padding length)\n",
      "  1651|         0|            0|            0|  0.00%|        >>> S_min = 10  # Minimum target length, for demonstration purposes\n",
      "  1652|         0|            0|            0|  0.00%|        >>>\n",
      "  1653|         0|            0|            0|  0.00%|        >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
      "  1654|         0|            0|            0|  0.00%|        >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
      "  1655|         0|            0|            0|  0.00%|        >>>\n",
      "  1656|         0|            0|            0|  0.00%|        >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
      "  1657|         0|            0|            0|  0.00%|        >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
      "  1658|         0|            0|            0|  0.00%|        >>>\n",
      "  1659|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
      "  1660|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
      "  1661|         0|            0|            0|  0.00%|        >>> ctc_loss = nn.CTCLoss()\n",
      "  1662|         0|            0|            0|  0.00%|        >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
      "  1663|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  1664|         0|            0|            0|  0.00%|        >>>\n",
      "  1665|         0|            0|            0|  0.00%|        >>>\n",
      "  1666|         0|            0|            0|  0.00%|        >>> # Target are to be un-padded\n",
      "  1667|         0|            0|            0|  0.00%|        >>> T = 50      # Input sequence length\n",
      "  1668|         0|            0|            0|  0.00%|        >>> C = 20      # Number of classes (including blank)\n",
      "  1669|         0|            0|            0|  0.00%|        >>> N = 16      # Batch size\n",
      "  1670|         0|            0|            0|  0.00%|        >>>\n",
      "  1671|         0|            0|            0|  0.00%|        >>> # Initialize random batch of input vectors, for *size = (T,N,C)\n",
      "  1672|         0|            0|            0|  0.00%|        >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
      "  1673|         0|            0|            0|  0.00%|        >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
      "  1674|         0|            0|            0|  0.00%|        >>>\n",
      "  1675|         0|            0|            0|  0.00%|        >>> # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
      "  1676|         0|            0|            0|  0.00%|        >>> target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
      "  1677|         0|            0|            0|  0.00%|        >>> target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
      "  1678|         0|            0|            0|  0.00%|        >>> ctc_loss = nn.CTCLoss()\n",
      "  1679|         0|            0|            0|  0.00%|        >>> loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
      "  1680|         0|            0|            0|  0.00%|        >>> loss.backward()\n",
      "  1681|         0|            0|            0|  0.00%|\n",
      "  1682|         0|            0|            0|  0.00%|    Reference:\n",
      "  1683|         0|            0|            0|  0.00%|        A. Graves et al.: Connectionist Temporal Classification:\n",
      "  1684|         0|            0|            0|  0.00%|        Labelling Unsegmented Sequence Data with Recurrent Neural Networks:\n",
      "  1685|         0|            0|            0|  0.00%|        https://www.cs.toronto.edu/~graves/icml_2006.pdf\n",
      "  1686|         0|            0|            0|  0.00%|\n",
      "  1687|         0|            0|            0|  0.00%|    Note:\n",
      "  1688|         0|            0|            0|  0.00%|        In order to use CuDNN, the following must be satisfied: :attr:`targets` must be\n",
      "  1689|         0|            0|            0|  0.00%|        in concatenated format, all :attr:`input_lengths` must be `T`.  :math:`blank=0`,\n",
      "  1690|         0|            0|            0|  0.00%|        :attr:`target_lengths` :math:`\\leq 256`, the integer arguments must be of\n",
      "  1691|         0|            0|            0|  0.00%|        dtype :attr:`torch.int32`.\n",
      "  1692|         0|            0|            0|  0.00%|\n",
      "  1693|         0|            0|            0|  0.00%|        The regular implementation uses the (more common in PyTorch) `torch.long` dtype.\n",
      "  1694|         0|            0|            0|  0.00%|\n",
      "  1695|         0|            0|            0|  0.00%|\n",
      "  1696|         0|            0|            0|  0.00%|    Note:\n",
      "  1697|         0|            0|            0|  0.00%|        In some circumstances when using the CUDA backend with CuDNN, this operator\n",
      "  1698|         0|            0|            0|  0.00%|        may select a nondeterministic algorithm to increase performance. If this is\n",
      "  1699|         0|            0|            0|  0.00%|        undesirable, you can try to make the operation deterministic (potentially at\n",
      "  1700|         0|            0|            0|  0.00%|        a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
      "  1701|         0|            0|            0|  0.00%|        True``.\n",
      "  1702|         0|            0|            0|  0.00%|        Please see the notes on :doc:`/notes/randomness` for background.\n",
      "  1703|         0|            0|            0|  0.00%|    \"\"\"\n",
      "  1704|         0|            0|            0|  0.00%|    __constants__ = ['blank', 'reduction']\n",
      "  1705|         0|            0|            0|  0.00%|    blank: int\n",
      "  1706|         0|            0|            0|  0.00%|    zero_infinity: bool\n",
      "  1707|         0|            0|            0|  0.00%|\n",
      "  1708|         0|            0|            0|  0.00%|    def __init__(self, blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False):\n",
      "  1709|         0|            0|            0|  0.00%|        super(CTCLoss, self).__init__(reduction=reduction)\n",
      "  1710|         0|            0|            0|  0.00%|        self.blank = blank\n",
      "  1711|         0|            0|            0|  0.00%|        self.zero_infinity = zero_infinity\n",
      "  1712|         0|            0|            0|  0.00%|\n",
      "  1713|         0|            0|            0|  0.00%|    def forward(self, log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor) -> Tensor:\n",
      "  1714|         0|            0|            0|  0.00%|        return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n",
      "  1715|         0|            0|            0|  0.00%|                          self.zero_infinity)\n",
      "  1716|         0|            0|            0|  0.00%|\n",
      "  1717|         0|            0|            0|  0.00%|# TODO: L1HingeEmbeddingCriterion\n",
      "  1718|         0|            0|            0|  0.00%|# TODO: MSECriterion weight\n",
      "  1719|         0|            0|            0|  0.00%|# TODO: ClassSimplexCriterion\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_tensor.py\n",
      "File duration: 7.77245e-05s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from collections import OrderedDict\n",
      "     2|         0|            0|            0|  0.00%|import enum\n",
      "     3|         0|            0|            0|  0.00%|import functools\n",
      "     4|         0|            0|            0|  0.00%|from numbers import Number\n",
      "     5|         0|            0|            0|  0.00%|from typing import Any, Dict, Optional, Tuple, Union\n",
      "     6|         0|            0|            0|  0.00%|import warnings\n",
      "     7|         0|            0|            0|  0.00%|import copyreg\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|import torch\n",
      "    10|         0|            0|            0|  0.00%|import torch._C as _C\n",
      "    11|         0|            0|            0|  0.00%|from torch._namedtensor_internals import (\n",
      "    12|         0|            0|            0|  0.00%|    update_names, check_serializing_named_tensor, resolve_ellipsis,\n",
      "    13|         0|            0|            0|  0.00%|    unzip_namedshape, single_ellipsis_index, is_ellipsis)\n",
      "    14|         0|            0|            0|  0.00%|from torch.overrides import (\n",
      "    15|         0|            0|            0|  0.00%|    has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n",
      "    16|         0|            0|            0|  0.00%|    handle_torch_function, get_default_nowrap_functions)\n",
      "    17|         0|            0|            0|  0.00%|import torch.utils.hooks as hooks\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|\n",
      "    20|         0|            0|            0|  0.00%|def _wrap_type_error_to_not_implemented(f):\n",
      "    21|         0|            0|            0|  0.00%|    # functools.wraps doesn't work well with methods in python 2\n",
      "    22|         0|            0|            0|  0.00%|    method_assignments = ('__name__', '__doc__')\n",
      "    23|         0|            0|            0|  0.00%|    assigned = functools.WRAPPER_ASSIGNMENTS\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|    @functools.wraps(f, assigned=assigned)\n",
      "    26|         0|            0|            0|  0.00%|    def wrapped(*args, **kwargs):\n",
      "    27|         0|            0|            0|  0.00%|        if has_torch_function(args):\n",
      "    28|         0|            0|            0|  0.00%|            return handle_torch_function(wrapped, args, *args, **kwargs)\n",
      "    29|         0|            0|            0|  0.00%|        try:\n",
      "    30|         0|            0|            0|  0.00%|            return f(*args, **kwargs)\n",
      "    31|         0|            0|            0|  0.00%|        except TypeError:\n",
      "    32|         0|            0|            0|  0.00%|            return NotImplemented\n",
      "    33|         0|            0|            0|  0.00%|    return wrapped\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses\n",
      "    36|         0|            0|            0|  0.00%|def _rebuild_from_type(func, type, args, dict):\n",
      "    37|         0|            0|            0|  0.00%|    if type is Tensor:\n",
      "    38|         0|            0|            0|  0.00%|        return func(*args)\n",
      "    39|         0|            0|            0|  0.00%|\n",
      "    40|         0|            0|            0|  0.00%|    ret = func(*args).as_subclass(type)\n",
      "    41|         0|            0|            0|  0.00%|    ret.__dict__ = dict\n",
      "    42|         0|            0|            0|  0.00%|    return ret\n",
      "    43|         0|            0|            0|  0.00%|\n",
      "    44|         0|            0|            0|  0.00%|def _rebuild_from_type_v2(func, new_type, args, state):\n",
      "    45|         0|            0|            0|  0.00%|    if new_type is Tensor:\n",
      "    46|         0|            0|            0|  0.00%|        return func(*args)\n",
      "    47|         0|            0|            0|  0.00%|\n",
      "    48|         0|            0|            0|  0.00%|    ret = func(*args).as_subclass(new_type)\n",
      "    49|         0|            0|            0|  0.00%|    # Tensor does define __setstate__ even though it doesn't define\n",
      "    50|         0|            0|            0|  0.00%|    # __getstate__. So only use __setstate__ if it is NOT the one defined\n",
      "    51|         0|            0|            0|  0.00%|    # on Tensor\n",
      "    52|         0|            0|            0|  0.00%|    if getattr(ret.__class__, \"__setstate__\", Tensor.__setstate__) is not Tensor.__setstate__:\n",
      "    53|         0|            0|            0|  0.00%|        ret.__setstate__(state)\n",
      "    54|         0|            0|            0|  0.00%|    else:\n",
      "    55|         0|            0|            0|  0.00%|        if isinstance(state, tuple):\n",
      "    56|         0|            0|            0|  0.00%|            if not len(state) == 2:\n",
      "    57|         0|            0|            0|  0.00%|                raise RuntimeError(f\"Invalid serialized state: {state}\")\n",
      "    58|         0|            0|            0|  0.00%|            dict_state = state[0]\n",
      "    59|         0|            0|            0|  0.00%|            slots_state = state[1]\n",
      "    60|         0|            0|            0|  0.00%|        else:\n",
      "    61|         0|            0|            0|  0.00%|            dict_state = state\n",
      "    62|         0|            0|            0|  0.00%|            slots_state = None\n",
      "    63|         0|            0|            0|  0.00%|\n",
      "    64|         0|            0|            0|  0.00%|        for k, v in dict_state.items():\n",
      "    65|         0|            0|            0|  0.00%|            setattr(ret, k, v)\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|        if slots_state:\n",
      "    68|         0|            0|            0|  0.00%|            for k, v in slots_state.items():\n",
      "    69|         0|            0|            0|  0.00%|                setattr(ret, k, v)\n",
      "    70|         0|            0|            0|  0.00%|    return ret\n",
      "    71|         0|            0|            0|  0.00%|\n",
      "    72|         0|            0|            0|  0.00%|\n",
      "    73|         0|            0|            0|  0.00%|# NB: If you subclass Tensor, and want to share the subclassed class\n",
      "    74|         0|            0|            0|  0.00%|# across processes, you must also update torch/multiprocessing/reductions.py\n",
      "    75|         0|            0|            0|  0.00%|# to define a ForkingPickler serialization mode for the class.\n",
      "    76|         0|            0|            0|  0.00%|#\n",
      "    77|         0|            0|            0|  0.00%|# NB: If you add a new method to Tensor, you must update\n",
      "    78|         0|            0|            0|  0.00%|# torch/__init__.py.in to add a type annotation for your method;\n",
      "    79|         0|            0|            0|  0.00%|# otherwise, it will not show up in autocomplete.\n",
      "    80|         0|            0|            0|  0.00%|class Tensor(torch._C._TensorBase):\n",
      "    81|         0|            0|            0|  0.00%|    def __deepcopy__(self, memo):\n",
      "    82|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "    83|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)\n",
      "    84|         0|            0|            0|  0.00%|        if not self.is_leaf:\n",
      "    85|         0|            0|            0|  0.00%|            raise RuntimeError(\"Only Tensors created explicitly by the user \"\n",
      "    86|         0|            0|            0|  0.00%|                               \"(graph leaves) support the deepcopy protocol at the moment\")\n",
      "    87|         0|            0|            0|  0.00%|        if id(self) in memo:\n",
      "    88|         0|            0|            0|  0.00%|            return memo[id(self)]\n",
      "    89|         0|            0|            0|  0.00%|        with torch.no_grad():\n",
      "    90|         0|            0|            0|  0.00%|            # TODO: skipping storage copy is wrong for meta, as meta\n",
      "    91|         0|            0|            0|  0.00%|            # does accurate alias tracking; however, the code below\n",
      "    92|         0|            0|            0|  0.00%|            # doesn't work because of\n",
      "    93|         0|            0|            0|  0.00%|            # https://github.com/pytorch/pytorch/issues/47442\n",
      "    94|         0|            0|            0|  0.00%|            if self.is_sparse or self.device.type in ['xla', 'mlc', 'ort', 'meta']:\n",
      "    95|         0|            0|            0|  0.00%|                new_tensor = self.clone()\n",
      "    96|         0|            0|            0|  0.00%|            else:\n",
      "    97|         0|            0|            0|  0.00%|                new_storage = self.storage().__deepcopy__(memo)\n",
      "    98|         0|            0|            0|  0.00%|                if self.is_quantized:\n",
      "    99|         0|            0|            0|  0.00%|                    # quantizer_params can be different type based on torch attribute\n",
      "   100|         0|            0|            0|  0.00%|                    quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[torch.qscheme, Tensor, Tensor, int]]\n",
      "   101|         0|            0|            0|  0.00%|                    if self.qscheme() == torch.per_tensor_affine:\n",
      "   102|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), self.q_scale(), self.q_zero_point()\n",
      "   103|         0|            0|            0|  0.00%|                    elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n",
      "   104|         0|            0|            0|  0.00%|                        quantizer_params = self.qscheme(), \\\n",
      "   105|         0|            0|            0|  0.00%|                            self.q_per_channel_scales(), \\\n",
      "   106|         0|            0|            0|  0.00%|                            self.q_per_channel_zero_points(), \\\n",
      "   107|         0|            0|            0|  0.00%|                            self.q_per_channel_axis()\n",
      "   108|         0|            0|            0|  0.00%|                    else:\n",
      "   109|         0|            0|            0|  0.00%|                        raise RuntimeError(f\"Unsupported qscheme {self.qscheme()} in deepcopy\")\n",
      "   110|         0|            0|            0|  0.00%|                    new_tensor = torch._utils._rebuild_qtensor(\n",
      "   111|         0|            0|            0|  0.00%|                        new_storage,\n",
      "   112|         0|            0|            0|  0.00%|                        self.storage_offset(),\n",
      "   113|         0|            0|            0|  0.00%|                        self.size(),\n",
      "   114|         0|            0|            0|  0.00%|                        self.stride(),\n",
      "   115|         0|            0|            0|  0.00%|                        quantizer_params,\n",
      "   116|         0|            0|            0|  0.00%|                        self.requires_grad,\n",
      "   117|         0|            0|            0|  0.00%|                        self._backward_hooks)\n",
      "   118|         0|            0|            0|  0.00%|                else:\n",
      "   119|         0|            0|            0|  0.00%|                    new_tensor = self.new_empty([])\n",
      "   120|         0|            0|            0|  0.00%|                    new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())\n",
      "   121|         0|            0|            0|  0.00%|                    if self.is_conj():\n",
      "   122|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.conj_physical()\n",
      "   123|         0|            0|            0|  0.00%|                    if self.is_neg():\n",
      "   124|         0|            0|            0|  0.00%|                        new_tensor = new_tensor.neg()\n",
      "   125|         0|            0|            0|  0.00%|                    new_tensor.requires_grad = self.requires_grad\n",
      "   126|         0|            0|            0|  0.00%|            if self.grad is not None:\n",
      "   127|         0|            0|            0|  0.00%|                new_tensor.grad = self.grad.__deepcopy__(memo)\n",
      "   128|         0|            0|            0|  0.00%|            memo[id(self)] = new_tensor\n",
      "   129|         0|            0|            0|  0.00%|            return new_tensor\n",
      "   130|         0|            0|            0|  0.00%|\n",
      "   131|         0|            0|            0|  0.00%|    def __reduce_ex__(self, proto):\n",
      "   132|         0|            0|            0|  0.00%|        if type(self) is Tensor:\n",
      "   133|         0|            0|            0|  0.00%|            return self._reduce_ex_internal(proto)\n",
      "   134|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   135|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)\n",
      "   136|         0|            0|            0|  0.00%|        func, args = self._reduce_ex_internal(proto)\n",
      "   137|         0|            0|            0|  0.00%|        # Get the state of the python subclass\n",
      "   138|         0|            0|            0|  0.00%|        # This loosely mimicks the function on the object class but since Tensor do not inherit\n",
      "   139|         0|            0|            0|  0.00%|        # from it, we cannot call that function directly\n",
      "   140|         0|            0|            0|  0.00%|        # https://github.com/python/cpython/blob/c83919bd635f4433f1c6ae8504996a9fe3c215e5/Objects/typeobject.c#L4891\n",
      "   141|         0|            0|            0|  0.00%|        getstate_fn = getattr(self, \"__getstate__\", None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   142|         0|            0|            0|  0.00%|        if getstate_fn:\n",
      "   143|         0|            0|            0|  0.00%|            state = getstate_fn()\n",
      "   144|         0|            0|            0|  0.00%|        else:\n",
      "   145|         0|            0|            0|  0.00%|            slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n",
      "   146|         0|            0|            0|  0.00%|            if slots_to_save:\n",
      "   147|         0|            0|            0|  0.00%|                state = (self.__dict__, {name: getattr(self, name) for name in slots_to_save if hasattr(self, name)})\n",
      "   148|         0|            0|            0|  0.00%|            else:\n",
      "   149|         0|            0|            0|  0.00%|                state = self.__dict__\n",
      "   150|         0|            0|            0|  0.00%|        return (_rebuild_from_type_v2, (func, type(self), args, state))\n",
      "   151|         0|            0|            0|  0.00%|\n",
      "   152|         0|            0|            0|  0.00%|    def _reduce_ex_internal(self, proto):\n",
      "   153|         0|            0|            0|  0.00%|        check_serializing_named_tensor(self)\n",
      "   154|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]\n",
      "   155|         0|            0|            0|  0.00%|        torch.utils.hooks.warn_if_has_hooks(self)\n",
      "   156|         0|            0|            0|  0.00%|        backward_hooks: Dict[Any, Any] = OrderedDict()\n",
      "   157|         0|            0|            0|  0.00%|        # Note: Numpy array is chosen to be the rebuild component for XLA, ORT, MLC Tensors.\n",
      "   158|         0|            0|            0|  0.00%|        # We considered a few options:\n",
      "   159|         0|            0|            0|  0.00%|        # 1. CPU tensor can't be used here.\n",
      "   160|         0|            0|            0|  0.00%|        #    Otherwise in torch.load CPU storage is reconstructed with randomly\n",
      "   161|         0|            0|            0|  0.00%|        #    initialized data, moved onto backend device, and then storage is updated\n",
      "   162|         0|            0|            0|  0.00%|        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;\n",
      "   163|         0|            0|            0|  0.00%|        #    their tensors are disconnected with storage so they don't get the update.\n",
      "   164|         0|            0|            0|  0.00%|        # 2. Python list is not a good fit due to performance reason.\n",
      "   165|         0|            0|            0|  0.00%|        #    `tolist()` converts every single element in the tensor into python objects\n",
      "   166|         0|            0|            0|  0.00%|        #    and serialize them one by one.\n",
      "   167|         0|            0|            0|  0.00%|        if self.device.type in ['xla', 'ort', 'mlc']:\n",
      "   168|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_device_tensor_from_numpy, (self.cpu().numpy(),\n",
      "   169|         0|            0|            0|  0.00%|                                                                     self.dtype,\n",
      "   170|         0|            0|            0|  0.00%|                                                                     str(self.device),\n",
      "   171|         0|            0|            0|  0.00%|                                                                     self.requires_grad))\n",
      "   172|         0|            0|            0|  0.00%|        if self.device.type == 'meta':\n",
      "   173|         0|            0|            0|  0.00%|            # NB: This implementation BREAKS storage sharing.  Current\n",
      "   174|         0|            0|            0|  0.00%|            # hypothesis is that no one cares for meta tensors.\n",
      "   175|         0|            0|            0|  0.00%|            arg_meta = (\n",
      "   176|         0|            0|            0|  0.00%|                self.dtype,\n",
      "   177|         0|            0|            0|  0.00%|                tuple(self.size()),\n",
      "   178|         0|            0|            0|  0.00%|                self.stride(),\n",
      "   179|         0|            0|            0|  0.00%|                self.requires_grad,\n",
      "   180|         0|            0|            0|  0.00%|            )\n",
      "   181|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)\n",
      "   182|         0|            0|            0|  0.00%|        if self.is_quantized:\n",
      "   183|         0|            0|            0|  0.00%|            # quantizer_params can be different type based on torch attribute\n",
      "   184|         0|            0|            0|  0.00%|            quantizer_params: Union[Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]]\n",
      "   185|         0|            0|            0|  0.00%|            if self.qscheme() == torch.per_tensor_affine:\n",
      "   186|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_tensor_affine,\n",
      "   187|         0|            0|            0|  0.00%|                                    self.q_scale(),\n",
      "   188|         0|            0|            0|  0.00%|                                    self.q_zero_point())\n",
      "   189|         0|            0|            0|  0.00%|            elif self.qscheme() in (torch.per_channel_affine, torch.per_channel_affine_float_qparams):\n",
      "   190|         0|            0|            0|  0.00%|                # convert scales and zero points to tuple to avoid recursive calls\n",
      "   191|         0|            0|            0|  0.00%|                # when/if we get multi-axis quantized tensors in the future, the shape\n",
      "   192|         0|            0|            0|  0.00%|                # is recoverable from the main tensor shape\n",
      "   193|         0|            0|            0|  0.00%|                quantizer_params = (torch.per_channel_affine,\n",
      "   194|         0|            0|            0|  0.00%|                                    self.q_per_channel_scales(),\n",
      "   195|         0|            0|            0|  0.00%|                                    self.q_per_channel_zero_points(),\n",
      "   196|         0|            0|            0|  0.00%|                                    self.q_per_channel_axis())\n",
      "   197|         0|            0|            0|  0.00%|            else:\n",
      "   198|         0|            0|            0|  0.00%|                raise RuntimeError(f\"Serialization is not supported for tensors of type {self.qscheme()}\")\n",
      "   199|         0|            0|            0|  0.00%|            args_qtensor = (self.storage(),\n",
      "   200|         0|            0|            0|  0.00%|                            self.storage_offset(),\n",
      "   201|         0|            0|            0|  0.00%|                            tuple(self.size()),\n",
      "   202|         0|            0|            0|  0.00%|                            self.stride(),\n",
      "   203|         0|            0|            0|  0.00%|                            quantizer_params,\n",
      "   204|         0|            0|            0|  0.00%|                            self.requires_grad,\n",
      "   205|         0|            0|            0|  0.00%|                            backward_hooks)\n",
      "   206|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_qtensor, args_qtensor)\n",
      "   207|         0|            0|            0|  0.00%|        elif self.is_sparse:\n",
      "   208|         0|            0|            0|  0.00%|            if self.layout == torch.sparse_coo:\n",
      "   209|         0|            0|            0|  0.00%|                args_sparse = (self.layout,\n",
      "   210|         0|            0|            0|  0.00%|                               (self._indices(),\n",
      "   211|         0|            0|            0|  0.00%|                                self._values(),\n",
      "   212|         0|            0|            0|  0.00%|                                self.size()))\n",
      "   213|         0|            0|            0|  0.00%|            else:\n",
      "   214|         0|            0|            0|  0.00%|                raise NotImplementedError(\n",
      "   215|         0|            0|            0|  0.00%|                    'sparse tensor __reduce_ex__ for layout `%s`' % (self.layout))\n",
      "   216|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_sparse_tensor, args_sparse)\n",
      "   217|         0|            0|            0|  0.00%|        else:\n",
      "   218|         0|            0|            0|  0.00%|            args = (self.storage(),\n",
      "   219|         0|            0|            0|  0.00%|                    self.storage_offset(),\n",
      "   220|         0|            0|            0|  0.00%|                    tuple(self.size()),\n",
      "   221|         0|            0|            0|  0.00%|                    self.stride(),\n",
      "   222|         0|            0|            0|  0.00%|                    self.requires_grad,\n",
      "   223|         0|            0|            0|  0.00%|                    backward_hooks)  # previously was self._backward_hooks\n",
      "   224|         0|            0|            0|  0.00%|            return (torch._utils._rebuild_tensor_v2, args)\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    def __setstate__(self, state):\n",
      "   227|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   228|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__setstate__, (self,), self, state)\n",
      "   229|         0|            0|            0|  0.00%|        # Warning: this method is NOT called when you torch.load() a tensor;\n",
      "   230|         0|            0|            0|  0.00%|        # that is managed by _rebuild_tensor_v2\n",
      "   231|         0|            0|            0|  0.00%|        if not self.is_leaf:\n",
      "   232|         0|            0|            0|  0.00%|            raise RuntimeError('__setstate__ can be only called on leaf Tensors')\n",
      "   233|         0|            0|            0|  0.00%|        if len(state) == 4:\n",
      "   234|         0|            0|            0|  0.00%|            # legacy serialization of Tensor\n",
      "   235|         0|            0|            0|  0.00%|            self.set_(*state)\n",
      "   236|         0|            0|            0|  0.00%|            return\n",
      "   237|         0|            0|            0|  0.00%|        elif len(state) == 5:\n",
      "   238|         0|            0|            0|  0.00%|            # legacy serialization of Variable\n",
      "   239|         0|            0|            0|  0.00%|            self.data = state[0]\n",
      "   240|         0|            0|            0|  0.00%|            state = (state[3], state[4], state[2])\n",
      "   241|         0|            0|            0|  0.00%|        # The setting of _backward_hooks is expected to be a no-op.\n",
      "   242|         0|            0|            0|  0.00%|        # See Note [Don't serialize hooks]\n",
      "   243|         0|            0|            0|  0.00%|        self.requires_grad, _, self._backward_hooks = state\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    def __repr__(self):\n",
      "   246|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   247|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__repr__, (self,), self)\n",
      "   248|         0|            0|            0|  0.00%|        # All strings are unicode in Python 3.\n",
      "   249|         0|            0|            0|  0.00%|        return torch._tensor_str._str(self)\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         1|   1.3113e-05|   1.3113e-05|  0.00%|    def backward(self, gradient=None, retain_graph=None, create_graph=False, inputs=None):\n",
      "   252|         0|            0|            0|  0.00%|        r\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "   253|         0|            0|            0|  0.00%|\n",
      "   254|         0|            0|            0|  0.00%|        The graph is differentiated using the chain rule. If the tensor is\n",
      "   255|         0|            0|            0|  0.00%|        non-scalar (i.e. its data has more than one element) and requires\n",
      "   256|         0|            0|            0|  0.00%|        gradient, the function additionally requires specifying ``gradient``.\n",
      "   257|         0|            0|            0|  0.00%|        It should be a tensor of matching type and location, that contains\n",
      "   258|         0|            0|            0|  0.00%|        the gradient of the differentiated function w.r.t. ``self``.\n",
      "   259|         0|            0|            0|  0.00%|\n",
      "   260|         0|            0|            0|  0.00%|        This function accumulates gradients in the leaves - you might need to zero\n",
      "   261|         0|            0|            0|  0.00%|        ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "   262|         0|            0|            0|  0.00%|        See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "   263|         0|            0|            0|  0.00%|        for details on the memory layout of accumulated gradients.\n",
      "   264|         0|            0|            0|  0.00%|\n",
      "   265|         0|            0|            0|  0.00%|        .. note::\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|            If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
      "   268|         0|            0|            0|  0.00%|            in a user-specified CUDA stream context, see\n",
      "   269|         0|            0|            0|  0.00%|            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   270|         0|            0|            0|  0.00%|\n",
      "   271|         0|            0|            0|  0.00%|        .. note::\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|            When ``inputs`` are provided and a given input is not a leaf,\n",
      "   274|         0|            0|            0|  0.00%|            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n",
      "   275|         0|            0|            0|  0.00%|            It is an implementation detail on which the user should not rely.\n",
      "   276|         0|            0|            0|  0.00%|            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
      "   277|         0|            0|            0|  0.00%|\n",
      "   278|         0|            0|            0|  0.00%|        Args:\n",
      "   279|         0|            0|            0|  0.00%|            gradient (Tensor or None): Gradient w.r.t. the\n",
      "   280|         0|            0|            0|  0.00%|                tensor. If it is a tensor, it will be automatically converted\n",
      "   281|         0|            0|            0|  0.00%|                to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "   282|         0|            0|            0|  0.00%|                None values can be specified for scalar Tensors or ones that\n",
      "   283|         0|            0|            0|  0.00%|                don't require grad. If a None value would be acceptable then\n",
      "   284|         0|            0|            0|  0.00%|                this argument is optional.\n",
      "   285|         0|            0|            0|  0.00%|            retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "   286|         0|            0|            0|  0.00%|                the grads will be freed. Note that in nearly all cases setting\n",
      "   287|         0|            0|            0|  0.00%|                this option to True is not needed and often can be worked around\n",
      "   288|         0|            0|            0|  0.00%|                in a much more efficient way. Defaults to the value of\n",
      "   289|         0|            0|            0|  0.00%|                ``create_graph``.\n",
      "   290|         0|            0|            0|  0.00%|            create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   291|         0|            0|            0|  0.00%|                be constructed, allowing to compute higher order derivative\n",
      "   292|         0|            0|            0|  0.00%|                products. Defaults to ``False``.\n",
      "   293|         0|            0|            0|  0.00%|            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "   294|         0|            0|            0|  0.00%|                accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
      "   295|         0|            0|            0|  0.00%|                provided, the gradient is accumulated into all the leaf Tensors that were\n",
      "   296|         0|            0|            0|  0.00%|                used to compute the attr::tensors.\n",
      "   297|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   298|         1|  1.19209e-05|  1.19209e-05|  0.00%|        if has_torch_function_unary(self):\n",
      "   299|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   300|         0|            0|            0|  0.00%|                Tensor.backward,\n",
      "   301|         0|            0|            0|  0.00%|                (self,),\n",
      "   302|         0|            0|            0|  0.00%|                self,\n",
      "   303|         0|            0|            0|  0.00%|                gradient=gradient,\n",
      "   304|         0|            0|            0|  0.00%|                retain_graph=retain_graph,\n",
      "   305|         0|            0|            0|  0.00%|                create_graph=create_graph,\n",
      "   306|         0|            0|            0|  0.00%|                inputs=inputs)\n",
      "   307|         1|  5.26905e-05|  5.26905e-05|  0.00%|        torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "(call)|         1|      0.11619|      0.11619|  1.45%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:69 backward\n",
      "   308|         0|            0|            0|  0.00%|\n",
      "   309|         0|            0|            0|  0.00%|    def register_hook(self, hook):\n",
      "   310|         0|            0|            0|  0.00%|        r\"\"\"Registers a backward hook.\n",
      "   311|         0|            0|            0|  0.00%|\n",
      "   312|         0|            0|            0|  0.00%|        The hook will be called every time a gradient with respect to the\n",
      "   313|         0|            0|            0|  0.00%|        Tensor is computed. The hook should have the following signature::\n",
      "   314|         0|            0|            0|  0.00%|\n",
      "   315|         0|            0|            0|  0.00%|            hook(grad) -> Tensor or None\n",
      "   316|         0|            0|            0|  0.00%|\n",
      "   317|         0|            0|            0|  0.00%|\n",
      "   318|         0|            0|            0|  0.00%|        The hook should not modify its argument, but it can optionally return\n",
      "   319|         0|            0|            0|  0.00%|        a new gradient which will be used in place of :attr:`grad`.\n",
      "   320|         0|            0|            0|  0.00%|\n",
      "   321|         0|            0|            0|  0.00%|        This function returns a handle with a method ``handle.remove()``\n",
      "   322|         0|            0|            0|  0.00%|        that removes the hook from the module.\n",
      "   323|         0|            0|            0|  0.00%|\n",
      "   324|         0|            0|            0|  0.00%|        Example::\n",
      "   325|         0|            0|            0|  0.00%|\n",
      "   326|         0|            0|            0|  0.00%|            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "   327|         0|            0|            0|  0.00%|            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "   328|         0|            0|            0|  0.00%|            >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "   329|         0|            0|            0|  0.00%|            >>> v.grad\n",
      "   330|         0|            0|            0|  0.00%|\n",
      "   331|         0|            0|            0|  0.00%|             2\n",
      "   332|         0|            0|            0|  0.00%|             4\n",
      "   333|         0|            0|            0|  0.00%|             6\n",
      "   334|         0|            0|            0|  0.00%|            [torch.FloatTensor of size (3,)]\n",
      "   335|         0|            0|            0|  0.00%|\n",
      "   336|         0|            0|            0|  0.00%|            >>> h.remove()  # removes the hook\n",
      "   337|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   338|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   339|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.register_hook, (self,), self, hook)\n",
      "   340|         0|            0|            0|  0.00%|        if not self.requires_grad:\n",
      "   341|         0|            0|            0|  0.00%|            raise RuntimeError(\"cannot register a hook on a tensor that \"\n",
      "   342|         0|            0|            0|  0.00%|                               \"doesn't require gradient\")\n",
      "   343|         0|            0|            0|  0.00%|        if self._backward_hooks is None:\n",
      "   344|         0|            0|            0|  0.00%|            self._backward_hooks = OrderedDict()\n",
      "   345|         0|            0|            0|  0.00%|            if self.grad_fn is not None:\n",
      "   346|         0|            0|            0|  0.00%|                self.grad_fn._register_hook_dict(self)\n",
      "   347|         0|            0|            0|  0.00%|        handle = hooks.RemovableHandle(self._backward_hooks)\n",
      "   348|         0|            0|            0|  0.00%|        self._backward_hooks[handle.id] = hook\n",
      "   349|         0|            0|            0|  0.00%|        return handle\n",
      "   350|         0|            0|            0|  0.00%|\n",
      "   351|         0|            0|            0|  0.00%|    def reinforce(self, reward):\n",
      "   352|         0|            0|            0|  0.00%|        def trim(str):\n",
      "   353|         0|            0|            0|  0.00%|            return '\\n'.join([line.strip() for line in str.split('\\n')])\n",
      "   354|         0|            0|            0|  0.00%|\n",
      "   355|         0|            0|            0|  0.00%|        raise RuntimeError(trim(r\"\"\"reinforce() was removed.\n",
      "   356|         0|            0|            0|  0.00%|            Use torch.distributions instead.\n",
      "   357|         0|            0|            0|  0.00%|            See https://pytorch.org/docs/master/distributions.html\n",
      "   358|         0|            0|            0|  0.00%|\n",
      "   359|         0|            0|            0|  0.00%|            Instead of:\n",
      "   360|         0|            0|            0|  0.00%|\n",
      "   361|         0|            0|            0|  0.00%|            probs = policy_network(state)\n",
      "   362|         0|            0|            0|  0.00%|            action = probs.multinomial()\n",
      "   363|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)\n",
      "   364|         0|            0|            0|  0.00%|            action.reinforce(reward)\n",
      "   365|         0|            0|            0|  0.00%|            action.backward()\n",
      "   366|         0|            0|            0|  0.00%|\n",
      "   367|         0|            0|            0|  0.00%|            Use:\n",
      "   368|         0|            0|            0|  0.00%|\n",
      "   369|         0|            0|            0|  0.00%|            probs = policy_network(state)\n",
      "   370|         0|            0|            0|  0.00%|            # NOTE: categorical is equivalent to what used to be called multinomial\n",
      "   371|         0|            0|            0|  0.00%|            m = torch.distributions.Categorical(probs)\n",
      "   372|         0|            0|            0|  0.00%|            action = m.sample()\n",
      "   373|         0|            0|            0|  0.00%|            next_state, reward = env.step(action)\n",
      "   374|         0|            0|            0|  0.00%|            loss = -m.log_prob(action) * reward\n",
      "   375|         0|            0|            0|  0.00%|            loss.backward()\n",
      "   376|         0|            0|            0|  0.00%|        \"\"\"))\n",
      "   377|         0|            0|            0|  0.00%|\n",
      "   378|         0|            0|            0|  0.00%|    detach = _C._add_docstr(_C._TensorBase.detach, r\"\"\"\n",
      "   379|         0|            0|            0|  0.00%|    Returns a new Tensor, detached from the current graph.\n",
      "   380|         0|            0|            0|  0.00%|\n",
      "   381|         0|            0|            0|  0.00%|    The result will never require gradient.\n",
      "   382|         0|            0|            0|  0.00%|\n",
      "   383|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never\n",
      "   384|         0|            0|            0|  0.00%|    have forward mode AD gradients.\n",
      "   385|         0|            0|            0|  0.00%|\n",
      "   386|         0|            0|            0|  0.00%|    .. note::\n",
      "   387|         0|            0|            0|  0.00%|\n",
      "   388|         0|            0|            0|  0.00%|      Returned Tensor shares the same storage with the original one.\n",
      "   389|         0|            0|            0|  0.00%|      In-place modifications on either of them will be seen, and may trigger\n",
      "   390|         0|            0|            0|  0.00%|      errors in correctness checks.\n",
      "   391|         0|            0|            0|  0.00%|      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "   392|         0|            0|            0|  0.00%|      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "   393|         0|            0|            0|  0.00%|      also update the original tensor. Now, these in-place changes will not update the\n",
      "   394|         0|            0|            0|  0.00%|      original tensor anymore, and will instead trigger an error.\n",
      "   395|         0|            0|            0|  0.00%|      For sparse tensors:\n",
      "   396|         0|            0|            0|  0.00%|      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "   397|         0|            0|            0|  0.00%|      returned tensor will not update the original tensor anymore, and will instead\n",
      "   398|         0|            0|            0|  0.00%|      trigger an error.\n",
      "   399|         0|            0|            0|  0.00%|    \"\"\")\n",
      "   400|         0|            0|            0|  0.00%|\n",
      "   401|         0|            0|            0|  0.00%|    detach_ = _C._add_docstr(_C._TensorBase.detach_, r\"\"\"\n",
      "   402|         0|            0|            0|  0.00%|    Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "   403|         0|            0|            0|  0.00%|    Views cannot be detached in-place.\n",
      "   404|         0|            0|            0|  0.00%|\n",
      "   405|         0|            0|            0|  0.00%|    This method also affects forward mode AD gradients and the result will never\n",
      "   406|         0|            0|            0|  0.00%|    have forward mode AD gradients.\n",
      "   407|         0|            0|            0|  0.00%|    \"\"\")\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|    def is_shared(self):\n",
      "   410|         0|            0|            0|  0.00%|        r\"\"\"Checks if tensor is in shared memory.\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|        This is always ``True`` for CUDA tensors.\n",
      "   413|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   414|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   415|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.is_shared, (self,), self)\n",
      "   416|         0|            0|            0|  0.00%|        return self.storage().is_shared()\n",
      "   417|         0|            0|            0|  0.00%|\n",
      "   418|         0|            0|            0|  0.00%|    def share_memory_(self):\n",
      "   419|         0|            0|            0|  0.00%|        r\"\"\"Moves the underlying storage to shared memory.\n",
      "   420|         0|            0|            0|  0.00%|\n",
      "   421|         0|            0|            0|  0.00%|        This is a no-op if the underlying storage is already in shared memory\n",
      "   422|         0|            0|            0|  0.00%|        and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "   423|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   424|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   425|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.share_memory_, (self,), self)\n",
      "   426|         0|            0|            0|  0.00%|        self.storage().share_memory_()\n",
      "   427|         0|            0|            0|  0.00%|        return self\n",
      "   428|         0|            0|            0|  0.00%|\n",
      "   429|         0|            0|            0|  0.00%|    def __reversed__(self):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   430|         0|            0|            0|  0.00%|        r\"\"\"Reverses the tensor along dimension 0.\"\"\"\n",
      "   431|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   432|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__reversed__, (self,), self)\n",
      "   433|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   434|         0|            0|            0|  0.00%|            return self\n",
      "   435|         0|            0|            0|  0.00%|        else:\n",
      "   436|         0|            0|            0|  0.00%|            return self.flip(0)\n",
      "   437|         0|            0|            0|  0.00%|\n",
      "   438|         0|            0|            0|  0.00%|    def norm(self, p=\"fro\", dim=None, keepdim=False, dtype=None):\n",
      "   439|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.norm`\"\"\"\n",
      "   440|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   441|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype)\n",
      "   442|         0|            0|            0|  0.00%|        return torch.norm(self, p, dim, keepdim, dtype=dtype)\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|    def lu(self, pivot=True, get_infos=False):\n",
      "   445|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.lu`\"\"\"\n",
      "   446|         0|            0|            0|  0.00%|        # If get_infos is True, then we don't need to check for errors and vice versa\n",
      "   447|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   448|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos)\n",
      "   449|         0|            0|            0|  0.00%|\n",
      "   450|         0|            0|            0|  0.00%|        LU, pivots, infos = torch._lu_with_info(self, pivot=pivot, check_errors=(not get_infos))\n",
      "   451|         0|            0|            0|  0.00%|        if get_infos:\n",
      "   452|         0|            0|            0|  0.00%|            return LU, pivots, infos\n",
      "   453|         0|            0|            0|  0.00%|        else:\n",
      "   454|         0|            0|            0|  0.00%|            return LU, pivots\n",
      "   455|         0|            0|            0|  0.00%|\n",
      "   456|         0|            0|            0|  0.00%|    def stft(self, n_fft: int, hop_length: Optional[int] = None,\n",
      "   457|         0|            0|            0|  0.00%|             win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n",
      "   458|         0|            0|            0|  0.00%|             center: bool = True, pad_mode: str = 'reflect', normalized: bool = False,\n",
      "   459|         0|            0|            0|  0.00%|             onesided: Optional[bool] = None, return_complex: Optional[bool] = None):\n",
      "   460|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.stft`\n",
      "   461|         0|            0|            0|  0.00%|\n",
      "   462|         0|            0|            0|  0.00%|        .. warning::\n",
      "   463|         0|            0|            0|  0.00%|          This function changed signature at version 0.4.1. Calling with\n",
      "   464|         0|            0|            0|  0.00%|          the previous signature may cause error or return incorrect result.\n",
      "   465|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   466|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   467|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   468|         0|            0|            0|  0.00%|                Tensor.stft, (self,), self, n_fft, hop_length=hop_length,\n",
      "   469|         0|            0|            0|  0.00%|                win_length=win_length, window=window, center=center, pad_mode=pad_mode, normalized=normalized,\n",
      "   470|         0|            0|            0|  0.00%|                onesided=onesided, return_complex=return_complex\n",
      "   471|         0|            0|            0|  0.00%|            )\n",
      "   472|         0|            0|            0|  0.00%|        return torch.stft(self, n_fft, hop_length, win_length, window, center,\n",
      "   473|         0|            0|            0|  0.00%|                          pad_mode, normalized, onesided, return_complex=return_complex)\n",
      "   474|         0|            0|            0|  0.00%|\n",
      "   475|         0|            0|            0|  0.00%|    def istft(self, n_fft: int, hop_length: Optional[int] = None,\n",
      "   476|         0|            0|            0|  0.00%|              win_length: Optional[int] = None, window: 'Optional[Tensor]' = None,\n",
      "   477|         0|            0|            0|  0.00%|              center: bool = True, normalized: bool = False,\n",
      "   478|         0|            0|            0|  0.00%|              onesided: Optional[bool] = None, length: Optional[int] = None,\n",
      "   479|         0|            0|            0|  0.00%|              return_complex: bool = False):\n",
      "   480|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.istft`\"\"\"\n",
      "   481|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   482|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   483|         0|            0|            0|  0.00%|                Tensor.istft, (self,), self, n_fft, hop_length=hop_length, win_length=win_length,\n",
      "   484|         0|            0|            0|  0.00%|                window=window, center=center, normalized=normalized, onesided=onesided, length=length,\n",
      "   485|         0|            0|            0|  0.00%|                return_complex=return_complex\n",
      "   486|         0|            0|            0|  0.00%|            )\n",
      "   487|         0|            0|            0|  0.00%|        return torch.istft(self, n_fft, hop_length, win_length, window, center,\n",
      "   488|         0|            0|            0|  0.00%|                           normalized, onesided, length, return_complex=return_complex)\n",
      "   489|         0|            0|            0|  0.00%|\n",
      "   490|         0|            0|            0|  0.00%|    def resize(self, *sizes):\n",
      "   491|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   492|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize, (self,), self, *sizes)\n",
      "   493|         0|            0|            0|  0.00%|        warnings.warn(\"non-inplace resize is deprecated\")\n",
      "   494|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize\n",
      "   495|         0|            0|            0|  0.00%|        return Resize.apply(self, sizes)\n",
      "   496|         0|            0|            0|  0.00%|\n",
      "   497|         0|            0|            0|  0.00%|    def resize_as(self, tensor):\n",
      "   498|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, tensor):\n",
      "   499|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)\n",
      "   500|         0|            0|            0|  0.00%|        warnings.warn(\"non-inplace resize_as is deprecated\")\n",
      "   501|         0|            0|            0|  0.00%|        from torch.autograd._functions import Resize\n",
      "   502|         0|            0|            0|  0.00%|        return Resize.apply(self, tensor.size())\n",
      "   503|         0|            0|            0|  0.00%|\n",
      "   504|         0|            0|            0|  0.00%|    def split(self, split_size, dim=0):\n",
      "   505|         0|            0|            0|  0.00%|        r\"\"\"See :func:`torch.split`\n",
      "   506|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   507|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   508|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.split, (self,), self, split_size, dim=dim)\n",
      "   509|         0|            0|            0|  0.00%|        if isinstance(split_size, int):\n",
      "   510|         0|            0|            0|  0.00%|            return super(Tensor, self).split(split_size, dim)\n",
      "   511|         0|            0|            0|  0.00%|        elif isinstance(split_size, Tensor):\n",
      "   512|         0|            0|            0|  0.00%|            try:\n",
      "   513|         0|            0|            0|  0.00%|                split_size = int(split_size)\n",
      "   514|         0|            0|            0|  0.00%|                return super(Tensor, self).split(split_size, dim)\n",
      "   515|         0|            0|            0|  0.00%|            except ValueError:\n",
      "   516|         0|            0|            0|  0.00%|                return super(Tensor, self).split_with_sizes(split_size, dim)\n",
      "   517|         0|            0|            0|  0.00%|        else:\n",
      "   518|         0|            0|            0|  0.00%|            return super(Tensor, self).split_with_sizes(split_size, dim)\n",
      "   519|         0|            0|            0|  0.00%|\n",
      "   520|         0|            0|            0|  0.00%|    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):\n",
      "   521|         0|            0|            0|  0.00%|        r\"\"\"Returns the unique elements of the input tensor.\n",
      "   522|         0|            0|            0|  0.00%|\n",
      "   523|         0|            0|            0|  0.00%|        See :func:`torch.unique`\n",
      "   524|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   525|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   526|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   527|         0|            0|            0|  0.00%|                Tensor.unique, (self,), self, sorted=sorted, return_inverse=return_inverse,\n",
      "   528|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim\n",
      "   529|         0|            0|            0|  0.00%|            )\n",
      "   530|         0|            0|            0|  0.00%|        return torch.unique(self, sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n",
      "   531|         0|            0|            0|  0.00%|\n",
      "   532|         0|            0|            0|  0.00%|    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):\n",
      "   533|         0|            0|            0|  0.00%|        r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "   534|         0|            0|            0|  0.00%|\n",
      "   535|         0|            0|            0|  0.00%|        See :func:`torch.unique_consecutive`\n",
      "   536|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   537|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   538|         0|            0|            0|  0.00%|            return handle_torch_function(\n",
      "   539|         0|            0|            0|  0.00%|                Tensor.unique_consecutive, (self,), self, return_inverse=return_inverse,\n",
      "   540|         0|            0|            0|  0.00%|                return_counts=return_counts, dim=dim\n",
      "   541|         0|            0|            0|  0.00%|            )\n",
      "   542|         0|            0|            0|  0.00%|        return torch.unique_consecutive(self, return_inverse=return_inverse, return_counts=return_counts, dim=dim)\n",
      "   543|         0|            0|            0|  0.00%|\n",
      "   544|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   545|         0|            0|            0|  0.00%|    def __rsub__(self, other):\n",
      "   546|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   547|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rsub__, (self, other), self, other)\n",
      "   548|         0|            0|            0|  0.00%|        return _C._VariableFunctions.rsub(self, other)\n",
      "   549|         0|            0|            0|  0.00%|\n",
      "   550|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   551|         0|            0|            0|  0.00%|    def __rdiv__(self, other):\n",
      "   552|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   553|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rdiv__, (self, other), self, other)\n",
      "   554|         0|            0|            0|  0.00%|        return self.reciprocal() * other\n",
      "   555|         0|            0|            0|  0.00%|\n",
      "   556|         0|            0|            0|  0.00%|    __rtruediv__ = __rdiv__\n",
      "   557|         0|            0|            0|  0.00%|    __itruediv__ = _C._TensorBase.__idiv__\n",
      "   558|         0|            0|            0|  0.00%|\n",
      "   559|         0|            0|            0|  0.00%|    __pow__ = _wrap_type_error_to_not_implemented(_C._TensorBase.pow)\n",
      "   560|         0|            0|            0|  0.00%|\n",
      "   561|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   562|         0|            0|            0|  0.00%|    def __rmod__(self, other):\n",
      "   563|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   564|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rmod__, (self, other), self, other)\n",
      "   565|         0|            0|            0|  0.00%|        return torch.remainder(other, self)\n",
      "   566|         0|            0|            0|  0.00%|\n",
      "   567|         0|            0|            0|  0.00%|    def __format__(self, format_spec):\n",
      "   568|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   569|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)\n",
      "   570|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   571|         0|            0|            0|  0.00%|            return self.item().__format__(format_spec)\n",
      "   572|         0|            0|            0|  0.00%|        return object.__format__(self, format_spec)\n",
      "   573|         0|            0|            0|  0.00%|\n",
      "   574|         0|            0|            0|  0.00%|    def __ipow__(self, other):  # type: ignore[misc]\n",
      "   575|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   576|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__ipow__, (self, other), self, other)\n",
      "   577|         0|            0|            0|  0.00%|        return NotImplemented\n",
      "   578|         0|            0|            0|  0.00%|\n",
      "   579|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   580|         0|            0|            0|  0.00%|    def __rpow__(self, other):\n",
      "   581|         0|            0|            0|  0.00%|        dtype = torch.result_type(other, self)\n",
      "   582|         0|            0|            0|  0.00%|        return torch.tensor(other, dtype=dtype, device=self.device) ** self\n",
      "   583|         0|            0|            0|  0.00%|\n",
      "   584|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   585|         0|            0|            0|  0.00%|    def __floordiv__(self, other):\n",
      "   586|         0|            0|            0|  0.00%|        warnings.warn(\"__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n",
      "   587|         0|            0|            0|  0.00%|                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n",
      "   588|         0|            0|            0|  0.00%|                      \"This results in incorrect rounding for negative values. \"\n",
      "   589|         0|            0|            0|  0.00%|                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n",
      "   590|         0|            0|            0|  0.00%|                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n",
      "   591|         0|            0|            0|  0.00%|        return torch.div(self, other, rounding_mode='trunc')\n",
      "   592|         0|            0|            0|  0.00%|\n",
      "   593|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   594|         0|            0|            0|  0.00%|    def __rfloordiv__(self, other):\n",
      "   595|         0|            0|            0|  0.00%|        warnings.warn(\"__rfloordiv__ is deprecated, and its behavior will change in a future version of pytorch. \"\n",
      "   596|         0|            0|            0|  0.00%|                      \"It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). \"\n",
      "   597|         0|            0|            0|  0.00%|                      \"This results in incorrect rounding for negative values. \"\n",
      "   598|         0|            0|            0|  0.00%|                      \"To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), \"\n",
      "   599|         0|            0|            0|  0.00%|                      \"or for actual floor division, use torch.div(a, b, rounding_mode='floor').\", stacklevel=3)\n",
      "   600|         0|            0|            0|  0.00%|        return torch.div(other, self, rounding_mode='trunc')\n",
      "   601|         0|            0|            0|  0.00%|\n",
      "   602|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   603|         0|            0|            0|  0.00%|    def __rlshift__(self, other):\n",
      "   604|         0|            0|            0|  0.00%|        return torch.bitwise_left_shift(other, self)\n",
      "   605|         0|            0|            0|  0.00%|\n",
      "   606|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   607|         0|            0|            0|  0.00%|    def __rrshift__(self, other):\n",
      "   608|         0|            0|            0|  0.00%|        return torch.bitwise_right_shift(other, self)\n",
      "   609|         0|            0|            0|  0.00%|\n",
      "   610|         0|            0|            0|  0.00%|    @_wrap_type_error_to_not_implemented\n",
      "   611|         0|            0|            0|  0.00%|    def __rmatmul__(self, other):\n",
      "   612|         0|            0|            0|  0.00%|        if has_torch_function_variadic(self, other):\n",
      "   613|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__rmatmul__, (self, other), self, other)\n",
      "   614|         0|            0|            0|  0.00%|        return torch.matmul(other, self)\n",
      "   615|         0|            0|            0|  0.00%|\n",
      "   616|         0|            0|            0|  0.00%|    __pos__ = _C._TensorBase.positive\n",
      "   617|         0|            0|            0|  0.00%|    __neg__ = _C._TensorBase.neg\n",
      "   618|         0|            0|            0|  0.00%|    __abs__ = _C._TensorBase.abs\n",
      "   619|         0|            0|            0|  0.00%|\n",
      "   620|         0|            0|            0|  0.00%|    def __len__(self):\n",
      "   621|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   622|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__len__, (self,), self)\n",
      "   623|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   624|         0|            0|            0|  0.00%|            raise TypeError(\"len() of a 0-d tensor\")\n",
      "   625|         0|            0|            0|  0.00%|        if torch._C._get_tracing_state():\n",
      "   626|         0|            0|            0|  0.00%|            warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n",
      "   627|         0|            0|            0|  0.00%|                          'Recommended usage would be tensor.shape[0]. '\n",
      "   628|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape might lead to errors or silently give '\n",
      "   629|         0|            0|            0|  0.00%|                          'incorrect results.', category=torch.jit.TracerWarning, stacklevel=2)\n",
      "   630|         0|            0|            0|  0.00%|        return self.shape[0]\n",
      "   631|         0|            0|            0|  0.00%|\n",
      "   632|         0|            0|            0|  0.00%|    def __iter__(self):\n",
      "   633|         0|            0|            0|  0.00%|        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\n",
      "   634|         0|            0|            0|  0.00%|        # generator and don't eagerly perform all the indexes.  This could\n",
      "   635|         0|            0|            0|  0.00%|        # save us work, and also helps keep trace ordering deterministic\n",
      "   636|         0|            0|            0|  0.00%|        # (e.g., if you zip(*hiddens), the eager map will force all the\n",
      "   637|         0|            0|            0|  0.00%|        # indexes of hiddens[0] before hiddens[1], while the generator\n",
      "   638|         0|            0|            0|  0.00%|        # map will interleave them.)\n",
      "   639|         0|            0|            0|  0.00%|        # NB: We have intentionally skipped __torch_function__ dispatch here.\n",
      "   640|         0|            0|            0|  0.00%|        # See gh-54457\n",
      "   641|         0|            0|            0|  0.00%|        if self.dim() == 0:\n",
      "   642|         0|            0|            0|  0.00%|            raise TypeError('iteration over a 0-d tensor')\n",
      "   643|         0|            0|            0|  0.00%|        if torch._C._get_tracing_state():\n",
      "   644|         0|            0|            0|  0.00%|            warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "   645|         0|            0|            0|  0.00%|                          'Passing a tensor of different shape won\\'t change the number of '\n",
      "   646|         0|            0|            0|  0.00%|                          'iterations executed (and might lead to errors or silently give '\n",
      "   647|         0|            0|            0|  0.00%|                          'incorrect results).', category=torch.jit.TracerWarning, stacklevel=2)\n",
      "   648|         0|            0|            0|  0.00%|        return iter(self.unbind(0))\n",
      "   649|         0|            0|            0|  0.00%|\n",
      "   650|         0|            0|            0|  0.00%|    def __hash__(self):\n",
      "   651|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   652|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__hash__, (self,), self)\n",
      "   653|         0|            0|            0|  0.00%|        return id(self)\n",
      "   654|         0|            0|            0|  0.00%|\n",
      "   655|         0|            0|            0|  0.00%|    def __dir__(self):\n",
      "   656|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   657|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dir__, (self,), self)\n",
      "   658|         0|            0|            0|  0.00%|        if self.is_quantized:\n",
      "   659|         0|            0|            0|  0.00%|            warnings.warn('Only a small subset of methods are supported for quantized tensors.')\n",
      "   660|         0|            0|            0|  0.00%|        tensor_methods = dir(self.__class__)\n",
      "   661|         0|            0|            0|  0.00%|        tensor_methods.remove('volatile')  # deprecated\n",
      "   662|         0|            0|            0|  0.00%|        attrs = list(self.__dict__.keys())\n",
      "   663|         0|            0|            0|  0.00%|        keys = tensor_methods + attrs\n",
      "   664|         0|            0|            0|  0.00%|\n",
      "   665|         0|            0|            0|  0.00%|        # property only available dense, cuda tensors\n",
      "   666|         0|            0|            0|  0.00%|        if (not self.is_cuda) or self.is_sparse:\n",
      "   667|         0|            0|            0|  0.00%|            keys.remove(\"__cuda_array_interface__\")\n",
      "   668|         0|            0|            0|  0.00%|\n",
      "   669|         0|            0|            0|  0.00%|        return sorted(keys)\n",
      "   670|         0|            0|            0|  0.00%|\n",
      "   671|         0|            0|            0|  0.00%|    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n",
      "   672|         0|            0|            0|  0.00%|    __array_priority__ = 1000    # prefer Tensor ops over numpy ones\n",
      "   673|         0|            0|            0|  0.00%|\n",
      "   674|         0|            0|            0|  0.00%|    def __array__(self, dtype=None):\n",
      "   675|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   676|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)\n",
      "   677|         0|            0|            0|  0.00%|        if dtype is None:\n",
      "   678|         0|            0|            0|  0.00%|            return self.numpy()\n",
      "   679|         0|            0|            0|  0.00%|        else:\n",
      "   680|         0|            0|            0|  0.00%|            return self.numpy().astype(dtype, copy=False)\n",
      "   681|         0|            0|            0|  0.00%|\n",
      "   682|         0|            0|            0|  0.00%|    # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "   683|         0|            0|            0|  0.00%|    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "   684|         0|            0|            0|  0.00%|    def __array_wrap__(self, array):\n",
      "   685|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   686|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__array_wrap__, (self,), self, array=array)\n",
      "   687|         0|            0|            0|  0.00%|        if array.dtype == bool:\n",
      "   688|         0|            0|            0|  0.00%|            # Workaround, torch has no built-in bool tensor\n",
      "   689|         0|            0|            0|  0.00%|            array = array.astype('uint8')\n",
      "   690|         0|            0|            0|  0.00%|        return torch.from_numpy(array)\n",
      "   691|         0|            0|            0|  0.00%|\n",
      "   692|         0|            0|            0|  0.00%|    def __contains__(self, element):\n",
      "   693|         0|            0|            0|  0.00%|        r\"\"\"Check if `element` is present in tensor\n",
      "   694|         0|            0|            0|  0.00%|\n",
      "   695|         0|            0|            0|  0.00%|        Args:\n",
      "   696|         0|            0|            0|  0.00%|            element (Tensor or scalar): element to be checked\n",
      "   697|         0|            0|            0|  0.00%|                for presence in current tensor\"\n",
      "   698|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   699|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   700|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__contains__, (self,), self, element)\n",
      "   701|         0|            0|            0|  0.00%|        if isinstance(element, (torch.Tensor, Number)):\n",
      "   702|         0|            0|            0|  0.00%|            # type hint doesn't understand the __contains__ result array\n",
      "   703|         0|            0|            0|  0.00%|            return (element == self).any().item()  # type: ignore[union-attr]\n",
      "   704|         0|            0|            0|  0.00%|\n",
      "   705|         0|            0|            0|  0.00%|        raise RuntimeError(\n",
      "   706|         0|            0|            0|  0.00%|            \"Tensor.__contains__ only supports Tensor or scalar, but you passed in a %s.\" %\n",
      "   707|         0|            0|            0|  0.00%|            type(element)\n",
      "   708|         0|            0|            0|  0.00%|        )\n",
      "   709|         0|            0|            0|  0.00%|\n",
      "   710|         0|            0|            0|  0.00%|    @property\n",
      "   711|         0|            0|            0|  0.00%|    def __cuda_array_interface__(self):\n",
      "   712|         0|            0|            0|  0.00%|        \"\"\"Array view description for cuda tensors.\n",
      "   713|         0|            0|            0|  0.00%|\n",
      "   714|         0|            0|            0|  0.00%|        See:\n",
      "   715|         0|            0|            0|  0.00%|        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "   716|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   717|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   718|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "   719|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]\n",
      "   720|         0|            0|            0|  0.00%|\n",
      "   721|         0|            0|            0|  0.00%|        # raise AttributeError for unsupported tensors, so that\n",
      "   722|         0|            0|            0|  0.00%|        # hasattr(cpu_tensor, \"__cuda_array_interface__\") is False.\n",
      "   723|         0|            0|            0|  0.00%|        if not self.is_cuda:\n",
      "   724|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   725|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on non-CUDA tensor type: %s \"\n",
      "   726|         0|            0|            0|  0.00%|                \"If CUDA data is required use tensor.cuda() to copy tensor to device memory.\" %\n",
      "   727|         0|            0|            0|  0.00%|                self.type()\n",
      "   728|         0|            0|            0|  0.00%|            )\n",
      "   729|         0|            0|            0|  0.00%|\n",
      "   730|         0|            0|            0|  0.00%|        if self.is_sparse:\n",
      "   731|         0|            0|            0|  0.00%|            raise AttributeError(\n",
      "   732|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on sparse type: %s \"\n",
      "   733|         0|            0|            0|  0.00%|                \"Use Tensor.to_dense() to convert to a dense tensor first.\" %\n",
      "   734|         0|            0|            0|  0.00%|                self.type()\n",
      "   735|         0|            0|            0|  0.00%|            )\n",
      "   736|         0|            0|            0|  0.00%|\n",
      "   737|         0|            0|            0|  0.00%|        # RuntimeError, matching tensor.__array__() behavior.\n",
      "   738|         0|            0|            0|  0.00%|        if self.requires_grad:\n",
      "   739|         0|            0|            0|  0.00%|            raise RuntimeError(\n",
      "   740|         0|            0|            0|  0.00%|                \"Can't get __cuda_array_interface__ on Variable that requires grad. \"\n",
      "   741|         0|            0|            0|  0.00%|                \"If gradients aren't required, use var.detach() to get Variable that doesn't require grad.\"\n",
      "   742|         0|            0|            0|  0.00%|            )\n",
      "   743|         0|            0|            0|  0.00%|\n",
      "   744|         0|            0|            0|  0.00%|        # CUDA devices are little-endian and tensors are stored in native byte\n",
      "   745|         0|            0|            0|  0.00%|        # order. 1-byte entries are endian-agnostic.\n",
      "   746|         0|            0|            0|  0.00%|        typestr = {\n",
      "   747|         0|            0|            0|  0.00%|            torch.complex64: \"<c8\",\n",
      "   748|         0|            0|            0|  0.00%|            torch.complex128: \"<c16\",\n",
      "   749|         0|            0|            0|  0.00%|            torch.float16: \"<f2\",\n",
      "   750|         0|            0|            0|  0.00%|            torch.float32: \"<f4\",\n",
      "   751|         0|            0|            0|  0.00%|            torch.float64: \"<f8\",\n",
      "   752|         0|            0|            0|  0.00%|            torch.uint8: \"|u1\",\n",
      "   753|         0|            0|            0|  0.00%|            torch.int8: \"|i1\",\n",
      "   754|         0|            0|            0|  0.00%|            torch.int16: \"<i2\",\n",
      "   755|         0|            0|            0|  0.00%|            torch.int32: \"<i4\",\n",
      "   756|         0|            0|            0|  0.00%|            torch.int64: \"<i8\",\n",
      "   757|         0|            0|            0|  0.00%|        }[self.dtype]\n",
      "   758|         0|            0|            0|  0.00%|\n",
      "   759|         0|            0|            0|  0.00%|        itemsize = self.storage().element_size()\n",
      "   760|         0|            0|            0|  0.00%|\n",
      "   761|         0|            0|            0|  0.00%|        shape = tuple(self.shape)\n",
      "   762|         0|            0|            0|  0.00%|        if self.is_contiguous():\n",
      "   763|         0|            0|            0|  0.00%|            # __cuda_array_interface__ v2 requires the strides to be omitted\n",
      "   764|         0|            0|            0|  0.00%|            # (either not set or set to None) for C-contiguous arrays.\n",
      "   765|         0|            0|            0|  0.00%|            strides = None\n",
      "   766|         0|            0|            0|  0.00%|        else:\n",
      "   767|         0|            0|            0|  0.00%|            strides = tuple(s * itemsize for s in self.stride())\n",
      "   768|         0|            0|            0|  0.00%|        data_ptr = self.data_ptr() if self.numel() > 0 else 0\n",
      "   769|         0|            0|            0|  0.00%|        data = (data_ptr, False)  # read-only is false\n",
      "   770|         0|            0|            0|  0.00%|\n",
      "   771|         0|            0|            0|  0.00%|        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)\n",
      "   772|         0|            0|            0|  0.00%|\n",
      "   773|         0|            0|            0|  0.00%|    def refine_names(self, *names):\n",
      "   774|         0|            0|            0|  0.00%|        r\"\"\"Refines the dimension names of :attr:`self` according to :attr:`names`.\n",
      "   775|         0|            0|            0|  0.00%|\n",
      "   776|         0|            0|            0|  0.00%|        Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n",
      "   777|         0|            0|            0|  0.00%|        A ``None`` dim can be refined to have any name; a named dim can only be\n",
      "   778|         0|            0|            0|  0.00%|        refined to have the same name.\n",
      "   779|         0|            0|            0|  0.00%|\n",
      "   780|         0|            0|            0|  0.00%|        Because named tensors can coexist with unnamed tensors, refining names\n",
      "   781|         0|            0|            0|  0.00%|        gives a nice way to write named-tensor-aware code that works with both\n",
      "   782|         0|            0|            0|  0.00%|        named and unnamed tensors.\n",
      "   783|         0|            0|            0|  0.00%|\n",
      "   784|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "   785|         0|            0|            0|  0.00%|        The Ellipsis is expanded greedily; it is expanded in-place to fill\n",
      "   786|         0|            0|            0|  0.00%|        :attr:`names` to the same length as ``self.dim()`` using names from the\n",
      "   787|         0|            0|            0|  0.00%|        corresponding indices of ``self.names``.\n",
      "   788|         0|            0|            0|  0.00%|\n",
      "   789|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal\n",
      "   790|         0|            0|            0|  0.00%|        instead (``'...'``).\n",
      "   791|         0|            0|            0|  0.00%|\n",
      "   792|         0|            0|            0|  0.00%|        Args:\n",
      "   793|         0|            0|            0|  0.00%|            names (iterable of str): The desired names of the output tensor. May\n",
      "   794|         0|            0|            0|  0.00%|                contain up to one Ellipsis.\n",
      "   795|         0|            0|            0|  0.00%|\n",
      "   796|         0|            0|            0|  0.00%|        Examples::\n",
      "   797|         0|            0|            0|  0.00%|\n",
      "   798|         0|            0|            0|  0.00%|            >>> imgs = torch.randn(32, 3, 128, 128)\n",
      "   799|         0|            0|            0|  0.00%|            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n",
      "   800|         0|            0|            0|  0.00%|            >>> named_imgs.names\n",
      "   801|         0|            0|            0|  0.00%|            ('N', 'C', 'H', 'W')\n",
      "   802|         0|            0|            0|  0.00%|\n",
      "   803|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 3, 5, 7, 11)\n",
      "   804|         0|            0|            0|  0.00%|            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n",
      "   805|         0|            0|            0|  0.00%|            >>> tensor.names\n",
      "   806|         0|            0|            0|  0.00%|            ('A', None, None, 'B', 'C')\n",
      "   807|         0|            0|            0|  0.00%|\n",
      "   808|         0|            0|            0|  0.00%|        .. warning::\n",
      "   809|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   810|         0|            0|            0|  0.00%|\n",
      "   811|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   812|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   813|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.refine_names, (self,), self, *names)\n",
      "   814|         0|            0|            0|  0.00%|        names = resolve_ellipsis(names, self.names, 'refine_names')\n",
      "   815|         0|            0|            0|  0.00%|        return super(Tensor, self).refine_names(names)\n",
      "   816|         0|            0|            0|  0.00%|\n",
      "   817|         0|            0|            0|  0.00%|    def align_to(self, *names):\n",
      "   818|         0|            0|            0|  0.00%|        r\"\"\"Permutes the dimensions of the :attr:`self` tensor to match the order\n",
      "   819|         0|            0|            0|  0.00%|        specified in :attr:`names`, adding size-one dims for any new names.\n",
      "   820|         0|            0|            0|  0.00%|\n",
      "   821|         0|            0|            0|  0.00%|        All of the dims of :attr:`self` must be named in order to use this method.\n",
      "   822|         0|            0|            0|  0.00%|        The resulting tensor is a view on the original tensor.\n",
      "   823|         0|            0|            0|  0.00%|\n",
      "   824|         0|            0|            0|  0.00%|        All dimension names of :attr:`self` must be present in :attr:`names`.\n",
      "   825|         0|            0|            0|  0.00%|        :attr:`names` may contain additional names that are not in ``self.names``;\n",
      "   826|         0|            0|            0|  0.00%|        the output tensor has a size-one dimension for each of those new names.\n",
      "   827|         0|            0|            0|  0.00%|\n",
      "   828|         0|            0|            0|  0.00%|        :attr:`names` may contain up to one Ellipsis (``...``).\n",
      "   829|         0|            0|            0|  0.00%|        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n",
      "   830|         0|            0|            0|  0.00%|        that are not mentioned in :attr:`names`, in the order that they appear\n",
      "   831|         0|            0|            0|  0.00%|        in :attr:`self`.\n",
      "   832|         0|            0|            0|  0.00%|\n",
      "   833|         0|            0|            0|  0.00%|        Python 2 does not support Ellipsis but one may use a string literal\n",
      "   834|         0|            0|            0|  0.00%|        instead (``'...'``).\n",
      "   835|         0|            0|            0|  0.00%|\n",
      "   836|         0|            0|            0|  0.00%|        Args:\n",
      "   837|         0|            0|            0|  0.00%|            names (iterable of str): The desired dimension ordering of the\n",
      "   838|         0|            0|            0|  0.00%|                output tensor. May contain up to one Ellipsis that is expanded\n",
      "   839|         0|            0|            0|  0.00%|                to all unmentioned dim names of :attr:`self`.\n",
      "   840|         0|            0|            0|  0.00%|\n",
      "   841|         0|            0|            0|  0.00%|        Examples::\n",
      "   842|         0|            0|            0|  0.00%|\n",
      "   843|         0|            0|            0|  0.00%|            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n",
      "   844|         0|            0|            0|  0.00%|            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   845|         0|            0|            0|  0.00%|\n",
      "   846|         0|            0|            0|  0.00%|            # Move the F and E dims to the front while keeping the rest in order\n",
      "   847|         0|            0|            0|  0.00%|            >>> named_tensor.align_to('F', 'E', ...)\n",
      "   848|         0|            0|            0|  0.00%|\n",
      "   849|         0|            0|            0|  0.00%|        .. warning::\n",
      "   850|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   851|         0|            0|            0|  0.00%|\n",
      "   852|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   853|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   854|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.align_to, (self,), self, *names)\n",
      "   855|         0|            0|            0|  0.00%|        ellipsis_idx = single_ellipsis_index(names, 'align_to')\n",
      "   856|         0|            0|            0|  0.00%|        if ellipsis_idx is None:\n",
      "   857|         0|            0|            0|  0.00%|            return super(Tensor, self).align_to(names)\n",
      "   858|         0|            0|            0|  0.00%|        return super(Tensor, self).align_to(\n",
      "   859|         0|            0|            0|  0.00%|            [name for name in names if not is_ellipsis(name)],\n",
      "   860|         0|            0|            0|  0.00%|            ellipsis_idx)\n",
      "   861|         0|            0|            0|  0.00%|\n",
      "   862|         0|            0|            0|  0.00%|    def unflatten(self, dim, sizes):\n",
      "   863|         0|            0|            0|  0.00%|        r\"\"\"Expands the dimension :attr:`dim` of the :attr:`self` tensor over multiple dimensions\n",
      "   864|         0|            0|            0|  0.00%|        of sizes given by :attr:`sizes`.\n",
      "   865|         0|            0|            0|  0.00%|\n",
      "   866|         0|            0|            0|  0.00%|        * :attr:`sizes` is the new shape of the unflattened dimension and it can be a `Tuple[int]` as well\n",
      "   867|         0|            0|            0|  0.00%|          as `torch.Size` if :attr:`self` is a `Tensor`, or `namedshape` (Tuple[(name: str, size: int)])\n",
      "   868|         0|            0|            0|  0.00%|          if :attr:`self` is a `NamedTensor`. The total number of elements in sizes must match the number\n",
      "   869|         0|            0|            0|  0.00%|          of elements in the original dim being unflattened.\n",
      "   870|         0|            0|            0|  0.00%|\n",
      "   871|         0|            0|            0|  0.00%|        Args:\n",
      "   872|         0|            0|            0|  0.00%|            dim (Union[int, str]): Dimension to unflatten\n",
      "   873|         0|            0|            0|  0.00%|            sizes (Union[Tuple[int] or torch.Size, Tuple[Tuple[str, int]]]): New shape of the unflattened dimension\n",
      "   874|         0|            0|            0|  0.00%|\n",
      "   875|         0|            0|            0|  0.00%|        Examples:\n",
      "   876|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (2, 2)).shape\n",
      "   877|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])\n",
      "   878|         0|            0|            0|  0.00%|            >>> torch.randn(3, 4, 1).unflatten(1, (-1, 2)).shape # the size -1 is inferred from the size of dimension 1\n",
      "   879|         0|            0|            0|  0.00%|            torch.Size([3, 2, 2, 1])\n",
      "   880|         0|            0|            0|  0.00%|            >>> torch.randn(2, 4, names=('A', 'B')).unflatten('B', (('B1', 2), ('B2', 2)))\n",
      "   881|         0|            0|            0|  0.00%|            tensor([[[-1.1772,  0.0180],\n",
      "   882|         0|            0|            0|  0.00%|                    [ 0.2412,  0.1431]],\n",
      "   883|         0|            0|            0|  0.00%|                    [[-1.1819, -0.8899],\n",
      "   884|         0|            0|            0|  0.00%|                    [ 1.5813,  0.2274]]], names=('A', 'B1', 'B2'))\n",
      "   885|         0|            0|            0|  0.00%|            >>> torch.randn(2, names=('A',)).unflatten('A', (('B1', -1), ('B2', 1)))\n",
      "   886|         0|            0|            0|  0.00%|            tensor([[-0.8591],\n",
      "   887|         0|            0|            0|  0.00%|                    [ 0.3100]], names=('B1', 'B2'))\n",
      "   888|         0|            0|            0|  0.00%|\n",
      "   889|         0|            0|            0|  0.00%|        .. warning::\n",
      "   890|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   891|         0|            0|            0|  0.00%|\n",
      "   892|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   893|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   894|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)\n",
      "   895|         0|            0|            0|  0.00%|\n",
      "   896|         0|            0|            0|  0.00%|        if not sizes:\n",
      "   897|         0|            0|            0|  0.00%|            raise RuntimeError(\"unflatten: sizes must be non-empty\")\n",
      "   898|         0|            0|            0|  0.00%|\n",
      "   899|         0|            0|            0|  0.00%|        names = None\n",
      "   900|         0|            0|            0|  0.00%|        if isinstance(sizes, OrderedDict) or (isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))):\n",
      "   901|         0|            0|            0|  0.00%|            names, sizes = unzip_namedshape(sizes)\n",
      "   902|         0|            0|            0|  0.00%|        return super(Tensor, self).unflatten(dim, sizes, names)\n",
      "   903|         0|            0|            0|  0.00%|\n",
      "   904|         0|            0|            0|  0.00%|\n",
      "   905|         0|            0|            0|  0.00%|    def rename_(self, *names, **rename_map):\n",
      "   906|         0|            0|            0|  0.00%|        \"\"\"In-place version of :meth:`~Tensor.rename`.\"\"\"\n",
      "   907|         0|            0|            0|  0.00%|\n",
      "   908|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   909|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename_, (self,), self, *names, **rename_map)\n",
      "   910|         0|            0|            0|  0.00%|\n",
      "   911|         0|            0|            0|  0.00%|        # Note [rename_ / rename API]\n",
      "   912|         0|            0|            0|  0.00%|        # The Python API for these is different from the C++ API. In Python:\n",
      "   913|         0|            0|            0|  0.00%|        # 1) tensor.rename(*names) takes a vararglist of names\n",
      "   914|         0|            0|            0|  0.00%|        # 2) tensor.rename(**rename_map) takes a map of names to rename.\n",
      "   915|         0|            0|            0|  0.00%|        # C++ is static, making it difficult to implement similar behavior.\n",
      "   916|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=True)\n",
      "   917|         0|            0|            0|  0.00%|\n",
      "   918|         0|            0|            0|  0.00%|    def rename(self, *names, **rename_map):\n",
      "   919|         0|            0|            0|  0.00%|        \"\"\"Renames dimension names of :attr:`self`.\n",
      "   920|         0|            0|            0|  0.00%|\n",
      "   921|         0|            0|            0|  0.00%|        There are two main usages:\n",
      "   922|         0|            0|            0|  0.00%|\n",
      "   923|         0|            0|            0|  0.00%|        ``self.rename(**rename_map)`` returns a view on tensor that has dims\n",
      "   924|         0|            0|            0|  0.00%|        renamed as specified in the mapping :attr:`rename_map`.\n",
      "   925|         0|            0|            0|  0.00%|\n",
      "   926|         0|            0|            0|  0.00%|        ``self.rename(*names)`` returns a view on tensor, renaming all\n",
      "   927|         0|            0|            0|  0.00%|        dimensions positionally using :attr:`names`.\n",
      "   928|         0|            0|            0|  0.00%|        Use ``self.rename(None)`` to drop names on a tensor.\n",
      "   929|         0|            0|            0|  0.00%|\n",
      "   930|         0|            0|            0|  0.00%|        One cannot specify both positional args :attr:`names` and keyword args\n",
      "   931|         0|            0|            0|  0.00%|        :attr:`rename_map`.\n",
      "   932|         0|            0|            0|  0.00%|\n",
      "   933|         0|            0|            0|  0.00%|        Examples::\n",
      "   934|         0|            0|            0|  0.00%|\n",
      "   935|         0|            0|            0|  0.00%|            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n",
      "   936|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n",
      "   937|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   938|         0|            0|            0|  0.00%|            ('batch', 'channels', 'H', 'W')\n",
      "   939|         0|            0|            0|  0.00%|\n",
      "   940|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename(None)\n",
      "   941|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   942|         0|            0|            0|  0.00%|            (None,)\n",
      "   943|         0|            0|            0|  0.00%|\n",
      "   944|         0|            0|            0|  0.00%|            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n",
      "   945|         0|            0|            0|  0.00%|            >>> renamed_imgs.names\n",
      "   946|         0|            0|            0|  0.00%|            ('batch', 'channel', 'height', 'width')\n",
      "   947|         0|            0|            0|  0.00%|\n",
      "   948|         0|            0|            0|  0.00%|        .. warning::\n",
      "   949|         0|            0|            0|  0.00%|            The named tensor API is experimental and subject to change.\n",
      "   950|         0|            0|            0|  0.00%|\n",
      "   951|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   952|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   953|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.rename, (self,), self, *names, **rename_map)\n",
      "   954|         0|            0|            0|  0.00%|\n",
      "   955|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]\n",
      "   956|         0|            0|            0|  0.00%|        return update_names(self, names, rename_map, inplace=False)\n",
      "   957|         0|            0|            0|  0.00%|\n",
      "   958|         0|            0|            0|  0.00%|    def to_sparse_csr(self):\n",
      "   959|         0|            0|            0|  0.00%|        \"\"\" Convert a tensor to compressed row storage format. Only works with 2D tensors.\n",
      "   960|         0|            0|            0|  0.00%|\n",
      "   961|         0|            0|            0|  0.00%|        Examples::\n",
      "   962|         0|            0|            0|  0.00%|\n",
      "   963|         0|            0|            0|  0.00%|            >>> dense = torch.randn(5, 5)\n",
      "   964|         0|            0|            0|  0.00%|            >>> sparse = dense.to_sparse_csr()\n",
      "   965|         0|            0|            0|  0.00%|            >>> sparse._nnz()\n",
      "   966|         0|            0|            0|  0.00%|            25\n",
      "   967|         0|            0|            0|  0.00%|\n",
      "   968|         0|            0|            0|  0.00%|        \"\"\"\n",
      "   969|         0|            0|            0|  0.00%|        shape = self.size()\n",
      "   970|         0|            0|            0|  0.00%|        fill_value = 0\n",
      "   971|         0|            0|            0|  0.00%|        if len(shape) != 2:\n",
      "   972|         0|            0|            0|  0.00%|            raise RuntimeError(\"Only 2D tensors can be converted to the CSR format but got shape: \", shape)\n",
      "   973|         0|            0|            0|  0.00%|\n",
      "   974|         0|            0|            0|  0.00%|        if self.is_sparse:\n",
      "   975|         0|            0|            0|  0.00%|            coalesced_self = self.coalesce()\n",
      "   976|         0|            0|            0|  0.00%|            row_indices = coalesced_self.indices()[0]\n",
      "   977|         0|            0|            0|  0.00%|            device = coalesced_self.values().device\n",
      "   978|         0|            0|            0|  0.00%|            crow_indices = torch._convert_indices_from_coo_to_csr(\n",
      "   979|         0|            0|            0|  0.00%|                row_indices, self.shape[0], out_int32=row_indices.dtype == torch.int32)\n",
      "   980|         0|            0|            0|  0.00%|            return torch.sparse_csr_tensor(crow_indices,\n",
      "   981|         0|            0|            0|  0.00%|                                           coalesced_self.indices()[1].contiguous(),\n",
      "   982|         0|            0|            0|  0.00%|                                           coalesced_self.values(),\n",
      "   983|         0|            0|            0|  0.00%|                                           size=coalesced_self.shape,\n",
      "   984|         0|            0|            0|  0.00%|                                           dtype=coalesced_self.dtype,\n",
      "   985|         0|            0|            0|  0.00%|                                           device=device)\n",
      "   986|         0|            0|            0|  0.00%|        elif self.is_sparse_csr:\n",
      "   987|         0|            0|            0|  0.00%|            return self\n",
      "   988|         0|            0|            0|  0.00%|        else:\n",
      "   989|         0|            0|            0|  0.00%|            return self.to_sparse().to_sparse_csr()\n",
      "   990|         0|            0|            0|  0.00%|\n",
      "   991|         0|            0|            0|  0.00%|    def _update_names(self, names, inplace):\n",
      "   992|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "   993|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor._update_names, (self,), self, names, inplace)\n",
      "   994|         0|            0|            0|  0.00%|\n",
      "   995|         0|            0|            0|  0.00%|        # See Note [rename_ / rename API]\n",
      "   996|         0|            0|            0|  0.00%|        if inplace:\n",
      "   997|         0|            0|            0|  0.00%|            return super(Tensor, self).rename_(names)\n",
      "   998|         0|            0|            0|  0.00%|        else:\n",
      "   999|         0|            0|            0|  0.00%|            return super(Tensor, self).rename(names)\n",
      "  1000|         0|            0|            0|  0.00%|\n",
      "  1001|         0|            0|            0|  0.00%|    @property\n",
      "  1002|         0|            0|            0|  0.00%|    def grad(self):\n",
      "  1003|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1004|         0|            0|            0|  0.00%|        This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "  1005|         0|            0|            0|  0.00%|        :func:`backward` computes gradients for ``self``.\n",
      "  1006|         0|            0|            0|  0.00%|        The attribute will then contain the gradients computed and future calls to\n",
      "  1007|         0|            0|            0|  0.00%|        :func:`backward` will accumulate (add) gradients into it.\n",
      "  1008|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1009|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1010|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1011|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__get__, (self,), self)  # type: ignore[attr-defined]\n",
      "  1012|         0|            0|            0|  0.00%|\n",
      "  1013|         0|            0|            0|  0.00%|        return self._grad\n",
      "  1014|         0|            0|            0|  0.00%|\n",
      "  1015|         0|            0|            0|  0.00%|    @grad.setter\n",
      "  1016|         0|            0|            0|  0.00%|    def grad(self, new_grad):\n",
      "  1017|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1018|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1019|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__set__, (self,), self, new_grad)  # type: ignore[attr-defined]\n",
      "  1020|         0|            0|            0|  0.00%|        self._grad = new_grad\n",
      "  1021|         0|            0|            0|  0.00%|\n",
      "  1022|         0|            0|            0|  0.00%|    @grad.deleter\n",
      "  1023|         0|            0|            0|  0.00%|    def grad(self):\n",
      "  1024|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1025|         0|            0|            0|  0.00%|            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n",
      "  1026|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.grad.__delete__, (self,), self)  # type: ignore[attr-defined]\n",
      "  1027|         0|            0|            0|  0.00%|        del self._grad\n",
      "  1028|         0|            0|            0|  0.00%|\n",
      "  1029|         0|            0|            0|  0.00%|    @classmethod\n",
      "  1030|         0|            0|            0|  0.00%|    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
      "  1031|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1032|         0|            0|            0|  0.00%|        This __torch_function__ implementation wraps subclasses such that\n",
      "  1033|         0|            0|            0|  0.00%|        methods called on subclasses return a subclass instance instead of\n",
      "  1034|         0|            0|            0|  0.00%|        a ``torch.Tensor`` instance.\n",
      "  1035|         0|            0|            0|  0.00%|\n",
      "  1036|         0|            0|            0|  0.00%|        One corollary to this is that you need coverage for torch.Tensor\n",
      "  1037|         0|            0|            0|  0.00%|        methods if implementing __torch_function__ for subclasses.\n",
      "  1038|         0|            0|            0|  0.00%|\n",
      "  1039|         0|            0|            0|  0.00%|        We recommend always calling ``super().__torch_function__`` as the base\n",
      "  1040|         0|            0|            0|  0.00%|        case when doing the above.\n",
      "  1041|         0|            0|            0|  0.00%|\n",
      "  1042|         0|            0|            0|  0.00%|        While not mandatory, we recommend making `__torch_function__` a classmethod.\n",
      "  1043|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1044|         0|            0|            0|  0.00%|        if kwargs is None:\n",
      "  1045|         0|            0|            0|  0.00%|            kwargs = {}\n",
      "  1046|         0|            0|            0|  0.00%|\n",
      "  1047|         0|            0|            0|  0.00%|        if not all(issubclass(cls, t) for t in types):\n",
      "  1048|         0|            0|            0|  0.00%|            return NotImplemented\n",
      "  1049|         0|            0|            0|  0.00%|\n",
      "  1050|         0|            0|            0|  0.00%|        with _C.DisableTorchFunction():\n",
      "  1051|         0|            0|            0|  0.00%|            ret = func(*args, **kwargs)\n",
      "  1052|         0|            0|            0|  0.00%|            if func in get_default_nowrap_functions():\n",
      "  1053|         0|            0|            0|  0.00%|                return ret\n",
      "  1054|         0|            0|            0|  0.00%|            else:\n",
      "  1055|         0|            0|            0|  0.00%|                return _convert(ret, cls)\n",
      "  1056|         0|            0|            0|  0.00%|\n",
      "  1057|         0|            0|            0|  0.00%|    def __dlpack__(self, stream=None):\n",
      "  1058|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1059|         0|            0|            0|  0.00%|        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_\n",
      "  1060|         0|            0|            0|  0.00%|        of the current tensor to be exported to other libraries.\n",
      "  1061|         0|            0|            0|  0.00%|\n",
      "  1062|         0|            0|            0|  0.00%|        This function will be called from the `from_dlpack` method\n",
      "  1063|         0|            0|            0|  0.00%|        of the library that will consume the capsule. `from_dlpack` passes the current\n",
      "  1064|         0|            0|            0|  0.00%|        stream to this method as part of the specification.\n",
      "  1065|         0|            0|            0|  0.00%|\n",
      "  1066|         0|            0|            0|  0.00%|        Args:\n",
      "  1067|         0|            0|            0|  0.00%|            stream (integer or None): An optional Python integer representing a\n",
      "  1068|         0|            0|            0|  0.00%|            pointer to a CUDA stream. The current stream is synchronized with\n",
      "  1069|         0|            0|            0|  0.00%|            this stream before the capsule is created, and since the capsule\n",
      "  1070|         0|            0|            0|  0.00%|            shares its storage with the tensor this make it safe to access from\n",
      "  1071|         0|            0|            0|  0.00%|            both streams.  If None or -1 is passed then no synchronization is performed.\n",
      "  1072|         0|            0|            0|  0.00%|        \"\"\"\n",
      "  1073|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1074|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)\n",
      "  1075|         0|            0|            0|  0.00%|\n",
      "  1076|         0|            0|            0|  0.00%|        # DLPack capsules can't capture all of PyTorch's semantics,\n",
      "  1077|         0|            0|            0|  0.00%|        # so we prohibit exporting tensors that would lose their properties like\n",
      "  1078|         0|            0|            0|  0.00%|        # requires_grad and having the conjugate bit set.\n",
      "  1079|         0|            0|            0|  0.00%|        if self.requires_grad:\n",
      "  1080|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors that require gradient, use tensor.detach()')\n",
      "  1081|         0|            0|            0|  0.00%|        if self.is_conj():\n",
      "  1082|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors with the conjugate bit set')\n",
      "  1083|         0|            0|            0|  0.00%|        if self.layout != torch.strided:\n",
      "  1084|         0|            0|            0|  0.00%|            raise RuntimeError('Can\\'t export tensors with layout other than torch.strided')\n",
      "  1085|         0|            0|            0|  0.00%|\n",
      "  1086|         0|            0|            0|  0.00%|        if stream is not None and type(stream) is not int:\n",
      "  1087|         0|            0|            0|  0.00%|            # Stream pointers in CUDA/ROCm are uniquely numbered and can\n",
      "  1088|         0|            0|            0|  0.00%|            # be retrieved from their integer value.\n",
      "  1089|         0|            0|            0|  0.00%|            raise TypeError('stream must be ``int`` or ``none``')\n",
      "  1090|         0|            0|            0|  0.00%|        elif stream is not None and stream != -1:\n",
      "  1091|         0|            0|            0|  0.00%|            if self.device.type == 'cuda':\n",
      "  1092|         0|            0|            0|  0.00%|                stream = torch.cuda.streams.ExternalStream(stream)\n",
      "  1093|         0|            0|            0|  0.00%|                # Only synchronize on different streams\n",
      "  1094|         0|            0|            0|  0.00%|                if stream != torch.cuda.current_stream:\n",
      "  1095|         0|            0|            0|  0.00%|                    event = torch.cuda.Event()\n",
      "  1096|         0|            0|            0|  0.00%|                    event.record(torch.cuda.current_stream())\n",
      "  1097|         0|            0|            0|  0.00%|                    stream.wait_event(event)\n",
      "  1098|         0|            0|            0|  0.00%|        return torch.to_dlpack(self)\n",
      "  1099|         0|            0|            0|  0.00%|\n",
      "  1100|         0|            0|            0|  0.00%|    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:\n",
      "  1101|         0|            0|            0|  0.00%|        # Avoid circular import\n",
      "  1102|         0|            0|            0|  0.00%|        from torch.utils.dlpack import DLDeviceType\n",
      "  1103|         0|            0|            0|  0.00%|        if has_torch_function_unary(self):\n",
      "  1104|         0|            0|            0|  0.00%|            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)\n",
      "  1105|         0|            0|            0|  0.00%|        idx = self.device.index if self.device.index is not None else 0\n",
      "  1106|         0|            0|            0|  0.00%|        if self.device.type == 'cuda' and torch.version.hip is not None:\n",
      "  1107|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLROCM\n",
      "  1108|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu' and self.is_pinned():\n",
      "  1109|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPUPinned\n",
      "  1110|         0|            0|            0|  0.00%|        elif self.device.type == 'cuda':\n",
      "  1111|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLGPU\n",
      "  1112|         0|            0|            0|  0.00%|        elif self.device.type == 'cpu':\n",
      "  1113|         0|            0|            0|  0.00%|            device_type = DLDeviceType.kDLCPU\n",
      "  1114|         0|            0|            0|  0.00%|        else:\n",
      "  1115|         0|            0|            0|  0.00%|            raise ValueError('Unknown device type {} for Dlpack'.format(self.device.type))\n",
      "  1116|         0|            0|            0|  0.00%|        return (device_type, idx)\n",
      "  1117|         0|            0|            0|  0.00%|\n",
      "  1118|         0|            0|            0|  0.00%|    __module__ = 'torch'\n",
      "  1119|         0|            0|            0|  0.00%|\n",
      "  1120|         0|            0|            0|  0.00%|def _convert(ret, cls):\n",
      "  1121|         0|            0|            0|  0.00%|    if cls is Tensor:\n",
      "  1122|         0|            0|            0|  0.00%|        return ret\n",
      "  1123|         0|            0|            0|  0.00%|\n",
      "  1124|         0|            0|            0|  0.00%|    if isinstance(ret, Tensor) and not isinstance(ret, cls):\n",
      "  1125|         0|            0|            0|  0.00%|        ret = ret.as_subclass(cls)\n",
      "  1126|         0|            0|            0|  0.00%|\n",
      "  1127|         0|            0|            0|  0.00%|    if isinstance(ret, (tuple, list)):\n",
      "  1128|         0|            0|            0|  0.00%|        # Also handles things like namedtuples\n",
      "  1129|         0|            0|            0|  0.00%|        ret = type(ret)(_convert(r, cls) for r in ret)\n",
      "  1130|         0|            0|            0|  0.00%|\n",
      "  1131|         0|            0|            0|  0.00%|    return ret\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_VF.py\n",
      "File duration: 7.43866e-05s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\"\"\"\n",
      "     2|         0|            0|            0|  0.00%|This makes the functions in torch._C._VariableFunctions available as\n",
      "     3|         0|            0|            0|  0.00%|    torch._VF.<funcname>\n",
      "     4|         0|            0|            0|  0.00%|without mypy being able to find them.\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|A subset of those functions are mapped to ATen functions in\n",
      "     7|         0|            0|            0|  0.00%|torch/jit/_builtins.py\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|See https://github.com/pytorch/pytorch/issues/21478 for the reason for\n",
      "    10|         0|            0|            0|  0.00%|introducing torch._VF\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|\"\"\"\n",
      "    13|         0|            0|            0|  0.00%|import torch\n",
      "    14|         0|            0|            0|  0.00%|import sys\n",
      "    15|         0|            0|            0|  0.00%|import types\n",
      "    16|         0|            0|            0|  0.00%|\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|class VFModule(types.ModuleType):\n",
      "    19|         0|            0|            0|  0.00%|    vf: types.ModuleType\n",
      "    20|         0|            0|            0|  0.00%|\n",
      "    21|         0|            0|            0|  0.00%|    def __init__(self, name):\n",
      "    22|         0|            0|            0|  0.00%|        super(VFModule, self).__init__(name)\n",
      "    23|         0|            0|            0|  0.00%|        self.vf = torch._C._VariableFunctions\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|        11|  2.67029e-05|  2.42753e-06|  0.00%|    def __getattr__(self, attr):\n",
      "    26|        11|  4.76837e-05|  4.33488e-06|  0.00%|        return getattr(self.vf, attr)\n",
      "    27|         0|            0|            0|  0.00%|\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         0|            0|            0|  0.00%|sys.modules[__name__] = VFModule(__name__)\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/_reduction.py\n",
      "File duration: 2.40803e-05s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|from typing import Optional\n",
      "     2|         0|            0|            0|  0.00%|import warnings\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|# NB: Keep this file in sync with enums in aten/src/ATen/core/Reduction.h\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         1|  4.29153e-06|  4.29153e-06|  0.00%|def get_enum(reduction: str) -> int:\n",
      "     8|         1|  1.09673e-05|  1.09673e-05|  0.00%|    if reduction == 'none':\n",
      "     9|         0|            0|            0|  0.00%|        ret = 0\n",
      "    10|         1|   3.8147e-06|   3.8147e-06|  0.00%|    elif reduction == 'mean':\n",
      "    11|         1|  3.09944e-06|  3.09944e-06|  0.00%|        ret = 1\n",
      "    12|         0|            0|            0|  0.00%|    elif reduction == 'elementwise_mean':\n",
      "    13|         0|            0|            0|  0.00%|        warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n",
      "    14|         0|            0|            0|  0.00%|        ret = 1\n",
      "    15|         0|            0|            0|  0.00%|    elif reduction == 'sum':\n",
      "    16|         0|            0|            0|  0.00%|        ret = 2\n",
      "    17|         0|            0|            0|  0.00%|    else:\n",
      "    18|         0|            0|            0|  0.00%|        ret = -1  # TODO: remove once JIT exceptions support control flow\n",
      "    19|         0|            0|            0|  0.00%|        raise ValueError(\"{} is not a valid value for reduction\".format(reduction))\n",
      "    20|         1|  1.90735e-06|  1.90735e-06|  0.00%|    return ret\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|# In order to support previous versions, accept boolean size_average and reduce\n",
      "    23|         0|            0|            0|  0.00%|# and convert them into the new constants for now\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|\n",
      "    26|         0|            0|            0|  0.00%|# We use these functions in torch/legacy as well, in which case we'll silence the warning\n",
      "    27|         0|            0|            0|  0.00%|def legacy_get_string(size_average: Optional[bool], reduce: Optional[bool], emit_warning: bool = True) -> str:\n",
      "    28|         0|            0|            0|  0.00%|    warning = \"size_average and reduce args will be deprecated, please use reduction='{}' instead.\"\n",
      "    29|         0|            0|            0|  0.00%|\n",
      "    30|         0|            0|            0|  0.00%|    if size_average is None:\n",
      "    31|         0|            0|            0|  0.00%|        size_average = True\n",
      "    32|         0|            0|            0|  0.00%|    if reduce is None:\n",
      "    33|         0|            0|            0|  0.00%|        reduce = True\n",
      "    34|         0|            0|            0|  0.00%|\n",
      "    35|         0|            0|            0|  0.00%|    if size_average and reduce:\n",
      "    36|         0|            0|            0|  0.00%|        ret = 'mean'\n",
      "    37|         0|            0|            0|  0.00%|    elif reduce:\n",
      "    38|         0|            0|            0|  0.00%|        ret = 'sum'\n",
      "    39|         0|            0|            0|  0.00%|    else:\n",
      "    40|         0|            0|            0|  0.00%|        ret = 'none'\n",
      "    41|         0|            0|            0|  0.00%|    if emit_warning:\n",
      "    42|         0|            0|            0|  0.00%|        warnings.warn(warning.format(ret))\n",
      "    43|         0|            0|            0|  0.00%|    return ret\n",
      "    44|         0|            0|            0|  0.00%|\n",
      "    45|         0|            0|            0|  0.00%|\n",
      "    46|         0|            0|            0|  0.00%|def legacy_get_enum(size_average: Optional[bool], reduce: Optional[bool], emit_warning: bool = True) -> int:\n",
      "    47|         0|            0|            0|  0.00%|    return get_enum(legacy_get_string(size_average, reduce, emit_warning))\n",
      "File: <string>\n",
      "File duration: 2.02656e-05s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\n",
      "     2|         0|            0|            0|  0.00%|\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         2|  5.24521e-06|   2.6226e-06|  0.00%|\n",
      "    13|         0|            0|            0|  0.00%|\n",
      "    14|         2|  1.50204e-05|  7.51019e-06|  0.00%|\n",
      "File: /Users/sr_old/Desktop/sr2/sr2_functions_new.py\n",
      "File duration: 0s (0.00%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|# TODO: Tensorboard? Or functionality to collect and plot gradients?\n",
      "     2|         0|            0|            0|  0.00%|# clip gradients?\n",
      "     3|         0|            0|            0|  0.00%|\n",
      "     4|         0|            0|            0|  0.00%|\n",
      "     5|         0|            0|            0|  0.00%|colab = False\n",
      "     6|         0|            0|            0|  0.00%|\n",
      "     7|         0|            0|            0|  0.00%|#print(__name__)\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|\n",
      "    10|         0|            0|            0|  0.00%|\n",
      "    11|         0|            0|            0|  0.00%|# Things we set here:\n",
      "    12|         0|            0|            0|  0.00%|#   terminal_output -- where to print\n",
      "    13|         0|            0|            0|  0.00%|#   optimizer\n",
      "    14|         0|            0|            0|  0.00%|#\n",
      "    15|         0|            0|            0|  0.00%|# arbitrary constants: 1000\n",
      "    16|         0|            0|            0|  0.00%|# clip grad norm, patience, big validation loss (twice), training losses placeholder\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|\n",
      "    19|         0|            0|            0|  0.00%|import pprofile\n",
      "    20|         0|            0|            0|  0.00%|profiler = pprofile.Profile()\n",
      "    21|         0|            0|            0|  0.00%|\n",
      "    22|         0|            0|            0|  0.00%|\n",
      "    23|         0|            0|            0|  0.00%|import random\n",
      "    24|         0|            0|            0|  0.00%|from statistics import stdev\n",
      "    25|         0|            0|            0|  0.00%|from random import choice\n",
      "    26|         0|            0|            0|  0.00%|import numpy as np\n",
      "    27|         0|            0|            0|  0.00%|import matplotlib.pyplot as plt\n",
      "    28|         0|            0|            0|  0.00%|from matplotlib.pyplot import rcParams\n",
      "    29|         0|            0|            0|  0.00%|plt.style.use('ggplot')\n",
      "    30|         0|            0|            0|  0.00%|from sympy import *\n",
      "    31|         0|            0|            0|  0.00%|from collections import Counter\n",
      "    32|         0|            0|            0|  0.00%|from sklearn.manifold import TSNE\n",
      "    33|         0|            0|            0|  0.00%|import math\n",
      "    34|         0|            0|            0|  0.00%|from matplotlib.ticker import FuncFormatter\n",
      "    35|         0|            0|            0|  0.00%|import torch\n",
      "    36|         0|            0|            0|  0.00%|from torch.utils.data import DataLoader\n",
      "    37|         0|            0|            0|  0.00%|import torch.optim as optim\n",
      "    38|         0|            0|            0|  0.00%|import datetime\n",
      "    39|         0|            0|            0|  0.00%|import os\n",
      "    40|         0|            0|            0|  0.00%|import sys\n",
      "    41|         0|            0|            0|  0.00%|\n",
      "    42|         0|            0|            0|  0.00%|torch.manual_seed(42)\n",
      "    43|         0|            0|            0|  0.00%|np.random.seed(42)\n",
      "    44|         0|            0|            0|  0.00%|random.seed(0)\n",
      "    45|         0|            0|            0|  0.00%|\n",
      "    46|         0|            0|            0|  0.00%|\n",
      "    47|         0|            0|            0|  0.00%|terminal_output = sys.stdout\n",
      "    48|         0|            0|            0|  0.00%|\n",
      "    49|         0|            0|            0|  0.00%|#if colab:\n",
      "    50|         0|            0|            0|  0.00%|#    terminal_output = sys.stdout\n",
      "    51|         0|            0|            0|  0.00%|#else:\n",
      "    52|         0|            0|            0|  0.00%|#     this outputs to terminal\n",
      "    53|         0|            0|            0|  0.00%|#    terminal_output = open('/dev/stdout', 'w')\n",
      "    54|         0|            0|            0|  0.00%|\n",
      "    55|         0|            0|            0|  0.00%|\n",
      "    56|         0|            0|            0|  0.00%|if colab:\n",
      "    57|         0|            0|            0|  0.00%|    from google.colab import files\n",
      "    58|         0|            0|            0|  0.00%|\n",
      "    59|         0|            0|            0|  0.00%|# if server!?\n",
      "    60|         0|            0|            0|  0.00%|\n",
      "    61|         0|            0|            0|  0.00%|\n",
      "    62|         0|            0|            0|  0.00%|\n",
      "    63|         0|            0|            0|  0.00%|####################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    64|         0|            0|            0|  0.00%|## Equations/data utilities\n",
      "    65|         0|            0|            0|  0.00%|####################################################################################################\n",
      "    66|         0|            0|            0|  0.00%|\n",
      "    67|         0|            0|            0|  0.00%|def lambdifier(expr, nvars):\n",
      "    68|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "    69|         0|            0|            0|  0.00%|    # get an expression that accepts numpy\n",
      "    70|         0|            0|            0|  0.00%|\n",
      "    71|         0|            0|            0|  0.00%|    v_names = [\"x\" + str(k) for k in range(nvars)]\n",
      "    72|         0|            0|            0|  0.00%|    for name in v_names:\n",
      "    73|         0|            0|            0|  0.00%|        globals()[name] = symbols(name)\n",
      "    74|         0|            0|            0|  0.00%|\n",
      "    75|         0|            0|            0|  0.00%|    # the case when f_d is just a number\n",
      "    76|         0|            0|            0|  0.00%|    if len(expr.free_symbols) == 0:\n",
      "    77|         0|            0|            0|  0.00%|        return round(float(expr), 2)\n",
      "    78|         0|            0|            0|  0.00%|\n",
      "    79|         0|            0|            0|  0.00%|    expr_np = lambdify([globals()[name] for name in v_names], expr)\n",
      "    80|         0|            0|            0|  0.00%|\n",
      "    81|         0|            0|            0|  0.00%|    return expr_np\n",
      "    82|         0|            0|            0|  0.00%|\n",
      "    83|         0|            0|            0|  0.00%|\n",
      "    84|         0|            0|            0|  0.00%|def subber(matchobj, items, item_probs):\n",
      "    85|         0|            0|            0|  0.00%|    # 17NOV21\n",
      "    86|         0|            0|            0|  0.00%|    # this function does not depend on matchobj, but it needs to be there as a variable\n",
      "    87|         0|            0|            0|  0.00%|    # sample one of the items and return\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|    # item_probs are allowed not sum to 1, but must be between 1 and 0\n",
      "    90|         0|            0|            0|  0.00%|    out = items[np.argmax(np.random.multinomial(1, item_probs))]\n",
      "    91|         0|            0|            0|  0.00%|\n",
      "    92|         0|            0|            0|  0.00%|    return out\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|def illustrator_list(lengths, strn, bins = 150):\n",
      "    95|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "    96|         0|            0|            0|  0.00%|    # lengths = [len(k) for k in texts]\n",
      "    97|         0|            0|            0|  0.00%|    # round entries beforehand!\n",
      "    98|         0|            0|            0|  0.00%|\n",
      "    99|         0|            0|            0|  0.00%|    print(\"\")\n",
      "   100|         0|            0|            0|  0.00%|    print(\"corpus size,    min,    max:\")\n",
      "   101|         0|            0|            0|  0.00%|    print((len(lengths), min(lengths), max(lengths)))\n",
      "   102|         0|            0|            0|  0.00%|    print(\"mean:\")\n",
      "   103|         0|            0|            0|  0.00%|    print(round(sum(lengths) / len(lengths), 2))\n",
      "   104|         0|            0|            0|  0.00%|    #print(\"mode:\")\n",
      "   105|         0|            0|            0|  0.00%|    #print(max(set(lengths), key=lengths.count))\n",
      "   106|         0|            0|            0|  0.00%|    print(\"SD:\")\n",
      "   107|         0|            0|            0|  0.00%|    print(stdev(lengths))\n",
      "   108|         0|            0|            0|  0.00%|    print(\"min tail:\")\n",
      "   109|         0|            0|            0|  0.00%|    S = sorted(lengths, reverse=False)\n",
      "   110|         0|            0|            0|  0.00%|    print(S[:10])\n",
      "   111|         0|            0|            0|  0.00%|    print(\"max tail:\")\n",
      "   112|         0|            0|            0|  0.00%|    print(S[:10])\n",
      "   113|         0|            0|            0|  0.00%|    print(\"\")\n",
      "   114|         0|            0|            0|  0.00%|\n",
      "   115|         0|            0|            0|  0.00%|    a = np.array(lengths)\n",
      "   116|         0|            0|            0|  0.00%|    rcParams['figure.figsize'] = 5, 5\n",
      "   117|         0|            0|            0|  0.00%|    plt.hist(a, bins=bins)\n",
      "   118|         0|            0|            0|  0.00%|    plt.title(strn + \"\\nN = \" + str(len(lengths)), fontsize=15)\n",
      "   119|         0|            0|            0|  0.00%|    plt.grid(True)\n",
      "   120|         0|            0|            0|  0.00%|    plt.ylabel(\"Number of items\", fontsize = 15)\n",
      "   121|         0|            0|            0|  0.00%|    # here set the plot range\n",
      "   122|         0|            0|            0|  0.00%|#    plt.xlim([0.0, 50.0])\n",
      "   123|         0|            0|            0|  0.00%|#    plt.xticks(range(0, 50, 4))\n",
      "   124|         0|            0|            0|  0.00%|\n",
      "   125|         0|            0|            0|  0.00%|    plt.tick_params(labelsize=12)\n",
      "   126|         0|            0|            0|  0.00%|    plt.show()\n",
      "   127|         0|            0|            0|  0.00%|\n",
      "   128|         0|            0|            0|  0.00%|\n",
      "   129|         0|            0|            0|  0.00%|\n",
      "   130|         0|            0|            0|  0.00%|\n",
      "   131|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   132|         0|            0|            0|  0.00%|## PyTorch functions\n",
      "   133|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   134|         0|            0|            0|  0.00%|\n",
      "   135|         0|            0|            0|  0.00%|def batcher(dataset, bsize):\n",
      "   136|         0|            0|            0|  0.00%|    # 9MAY22\n",
      "   137|         0|            0|            0|  0.00%|    # go from a dataset object to batches without using a data loader\n",
      "   138|         0|            0|            0|  0.00%|    indexes = range(0, len(dataset), bsize)\n",
      "   139|         0|            0|            0|  0.00%|    for i in indexes:\n",
      "   140|         0|            0|            0|  0.00%|        yield dataset[i:i+bsize]\n",
      "   141|         0|            0|            0|  0.00%|\n",
      "   142|         0|            0|            0|  0.00%|\n",
      "   143|         0|            0|            0|  0.00%|\n",
      "   144|         0|            0|            0|  0.00%|def train_epoch(model, lossmaker, train_loader, optimizers, acc_steps, device, epoch):\n",
      "   145|         0|            0|            0|  0.00%|    # 16APR22\n",
      "   146|         0|            0|            0|  0.00%|    # runs through the training set once and trains the model using batches\n",
      "   147|         0|            0|            0|  0.00%|    # collects and returns batch losses as a list\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         0|            0|            0|  0.00%|    model.train()\n",
      "   150|         0|            0|            0|  0.00%|    i = 1\n",
      "   151|         0|            0|            0|  0.00%|    loss_item = 0\n",
      "   152|         0|            0|            0|  0.00%|    losses = []\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         0|            0|            0|  0.00%|\n",
      "   155|         0|            0|            0|  0.00%|    for x, y in train_loader:\n",
      "   156|         0|            0|            0|  0.00%|\n",
      "   157|         0|            0|            0|  0.00%|        # reassignment ok, yes?\n",
      "   158|         0|            0|            0|  0.00%|        # because we call .backward() and destroy computation graph?\n",
      "   159|         0|            0|            0|  0.00%|\n",
      "   160|         0|            0|            0|  0.00%|        with profiler:\n",
      "   161|         0|            0|            0|  0.00%|            loss = lossmaker(x, y, model, device, epoch)/acc_steps\n",
      "(call)|         1|    0.0883031|    0.0883031|  1.11%|# <ipython-input-176-5d68b8565542>:1 lossmaker1\n",
      "   162|         0|            0|            0|  0.00%|            loss.backward()\n",
      "(call)|         1|     0.116268|     0.116268|  1.46%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/_tensor.py:251 backward\n",
      "   163|         0|            0|            0|  0.00%|\n",
      "   164|         0|            0|            0|  0.00%|            profiler.print_stats()\n",
      "   165|         0|            0|            0|  0.00%|        loss_item = loss_item + loss.item()\n",
      "   166|         0|            0|            0|  0.00%|\n",
      "   167|         0|            0|            0|  0.00%|        if i % acc_steps == 0:\n",
      "   168|         0|            0|            0|  0.00%|            # clip gradients here\n",
      "   169|         0|            0|            0|  0.00%|            torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
      "   170|         0|            0|            0|  0.00%|            # update model parameters\n",
      "   171|         0|            0|            0|  0.00%|            [k.step() for k in optimizers]\n",
      "   172|         0|            0|            0|  0.00%|            # erase gradients\n",
      "   173|         0|            0|            0|  0.00%|            #[k.zero_grad() for k in optimizers]\n",
      "   174|         0|            0|            0|  0.00%|            model.zero_grad(set_to_none=True)\n",
      "   175|         0|            0|            0|  0.00%|            # save full_batch loss\n",
      "   176|         0|            0|            0|  0.00%|            losses.append(loss_item)\n",
      "   177|         0|            0|            0|  0.00%|            loss_item = 0\n",
      "   178|         0|            0|            0|  0.00%|\n",
      "   179|         0|            0|            0|  0.00%|        i = i + 1\n",
      "   180|         0|            0|            0|  0.00%|\n",
      "   181|         0|            0|            0|  0.00%|    return losses\n",
      "   182|         0|            0|            0|  0.00%|\n",
      "   183|         0|            0|            0|  0.00%|\n",
      "   184|         0|            0|            0|  0.00%|def epochend_lcalc(model, lossmaker, loader, device, epoch):\n",
      "   185|         0|            0|            0|  0.00%|    # 17APR22\n",
      "   186|         0|            0|            0|  0.00%|    # this function returns the train or validation loss (e.g. at the end of an epoch, or for evaluation)\n",
      "   187|         0|            0|            0|  0.00%|    # the loader given can be either train or val\n",
      "   188|         0|            0|            0|  0.00%|    # here the model is in evaluation mode, so training loss could come out a bit shifted wrt batch evals (?)\n",
      "   189|         0|            0|            0|  0.00%|    # you could code up e.g. accuracy here as well\n",
      "   190|         0|            0|            0|  0.00%|\n",
      "   191|         0|            0|            0|  0.00%|    model.eval()\n",
      "   192|         0|            0|            0|  0.00%|\n",
      "   193|         0|            0|            0|  0.00%|    with torch.no_grad():\n",
      "   194|         0|            0|            0|  0.00%|        losses = []\n",
      "   195|         0|            0|            0|  0.00%|\n",
      "   196|         0|            0|            0|  0.00%|        for x, y in loader:\n",
      "   197|         0|            0|            0|  0.00%|            loss_item = lossmaker(x, y, model, device, epoch).item()\n",
      "   198|         0|            0|            0|  0.00%|            losses.append(loss_item)\n",
      "   199|         0|            0|            0|  0.00%|\n",
      "   200|         0|            0|            0|  0.00%|    # we average the batch losses, this requires loss additivity of the right kind\n",
      "   201|         0|            0|            0|  0.00%|    return np.mean(losses)\n",
      "   202|         0|            0|            0|  0.00%|\n",
      "   203|         0|            0|            0|  0.00%|\n",
      "   204|         0|            0|            0|  0.00%|\n",
      "   205|         0|            0|            0|  0.00%|\n",
      "   206|         0|            0|            0|  0.00%|\n",
      "   207|         0|            0|            0|  0.00%|def run_model(train_dataset, val_dataset, model_class, lossmaker, device,\n",
      "   208|         0|            0|            0|  0.00%|\n",
      "   209|         0|            0|            0|  0.00%|              lrate, bsize, acc_steps, bsize_eval, epochs, patience = 1000, ratio = 1,\n",
      "   210|         0|            0|            0|  0.00%|\n",
      "   211|         0|            0|            0|  0.00%|              # for saving BOTH the learning curve and the model\n",
      "   212|         0|            0|            0|  0.00%|              save=False, path=\"\", atlas = False,\n",
      "   213|         0|            0|            0|  0.00%|\n",
      "   214|         0|            0|            0|  0.00%|                # we pass these (= the rest) to the model class\n",
      "   215|         0|            0|            0|  0.00%|                **kwargs\n",
      "   216|         0|            0|            0|  0.00%|\n",
      "   217|         0|            0|            0|  0.00%|              ):\n",
      "   218|         0|            0|            0|  0.00%|    # 17APR22\n",
      "   219|         0|            0|            0|  0.00%|    # instantiate and run the model, return the final performance figure, plot the curves\n",
      "   220|         0|            0|            0|  0.00%|    # this is meant to run well both on its own and within a loop for atlases or a loop for optimization\n",
      "   221|         0|            0|            0|  0.00%|    # we leave explicit the parameters that will exist regardless of the model type\n",
      "   222|         0|            0|            0|  0.00%|    # TODO: leave optimizer choice here?\n",
      "   223|         0|            0|            0|  0.00%|    # LR scheduling?\n",
      "   224|         0|            0|            0|  0.00%|    # you could return predictions as well!?\n",
      "   225|         0|            0|            0|  0.00%|\n",
      "   226|         0|            0|            0|  0.00%|    global model_path, epoch\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    # MAKE_MODEL_HERE\n",
      "   229|         0|            0|            0|  0.00%|    m = model_class(**kwargs, device = device).to(device)\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|    # truncate the dictionary:\n",
      "   232|         0|            0|            0|  0.00%|    del kwargs['vocab']\n",
      "   233|         0|            0|            0|  0.00%|    del kwargs['vocab_out']\n",
      "   234|         0|            0|            0|  0.00%|\n",
      "   235|         0|            0|            0|  0.00%|    t = \"{:.0e}\".format(lrate) + '_' + str(ratio) + \"_\"  + str(bsize * acc_steps) + '_' + str(kwargs).replace(\" \", \"\")\n",
      "   236|         0|            0|            0|  0.00%|    t = \"{:.0e}\".format(lrate) + '_' + str(ratio) + \"_\"  + str(bsize * acc_steps) + '_' + str(kwargs).replace(\" \", \"\")\n",
      "   237|         0|            0|            0|  0.00%|    modelpath = path + \"/models\"\n",
      "   238|         0|            0|            0|  0.00%|    atlaspath = path + \"/atlases\"\n",
      "   239|         0|            0|            0|  0.00%|\n",
      "   240|         0|            0|            0|  0.00%|    if colab:\n",
      "   241|         0|            0|            0|  0.00%|        modelpath = '/content/gdrive/MyDrive/' + modelpath\n",
      "   242|         0|            0|            0|  0.00%|        atlaspath = '/content/gdrive/MyDrive/' + atlaspath\n",
      "   243|         0|            0|            0|  0.00%|        # print(modelpath)\n",
      "   244|         0|            0|            0|  0.00%|\n",
      "   245|         0|            0|            0|  0.00%|    if save:\n",
      "   246|         0|            0|            0|  0.00%|        os.makedirs(path, exist_ok=True)\n",
      "   247|         0|            0|            0|  0.00%|        os.makedirs(modelpath, exist_ok=True)\n",
      "   248|         0|            0|            0|  0.00%|        os.makedirs(atlaspath, exist_ok=True)\n",
      "   249|         0|            0|            0|  0.00%|        model_path = os.path.join(modelpath, t + \".pt\")\n",
      "   250|         0|            0|            0|  0.00%|\n",
      "   251|         0|            0|            0|  0.00%|        pic_path = os.path.join(path, t + \".png\")\n",
      "   252|         0|            0|            0|  0.00%|        if colab:\n",
      "   253|         0|            0|            0|  0.00%|            pic_path = os.path.join('/content/gdrive/MyDrive/' + path, t + \".png\")\n",
      "   254|         0|            0|            0|  0.00%|            #print(pic_path)\n",
      "   255|         0|            0|            0|  0.00%|        if atlas:\n",
      "   256|         0|            0|            0|  0.00%|            pic_path = os.path.join(atlaspath, t + \".png\")\n",
      "   257|         0|            0|            0|  0.00%|\n",
      "   258|         0|            0|            0|  0.00%|\n",
      "   259|         0|            0|            0|  0.00%|    start_time = datetime.datetime.now()\n",
      "   260|         0|            0|            0|  0.00%|\n",
      "   261|         0|            0|            0|  0.00%|\n",
      "   262|         0|            0|            0|  0.00%| #   train_loader = DataLoader(train_dataset, batch_size=bsize, shuffle=False)\n",
      "   263|         0|            0|            0|  0.00%| #   train_loader_epochend = DataLoader(train_dataset, batch_size=bsize_eval, shuffle=False)\n",
      "   264|         0|            0|            0|  0.00%| #   val_loader_epochend = DataLoader(val_dataset, batch_size=bsize_eval, shuffle=False)\n",
      "   265|         0|            0|            0|  0.00%|\n",
      "   266|         0|            0|            0|  0.00%|\n",
      "   267|         0|            0|            0|  0.00%|    #optimizer = optim.SGD(m.parameters(), lr=lrate)\n",
      "   268|         0|            0|            0|  0.00%|    #optimizers = [optim.Adam(m.parameters(), lr=lrate)]\n",
      "   269|         0|            0|            0|  0.00%|    optimizers = [optim.Adam(m.encoder.parameters(), lr=lrate), optim.Adam(m.decoder.parameters(), lr=lrate*ratio)]\n",
      "   270|         0|            0|            0|  0.00%|\n",
      "   271|         0|            0|            0|  0.00%|\n",
      "   272|         0|            0|            0|  0.00%|    training_losses_full = []\n",
      "   273|         0|            0|            0|  0.00%|\n",
      "   274|         0|            0|            0|  0.00%|    # these two are introduced for cleaner code: to be deleted later\n",
      "   275|         0|            0|            0|  0.00%|    training_losses = [1000]\n",
      "   276|         0|            0|            0|  0.00%|    val_losses = [1000]\n",
      "   277|         0|            0|            0|  0.00%|\n",
      "   278|         0|            0|            0|  0.00%|    ref_val_loss = 1000\n",
      "   279|         0|            0|            0|  0.00%|    trigger_times = 0\n",
      "   280|         0|            0|            0|  0.00%|    patience = patience\n",
      "   281|         0|            0|            0|  0.00%|\n",
      "   282|         0|            0|            0|  0.00%|    for epoch in range(epochs):\n",
      "   283|         0|            0|            0|  0.00%|\n",
      "   284|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Starting epoch \" + str(epoch), file=terminal_output)\n",
      "   285|         0|            0|            0|  0.00%|\n",
      "   286|         0|            0|            0|  0.00%|        # TRAINING\n",
      "   287|         0|            0|            0|  0.00%|        training_losses_full += train_epoch(m, lossmaker, batcher(train_dataset, bsize), optimizers, acc_steps, device, epoch)\n",
      "   288|         0|            0|            0|  0.00%|\n",
      "   289|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Calculating figures\", file=terminal_output)\n",
      "   290|         0|            0|            0|  0.00%|\n",
      "   291|         0|            0|            0|  0.00%|        # END-OF-EPOCH loss figures\n",
      "   292|         0|            0|            0|  0.00%|\n",
      "   293|         0|            0|            0|  0.00%|        train_loss = epochend_lcalc(m, lossmaker, batcher(train_dataset, bsize_eval), device, epoch)\n",
      "   294|         0|            0|            0|  0.00%|        training_losses.append(train_loss)\n",
      "   295|         0|            0|            0|  0.00%|\n",
      "   296|         0|            0|            0|  0.00%|        val_loss = epochend_lcalc(m, lossmaker, batcher(val_dataset, bsize_eval), device, epoch)\n",
      "   297|         0|            0|            0|  0.00%|\n",
      "   298|         0|            0|            0|  0.00%|        # print(train_loss, val_loss)\n",
      "   299|         0|            0|            0|  0.00%|\n",
      "   300|         0|            0|            0|  0.00%|        # FIRST: save model if current val_loss is the best so far\n",
      "   301|         0|            0|            0|  0.00%|        if val_loss <= min(val_losses):\n",
      "   302|         0|            0|            0|  0.00%|            if save:\n",
      "   303|         0|            0|            0|  0.00%|               #2+3\n",
      "   304|         0|            0|            0|  0.00%|                torch.save(m.state_dict(), model_path)\n",
      "   305|         0|            0|            0|  0.00%|\n",
      "   306|         0|            0|            0|  0.00%|        # SECOND: do the early stopping thing\n",
      "   307|         0|            0|            0|  0.00%|        if val_loss > ref_val_loss:\n",
      "   308|         0|            0|            0|  0.00%|            trigger_times += 1\n",
      "   309|         0|            0|            0|  0.00%|            # here possibly introduce lr scheduling\n",
      "   310|         0|            0|            0|  0.00%|            # optimizer =\n",
      "   311|         0|            0|            0|  0.00%|            if trigger_times == patience:\n",
      "   312|         0|            0|            0|  0.00%|                val_losses.append(val_loss)\n",
      "   313|         0|            0|            0|  0.00%|                print('Early stopping after completing epoch '+ str(epoch))\n",
      "   314|         0|            0|            0|  0.00%|                #print(val_losses)\n",
      "   315|         0|            0|            0|  0.00%|                break\n",
      "   316|         0|            0|            0|  0.00%|            else:\n",
      "   317|         0|            0|            0|  0.00%|                val_losses.append(val_loss)\n",
      "   318|         0|            0|            0|  0.00%|        else:\n",
      "   319|         0|            0|            0|  0.00%|            trigger_times = 0\n",
      "   320|         0|            0|            0|  0.00%|            ref_val_loss = val_loss\n",
      "   321|         0|            0|            0|  0.00%|            val_losses.append(val_loss)\n",
      "   322|         0|            0|            0|  0.00%|\n",
      "   323|         0|            0|            0|  0.00%|        print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  Ending epoch \" + str(epoch) +\n",
      "   324|         0|            0|            0|  0.00%|              \"    train_loss: \" + str(np.round(training_losses[-1], 2)) +\n",
      "   325|         0|            0|            0|  0.00%|              \"   val_loss: \" + str(np.round(val_losses[-1], 2)), file=terminal_output)\n",
      "   326|         0|            0|            0|  0.00%|\n",
      "   327|         0|            0|            0|  0.00%|\n",
      "   328|         0|            0|            0|  0.00%|\n",
      "   329|         0|            0|            0|  0.00%|    end_time = datetime.datetime.now()\n",
      "   330|         0|            0|            0|  0.00%|\n",
      "   331|         0|            0|            0|  0.00%|\n",
      "   332|         0|            0|            0|  0.00%|    val_losses = val_losses[1:]\n",
      "   333|         0|            0|            0|  0.00%|    training_losses = training_losses[1:]\n",
      "   334|         0|            0|            0|  0.00%|\n",
      "   335|         0|            0|            0|  0.00%|    TLOSS = np.round(np.array(training_losses).min(), 4)\n",
      "   336|         0|            0|            0|  0.00%|    VLOSS = np.round(np.array(val_losses).min(), 4)\n",
      "   337|         0|            0|            0|  0.00%|\n",
      "   338|         0|            0|            0|  0.00%|\n",
      "   339|         0|            0|            0|  0.00%|    x = range(1, len(training_losses_full) + 1)\n",
      "   340|         0|            0|            0|  0.00%|\n",
      "   341|         0|            0|            0|  0.00%|    # here we multiply an \"epochs\" array with the number of batch evaluations per epoch\n",
      "   342|         0|            0|            0|  0.00%|    # dataset of 70 and bsize of 20 gives 4 batch evaluations per epoch\n",
      "   343|         0|            0|            0|  0.00%|    # eps = np.arange(1, len(validation_losses) + 1) * math.ceil(len(train_dataset) / (bsize))\n",
      "   344|         0|            0|            0|  0.00%|    # now modify for the gradient accumulation thing:\n",
      "   345|         0|            0|            0|  0.00%|    # // integer division, / float division\n",
      "   346|         0|            0|            0|  0.00%|\n",
      "   347|         0|            0|            0|  0.00%|    evals_per_epoch = math.ceil(len(train_dataset) / (bsize))//acc_steps\n",
      "   348|         0|            0|            0|  0.00%|    #print(\"estimated\")\n",
      "   349|         0|            0|            0|  0.00%|    #print(evals_per_epoch)\n",
      "   350|         0|            0|            0|  0.00%|    #print(\"actual\")\n",
      "   351|         0|            0|            0|  0.00%|    #print(len(training_losses_full)/len(val_losses))\n",
      "   352|         0|            0|            0|  0.00%|    eps = np.arange(1, len(val_losses) + 1) * evals_per_epoch\n",
      "   353|         0|            0|            0|  0.00%|\n",
      "   354|         0|            0|            0|  0.00%|    plt.style.use('default')\n",
      "   355|         0|            0|            0|  0.00%|    rcParams['grid.linestyle'] = \"dotted\"\n",
      "   356|         0|            0|            0|  0.00%|    rcParams['figure.figsize'] = 4, 4\n",
      "   357|         0|            0|            0|  0.00%|\n",
      "   358|         0|            0|            0|  0.00%|\n",
      "   359|         0|            0|            0|  0.00%|    plt.plot(x, training_losses_full, 'r', label='tr_loss_full')  # , linewidth=0.8)\n",
      "   360|         0|            0|            0|  0.00%|    plt.plot(eps, training_losses, 'o-', label='tr_loss', color=\"green\", markersize=4)\n",
      "   361|         0|            0|            0|  0.00%|    plt.plot(eps, val_losses, 'o-', label='val_loss', color=\"blue\", markersize=4)\n",
      "   362|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"best tr_loss:\\n\" + str(TLOSS))\n",
      "   363|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"best val_loss:\\n\" + str(VLOSS))\n",
      "   364|         0|            0|            0|  0.00%|    plt.plot([], [], ' ', label=\"duration:\\n\" + str(end_time - start_time)[0:4])\n",
      "   365|         0|            0|            0|  0.00%|\n",
      "   366|         0|            0|            0|  0.00%|    plt.legend(fontsize=9)\n",
      "   367|         0|            0|            0|  0.00%|\n",
      "   368|         0|            0|            0|  0.00%|    ###############################\n",
      "   369|         0|            0|            0|  0.00%|    axes = plt.gca()\n",
      "   370|         0|            0|            0|  0.00%|    # this is LR\n",
      "   371|         0|            0|            0|  0.00%|    # axes.set_ylim([0, 0.5])\n",
      "   372|         0|            0|            0|  0.00%|\n",
      "   373|         0|            0|            0|  0.00%|    axes.set_ylim([0, 8])\n",
      "   374|         0|            0|            0|  0.00%|\n",
      "   375|         0|            0|            0|  0.00%|    scientific_formatter = FuncFormatter(scientific)\n",
      "   376|         0|            0|            0|  0.00%|    plt.gca().xaxis.set_major_formatter(scientific_formatter)\n",
      "   377|         0|            0|            0|  0.00%|    plt.xticks(rotation=45)\n",
      "   378|         0|            0|            0|  0.00%|    plt.grid(color='black')\n",
      "   379|         0|            0|            0|  0.00%|    axes.set_axisbelow(False)\n",
      "   380|         0|            0|            0|  0.00%|\n",
      "   381|         0|            0|            0|  0.00%|\n",
      "   382|         0|            0|            0|  0.00%|    plt.title(\n",
      "   383|         0|            0|            0|  0.00%|        'lrate:' + \"{:.0e}\".format(lrate) + ', ratio:' + str(ratio) +  ', bsize:' + str(bsize*acc_steps) + ', \\n'\n",
      "   384|         0|            0|            0|  0.00%|        + 'n_epochs:' + str(epoch+1) + ', train:' + str(len(train_dataset)) + ', val:' + str(len(val_dataset)) + ', \\n'\n",
      "   385|         0|            0|            0|  0.00%|             + str(kwargs)[:40] + '\\n' + str(kwargs)[40:],\n",
      "   386|         0|            0|            0|  0.00%|\n",
      "   387|         0|            0|            0|  0.00%|        fontsize=9\n",
      "   388|         0|            0|            0|  0.00%|    )\n",
      "   389|         0|            0|            0|  0.00%|\n",
      "   390|         0|            0|            0|  0.00%|    plt.tight_layout()\n",
      "   391|         0|            0|            0|  0.00%|\n",
      "   392|         0|            0|            0|  0.00%|    if save == True:\n",
      "   393|         0|            0|            0|  0.00%|        plt.savefig(pic_path)\n",
      "   394|         0|            0|            0|  0.00%|      #  if colab:\n",
      "   395|         0|            0|            0|  0.00%|      #      p = os.path.normpath(pic_path)\n",
      "   396|         0|            0|            0|  0.00%|      #      plt.savefig(p)\n",
      "   397|         0|            0|            0|  0.00%|      #      files.download(p)\n",
      "   398|         0|            0|            0|  0.00%|\n",
      "   399|         0|            0|            0|  0.00%|    print(\"\", file=terminal_output)\n",
      "   400|         0|            0|            0|  0.00%|    print(\"best training_loss = %s, best validation_loss = %s\" % (TLOSS, VLOSS), file=terminal_output)\n",
      "   401|         0|            0|            0|  0.00%|    print('Duration_: {}'.format(end_time - start_time), file=terminal_output)\n",
      "   402|         0|            0|            0|  0.00%|\n",
      "   403|         0|            0|            0|  0.00%|    print(\"best training_loss = %s, best validation_loss = %s\" % (TLOSS, VLOSS))\n",
      "   404|         0|            0|            0|  0.00%|    print('Duration_: {}'.format(end_time - start_time))\n",
      "   405|         0|            0|            0|  0.00%|\n",
      "   406|         0|            0|            0|  0.00%|    print(datetime.datetime.now().strftime(\"%H:%M:%S\") + \"  END RUN_MODEL CALL\", file=terminal_output)\n",
      "   407|         0|            0|            0|  0.00%|    print(\"\", file=terminal_output)\n",
      "   408|         0|            0|            0|  0.00%|\n",
      "   409|         0|            0|            0|  0.00%|\n",
      "   410|         0|            0|            0|  0.00%|    return (TLOSS, VLOSS)\n",
      "   411|         0|            0|            0|  0.00%|\n",
      "   412|         0|            0|            0|  0.00%|\n",
      "   413|         0|            0|            0|  0.00%|\n",
      "   414|         0|            0|            0|  0.00%|\n",
      "   415|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   416|         0|            0|            0|  0.00%|## other utils\n",
      "   417|         0|            0|            0|  0.00%|####################################################################################################\n",
      "   418|         0|            0|            0|  0.00%|\n",
      "   419|         0|            0|            0|  0.00%|\n",
      "   420|         0|            0|            0|  0.00%|def unison_shuffler(a, b, rng):\n",
      "   421|         0|            0|            0|  0.00%|    # only np arrays accepted?\n",
      "   422|         0|            0|            0|  0.00%|    assert len(a) == len(b)\n",
      "   423|         0|            0|            0|  0.00%|    p = rng.permutation(len(a))\n",
      "   424|         0|            0|            0|  0.00%|    return a[p], b[p]\n",
      "   425|         0|            0|            0|  0.00%|\n",
      "   426|         0|            0|            0|  0.00%|def scientific(x, pos):\n",
      "   427|         0|            0|            0|  0.00%|    # x:  tick value - ie. what you currently see in yticks\n",
      "   428|         0|            0|            0|  0.00%|    # pos: a position - ie. the index of the tick (from 0 to 9 in this example)\n",
      "   429|         0|            0|            0|  0.00%|    return '%.1E' % x\n",
      "   430|         0|            0|            0|  0.00%|\n",
      "   431|         0|            0|            0|  0.00%|\n",
      "   432|         0|            0|            0|  0.00%|def clean_list(l, index):\n",
      "   433|         0|            0|            0|  0.00%|    # 18NOV22\n",
      "   434|         0|            0|            0|  0.00%|    # this is needed for beam search\n",
      "   435|         0|            0|            0|  0.00%|    # return e.g. [576, [576, 619, 1050]] cleaned up\n",
      "   436|         0|            0|            0|  0.00%|    #            with the last bit according to the expansion index\n",
      "   437|         0|            0|            0|  0.00%|\n",
      "   438|         0|            0|            0|  0.00%|    last_element = l[-1]\n",
      "   439|         0|            0|            0|  0.00%|\n",
      "   440|         0|            0|            0|  0.00%|    if type(last_element) != list:\n",
      "   441|         0|            0|            0|  0.00%|        assert index == 0\n",
      "   442|         0|            0|            0|  0.00%|        return l\n",
      "   443|         0|            0|            0|  0.00%|\n",
      "   444|         0|            0|            0|  0.00%|    last_element = last_element[index]\n",
      "   445|         0|            0|            0|  0.00%|\n",
      "   446|         0|            0|            0|  0.00%|    out = l[:-1]\n",
      "   447|         0|            0|            0|  0.00%|    out.append(last_element)\n",
      "   448|         0|            0|            0|  0.00%|\n",
      "   449|         0|            0|            0|  0.00%|    return out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration: 15.1136s\n",
      "File: /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py\n",
      "File duration: 0.11619s (0.77%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         0|            0|            0|  0.00%|\"\"\"\n",
      "     2|         0|            0|            0|  0.00%|``torch.autograd`` provides classes and functions implementing automatic\n",
      "     3|         0|            0|            0|  0.00%|differentiation of arbitrary scalar valued functions. It requires minimal\n",
      "     4|         0|            0|            0|  0.00%|changes to the existing code - you only need to declare :class:`Tensor` s\n",
      "     5|         0|            0|            0|  0.00%|for which gradients should be computed with the ``requires_grad=True`` keyword.\n",
      "     6|         0|            0|            0|  0.00%|As of now, we only support autograd for floating point :class:`Tensor` types (\n",
      "     7|         0|            0|            0|  0.00%|half, float, double and bfloat16) and complex :class:`Tensor` types (cfloat, cdouble).\n",
      "     8|         0|            0|            0|  0.00%|\"\"\"\n",
      "     9|         0|            0|            0|  0.00%|import torch\n",
      "    10|         0|            0|            0|  0.00%|import warnings\n",
      "    11|         0|            0|            0|  0.00%|\n",
      "    12|         0|            0|            0|  0.00%|from torch.types import _TensorOrTensors\n",
      "    13|         0|            0|            0|  0.00%|from typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n",
      "    14|         0|            0|            0|  0.00%|\n",
      "    15|         0|            0|            0|  0.00%|from .variable import Variable\n",
      "    16|         0|            0|            0|  0.00%|from .function import Function, NestedIOFunction\n",
      "    17|         0|            0|            0|  0.00%|from .gradcheck import gradcheck, gradgradcheck\n",
      "    18|         0|            0|            0|  0.00%|from .grad_mode import no_grad, enable_grad, set_grad_enabled, inference_mode\n",
      "    19|         0|            0|            0|  0.00%|from .anomaly_mode import detect_anomaly, set_detect_anomaly\n",
      "    20|         0|            0|            0|  0.00%|from ..overrides import has_torch_function, handle_torch_function\n",
      "    21|         0|            0|            0|  0.00%|from . import functional\n",
      "    22|         0|            0|            0|  0.00%|from . import forward_ad\n",
      "    23|         0|            0|            0|  0.00%|from . import graph\n",
      "    24|         0|            0|            0|  0.00%|\n",
      "    25|         0|            0|            0|  0.00%|__all__ = ['Variable', 'Function', 'backward', 'grad_mode']\n",
      "    26|         0|            0|            0|  0.00%|\n",
      "    27|         0|            0|            0|  0.00%|_OptionalTensor = Optional[torch.Tensor]\n",
      "    28|         0|            0|            0|  0.00%|\n",
      "    29|         1|  7.86781e-06|  7.86781e-06|  0.00%|def _make_grads(outputs: Sequence[torch.Tensor], grads: Sequence[_OptionalTensor]) -> Tuple[_OptionalTensor, ...]:\n",
      "    30|         1|  4.76837e-06|  4.76837e-06|  0.00%|    new_grads: List[_OptionalTensor] = []\n",
      "    31|         2|  3.14713e-05|  1.57356e-05|  0.00%|    for out, grad in zip(outputs, grads):\n",
      "    32|         1|  4.05312e-06|  4.05312e-06|  0.00%|        if isinstance(grad, torch.Tensor):\n",
      "    33|         0|            0|            0|  0.00%|            if not out.shape == grad.shape:\n",
      "    34|         0|            0|            0|  0.00%|                raise RuntimeError(\"Mismatch in shape: grad_output[\"\n",
      "    35|         0|            0|            0|  0.00%|                                   + str(grads.index(grad)) + \"] has a shape of \"\n",
      "    36|         0|            0|            0|  0.00%|                                   + str(grad.shape) + \" and output[\"\n",
      "    37|         0|            0|            0|  0.00%|                                   + str(outputs.index(out)) + \"] has a shape of \"\n",
      "    38|         0|            0|            0|  0.00%|                                   + str(out.shape) + \".\")\n",
      "    39|         0|            0|            0|  0.00%|            if out.dtype.is_complex != grad.dtype.is_complex:\n",
      "    40|         0|            0|            0|  0.00%|                raise RuntimeError(\"For complex Tensors, both grad_output and output\"\n",
      "    41|         0|            0|            0|  0.00%|                                   \" are required to have the same dtype.\"\n",
      "    42|         0|            0|            0|  0.00%|                                   \" Mismatch in dtype: grad_output[\"\n",
      "    43|         0|            0|            0|  0.00%|                                   + str(grads.index(grad)) + \"] has a dtype of \"\n",
      "    44|         0|            0|            0|  0.00%|                                   + str(grad.dtype) + \" and output[\"\n",
      "    45|         0|            0|            0|  0.00%|                                   + str(outputs.index(out)) + \"] has a dtype of \"\n",
      "    46|         0|            0|            0|  0.00%|                                   + str(out.dtype) + \".\")\n",
      "    47|         0|            0|            0|  0.00%|            new_grads.append(grad)\n",
      "    48|         1|  2.86102e-06|  2.86102e-06|  0.00%|        elif grad is None:\n",
      "    49|         1|  4.05312e-06|  4.05312e-06|  0.00%|            if out.requires_grad:\n",
      "    50|         1|  4.05312e-06|  4.05312e-06|  0.00%|                if out.numel() != 1:\n",
      "    51|         0|            0|            0|  0.00%|                    raise RuntimeError(\"grad can be implicitly created only for scalar outputs\")\n",
      "    52|         1|   0.00190282|   0.00190282|  0.01%|                new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n",
      "    53|         0|            0|            0|  0.00%|            else:\n",
      "    54|         0|            0|            0|  0.00%|                new_grads.append(None)\n",
      "    55|         0|            0|            0|  0.00%|        else:\n",
      "    56|         0|            0|            0|  0.00%|            raise TypeError(\"gradients can be either Tensors or None, but got \" +\n",
      "    57|         0|            0|            0|  0.00%|                            type(grad).__name__)\n",
      "    58|         1|  5.96046e-06|  5.96046e-06|  0.00%|    return tuple(new_grads)\n",
      "    59|         0|            0|            0|  0.00%|\n",
      "    60|         0|            0|            0|  0.00%|\n",
      "    61|         1|   2.6226e-06|   2.6226e-06|  0.00%|def _tensor_or_tensors_to_tuple(tensors: Optional[_TensorOrTensors], length: int) -> Tuple[_OptionalTensor, ...]:\n",
      "    62|         1|  3.09944e-06|  3.09944e-06|  0.00%|    if tensors is None:\n",
      "    63|         1|  4.05312e-06|  4.05312e-06|  0.00%|        return (None, ) * length\n",
      "    64|         0|            0|            0|  0.00%|    if isinstance(tensors, torch.Tensor):\n",
      "    65|         0|            0|            0|  0.00%|        return (tensors, )\n",
      "    66|         0|            0|            0|  0.00%|    return tuple(tensors)\n",
      "    67|         0|            0|            0|  0.00%|\n",
      "    68|         0|            0|            0|  0.00%|\n",
      "    69|         1|  1.21593e-05|  1.21593e-05|  0.00%|def backward(\n",
      "    70|         0|            0|            0|  0.00%|    tensors: _TensorOrTensors,\n",
      "    71|         0|            0|            0|  0.00%|    grad_tensors: Optional[_TensorOrTensors] = None,\n",
      "    72|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,\n",
      "    73|         0|            0|            0|  0.00%|    create_graph: bool = False,\n",
      "    74|         0|            0|            0|  0.00%|    grad_variables: Optional[_TensorOrTensors] = None,\n",
      "    75|         0|            0|            0|  0.00%|    inputs: Optional[_TensorOrTensors] = None,\n",
      "    76|         0|            0|            0|  0.00%|) -> None:\n",
      "    77|         0|            0|            0|  0.00%|    r\"\"\"Computes the sum of gradients of given tensors with respect to graph\n",
      "    78|         0|            0|            0|  0.00%|    leaves.\n",
      "    79|         0|            0|            0|  0.00%|\n",
      "    80|         0|            0|            0|  0.00%|    The graph is differentiated using the chain rule. If any of ``tensors``\n",
      "    81|         0|            0|            0|  0.00%|    are non-scalar (i.e. their data has more than one element) and require\n",
      "    82|         0|            0|            0|  0.00%|    gradient, then the Jacobian-vector product would be computed, in this\n",
      "    83|         0|            0|            0|  0.00%|    case the function additionally requires specifying ``grad_tensors``.\n",
      "    84|         0|            0|            0|  0.00%|    It should be a sequence of matching length, that contains the \"vector\"\n",
      "    85|         0|            0|            0|  0.00%|    in the Jacobian-vector product, usually the gradient of the differentiated\n",
      "    86|         0|            0|            0|  0.00%|    function w.r.t. corresponding tensors (``None`` is an acceptable value for\n",
      "    87|         0|            0|            0|  0.00%|    all tensors that don't need gradient tensors).\n",
      "    88|         0|            0|            0|  0.00%|\n",
      "    89|         0|            0|            0|  0.00%|    This function accumulates gradients in the leaves - you might need to zero\n",
      "    90|         0|            0|            0|  0.00%|    ``.grad`` attributes or set them to ``None`` before calling it.\n",
      "    91|         0|            0|            0|  0.00%|    See :ref:`Default gradient layouts<default-grad-layouts>`\n",
      "    92|         0|            0|            0|  0.00%|    for details on the memory layout of accumulated gradients.\n",
      "    93|         0|            0|            0|  0.00%|\n",
      "    94|         0|            0|            0|  0.00%|    .. note::\n",
      "    95|         0|            0|            0|  0.00%|        Using this method with ``create_graph=True`` will create a reference cycle\n",
      "    96|         0|            0|            0|  0.00%|        between the parameter and its gradient which can cause a memory leak.\n",
      "    97|         0|            0|            0|  0.00%|        We recommend using ``autograd.grad`` when creating the graph to avoid this.\n",
      "    98|         0|            0|            0|  0.00%|        If you have to use this function, make sure to reset the ``.grad`` fields of your\n",
      "    99|         0|            0|            0|  0.00%|        parameters to ``None`` after use to break the cycle and avoid the leak.\n",
      "   100|         0|            0|            0|  0.00%|\n",
      "   101|         0|            0|            0|  0.00%|    .. note::\n",
      "   102|         0|            0|            0|  0.00%|\n",
      "   103|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_tensors``, and/or call ``backward``\n",
      "   104|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see\n",
      "   105|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   106|         0|            0|            0|  0.00%|\n",
      "   107|         0|            0|            0|  0.00%|    .. note::\n",
      "   108|         0|            0|            0|  0.00%|\n",
      "   109|         0|            0|            0|  0.00%|        When ``inputs`` are provided and a given input is not a leaf,\n",
      "   110|         0|            0|            0|  0.00%|        the current implementation will call its grad_fn (even though it is not strictly needed to get this gradients).\n",
      "   111|         0|            0|            0|  0.00%|        It is an implementation detail on which the user should not rely.\n",
      "   112|         0|            0|            0|  0.00%|        See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
      "   113|         0|            0|            0|  0.00%|\n",
      "   114|         0|            0|            0|  0.00%|    Args:\n",
      "   115|         0|            0|            0|  0.00%|        tensors (Sequence[Tensor] or Tensor): Tensors of which the derivative will be\n",
      "   116|         0|            0|            0|  0.00%|            computed.\n",
      "   117|         0|            0|            0|  0.00%|        grad_tensors (Sequence[Tensor or None] or Tensor, optional): The \"vector\" in\n",
      "   118|         0|            0|            0|  0.00%|            the Jacobian-vector product, usually gradients w.r.t. each element of\n",
      "   119|         0|            0|            0|  0.00%|            corresponding tensors. None values can be specified for scalar Tensors or\n",
      "   120|         0|            0|            0|  0.00%|            ones that don't require grad. If a None value would be acceptable for all\n",
      "   121|         0|            0|            0|  0.00%|            grad_tensors, then this argument is optional.\n",
      "   122|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad\n",
      "   123|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``\n",
      "   124|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient\n",
      "   125|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.\n",
      "   126|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   127|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.\n",
      "   128|         0|            0|            0|  0.00%|            Defaults to ``False``.\n",
      "   129|         0|            0|            0|  0.00%|        inputs (Sequence[Tensor] or Tensor, optional): Inputs w.r.t. which the gradient\n",
      "   130|         0|            0|            0|  0.00%|            be will accumulated into ``.grad``. All other Tensors will be ignored. If\n",
      "   131|         0|            0|            0|  0.00%|            not provided, the gradient is accumulated into all the leaf Tensors that\n",
      "   132|         0|            0|            0|  0.00%|            were used to compute the attr::tensors.\n",
      "   133|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   134|         1|  8.10623e-06|  8.10623e-06|  0.00%|    if grad_variables is not None:\n",
      "   135|         0|            0|            0|  0.00%|        warnings.warn(\"'grad_variables' is deprecated. Use 'grad_tensors' instead.\")\n",
      "   136|         0|            0|            0|  0.00%|        if grad_tensors is None:\n",
      "   137|         0|            0|            0|  0.00%|            grad_tensors = grad_variables\n",
      "   138|         0|            0|            0|  0.00%|        else:\n",
      "   139|         0|            0|            0|  0.00%|            raise RuntimeError(\"'grad_tensors' and 'grad_variables' (deprecated) \"\n",
      "   140|         0|            0|            0|  0.00%|                               \"arguments both passed to backward(). Please only \"\n",
      "   141|         0|            0|            0|  0.00%|                               \"use 'grad_tensors'.\")\n",
      "   142|         1|  2.86102e-06|  2.86102e-06|  0.00%|    if inputs is not None and len(inputs) == 0:\n",
      "   143|         0|            0|            0|  0.00%|        raise RuntimeError(\"'inputs' argument to backward() cannot be empty.\")\n",
      "   144|         0|            0|            0|  0.00%|\n",
      "   145|         1|  5.00679e-06|  5.00679e-06|  0.00%|    tensors = (tensors,) if isinstance(tensors, torch.Tensor) else tuple(tensors)\n",
      "   146|         1|  2.86102e-06|  2.86102e-06|  0.00%|    inputs = (inputs,) if isinstance(inputs, torch.Tensor) else \\\n",
      "   147|         1|  5.00679e-06|  5.00679e-06|  0.00%|        tuple(inputs) if inputs is not None else tuple()\n",
      "   148|         0|            0|            0|  0.00%|\n",
      "   149|         1|  1.12057e-05|  1.12057e-05|  0.00%|    grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, len(tensors))\n",
      "(call)|         1|  9.77516e-06|  9.77516e-06|  0.00%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:61 _tensor_or_tensors_to_tuple\n",
      "   150|         1|  2.12193e-05|  2.12193e-05|  0.00%|    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
      "(call)|         1|   0.00196791|   0.00196791|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/autograd/__init__.py:29 _make_grads\n",
      "   151|         1|  4.05312e-06|  4.05312e-06|  0.00%|    if retain_graph is None:\n",
      "   152|         1|  2.86102e-06|  2.86102e-06|  0.00%|        retain_graph = create_graph\n",
      "   153|         0|            0|            0|  0.00%|\n",
      "   154|         1|  1.00136e-05|  1.00136e-05|  0.00%|    Variable._execution_engine.run_backward(\n",
      "   155|         1|  4.29153e-06|  4.29153e-06|  0.00%|        tensors, grad_tensors_, retain_graph, create_graph, inputs,\n",
      "   156|         1|     0.114123|     0.114123|  0.76%|        allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "   157|         0|            0|            0|  0.00%|\n",
      "   158|         0|            0|            0|  0.00%|\n",
      "   159|         0|            0|            0|  0.00%|def grad(\n",
      "   160|         0|            0|            0|  0.00%|    outputs: _TensorOrTensors,\n",
      "   161|         0|            0|            0|  0.00%|    inputs: _TensorOrTensors,\n",
      "   162|         0|            0|            0|  0.00%|    grad_outputs: Optional[_TensorOrTensors] = None,\n",
      "   163|         0|            0|            0|  0.00%|    retain_graph: Optional[bool] = None,\n",
      "   164|         0|            0|            0|  0.00%|    create_graph: bool = False,\n",
      "   165|         0|            0|            0|  0.00%|    only_inputs: bool = True,\n",
      "   166|         0|            0|            0|  0.00%|    allow_unused: bool = False\n",
      "   167|         0|            0|            0|  0.00%|) -> Tuple[torch.Tensor, ...]:\n",
      "   168|         0|            0|            0|  0.00%|    r\"\"\"Computes and returns the sum of gradients of outputs with respect to\n",
      "   169|         0|            0|            0|  0.00%|    the inputs.\n",
      "   170|         0|            0|            0|  0.00%|\n",
      "   171|         0|            0|            0|  0.00%|    ``grad_outputs`` should be a sequence of length matching ``output``\n",
      "   172|         0|            0|            0|  0.00%|    containing the \"vector\" in Jacobian-vector product, usually the pre-computed\n",
      "   173|         0|            0|            0|  0.00%|    gradients w.r.t. each of the outputs. If an output doesn't require_grad,\n",
      "   174|         0|            0|            0|  0.00%|    then the gradient can be ``None``).\n",
      "   175|         0|            0|            0|  0.00%|\n",
      "   176|         0|            0|            0|  0.00%|    .. note::\n",
      "   177|         0|            0|            0|  0.00%|\n",
      "   178|         0|            0|            0|  0.00%|        If you run any forward ops, create ``grad_outputs``, and/or call ``grad``\n",
      "   179|         0|            0|            0|  0.00%|        in a user-specified CUDA stream context, see\n",
      "   180|         0|            0|            0|  0.00%|        :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
      "   181|         0|            0|            0|  0.00%|\n",
      "   182|         0|            0|            0|  0.00%|    .. note::\n",
      "   183|         0|            0|            0|  0.00%|\n",
      "   184|         0|            0|            0|  0.00%|        ``only_inputs`` argument is deprecated and is ignored now (defaults to ``True``).\n",
      "   185|         0|            0|            0|  0.00%|        To accumulate gradient for other parts of the graph, please use\n",
      "   186|         0|            0|            0|  0.00%|        ``torch.autograd.backward``.\n",
      "   187|         0|            0|            0|  0.00%|\n",
      "   188|         0|            0|            0|  0.00%|    Args:\n",
      "   189|         0|            0|            0|  0.00%|        outputs (sequence of Tensor): outputs of the differentiated function.\n",
      "   190|         0|            0|            0|  0.00%|        inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
      "   191|         0|            0|            0|  0.00%|            returned (and not accumulated into ``.grad``).\n",
      "   192|         0|            0|            0|  0.00%|        grad_outputs (sequence of Tensor): The \"vector\" in the Jacobian-vector product.\n",
      "   193|         0|            0|            0|  0.00%|            Usually gradients w.r.t. each output. None values can be specified for scalar\n",
      "   194|         0|            0|            0|  0.00%|            Tensors or ones that don't require grad. If a None value would be acceptable\n",
      "   195|         0|            0|            0|  0.00%|            for all grad_tensors, then this argument is optional. Default: None.\n",
      "   196|         0|            0|            0|  0.00%|        retain_graph (bool, optional): If ``False``, the graph used to compute the grad\n",
      "   197|         0|            0|            0|  0.00%|            will be freed. Note that in nearly all cases setting this option to ``True``\n",
      "   198|         0|            0|            0|  0.00%|            is not needed and often can be worked around in a much more efficient\n",
      "   199|         0|            0|            0|  0.00%|            way. Defaults to the value of ``create_graph``.\n",
      "   200|         0|            0|            0|  0.00%|        create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "   201|         0|            0|            0|  0.00%|            be constructed, allowing to compute higher order derivative products.\n",
      "   202|         0|            0|            0|  0.00%|            Default: ``False``.\n",
      "   203|         0|            0|            0|  0.00%|        allow_unused (bool, optional): If ``False``, specifying inputs that were not\n",
      "   204|         0|            0|            0|  0.00%|            used when computing outputs (and therefore their grad is always zero)\n",
      "   205|         0|            0|            0|  0.00%|            is an error. Defaults to ``False``.\n",
      "   206|         0|            0|            0|  0.00%|    \"\"\"\n",
      "   207|         0|            0|            0|  0.00%|    outputs = (outputs,) if isinstance(outputs, torch.Tensor) else tuple(outputs)\n",
      "   208|         0|            0|            0|  0.00%|    inputs = (inputs,) if isinstance(inputs, torch.Tensor) else tuple(inputs)\n",
      "   209|         0|            0|            0|  0.00%|    overridable_args = outputs + inputs\n",
      "   210|         0|            0|            0|  0.00%|    if has_torch_function(overridable_args):\n",
      "   211|         0|            0|            0|  0.00%|        return handle_torch_function(\n",
      "   212|         0|            0|            0|  0.00%|            grad,\n",
      "   213|         0|            0|            0|  0.00%|            overridable_args,\n",
      "   214|         0|            0|            0|  0.00%|            outputs,\n",
      "   215|         0|            0|            0|  0.00%|            inputs,\n",
      "   216|         0|            0|            0|  0.00%|            grad_outputs=grad_outputs,\n",
      "   217|         0|            0|            0|  0.00%|            retain_graph=retain_graph,\n",
      "   218|         0|            0|            0|  0.00%|            create_graph=create_graph,\n",
      "   219|         0|            0|            0|  0.00%|            only_inputs=only_inputs,\n",
      "   220|         0|            0|            0|  0.00%|            allow_unused=allow_unused,\n",
      "   221|         0|            0|            0|  0.00%|        )\n",
      "   222|         0|            0|            0|  0.00%|\n",
      "   223|         0|            0|            0|  0.00%|    if not only_inputs:\n",
      "   224|         0|            0|            0|  0.00%|        warnings.warn(\"only_inputs argument is deprecated and is ignored now \"\n",
      "   225|         0|            0|            0|  0.00%|                      \"(defaults to True). To accumulate gradient for other \"\n",
      "   226|         0|            0|            0|  0.00%|                      \"parts of the graph, please use torch.autograd.backward.\")\n",
      "   227|         0|            0|            0|  0.00%|\n",
      "   228|         0|            0|            0|  0.00%|    grad_outputs_ = _tensor_or_tensors_to_tuple(grad_outputs, len(outputs))\n",
      "   229|         0|            0|            0|  0.00%|    grad_outputs_ = _make_grads(outputs, grad_outputs_)\n",
      "   230|         0|            0|            0|  0.00%|\n",
      "   231|         0|            0|            0|  0.00%|    if retain_graph is None:\n",
      "   232|         0|            0|            0|  0.00%|        retain_graph = create_graph\n",
      "   233|         0|            0|            0|  0.00%|\n",
      "   234|         0|            0|            0|  0.00%|    return Variable._execution_engine.run_backward(\n",
      "   235|         0|            0|            0|  0.00%|        outputs, grad_outputs_, retain_graph, create_graph,\n",
      "   236|         0|            0|            0|  0.00%|        inputs, allow_unused, accumulate_grad=False)\n",
      "   237|         0|            0|            0|  0.00%|\n",
      "   238|         0|            0|            0|  0.00%|\n",
      "   239|         0|            0|            0|  0.00%|# This function applies in case of gradient checkpointing for memory\n",
      "   240|         0|            0|            0|  0.00%|# optimization. Currently, gradient checkpointing is supported only if the\n",
      "   241|         0|            0|            0|  0.00%|# execution engine is invoked through torch.autograd.backward() and its\n",
      "   242|         0|            0|            0|  0.00%|# inputs argument is not passed. It is not supported for torch.autograd.grad().\n",
      "   243|         0|            0|            0|  0.00%|# This is because if inputs are specified, the gradient won't be calculated for\n",
      "   244|         0|            0|            0|  0.00%|# anything else e.g. model parameters like weights, bias etc.\n",
      "   245|         0|            0|            0|  0.00%|#\n",
      "   246|         0|            0|            0|  0.00%|# This function returns whether the checkpointing is valid i.e. torch.autograd.backward\n",
      "   247|         0|            0|            0|  0.00%|# or not i.e. torch.autograd.grad. The implementation works by maintaining a thread\n",
      "   248|         0|            0|            0|  0.00%|# local variable in torch/csrc/autograd/engine.cpp which looks at the NodeTask\n",
      "   249|         0|            0|            0|  0.00%|# in the stack and before a NodeTask is executed in evaluate_function, it\n",
      "   250|         0|            0|            0|  0.00%|# checks for whether reentrant backwards is imperative or not.\n",
      "   251|         0|            0|            0|  0.00%|# See https://github.com/pytorch/pytorch/pull/4594 for more discussion/context\n",
      "   252|         0|            0|            0|  0.00%|def _is_checkpoint_valid():\n",
      "   253|         0|            0|            0|  0.00%|    return Variable._execution_engine.is_checkpoint_valid()\n",
      "   254|         0|            0|            0|  0.00%|\n",
      "   255|         0|            0|            0|  0.00%|\n",
      "   256|         0|            0|            0|  0.00%|def variable(*args, **kwargs):\n",
      "   257|         0|            0|            0|  0.00%|    warnings.warn(\"torch.autograd.variable(...) is deprecated, use torch.tensor(...) instead\")\n",
      "   258|         0|            0|            0|  0.00%|    return torch.tensor(*args, **kwargs)\n",
      "   259|         0|            0|            0|  0.00%|\n",
      "   260|         0|            0|            0|  0.00%|if not torch._C._autograd_init():\n",
      "   261|         0|            0|            0|  0.00%|    raise RuntimeError(\"autograd initialization failed\")\n",
      "   262|         0|            0|            0|  0.00%|\n",
      "   263|         0|            0|            0|  0.00%|# Import all native method/classes\n",
      "   264|         0|            0|            0|  0.00%|from torch._C._autograd import (DeviceType, ProfilerActivity, ProfilerState, ProfilerConfig, ProfilerEvent,\n",
      "   265|         0|            0|            0|  0.00%|                                _enable_profiler_legacy, _disable_profiler_legacy, _profiler_enabled,\n",
      "   266|         0|            0|            0|  0.00%|                                _enable_record_function, _set_empty_test_observer, kineto_available,\n",
      "   267|         0|            0|            0|  0.00%|                                _supported_activities, _add_metadata_json, SavedTensor,\n",
      "   268|         0|            0|            0|  0.00%|                                _register_saved_tensors_default_hooks, _reset_saved_tensors_default_hooks)\n",
      "   269|         0|            0|            0|  0.00%|\n",
      "   270|         0|            0|            0|  0.00%|from torch._C._autograd import (_ProfilerResult, _KinetoEvent,\n",
      "   271|         0|            0|            0|  0.00%|                                _prepare_profiler, _enable_profiler, _disable_profiler)\n",
      "   272|         0|            0|            0|  0.00%|\n",
      "   273|         0|            0|            0|  0.00%|from . import profiler\n",
      "File: <ipython-input-176-5d68b8565542>\n",
      "File duration: 0.0572484s (0.38%)\n",
      "Line #|      Hits|         Time| Time per hit|      %|Source code\n",
      "------+----------+-------------+-------------+-------+-----------\n",
      "     1|         1|  1.09673e-05|  1.09673e-05|  0.00%|def lossmaker1(x, y, model, device, epoch):\n",
      "     2|         0|            0|            0|  0.00%|    # our loss function for a single batch\n",
      "     3|         0|            0|            0|  0.00%|    # this can be used both for training and for end-of-epoch evaluation\n",
      "     4|         0|            0|            0|  0.00%|    # (done in other functions)\n",
      "     5|         0|            0|            0|  0.00%|\n",
      "     6|         1|  4.22001e-05|  4.22001e-05|  0.00%|    loss = nn.CrossEntropyLoss(reduction='mean', ignore_index = 0)\n",
      "(call)|         1|  0.000865936|  0.000865936|  0.01%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/loss.py:1143 __init__\n",
      "     7|         0|            0|            0|  0.00%|\n",
      "     8|         0|            0|            0|  0.00%|\n",
      "     9|         0|            0|            0|  0.00%|#   we have: (input_tokens, input_lengths), (output_tokens, output_lengths)\n",
      "    10|         1|  5.00679e-06|  5.00679e-06|  0.00%|    input_tokens, input_lengths = x\n",
      "    11|         1|  1.09673e-05|  1.09673e-05|  0.00%|    input_tokens = input_tokens.to(device)\n",
      "    12|         0|            0|            0|  0.00%|\n",
      "    13|         1|  5.00679e-06|  5.00679e-06|  0.00%|    output_tokens, _ = y\n",
      "    14|         1|  5.96046e-06|  5.96046e-06|  0.00%|    output_tokens = output_tokens.to(device)\n",
      "    15|         0|            0|            0|  0.00%|\n",
      "    16|         1|  2.00272e-05|  2.00272e-05|  0.00%|    token_predictions, attentions = model(input_tokens, input_lengths, output_tokens, epoch)\n",
      "(call)|         1|    0.0828838|    0.0828838|  0.55%|# /Users/sr_old/Desktop/sr2/p3sr2/lib/python3.6/site-packages/torch/nn/modules/module.py:1096 _call_impl\n",
      "    17|         0|            0|            0|  0.00%|\n",
      "    18|         0|            0|            0|  0.00%|    # prediction first, target second\n",
      "    19|         1|  6.19888e-06|  6.19888e-06|  0.00%|    # L_out x B x vocab -> B x vocab x L_out\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-227eefeb9be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0matt_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"z_epoch 8->10\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               )\n",
      "\u001b[0;32m~/Desktop/sr2/sr2_functions_new.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(train_dataset, val_dataset, model_class, lossmaker, device, lrate, bsize, acc_steps, bsize_eval, epochs, patience, ratio, save, path, atlas, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mtraining_losses_full\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossmaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"  Calculating figures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterminal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/sr2_functions_new.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, lossmaker, train_loader, optimizers, acc_steps, device, epoch)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mloss_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_item\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/pprofile/__init__.py\u001b[0m in \u001b[0;36mprint_stats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \"\"\"\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncodeOrReplaceWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mProfileRunnerBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/pprofile/__init__.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, out, filename, commandline, relative_path)\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0;34mu'percent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpercent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                     \u001b[0;34mu'line'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 }, file=out)\n\u001b[0m\u001b[1;32m    797\u001b[0m                 for (\n\u001b[1;32m    798\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/pprofile/__init__.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             self._write(\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 )\n\u001b[1;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sr2/p3sr2/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# \n",
    "outputs = run_model(train_dataset, val_dataset, Luong_full, lossmaker1, device= device, \n",
    "              lrate = 5e-3, ratio = 1, bsize = 16, acc_steps = 2, \n",
    "                                                    bsize_eval = 16, epochs = 8, patience = 2,\n",
    "                    save = True, path = results_path, \n",
    "                  # the below are passed to the model class\n",
    "                vocab = input_lang.n_words, h_size = 30, dropout = 0, n_layers = 2, \n",
    "                    att_method = 'dot', vocab_out = output_lang.n_words,\n",
    "                    c = \"first\"  \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "19:37:38  Starting epoch 0\n",
      "19:38:23  Calculating figures\n",
      "19:38:35  Ending epoch 0    train_loss: 3.05   val_loss: 3.08\n",
      "19:38:35  Starting epoch 1\n",
      "19:39:21  Calculating figures\n",
      "19:39:33  Ending epoch 1    train_loss: 2.67   val_loss: 2.72\n",
      "19:39:33  Starting epoch 2\n",
      "19:40:20  Calculating figures\n",
      "19:40:33  Ending epoch 2    train_loss: 2.51   val_loss: 2.58\n",
      "19:40:33  Starting epoch 3\n",
      "19:41:21  Calculating figures\n",
      "19:41:34  Ending epoch 3    train_loss: 2.4   val_loss: 2.5\n",
      "19:41:34  Starting epoch 4\n",
      "19:42:24  Calculating figures\n",
      "19:42:37  Ending epoch 4    train_loss: 2.33   val_loss: 2.48\n",
      "19:42:37  Starting epoch 5\n",
      "19:43:27  Calculating figures\n",
      "19:43:41  Ending epoch 5    train_loss: 2.26   val_loss: 2.45\n",
      "19:43:41  Starting epoch 6\n",
      "19:44:32  Calculating figures\n",
      "19:44:45  Ending epoch 6    train_loss: 2.18   val_loss: 2.41\n",
      "19:44:45  Starting epoch 7\n",
      "19:45:37  Calculating figures\n",
      "19:45:51  Ending epoch 7    train_loss: 2.12   val_loss: 2.35\n",
      "19:45:51  Starting epoch 8\n",
      "19:46:43  Calculating figures\n",
      "19:46:57  Ending epoch 8    train_loss: 2.04   val_loss: 2.31\n",
      "19:46:57  Starting epoch 9\n",
      "19:47:49  Calculating figures\n",
      "19:48:03  Ending epoch 9    train_loss: 1.97   val_loss: 2.27\n",
      "19:48:03  Starting epoch 10\n",
      "19:48:54  Calculating figures\n",
      "19:49:08  Ending epoch 10    train_loss: 1.92   val_loss: 2.25\n",
      "19:49:08  Starting epoch 11\n",
      "19:49:58  Calculating figures\n",
      "19:50:13  Ending epoch 11    train_loss: 1.87   val_loss: 2.22\n",
      "19:50:13  Starting epoch 12\n",
      "19:51:02  Calculating figures\n",
      "19:51:17  Ending epoch 12    train_loss: 1.82   val_loss: 2.19\n",
      "19:51:17  Starting epoch 13\n",
      "19:52:06  Calculating figures\n",
      "19:52:21  Ending epoch 13    train_loss: 1.79   val_loss: 2.19\n",
      "19:52:21  Starting epoch 14\n",
      "19:53:10  Calculating figures\n",
      "19:53:25  Ending epoch 14    train_loss: 1.75   val_loss: 2.17\n",
      "19:53:25  Starting epoch 15\n",
      "19:54:14  Calculating figures\n",
      "19:54:28  Ending epoch 15    train_loss: 1.72   val_loss: 2.16\n",
      "19:54:28  Starting epoch 16\n",
      "19:55:18  Calculating figures\n",
      "19:55:32  Ending epoch 16    train_loss: 1.7   val_loss: 2.16\n",
      "19:55:32  Starting epoch 17\n",
      "19:56:21  Calculating figures\n",
      "19:56:35  Ending epoch 17    train_loss: 1.67   val_loss: 2.14\n",
      "19:56:35  Starting epoch 18\n",
      "19:57:25  Calculating figures\n",
      "19:57:39  Ending epoch 18    train_loss: 1.65   val_loss: 2.14\n",
      "19:57:39  Starting epoch 19\n",
      "19:58:28  Calculating figures\n",
      "19:58:43  Ending epoch 19    train_loss: 1.62   val_loss: 2.12\n",
      "\n",
      "best training_loss = 1.62, best validation_loss = 2.1233\n",
      "Duration_: 0:21:04.789731\n",
      "best training_loss = 1.62, best validation_loss = 2.1233\n",
      "Duration_: 0:21:04.789731\n",
      "19:58:43  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 2\n",
      "19:58:43  Starting epoch 0\n",
      "19:59:31  Calculating figures\n",
      "19:59:43  Ending epoch 0    train_loss: 3.34   val_loss: 3.36\n",
      "19:59:43  Starting epoch 1\n",
      "20:00:32  Calculating figures\n",
      "20:00:45  Ending epoch 1    train_loss: 3.0   val_loss: 3.06\n",
      "20:00:45  Starting epoch 2\n",
      "20:01:34  Calculating figures\n",
      "20:01:48  Ending epoch 2    train_loss: 2.8   val_loss: 2.92\n",
      "20:01:48  Starting epoch 3\n",
      "20:02:39  Calculating figures\n",
      "20:02:53  Ending epoch 3    train_loss: 2.67   val_loss: 2.76\n",
      "20:02:53  Starting epoch 4\n",
      "20:03:46  Calculating figures\n",
      "20:04:00  Ending epoch 4    train_loss: 2.59   val_loss: 2.68\n",
      "20:04:00  Starting epoch 5\n",
      "20:04:55  Calculating figures\n",
      "20:05:09  Ending epoch 5    train_loss: 2.49   val_loss: 2.65\n",
      "20:05:09  Starting epoch 6\n",
      "20:06:05  Calculating figures\n",
      "20:06:19  Ending epoch 6    train_loss: 2.37   val_loss: 2.53\n",
      "20:06:19  Starting epoch 7\n",
      "20:07:16  Calculating figures\n",
      "20:07:30  Ending epoch 7    train_loss: 2.28   val_loss: 2.47\n",
      "20:07:30  Starting epoch 8\n",
      "20:08:27  Calculating figures\n",
      "20:08:42  Ending epoch 8    train_loss: 2.18   val_loss: 2.4\n",
      "20:08:42  Starting epoch 9\n",
      "20:09:38  Calculating figures\n",
      "20:09:53  Ending epoch 9    train_loss: 2.1   val_loss: 2.34\n",
      "20:09:53  Starting epoch 10\n",
      "20:10:49  Calculating figures\n",
      "20:11:05  Ending epoch 10    train_loss: 2.04   val_loss: 2.31\n",
      "20:11:05  Starting epoch 11\n",
      "20:12:01  Calculating figures\n",
      "20:12:16  Ending epoch 11    train_loss: 1.98   val_loss: 2.26\n",
      "20:12:16  Starting epoch 12\n",
      "20:13:12  Calculating figures\n",
      "20:13:27  Ending epoch 12    train_loss: 1.93   val_loss: 2.24\n",
      "20:13:27  Starting epoch 13\n",
      "20:14:23  Calculating figures\n",
      "20:14:38  Ending epoch 13    train_loss: 1.89   val_loss: 2.21\n",
      "20:14:38  Starting epoch 14\n",
      "20:15:34  Calculating figures\n",
      "20:15:49  Ending epoch 14    train_loss: 1.85   val_loss: 2.2\n",
      "20:15:49  Starting epoch 15\n",
      "20:16:45  Calculating figures\n",
      "20:17:00  Ending epoch 15    train_loss: 1.8   val_loss: 2.17\n",
      "20:17:00  Starting epoch 16\n",
      "20:17:57  Calculating figures\n",
      "20:18:12  Ending epoch 16    train_loss: 1.78   val_loss: 2.17\n",
      "20:18:12  Starting epoch 17\n",
      "20:19:14  Calculating figures\n",
      "20:19:29  Ending epoch 17    train_loss: 1.74   val_loss: 2.15\n",
      "20:19:29  Starting epoch 18\n",
      "20:20:30  Calculating figures\n",
      "20:20:46  Ending epoch 18    train_loss: 1.71   val_loss: 2.14\n",
      "20:20:46  Starting epoch 19\n",
      "20:21:45  Calculating figures\n",
      "20:22:00  Ending epoch 19    train_loss: 1.68   val_loss: 2.14\n",
      "\n",
      "best training_loss = 1.6833, best validation_loss = 2.139\n",
      "Duration_: 0:23:17.419425\n",
      "best training_loss = 1.6833, best validation_loss = 2.139\n",
      "Duration_: 0:23:17.419425\n",
      "20:22:00  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 3\n",
      "20:22:00  Starting epoch 0\n",
      "20:22:55  Calculating figures\n",
      "20:23:08  Ending epoch 0    train_loss: 2.7   val_loss: 2.76\n",
      "20:23:08  Starting epoch 1\n",
      "20:23:57  Calculating figures\n",
      "20:24:10  Ending epoch 1    train_loss: 2.23   val_loss: 2.4\n",
      "20:24:10  Starting epoch 2\n",
      "20:24:59  Calculating figures\n",
      "20:25:12  Ending epoch 2    train_loss: 2.02   val_loss: 2.25\n",
      "20:25:12  Starting epoch 3\n",
      "20:26:04  Calculating figures\n",
      "20:26:18  Ending epoch 3    train_loss: 1.87   val_loss: 2.12\n",
      "20:26:18  Starting epoch 4\n",
      "20:27:09  Calculating figures\n",
      "20:27:24  Ending epoch 4    train_loss: 1.8   val_loss: 2.06\n",
      "20:27:24  Starting epoch 5\n",
      "20:28:15  Calculating figures\n",
      "20:28:29  Ending epoch 5    train_loss: 1.74   val_loss: 2.06\n",
      "20:28:29  Starting epoch 6\n",
      "20:29:20  Calculating figures\n",
      "20:29:36  Ending epoch 6    train_loss: 1.65   val_loss: 2.05\n",
      "20:29:36  Starting epoch 7\n",
      "20:30:28  Calculating figures\n",
      "20:30:44  Ending epoch 7    train_loss: 1.56   val_loss: 2.01\n",
      "20:30:44  Starting epoch 8\n",
      "20:31:36  Calculating figures\n",
      "20:31:51  Ending epoch 8    train_loss: 1.48   val_loss: 1.94\n",
      "20:31:51  Starting epoch 9\n",
      "20:32:47  Calculating figures\n",
      "20:33:02  Ending epoch 9    train_loss: 1.42   val_loss: 1.9\n",
      "20:33:02  Starting epoch 10\n",
      "20:33:56  Calculating figures\n",
      "20:34:11  Ending epoch 10    train_loss: 1.33   val_loss: 1.86\n",
      "20:34:11  Starting epoch 11\n",
      "20:35:03  Calculating figures\n",
      "20:35:19  Ending epoch 11    train_loss: 1.29   val_loss: 1.85\n",
      "20:35:19  Starting epoch 12\n",
      "20:36:12  Calculating figures\n",
      "20:36:27  Ending epoch 12    train_loss: 1.25   val_loss: 1.83\n",
      "20:36:27  Starting epoch 13\n",
      "20:37:21  Calculating figures\n",
      "20:37:37  Ending epoch 13    train_loss: 1.19   val_loss: 1.81\n",
      "20:37:37  Starting epoch 14\n",
      "20:38:29  Calculating figures\n",
      "20:38:44  Ending epoch 14    train_loss: 1.15   val_loss: 1.79\n",
      "20:38:44  Starting epoch 15\n",
      "20:39:37  Calculating figures\n",
      "20:39:52  Ending epoch 15    train_loss: 1.12   val_loss: 1.78\n",
      "20:39:52  Starting epoch 16\n",
      "20:40:46  Calculating figures\n",
      "20:41:01  Ending epoch 16    train_loss: 1.09   val_loss: 1.78\n",
      "20:41:01  Starting epoch 17\n",
      "20:41:53  Calculating figures\n",
      "20:42:08  Ending epoch 17    train_loss: 1.07   val_loss: 1.79\n",
      "20:42:08  Starting epoch 18\n",
      "20:43:00  Calculating figures\n",
      "Early stopping after completing epoch 18\n",
      "\n",
      "best training_loss = 1.0667, best validation_loss = 1.778\n",
      "Duration_: 0:21:15.053894\n",
      "best training_loss = 1.0667, best validation_loss = 1.778\n",
      "Duration_: 0:21:15.053894\n",
      "20:43:16  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 4\n",
      "20:43:16  Starting epoch 0\n",
      "20:44:06  Calculating figures\n",
      "20:44:19  Ending epoch 0    train_loss: 3.08   val_loss: 3.11\n",
      "20:44:19  Starting epoch 1\n",
      "20:45:11  Calculating figures\n",
      "20:45:24  Ending epoch 1    train_loss: 2.65   val_loss: 2.73\n",
      "20:45:24  Starting epoch 2\n",
      "20:46:17  Calculating figures\n",
      "20:46:31  Ending epoch 2    train_loss: 2.37   val_loss: 2.51\n",
      "20:46:31  Starting epoch 3\n",
      "20:47:24  Calculating figures\n",
      "20:47:38  Ending epoch 3    train_loss: 2.16   val_loss: 2.41\n",
      "20:47:38  Starting epoch 4\n",
      "20:48:32  Calculating figures\n",
      "20:48:47  Ending epoch 4    train_loss: 2.06   val_loss: 2.28\n",
      "20:48:47  Starting epoch 5\n",
      "20:49:45  Calculating figures\n",
      "20:50:00  Ending epoch 5    train_loss: 1.95   val_loss: 2.22\n",
      "20:50:00  Starting epoch 6\n",
      "20:50:57  Calculating figures\n",
      "20:51:13  Ending epoch 6    train_loss: 1.86   val_loss: 2.17\n",
      "20:51:13  Starting epoch 7\n",
      "20:52:13  Calculating figures\n",
      "20:52:29  Ending epoch 7    train_loss: 1.77   val_loss: 2.11\n",
      "20:52:29  Starting epoch 8\n",
      "20:53:27  Calculating figures\n",
      "20:53:44  Ending epoch 8    train_loss: 1.68   val_loss: 2.06\n",
      "20:53:44  Starting epoch 9\n",
      "20:54:43  Calculating figures\n",
      "20:54:59  Ending epoch 9    train_loss: 1.58   val_loss: 1.99\n",
      "20:54:59  Starting epoch 10\n",
      "20:55:56  Calculating figures\n",
      "20:56:13  Ending epoch 10    train_loss: 1.53   val_loss: 1.97\n",
      "20:56:13  Starting epoch 11\n",
      "20:57:10  Calculating figures\n",
      "20:57:26  Ending epoch 11    train_loss: 1.46   val_loss: 1.92\n",
      "20:57:26  Starting epoch 12\n",
      "20:58:27  Calculating figures\n",
      "20:58:43  Ending epoch 12    train_loss: 1.42   val_loss: 1.91\n",
      "20:58:43  Starting epoch 13\n",
      "20:59:42  Calculating figures\n",
      "20:59:59  Ending epoch 13    train_loss: 1.39   val_loss: 1.91\n",
      "20:59:59  Starting epoch 14\n",
      "21:00:59  Calculating figures\n",
      "21:01:14  Ending epoch 14    train_loss: 1.33   val_loss: 1.88\n",
      "21:01:14  Starting epoch 15\n",
      "21:02:15  Calculating figures\n",
      "21:02:31  Ending epoch 15    train_loss: 1.3   val_loss: 1.87\n",
      "21:02:31  Starting epoch 16\n",
      "21:03:31  Calculating figures\n",
      "21:03:47  Ending epoch 16    train_loss: 1.27   val_loss: 1.88\n",
      "21:03:47  Starting epoch 17\n",
      "21:04:48  Calculating figures\n",
      "21:05:04  Ending epoch 17    train_loss: 1.23   val_loss: 1.86\n",
      "21:05:04  Starting epoch 18\n",
      "21:06:04  Calculating figures\n",
      "21:06:20  Ending epoch 18    train_loss: 1.18   val_loss: 1.83\n",
      "21:06:20  Starting epoch 19\n",
      "21:07:21  Calculating figures\n",
      "21:07:37  Ending epoch 19    train_loss: 1.17   val_loss: 1.85\n",
      "\n",
      "best training_loss = 1.1731, best validation_loss = 1.8326\n",
      "Duration_: 0:24:20.927499\n",
      "best training_loss = 1.1731, best validation_loss = 1.8326\n",
      "Duration_: 0:24:20.927499\n",
      "21:07:37  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 5\n",
      "21:07:37  Starting epoch 0\n",
      "21:08:28  Calculating figures\n",
      "21:08:43  Ending epoch 0    train_loss: 2.05   val_loss: 2.19\n",
      "21:08:43  Starting epoch 1\n",
      "21:09:35  Calculating figures\n",
      "21:09:50  Ending epoch 1    train_loss: 1.59   val_loss: 1.89\n",
      "21:09:50  Starting epoch 2\n",
      "21:10:44  Calculating figures\n",
      "21:10:59  Ending epoch 2    train_loss: 1.29   val_loss: 1.76\n",
      "21:10:59  Starting epoch 3\n",
      "21:11:52  Calculating figures\n",
      "21:12:08  Ending epoch 3    train_loss: 1.27   val_loss: 1.67\n",
      "21:12:08  Starting epoch 4\n",
      "21:13:01  Calculating figures\n",
      "21:13:16  Ending epoch 4    train_loss: 1.25   val_loss: 1.69\n",
      "21:13:16  Starting epoch 5\n",
      "21:14:11  Calculating figures\n",
      "Early stopping after completing epoch 5\n",
      "\n",
      "best training_loss = 1.1574, best validation_loss = 1.6685\n",
      "Duration_: 0:06:49.512882\n",
      "best training_loss = 1.1574, best validation_loss = 1.6685\n",
      "Duration_: 0:06:49.512882\n",
      "21:14:27  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 6\n",
      "21:14:27  Starting epoch 0\n",
      "21:15:25  Calculating figures\n",
      "21:15:40  Ending epoch 0    train_loss: 2.59   val_loss: 2.67\n",
      "21:15:40  Starting epoch 1\n",
      "21:16:39  Calculating figures\n",
      "21:16:54  Ending epoch 1    train_loss: 2.05   val_loss: 2.26\n",
      "21:16:54  Starting epoch 2\n",
      "21:17:56  Calculating figures\n",
      "21:18:13  Ending epoch 2    train_loss: 1.74   val_loss: 2.07\n",
      "21:18:13  Starting epoch 3\n",
      "21:19:18  Calculating figures\n",
      "21:19:34  Ending epoch 3    train_loss: 1.58   val_loss: 1.91\n",
      "21:19:34  Starting epoch 4\n",
      "21:20:34  Calculating figures\n",
      "21:20:51  Ending epoch 4    train_loss: 1.48   val_loss: 1.89\n",
      "21:20:51  Starting epoch 5\n",
      "21:21:54  Calculating figures\n",
      "21:22:11  Ending epoch 5    train_loss: 1.36   val_loss: 1.8\n",
      "21:22:11  Starting epoch 6\n",
      "21:23:12  Calculating figures\n",
      "21:23:29  Ending epoch 6    train_loss: 1.28   val_loss: 1.76\n",
      "21:23:29  Starting epoch 7\n",
      "21:24:31  Calculating figures\n",
      "21:24:49  Ending epoch 7    train_loss: 1.17   val_loss: 1.7\n",
      "21:24:49  Starting epoch 8\n",
      "21:25:53  Calculating figures\n",
      "21:26:11  Ending epoch 8    train_loss: 1.09   val_loss: 1.68\n",
      "21:26:11  Starting epoch 9\n",
      "21:27:16  Calculating figures\n",
      "21:27:33  Ending epoch 9    train_loss: 1.01   val_loss: 1.66\n",
      "21:27:33  Starting epoch 10\n",
      "21:28:35  Calculating figures\n",
      "21:28:53  Ending epoch 10    train_loss: 0.97   val_loss: 1.66\n",
      "21:28:53  Starting epoch 11\n",
      "21:29:56  Calculating figures\n",
      "21:30:13  Ending epoch 11    train_loss: 0.96   val_loss: 1.7\n",
      "21:30:13  Starting epoch 12\n",
      "21:31:15  Calculating figures\n",
      "Early stopping after completing epoch 12\n",
      "\n",
      "best training_loss = 0.938, best validation_loss = 1.661\n",
      "Duration_: 0:17:06.199325\n",
      "best training_loss = 0.938, best validation_loss = 1.661\n",
      "Duration_: 0:17:06.199325\n",
      "21:31:33  END RUN_MODEL CALL\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1:53:55.798009\n",
      "END ATLAS CALCULATION\n",
      "Duration: 1:53:55.798081\n",
      "21:31:34\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "params = {     # put the longest before the shortest\n",
    "    \"lrate\": [5e-3],   # \n",
    "    \"dropout\": [0],\n",
    "    \"ratio\": [1],             \n",
    "    \"acc_steps\": [2],          \n",
    "    \"bsize\": [16],\n",
    "    \"h_size\": [30, 60, 90],\n",
    "    \"n_layers\": [2, 3],\n",
    "    \"att_method\": ['dot']\n",
    "}\n",
    "\n",
    "keys = params.keys()\n",
    "values = (params[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "start_time  = datetime.datetime.now()  \n",
    "plt.style.use('default')\n",
    "count = 1                   \n",
    "rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "for i in combinations:        \n",
    "        #print(\"Count: \"+str(count))\n",
    "        print(\"Count: \"+str(count), file = terminal_output)\n",
    "\n",
    "                    #####\n",
    "        plt.subplot(3, 2, count)                                                                           \n",
    "        run_model(train_dataset, val_dataset, Luong_full, lossmaker1, device = device, \n",
    "                  bsize_eval = 64 , patience = 2, epochs = 20,\n",
    "                  save = True, path = results_path, atlas = True,\n",
    "                  vocab = input_lang.n_words, vocab_out = output_lang.n_words, c = \"\",\n",
    "                  **i)\n",
    "        count = count+1\n",
    "        print(\"\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time))    \n",
    "print(\"END ATLAS CALCULATION\", file=terminal_output)\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time), file=terminal_output)    \n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"), file=terminal_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "21:51:55  Starting epoch 0\n",
      "21:52:45  Calculating figures\n",
      "21:52:59  Ending epoch 0    train_loss: 2.12   val_loss: 2.24\n",
      "21:52:59  Starting epoch 1\n",
      "21:53:51  Calculating figures\n",
      "21:54:05  Ending epoch 1    train_loss: 1.64   val_loss: 1.85\n",
      "21:54:05  Starting epoch 2\n",
      "21:54:57  Calculating figures\n",
      "21:55:11  Ending epoch 2    train_loss: 1.41   val_loss: 1.78\n",
      "21:55:11  Starting epoch 3\n",
      "21:56:04  Calculating figures\n",
      "21:56:19  Ending epoch 3    train_loss: 1.28   val_loss: 1.67\n",
      "21:56:19  Starting epoch 4\n",
      "21:57:14  Calculating figures\n",
      "21:57:29  Ending epoch 4    train_loss: 1.16   val_loss: 1.67\n",
      "21:57:29  Starting epoch 5\n",
      "21:58:24  Calculating figures\n",
      "21:58:40  Ending epoch 5    train_loss: 1.17   val_loss: 1.69\n",
      "21:58:40  Starting epoch 6\n",
      "21:59:36  Calculating figures\n",
      "21:59:52  Ending epoch 6    train_loss: 1.08   val_loss: 1.65\n",
      "21:59:52  Starting epoch 7\n",
      "22:00:50  Calculating figures\n",
      "22:01:07  Ending epoch 7    train_loss: 1.04   val_loss: 1.66\n",
      "22:01:07  Starting epoch 8\n",
      "22:02:04  Calculating figures\n",
      "22:02:20  Ending epoch 8    train_loss: 1.0   val_loss: 1.65\n",
      "22:02:20  Starting epoch 9\n",
      "22:03:16  Calculating figures\n",
      "22:03:32  Ending epoch 9    train_loss: 0.97   val_loss: 1.66\n",
      "22:03:32  Starting epoch 10\n",
      "22:04:29  Calculating figures\n",
      "22:04:44  Ending epoch 10    train_loss: 0.92   val_loss: 1.65\n",
      "22:04:44  Starting epoch 11\n",
      "22:05:40  Calculating figures\n",
      "22:05:55  Ending epoch 11    train_loss: 0.86   val_loss: 1.62\n",
      "22:05:55  Starting epoch 12\n",
      "22:06:51  Calculating figures\n",
      "22:07:06  Ending epoch 12    train_loss: 0.84   val_loss: 1.66\n",
      "22:07:06  Starting epoch 13\n",
      "22:08:02  Calculating figures\n",
      "22:08:17  Ending epoch 13    train_loss: 0.82   val_loss: 1.65\n",
      "22:08:17  Starting epoch 14\n",
      "22:09:12  Calculating figures\n",
      "22:09:27  Ending epoch 14    train_loss: 0.78   val_loss: 1.7\n",
      "\n",
      "best training_loss = 0.7816, best validation_loss = 1.6229\n",
      "Duration_: 0:17:32.255196\n",
      "best training_loss = 0.7816, best validation_loss = 1.6229\n",
      "Duration_: 0:17:32.255196\n",
      "22:09:28  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 2\n",
      "22:09:28  Starting epoch 0\n",
      "22:10:33  Calculating figures\n",
      "22:10:51  Ending epoch 0    train_loss: 1.96   val_loss: 2.11\n",
      "22:10:51  Starting epoch 1\n",
      "22:11:58  Calculating figures\n",
      "22:12:16  Ending epoch 1    train_loss: 1.37   val_loss: 1.64\n",
      "22:12:16  Starting epoch 2\n",
      "22:13:25  Calculating figures\n",
      "22:13:44  Ending epoch 2    train_loss: 1.14   val_loss: 1.54\n",
      "22:13:44  Starting epoch 3\n",
      "22:14:55  Calculating figures\n",
      "22:15:14  Ending epoch 3    train_loss: 1.02   val_loss: 1.43\n",
      "22:15:14  Starting epoch 4\n",
      "22:16:22  Calculating figures\n",
      "22:16:42  Ending epoch 4    train_loss: 1.03   val_loss: 1.48\n",
      "22:16:42  Starting epoch 5\n",
      "22:17:51  Calculating figures\n",
      "22:18:10  Ending epoch 5    train_loss: 0.95   val_loss: 1.49\n",
      "22:18:10  Starting epoch 6\n",
      "22:19:21  Calculating figures\n",
      "22:19:41  Ending epoch 6    train_loss: 0.92   val_loss: 1.48\n",
      "22:19:41  Starting epoch 7\n",
      "22:20:53  Calculating figures\n",
      "22:21:12  Ending epoch 7    train_loss: 0.87   val_loss: 1.49\n",
      "22:21:12  Starting epoch 8\n",
      "22:22:22  Calculating figures\n",
      "Early stopping after completing epoch 8\n",
      "\n",
      "best training_loss = 0.812, best validation_loss = 1.4291\n",
      "Duration_: 0:13:14.824863\n",
      "best training_loss = 0.812, best validation_loss = 1.4291\n",
      "Duration_: 0:13:14.824863\n",
      "22:22:42  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 3\n",
      "22:22:42  Starting epoch 0\n",
      "22:23:34  Calculating figures\n",
      "22:23:47  Ending epoch 0    train_loss: 2.17   val_loss: 2.3\n",
      "22:23:47  Starting epoch 1\n",
      "22:24:38  Calculating figures\n",
      "22:24:51  Ending epoch 1    train_loss: 1.72   val_loss: 1.95\n",
      "22:24:51  Starting epoch 2\n",
      "22:25:44  Calculating figures\n",
      "22:25:57  Ending epoch 2    train_loss: 1.46   val_loss: 1.81\n",
      "22:25:57  Starting epoch 3\n",
      "22:26:51  Calculating figures\n",
      "22:27:05  Ending epoch 3    train_loss: 1.36   val_loss: 1.74\n",
      "22:27:05  Starting epoch 4\n",
      "22:27:58  Calculating figures\n",
      "22:28:13  Ending epoch 4    train_loss: 1.29   val_loss: 1.67\n",
      "22:28:13  Starting epoch 5\n",
      "22:29:08  Calculating figures\n",
      "22:29:22  Ending epoch 5    train_loss: 1.29   val_loss: 1.72\n",
      "22:29:22  Starting epoch 6\n",
      "22:30:18  Calculating figures\n",
      "22:30:33  Ending epoch 6    train_loss: 1.24   val_loss: 1.7\n",
      "22:30:33  Starting epoch 7\n",
      "22:31:29  Calculating figures\n",
      "22:31:44  Ending epoch 7    train_loss: 1.2   val_loss: 1.68\n",
      "22:31:44  Starting epoch 8\n",
      "22:32:41  Calculating figures\n",
      "22:32:57  Ending epoch 8    train_loss: 1.12   val_loss: 1.64\n",
      "22:32:57  Starting epoch 9\n",
      "22:33:52  Calculating figures\n",
      "22:34:07  Ending epoch 9    train_loss: 1.08   val_loss: 1.64\n",
      "22:34:07  Starting epoch 10\n",
      "22:35:03  Calculating figures\n",
      "22:35:18  Ending epoch 10    train_loss: 1.03   val_loss: 1.6\n",
      "22:35:18  Starting epoch 11\n",
      "22:36:14  Calculating figures\n",
      "22:36:29  Ending epoch 11    train_loss: 0.99   val_loss: 1.57\n",
      "22:36:29  Starting epoch 12\n",
      "22:37:25  Calculating figures\n",
      "22:37:41  Ending epoch 12    train_loss: 0.97   val_loss: 1.59\n",
      "22:37:41  Starting epoch 13\n",
      "22:38:37  Calculating figures\n",
      "22:38:52  Ending epoch 13    train_loss: 0.96   val_loss: 1.59\n",
      "22:38:52  Starting epoch 14\n",
      "22:39:49  Calculating figures\n",
      "22:40:04  Ending epoch 14    train_loss: 0.93   val_loss: 1.6\n",
      "\n",
      "best training_loss = 0.9348, best validation_loss = 1.5717\n",
      "Duration_: 0:17:21.427166\n",
      "best training_loss = 0.9348, best validation_loss = 1.5717\n",
      "Duration_: 0:17:21.427166\n",
      "22:40:04  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 4\n",
      "22:40:04  Starting epoch 0\n",
      "22:41:11  Calculating figures\n",
      "22:41:29  Ending epoch 0    train_loss: 2.13   val_loss: 2.26\n",
      "22:41:29  Starting epoch 1\n",
      "22:42:36  Calculating figures\n",
      "22:42:54  Ending epoch 1    train_loss: 1.51   val_loss: 1.72\n",
      "22:42:54  Starting epoch 2\n",
      "22:44:02  Calculating figures\n",
      "22:44:21  Ending epoch 2    train_loss: 1.22   val_loss: 1.58\n",
      "22:44:21  Starting epoch 3\n",
      "22:45:30  Calculating figures\n",
      "22:45:49  Ending epoch 3    train_loss: 1.18   val_loss: 1.58\n",
      "22:45:49  Starting epoch 4\n",
      "22:47:00  Calculating figures\n",
      "22:47:19  Ending epoch 4    train_loss: 1.1   val_loss: 1.51\n",
      "22:47:19  Starting epoch 5\n",
      "22:48:28  Calculating figures\n",
      "22:48:47  Ending epoch 5    train_loss: 1.05   val_loss: 1.51\n",
      "22:48:47  Starting epoch 6\n",
      "22:49:58  Calculating figures\n",
      "22:50:18  Ending epoch 6    train_loss: 1.03   val_loss: 1.52\n",
      "22:50:18  Starting epoch 7\n",
      "22:51:31  Calculating figures\n",
      "22:51:52  Ending epoch 7    train_loss: 1.01   val_loss: 1.52\n",
      "22:51:52  Starting epoch 8\n",
      "22:53:02  Calculating figures\n",
      "22:53:21  Ending epoch 8    train_loss: 0.94   val_loss: 1.48\n",
      "22:53:21  Starting epoch 9\n",
      "22:54:33  Calculating figures\n",
      "22:54:52  Ending epoch 9    train_loss: 0.89   val_loss: 1.47\n",
      "22:54:52  Starting epoch 10\n",
      "22:56:06  Calculating figures\n",
      "22:56:27  Ending epoch 10    train_loss: 0.88   val_loss: 1.48\n",
      "22:56:27  Starting epoch 11\n",
      "22:57:38  Calculating figures\n",
      "22:57:58  Ending epoch 11    train_loss: 0.85   val_loss: 1.46\n",
      "22:57:58  Starting epoch 12\n",
      "22:59:09  Calculating figures\n",
      "22:59:29  Ending epoch 12    train_loss: 0.81   val_loss: 1.43\n",
      "22:59:29  Starting epoch 13\n",
      "23:00:41  Calculating figures\n",
      "23:01:01  Ending epoch 13    train_loss: 0.8   val_loss: 1.44\n",
      "23:01:01  Starting epoch 14\n",
      "23:02:12  Calculating figures\n",
      "23:02:32  Ending epoch 14    train_loss: 0.78   val_loss: 1.44\n",
      "\n",
      "best training_loss = 0.7808, best validation_loss = 1.4323\n",
      "Duration_: 0:22:27.471917\n",
      "best training_loss = 0.7808, best validation_loss = 1.4323\n",
      "Duration_: 0:22:27.471917\n",
      "23:02:32  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 5\n",
      "23:02:32  Starting epoch 0\n",
      "23:03:22  Calculating figures\n",
      "23:03:36  Ending epoch 0    train_loss: 2.26   val_loss: 2.36\n",
      "23:03:36  Starting epoch 1\n",
      "23:04:27  Calculating figures\n",
      "23:04:41  Ending epoch 1    train_loss: 1.85   val_loss: 2.01\n",
      "23:04:41  Starting epoch 2\n",
      "23:05:33  Calculating figures\n",
      "23:05:47  Ending epoch 2    train_loss: 1.68   val_loss: 1.93\n",
      "23:05:47  Starting epoch 3\n",
      "23:06:39  Calculating figures\n",
      "23:06:54  Ending epoch 3    train_loss: 1.58   val_loss: 1.88\n",
      "23:06:54  Starting epoch 4\n",
      "23:07:47  Calculating figures\n",
      "23:08:01  Ending epoch 4    train_loss: 1.42   val_loss: 1.79\n",
      "23:08:01  Starting epoch 5\n",
      "23:08:56  Calculating figures\n",
      "23:09:11  Ending epoch 5    train_loss: 1.4   val_loss: 1.74\n",
      "23:09:11  Starting epoch 6\n",
      "23:10:06  Calculating figures\n",
      "23:10:21  Ending epoch 6    train_loss: 1.37   val_loss: 1.75\n",
      "23:10:21  Starting epoch 7\n",
      "23:11:17  Calculating figures\n",
      "23:11:33  Ending epoch 7    train_loss: 1.31   val_loss: 1.7\n",
      "23:11:33  Starting epoch 8\n",
      "23:12:28  Calculating figures\n",
      "23:12:44  Ending epoch 8    train_loss: 1.27   val_loss: 1.69\n",
      "23:12:44  Starting epoch 9\n",
      "23:13:41  Calculating figures\n",
      "23:13:56  Ending epoch 9    train_loss: 1.22   val_loss: 1.66\n",
      "23:13:56  Starting epoch 10\n",
      "23:14:51  Calculating figures\n",
      "23:15:07  Ending epoch 10    train_loss: 1.19   val_loss: 1.65\n",
      "23:15:07  Starting epoch 11\n",
      "23:16:02  Calculating figures\n",
      "23:16:18  Ending epoch 11    train_loss: 1.15   val_loss: 1.63\n",
      "23:16:18  Starting epoch 12\n",
      "23:17:13  Calculating figures\n",
      "23:17:28  Ending epoch 12    train_loss: 1.11   val_loss: 1.61\n",
      "23:17:28  Starting epoch 13\n",
      "23:18:24  Calculating figures\n",
      "23:18:39  Ending epoch 13    train_loss: 1.08   val_loss: 1.6\n",
      "23:18:39  Starting epoch 14\n",
      "23:19:35  Calculating figures\n",
      "23:19:50  Ending epoch 14    train_loss: 1.06   val_loss: 1.58\n",
      "\n",
      "best training_loss = 1.0646, best validation_loss = 1.5808\n",
      "Duration_: 0:17:18.237540\n",
      "best training_loss = 1.0646, best validation_loss = 1.5808\n",
      "Duration_: 0:17:18.237540\n",
      "23:19:50  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 6\n",
      "23:19:50  Starting epoch 0\n",
      "23:21:00  Calculating figures\n",
      "23:21:18  Ending epoch 0    train_loss: 2.16   val_loss: 2.28\n",
      "23:21:18  Starting epoch 1\n",
      "23:22:26  Calculating figures\n",
      "23:22:44  Ending epoch 1    train_loss: 1.61   val_loss: 1.79\n",
      "23:22:44  Starting epoch 2\n",
      "23:23:51  Calculating figures\n",
      "23:24:09  Ending epoch 2    train_loss: 1.32   val_loss: 1.69\n",
      "23:24:09  Starting epoch 3\n",
      "23:25:17  Calculating figures\n",
      "23:25:36  Ending epoch 3    train_loss: 1.2   val_loss: 1.52\n",
      "23:25:36  Starting epoch 4\n",
      "23:26:44  Calculating figures\n",
      "23:27:04  Ending epoch 4    train_loss: 1.19   val_loss: 1.56\n",
      "23:27:04  Starting epoch 5\n",
      "23:28:16  Calculating figures\n",
      "23:28:36  Ending epoch 5    train_loss: 1.13   val_loss: 1.53\n",
      "23:28:36  Starting epoch 6\n",
      "23:29:46  Calculating figures\n",
      "23:30:05  Ending epoch 6    train_loss: 1.1   val_loss: 1.53\n",
      "23:30:05  Starting epoch 7\n",
      "23:31:16  Calculating figures\n",
      "23:31:36  Ending epoch 7    train_loss: 1.11   val_loss: 1.56\n",
      "23:31:36  Starting epoch 8\n",
      "23:32:48  Calculating figures\n",
      "23:33:09  Ending epoch 8    train_loss: 1.06   val_loss: 1.51\n",
      "23:33:09  Starting epoch 9\n",
      "23:34:19  Calculating figures\n",
      "23:34:39  Ending epoch 9    train_loss: 1.01   val_loss: 1.47\n",
      "23:34:39  Starting epoch 10\n",
      "23:35:50  Calculating figures\n",
      "23:36:10  Ending epoch 10    train_loss: 0.96   val_loss: 1.44\n",
      "23:36:10  Starting epoch 11\n",
      "23:37:23  Calculating figures\n",
      "23:37:44  Ending epoch 11    train_loss: 0.97   val_loss: 1.47\n",
      "23:37:44  Starting epoch 12\n",
      "23:38:54  Calculating figures\n",
      "23:39:14  Ending epoch 12    train_loss: 0.93   val_loss: 1.43\n",
      "23:39:14  Starting epoch 13\n",
      "23:40:25  Calculating figures\n",
      "23:40:45  Ending epoch 13    train_loss: 0.91   val_loss: 1.44\n",
      "23:40:45  Starting epoch 14\n",
      "23:41:57  Calculating figures\n",
      "23:42:17  Ending epoch 14    train_loss: 0.89   val_loss: 1.42\n",
      "\n",
      "best training_loss = 0.8897, best validation_loss = 1.4166\n",
      "Duration_: 0:22:26.785881\n",
      "best training_loss = 0.8897, best validation_loss = 1.4166\n",
      "Duration_: 0:22:26.785881\n",
      "23:42:18  END RUN_MODEL CALL\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1:50:22.670856\n",
      "END ATLAS CALCULATION\n",
      "Duration: 1:50:22.670910\n",
      "23:42:18\n"
     ]
    }
   ],
   "source": [
    "# Better manually rename the picture saved in the folder.\n",
    "# Otherwise there's a slight risk of it being over\n",
    "\n",
    "params = {     # put the longest before the shortest\n",
    "    \"lrate\": [5e-3],  \n",
    "    \"dropout\": [0, 0.1, 0.2],\n",
    "    \"ratio\": [1],             \n",
    "    \"acc_steps\": [2],          \n",
    "    \"bsize\": [16],\n",
    "    \"h_size\": [90],\n",
    "    \"n_layers\": [2],\n",
    "    \"att_method\": ['dot', 'general']\n",
    "}\n",
    "\n",
    "keys = params.keys()\n",
    "values = (params[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "start_time  = datetime.datetime.now()  \n",
    "plt.style.use('default')\n",
    "count = 1                   \n",
    "rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "for i in combinations:        \n",
    "        #print(\"Count: \"+str(count))\n",
    "        print(\"Count: \"+str(count), file = terminal_output)\n",
    "\n",
    "                    #####\n",
    "        plt.subplot(3, 3, count)                                                                           \n",
    "        run_model(train_dataset, val_dataset, Luong_full, lossmaker1, device = device, \n",
    "                  bsize_eval = 64 , patience = 5, epochs = 15,\n",
    "                  save = True, path = results_path, atlas = True,\n",
    "                  vocab = input_lang.n_words, vocab_out = output_lang.n_words, c = \"\",\n",
    "                  **i)\n",
    "        count = count+1\n",
    "        print(\"\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time))    \n",
    "print(\"END ATLAS CALCULATION\", file=terminal_output)\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time), file=terminal_output)    \n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"), file=terminal_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TikaC5GIR0qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "20:16:16  Starting epoch 0\n",
      "20:17:25  Calculating figures\n",
      "20:17:44  Ending epoch 0    train_loss: 2.14   val_loss: 2.26\n",
      "20:17:44  Starting epoch 1\n",
      "20:18:49  Calculating figures\n",
      "20:19:07  Ending epoch 1    train_loss: 1.65   val_loss: 1.82\n",
      "20:19:07  Starting epoch 2\n",
      "20:20:13  Calculating figures\n",
      "20:20:31  Ending epoch 2    train_loss: 1.35   val_loss: 1.66\n",
      "20:20:31  Starting epoch 3\n",
      "20:21:38  Calculating figures\n",
      "20:21:57  Ending epoch 3    train_loss: 1.3   val_loss: 1.55\n",
      "20:21:57  Starting epoch 4\n",
      "20:23:06  Calculating figures\n",
      "20:23:25  Ending epoch 4    train_loss: 1.28   val_loss: 1.58\n",
      "20:23:25  Starting epoch 5\n",
      "20:24:36  Calculating figures\n",
      "20:24:55  Ending epoch 5    train_loss: 1.19   val_loss: 1.57\n",
      "20:24:55  Starting epoch 6\n",
      "20:26:04  Calculating figures\n",
      "20:26:23  Ending epoch 6    train_loss: 1.14   val_loss: 1.55\n",
      "20:26:23  Starting epoch 7\n",
      "20:27:33  Calculating figures\n",
      "20:27:52  Ending epoch 7    train_loss: 1.13   val_loss: 1.54\n",
      "20:27:52  Starting epoch 8\n",
      "20:29:04  Calculating figures\n",
      "20:29:24  Ending epoch 8    train_loss: 1.06   val_loss: 1.49\n",
      "20:29:24  Starting epoch 9\n",
      "20:30:31  Calculating figures\n",
      "20:30:50  Ending epoch 9    train_loss: 1.03   val_loss: 1.48\n",
      "20:30:50  Starting epoch 10\n",
      "20:31:59  Calculating figures\n",
      "20:32:18  Ending epoch 10    train_loss: 0.98   val_loss: 1.44\n",
      "20:32:18  Starting epoch 11\n",
      "20:33:28  Calculating figures\n",
      "20:33:47  Ending epoch 11    train_loss: 0.95   val_loss: 1.43\n",
      "20:33:47  Starting epoch 12\n",
      "20:34:55  Calculating figures\n",
      "20:35:14  Ending epoch 12    train_loss: 0.92   val_loss: 1.41\n",
      "20:35:14  Starting epoch 13\n",
      "20:36:25  Calculating figures\n",
      "20:36:44  Ending epoch 13    train_loss: 0.93   val_loss: 1.42\n",
      "20:36:44  Starting epoch 14\n",
      "20:37:55  Calculating figures\n",
      "20:38:13  Ending epoch 14    train_loss: 0.89   val_loss: 1.4\n",
      "\n",
      "best training_loss = 0.8865, best validation_loss = 1.4009\n",
      "Duration_: 0:21:57.482153\n",
      "best training_loss = 0.8865, best validation_loss = 1.4009\n",
      "Duration_: 0:21:57.482153\n",
      "20:38:13  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 2\n",
      "20:38:13  Starting epoch 0\n",
      "20:39:17  Calculating figures\n",
      "20:39:34  Ending epoch 0    train_loss: 2.26   val_loss: 2.45\n",
      "20:39:34  Starting epoch 1\n",
      "20:40:38  Calculating figures\n",
      "20:40:56  Ending epoch 1    train_loss: 1.91   val_loss: 2.22\n",
      "20:40:56  Starting epoch 2\n",
      "20:42:02  Calculating figures\n",
      "20:42:20  Ending epoch 2    train_loss: 1.88   val_loss: 2.26\n",
      "20:42:20  Starting epoch 3\n",
      "20:43:28  Calculating figures\n",
      "20:43:47  Ending epoch 3    train_loss: 1.89   val_loss: 2.24\n",
      "20:43:47  Starting epoch 4\n",
      "20:44:54  Calculating figures\n",
      "20:45:12  Ending epoch 4    train_loss: 1.99   val_loss: 2.45\n",
      "20:45:12  Starting epoch 5\n",
      "20:46:18  Calculating figures\n",
      "20:46:37  Ending epoch 5    train_loss: 1.9   val_loss: 2.37\n",
      "20:46:37  Starting epoch 6\n",
      "20:47:45  Calculating figures\n",
      "20:48:04  Ending epoch 6    train_loss: 1.79   val_loss: 2.28\n",
      "Early stopping after completing epoch 6\n",
      "\n",
      "best training_loss = 1.7931, best validation_loss = 2.2168\n",
      "Duration_: 0:09:50.835120\n",
      "best training_loss = 1.7931, best validation_loss = 2.2168\n",
      "Duration_: 0:09:50.835120\n",
      "20:48:04  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 3\n",
      "20:48:04  Starting epoch 0\n",
      "20:49:11  Calculating figures\n",
      "20:49:29  Ending epoch 0    train_loss: 2.5   val_loss: 2.57\n",
      "20:49:29  Starting epoch 1\n",
      "20:50:36  Calculating figures\n",
      "20:50:53  Ending epoch 1    train_loss: 1.95   val_loss: 2.15\n",
      "20:50:53  Starting epoch 2\n",
      "20:51:58  Calculating figures\n",
      "20:52:15  Ending epoch 2    train_loss: 1.7   val_loss: 1.9\n",
      "20:52:15  Starting epoch 3\n",
      "20:53:21  Calculating figures\n",
      "20:53:38  Ending epoch 3    train_loss: 1.48   val_loss: 1.75\n",
      "20:53:38  Starting epoch 4\n",
      "20:54:45  Calculating figures\n",
      "20:55:04  Ending epoch 4    train_loss: 1.39   val_loss: 1.68\n",
      "20:55:04  Starting epoch 5\n",
      "20:56:13  Calculating figures\n",
      "20:56:32  Ending epoch 5    train_loss: 1.28   val_loss: 1.61\n",
      "20:56:32  Starting epoch 6\n",
      "20:57:40  Calculating figures\n",
      "20:57:58  Ending epoch 6    train_loss: 1.23   val_loss: 1.6\n",
      "20:57:58  Starting epoch 7\n",
      "20:59:08  Calculating figures\n",
      "20:59:27  Ending epoch 7    train_loss: 1.17   val_loss: 1.54\n",
      "20:59:27  Starting epoch 8\n",
      "21:00:38  Calculating figures\n",
      "21:00:58  Ending epoch 8    train_loss: 1.09   val_loss: 1.48\n",
      "21:00:58  Starting epoch 9\n",
      "21:02:06  Calculating figures\n",
      "21:02:25  Ending epoch 9    train_loss: 1.01   val_loss: 1.43\n",
      "21:02:25  Starting epoch 10\n",
      "21:03:34  Calculating figures\n",
      "21:03:53  Ending epoch 10    train_loss: 0.96   val_loss: 1.4\n",
      "21:03:53  Starting epoch 11\n",
      "21:05:04  Calculating figures\n",
      "21:05:24  Ending epoch 11    train_loss: 0.93   val_loss: 1.39\n",
      "21:05:24  Starting epoch 12\n",
      "21:06:32  Calculating figures\n",
      "21:06:51  Ending epoch 12    train_loss: 0.9   val_loss: 1.4\n",
      "21:06:51  Starting epoch 13\n",
      "21:08:00  Calculating figures\n",
      "21:08:20  Ending epoch 13    train_loss: 0.84   val_loss: 1.34\n",
      "21:08:20  Starting epoch 14\n",
      "21:09:29  Calculating figures\n",
      "21:09:47  Ending epoch 14    train_loss: 0.81   val_loss: 1.33\n",
      "\n",
      "best training_loss = 0.8122, best validation_loss = 1.327\n",
      "Duration_: 0:21:43.137560\n",
      "best training_loss = 0.8122, best validation_loss = 1.327\n",
      "Duration_: 0:21:43.137560\n",
      "21:09:48  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 4\n",
      "21:09:48  Starting epoch 0\n",
      "21:10:51  Calculating figures\n",
      "21:11:08  Ending epoch 0    train_loss: 2.49   val_loss: 2.55\n",
      "21:11:08  Starting epoch 1\n",
      "21:12:13  Calculating figures\n",
      "21:12:31  Ending epoch 1    train_loss: 1.98   val_loss: 2.13\n",
      "21:12:31  Starting epoch 2\n",
      "21:13:36  Calculating figures\n",
      "21:13:54  Ending epoch 2    train_loss: 1.71   val_loss: 1.91\n",
      "21:13:54  Starting epoch 3\n",
      "21:15:02  Calculating figures\n",
      "21:15:20  Ending epoch 3    train_loss: 1.54   val_loss: 1.76\n",
      "21:15:20  Starting epoch 4\n",
      "21:16:29  Calculating figures\n",
      "21:16:47  Ending epoch 4    train_loss: 1.44   val_loss: 1.68\n",
      "21:16:47  Starting epoch 5\n",
      "21:17:54  Calculating figures\n",
      "21:18:12  Ending epoch 5    train_loss: 1.31   val_loss: 1.62\n",
      "21:18:12  Starting epoch 6\n",
      "21:19:21  Calculating figures\n",
      "21:19:40  Ending epoch 6    train_loss: 1.2   val_loss: 1.54\n",
      "21:19:40  Starting epoch 7\n",
      "21:20:50  Calculating figures\n",
      "21:21:10  Ending epoch 7    train_loss: 1.16   val_loss: 1.53\n",
      "21:21:10  Starting epoch 8\n",
      "21:22:17  Calculating figures\n",
      "21:22:35  Ending epoch 8    train_loss: 1.07   val_loss: 1.45\n",
      "21:22:35  Starting epoch 9\n",
      "21:23:44  Calculating figures\n",
      "21:24:03  Ending epoch 9    train_loss: 1.02   val_loss: 1.43\n",
      "21:24:03  Starting epoch 10\n",
      "21:25:12  Calculating figures\n",
      "21:25:31  Ending epoch 10    train_loss: 0.97   val_loss: 1.4\n",
      "21:25:31  Starting epoch 11\n",
      "21:26:38  Calculating figures\n",
      "21:26:56  Ending epoch 11    train_loss: 0.91   val_loss: 1.37\n",
      "21:26:56  Starting epoch 12\n",
      "21:28:05  Calculating figures\n",
      "21:28:24  Ending epoch 12    train_loss: 0.86   val_loss: 1.34\n",
      "21:28:24  Starting epoch 13\n",
      "21:29:34  Calculating figures\n",
      "21:29:53  Ending epoch 13    train_loss: 0.85   val_loss: 1.33\n",
      "21:29:53  Starting epoch 14\n",
      "21:31:01  Calculating figures\n",
      "21:31:19  Ending epoch 14    train_loss: 0.8   val_loss: 1.29\n",
      "\n",
      "best training_loss = 0.7988, best validation_loss = 1.2939\n",
      "Duration_: 0:21:31.809490\n",
      "best training_loss = 0.7988, best validation_loss = 1.2939\n",
      "Duration_: 0:21:31.809490\n",
      "21:31:20  END RUN_MODEL CALL\n",
      "\n",
      "\n",
      "Count: 5\n",
      "21:31:20  Starting epoch 0\n",
      "21:32:24  Calculating figures\n",
      "21:32:41  Ending epoch 0    train_loss: 2.6   val_loss: 2.66\n",
      "21:32:41  Starting epoch 1\n",
      "21:33:46  Calculating figures\n",
      "21:34:03  Ending epoch 1    train_loss: 2.08   val_loss: 2.24\n",
      "21:34:03  Starting epoch 2\n",
      "21:35:09  Calculating figures\n",
      "21:35:27  Ending epoch 2    train_loss: 1.82   val_loss: 1.95\n",
      "21:35:27  Starting epoch 3\n",
      "21:36:33  Calculating figures\n",
      "21:36:50  Ending epoch 3    train_loss: 1.59   val_loss: 1.87\n",
      "21:36:50  Starting epoch 4\n",
      "21:37:56  Calculating figures\n",
      "21:38:14  Ending epoch 4    train_loss: 1.48   val_loss: 1.72\n",
      "21:38:14  Starting epoch 5\n",
      "21:39:22  Calculating figures\n",
      "21:39:40  Ending epoch 5    train_loss: 1.38   val_loss: 1.66\n",
      "21:39:40  Starting epoch 6\n",
      "21:40:50  Calculating figures\n",
      "21:41:10  Ending epoch 6    train_loss: 1.27   val_loss: 1.6\n",
      "21:41:10  Starting epoch 7\n",
      "21:42:16  Calculating figures\n",
      "21:42:35  Ending epoch 7    train_loss: 1.23   val_loss: 1.59\n",
      "21:42:35  Starting epoch 8\n",
      "21:43:44  Calculating figures\n",
      "21:44:02  Ending epoch 8    train_loss: 1.14   val_loss: 1.51\n",
      "21:44:02  Starting epoch 9\n",
      "21:45:13  Calculating figures\n",
      "21:45:32  Ending epoch 9    train_loss: 1.05   val_loss: 1.46\n",
      "21:45:32  Starting epoch 10\n",
      "21:46:40  Calculating figures\n",
      "21:46:59  Ending epoch 10    train_loss: 1.0   val_loss: 1.42\n",
      "21:46:59  Starting epoch 11\n",
      "21:48:06  Calculating figures\n",
      "21:48:25  Ending epoch 11    train_loss: 0.98   val_loss: 1.43\n",
      "21:48:25  Starting epoch 12\n",
      "21:49:35  Calculating figures\n",
      "21:49:54  Ending epoch 12    train_loss: 0.91   val_loss: 1.38\n",
      "21:49:54  Starting epoch 13\n",
      "21:51:01  Calculating figures\n",
      "21:51:20  Ending epoch 13    train_loss: 0.88   val_loss: 1.37\n",
      "21:51:20  Starting epoch 14\n",
      "21:52:28  Calculating figures\n",
      "21:52:48  Ending epoch 14    train_loss: 0.83   val_loss: 1.33\n",
      "\n",
      "best training_loss = 0.8254, best validation_loss = 1.3324\n",
      "Duration_: 0:21:27.978525\n",
      "best training_loss = 0.8254, best validation_loss = 1.3324\n",
      "Duration_: 0:21:27.978525\n",
      "21:52:48  END RUN_MODEL CALL\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1:36:32.520405\n",
      "END ATLAS CALCULATION\n",
      "Duration: 1:36:32.520457\n",
      "21:52:48\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "params = {     # put the longest before the shortest\n",
    "    \"lrate\": [5e-3],  \n",
    "    \"dropout\": [0.2],\n",
    "    \"ratio\": [1, 5, 0.2, 0.05, 0.01],             \n",
    "    \"acc_steps\": [2],          \n",
    "    \"bsize\": [16],\n",
    "    \"h_size\": [90],\n",
    "    \"n_layers\": [2],\n",
    "    \"att_method\": ['general']\n",
    "}\n",
    "\n",
    "keys = params.keys()\n",
    "values = (params[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "start_time  = datetime.datetime.now()  \n",
    "plt.style.use('default')\n",
    "count = 1                   \n",
    "                    ###### widath, depth of the plotting canvas\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "for i in combinations:        \n",
    "        #print(\"Count: \"+str(count))\n",
    "        print(\"Count: \"+str(count), file = terminal_output)\n",
    "\n",
    "                    #rows, columns####\n",
    "        plt.subplot(3, 2, count)                                                                           \n",
    "        run_model(train_dataset, val_dataset, Luong_full, lossmaker1, device = device, \n",
    "                  bsize_eval = 64 , patience = 5, epochs = 15,\n",
    "                  save = True, path = results_path, atlas = True,\n",
    "                  vocab = input_lang.n_words, vocab_out = output_lang.n_words, c = \"\",\n",
    "                  **i)\n",
    "        count = count+1\n",
    "        print(\"\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time))    \n",
    "print(\"END ATLAS CALCULATION\", file=terminal_output)\n",
    "print('Duration: {}'.format(datetime.datetime.now() - start_time), file=terminal_output)    \n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"), file=terminal_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:52:48  Starting epoch 0\n",
      "21:53:53  Calculating figures\n",
      "21:54:10  Ending epoch 0    train_loss: 2.48   val_loss: 2.55\n",
      "21:54:10  Starting epoch 1\n",
      "21:55:16  Calculating figures\n",
      "21:55:33  Ending epoch 1    train_loss: 2.0   val_loss: 2.14\n",
      "21:55:33  Starting epoch 2\n",
      "21:56:38  Calculating figures\n",
      "21:56:56  Ending epoch 2    train_loss: 1.78   val_loss: 1.92\n",
      "21:56:56  Starting epoch 3\n",
      "21:58:02  Calculating figures\n",
      "21:58:20  Ending epoch 3    train_loss: 1.59   val_loss: 1.81\n",
      "21:58:20  Starting epoch 4\n",
      "21:59:26  Calculating figures\n",
      "21:59:44  Ending epoch 4    train_loss: 1.48   val_loss: 1.73\n",
      "21:59:44  Starting epoch 5\n",
      "22:00:53  Calculating figures\n",
      "22:01:12  Ending epoch 5    train_loss: 1.37   val_loss: 1.68\n",
      "22:01:12  Starting epoch 6\n",
      "22:02:20  Calculating figures\n",
      "22:02:39  Ending epoch 6    train_loss: 1.31   val_loss: 1.64\n",
      "22:02:39  Starting epoch 7\n",
      "22:03:47  Calculating figures\n",
      "22:04:06  Ending epoch 7    train_loss: 1.24   val_loss: 1.61\n",
      "22:04:06  Starting epoch 8\n",
      "22:05:17  Calculating figures\n",
      "22:05:37  Ending epoch 8    train_loss: 1.14   val_loss: 1.53\n",
      "22:05:37  Starting epoch 9\n",
      "22:06:43  Calculating figures\n",
      "22:07:02  Ending epoch 9    train_loss: 1.1   val_loss: 1.49\n",
      "22:07:02  Starting epoch 10\n",
      "22:08:10  Calculating figures\n",
      "22:08:29  Ending epoch 10    train_loss: 1.02   val_loss: 1.43\n",
      "22:08:29  Starting epoch 11\n",
      "22:09:40  Calculating figures\n",
      "22:09:59  Ending epoch 11    train_loss: 0.98   val_loss: 1.41\n",
      "22:09:59  Starting epoch 12\n",
      "22:11:07  Calculating figures\n",
      "22:11:25  Ending epoch 12    train_loss: 0.91   val_loss: 1.37\n",
      "22:11:25  Starting epoch 13\n",
      "22:12:34  Calculating figures\n",
      "22:12:53  Ending epoch 13    train_loss: 0.89   val_loss: 1.36\n",
      "22:12:53  Starting epoch 14\n",
      "22:14:03  Calculating figures\n",
      "22:14:21  Ending epoch 14    train_loss: 0.86   val_loss: 1.35\n",
      "22:14:21  Starting epoch 15\n",
      "22:15:28  Calculating figures\n",
      "22:15:47  Ending epoch 15    train_loss: 0.82   val_loss: 1.33\n",
      "22:15:47  Starting epoch 16\n",
      "22:16:57  Calculating figures\n",
      "22:17:16  Ending epoch 16    train_loss: 0.79   val_loss: 1.32\n",
      "22:17:16  Starting epoch 17\n",
      "22:18:25  Calculating figures\n",
      "22:18:43  Ending epoch 17    train_loss: 0.75   val_loss: 1.3\n",
      "22:18:43  Starting epoch 18\n",
      "22:19:51  Calculating figures\n",
      "22:20:10  Ending epoch 18    train_loss: 0.72   val_loss: 1.28\n",
      "22:20:10  Starting epoch 19\n",
      "22:21:19  Calculating figures\n",
      "22:21:38  Ending epoch 19    train_loss: 0.73   val_loss: 1.31\n",
      "22:21:38  Starting epoch 20\n",
      "22:22:45  Calculating figures\n",
      "22:23:04  Ending epoch 20    train_loss: 0.69   val_loss: 1.29\n",
      "22:23:04  Starting epoch 21\n",
      "22:24:12  Calculating figures\n",
      "22:24:31  Ending epoch 21    train_loss: 0.67   val_loss: 1.29\n",
      "Early stopping after completing epoch 21\n",
      "\n",
      "best training_loss = 0.6734, best validation_loss = 1.2799\n",
      "Duration_: 0:31:42.978625\n",
      "best training_loss = 0.6734, best validation_loss = 1.2799\n",
      "Duration_: 0:31:42.978625\n",
      "22:24:31  END RUN_MODEL CALL\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "outputs = run_model(train_dataset, val_dataset, Luong_full, lossmaker1, device= device, \n",
    "              lrate = 5e-3, ratio = 0.05, bsize = 16, acc_steps = 2, \n",
    "                                                    bsize_eval = 64, epochs = 25, patience = 3,\n",
    "                    save = True, path = results_path, \n",
    "                  # the below are passed to the model class\n",
    "                vocab = input_lang.n_words, h_size = 90, dropout = 0.2, n_layers = 2, \n",
    "                    att_method = 'general', vocab_out = output_lang.n_words,\n",
    "                    c = \"final_model\"  \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_szg3yF3vWn_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydAkemdIR0qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8JmKUWfR0qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUyMPRzZR0qe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "vdbLKfzPR0qB",
    "Xzu9e8QJR0qZ"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
