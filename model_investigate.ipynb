{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1667993530412,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "yTweMLOmR9Vi"
   },
   "outputs": [],
   "source": [
    "# This notebook loads the final trained model, checks its performance and gets it to translate some \n",
    "# input sentences from the validation dataset.\n",
    "#\n",
    "# Possible extensions: Look at attention patterns.\n",
    "#                     Look at the learned embeddings.\n",
    "#                     One could train with teacher forcing, instead of Scheduled Sampling, and see if the results seem qualitatively\n",
    "#                        different, especially for longer sequences.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sr_old/Desktop/attention_seq2seq\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993531067,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "j_4Zesv4R0pw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sr_old/Desktop/attention_seq2seq/p3.10_attention_seq2seq/bin/python\n",
      "3.10.13 (main, Aug 24 2023, 22:36:46) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1667993549969,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "uKCSSSzgR0px"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXN7_Zd8R0py"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993549971,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "v_OTN1RsR0pz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1667993551882,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "gjvOdrVQR0p0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "#from torchviz import make_dot\n",
    "from torch.utils.data import Dataset, DataLoader #, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551882,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "c0HRxPJgR0p0"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551883,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "RfXhEsSJsGwd"
   },
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667993551883,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "yNLQt7gkR0p1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "from matplotlib.pyplot import rcParams\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 5,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993551885,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "u_3G23IeR0p2"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667993551886,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "GraMD30TR0p3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep_functions import LanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t9E_mHER0p5"
   },
   "source": [
    "## Device and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1667993553717,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "C7zP9bB0R0p7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553718,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "LBEwQWsOR0p9"
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553719,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "VP88-LbZR0p9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "#rng = np.random.default_rng(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553720,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "_utQ_MlrR0p-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL-ZtZWPR0p-"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667993553941,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "EQaVXJaCR0qA"
   },
   "outputs": [],
   "source": [
    "# Name of the folder where data is accessed and saved\n",
    "path = \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667993553941,
     "user": {
      "displayName": "Gatis Mikelsons",
      "userId": "14730005653465610901"
     },
     "user_tz": 0
    },
    "id": "9eK6QXRKR0qA"
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling\n",
    "with open(path + \"/input_lang.txt\", \"rb\") as y:\n",
    "    input_lang = pickle.load(y)\n",
    "with open(path + \"/output_lang.txt\", \"rb\") as y:\n",
    "    output_lang = pickle.load(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(path + '/train.pt', weights_only=False)\n",
    "val_dataset = torch.load(path + '/val.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now load the final model and investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Luong_full(vocab = input_lang.n_words, h_size = 90, dropout = 0.2, n_layers = 2, \n",
    "                    att_method = 'general', vocab_out = output_lang.n_words, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/5e-03_0.05_32_{'h_size':90,'dropout':0.2,'n_layers':2,'att_method':'general','c':'final_model'}.png\n",
      "results/5e-03_1_32_{'h_size':30,'dropout':0,'n_layers':2,'att_method':'dot','c':'first'}.png\n",
      "\n",
      "results/atlases:\n",
      "att_method-dropout.png\n",
      "hsize-layers.png\n",
      "lr-ratio.png\n",
      "lr-ratio_old.png\n",
      "\n",
      "results/models:\n",
      "5e-03_0.05_32_{'h_size':90,'dropout':0.2,'n_layers':2,'att_method':'general','c':'final_model'}.pt\n",
      "\n",
      "results/ratio5,ss10:\n",
      "5e-03_5_32_{'c':'','dropout':0,'h_size':90,'n_layers':3,'att_method':'dot'}.png\n",
      "5e-03_5_32_{'c':'','dropout':0.1,'h_size':60,'n_layers':2,'att_method':'general'}.png\n",
      "5e-03_5_32_{'c':'','dropout':0.3,'h_size':60,'n_layers':2,'att_method':'concat'}.png\n",
      "5e-03_5_32_{'h_size':30,'dropout':0,'n_layers':2,'att_method':'dot','c':''}.png\n"
     ]
    }
   ],
   "source": [
    "os.system(\"ls \" + results_path + \"/*\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the right model:\n",
    "name = \"5e-03_0.05_32_{'h_size':90,'dropout':0.2,'n_layers':2,'att_method':'general','c':'final_model'}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Luong_full(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(655, 90)\n",
       "    (gru): GRU(90, 45, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): LuongDecoder(\n",
       "    (embedding): Embedding(705, 90)\n",
       "    (gru): GRU(90, 90, num_layers=2, dropout=0.2)\n",
       "    (joinerFF): Linear(in_features=180, out_features=90, bias=True)\n",
       "    (projFF): Linear(in_features=90, out_features=705, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "    (alignment_vector): Attn(\n",
       "      (mFF): Linear(in_features=90, out_features=90, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.load_state_dict(torch.load(results_path + '/models/' + name, map_location=torch.device('cpu')))\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check that we can replicate the loss obtained.\n",
    "# Set the epoch parameter to a high number, to make sure there is no teacher forcing.\n",
    "\n",
    "val_loss = epochend_lcalc(m, lossmaker1, batcher(val_dataset, 800), device, epoch = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.277029554049174)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now give it something to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 60, 387,   8, 193],\n",
       "          [ 61, 211,  61,   3],\n",
       "          [314,  61,  39,  59],\n",
       "          [285, 511, 557,   6],\n",
       "          [  6,   6,   9,   2],\n",
       "          [  2,   2,   2,   0]]),\n",
       "  [6, 6, 6, 5]),\n",
       " (tensor([[ 22, 456,   7, 606],\n",
       "          [ 80, 539, 209, 209],\n",
       "          [495, 264, 370,  37],\n",
       "          [245,   4, 558,   4],\n",
       "          [  4,   2,   8,   2],\n",
       "          [  2,   0,   2,   0]]),\n",
       "  [6, 5, 6, 5]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec(inpt, index2word_dictn):\n",
    "    # This function takes a single tokenised sentence and translates the tokens, based on the dictionary provided.\n",
    "\n",
    "    inpt = inpt.numpy()\n",
    "    assert inpt.shape[1] == 1, \"More than one sequence input\"\n",
    "\n",
    "    return [index2word_dictn[k] for k in inpt.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(i, dataset, beamsize, model, input_index2word_dictn, output_index2word_dictn, device = device):\n",
    "    # This function is mostly needed for neat printing-out of the results.\n",
    "    # This calls the .beam_decode() method and we print the results in an orderly fashion.\n",
    "    # i is the sentence index in the dataset\n",
    "\n",
    "    inp = dataset[i][0][0]\n",
    "\n",
    "    print(\"INPUT:\")\n",
    "    print(dec(inp, input_index2word_dictn))\n",
    "    print(\"MODEL ANSWER:\")\n",
    "    print(dec(dataset[i][1][0], output_index2word_dictn))\n",
    "    print(\"\")\n",
    "    \n",
    "    beam = model.beam_decode(beamsize, inp.to(device), max_dec_length = 20)\n",
    "\n",
    "    # Now reorder and print the info from the beam\n",
    "    seqs = []\n",
    "    probs = []\n",
    "    for i in beam:\n",
    "        seq, prob, _ = i\n",
    "        seqs.append(seq)\n",
    "        probs.append(prob)\n",
    "\n",
    "    for k in zip(seqs, probs):\n",
    "            print(dec(torch.tensor(k[0]).unsqueeze(1), output_index2word_dictn), \"     \", round(k[1][0], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "['tu', 'es', 'important', '.', 'EOS']\n",
      "MODEL ANSWER:\n",
      "['you', 'are', 'important', '.', 'EOS']\n",
      "\n",
      "['you', 're', 'important', '.', 'EOS']       -0.6\n",
      "['you', 're', 'important', 'important', 'EOS']       -1.39\n",
      "['you', 're', 'important', '.', '.', 'EOS']       -2.94\n",
      "['you', 're', 'important', 'important', '.', 'EOS']       -3.41\n",
      "['you', 'are', 'important', '.', 'EOS']       -3.98\n"
     ]
    }
   ],
   "source": [
    "translate(10, val_dataset, 5, m, input_lang.index2word, output_lang.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597539553864471"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(-0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is fairly confident but (just technically) wrong in its topmost prediction.\n",
    "# I would have expected ['you', 'are', 'important', '.', 'EOS'] to have a higher log probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "['garde', 'le', '.', 'EOS']\n",
      "MODEL ANSWER:\n",
      "['keep', 'that', '.', 'EOS']\n",
      "\n",
      "['keep', 'it', '.', '.', 'EOS']       -4.16\n",
      "['keep', 'does', '.', '.', 'EOS']       -4.26\n",
      "['keep', 'does', 'it', '.', 'EOS']       -4.31\n",
      "['keep', 'it', '.', 'EOS']       -4.35\n",
      "['keep', 'saw', 'it', '.', 'EOS']       -4.63\n"
     ]
    }
   ],
   "source": [
    "translate(11, val_dataset, 5, m, input_lang.index2word, output_lang.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see evidence of the model learning that \"that\" and \"it\" are semantically related.\n",
    "# The emergence of \"does it\" and \"saw it\" may indicate the model learning typical 2-grams of the English language.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "['c', 'est', 'pour', 'toi', '.', 'EOS']\n",
      "MODEL ANSWER:\n",
      "['that', 's', 'for', 'you', '.', 'EOS']\n",
      "\n",
      "['it', 's', 'pretty', '.', '.', 'EOS']       -3.53\n",
      "['that', 's', 'for', '.', '.', 'EOS']       -3.74\n",
      "['that', 's', 'pretty', '.', '.', 'EOS']       -3.96\n",
      "['it', 's', 'for', '.', '.', 'EOS']       -4.04\n",
      "['that', 's', 'for', '.', 'EOS']       -4.28\n",
      "['it', 'is', 'pretty', '.', '.', 'EOS']       -4.3\n",
      "['that', 's', 'yourself', '.', 'EOS']       -4.42\n",
      "['this', 's', 'pretty', '.', '.', 'EOS']       -4.44\n",
      "['this', 's', 'for', '.', '.', 'EOS']       -4.49\n",
      "['it', 's', 'for', '.', 'EOS']       -4.5\n"
     ]
    }
   ],
   "source": [
    "translate(12, val_dataset, 10, m, input_lang.index2word, output_lang.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprised I do not see \"for you\" as a learned 2-gram here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "['soyez', 'honnete', 'avec', 'moi', '.', 'EOS']\n",
      "MODEL ANSWER:\n",
      "['be', 'honest', 'with', 'me', '.', 'EOS']\n",
      "\n",
      "['be', 'with', 'with', '.', 'EOS']       -1.7\n",
      "['honest', 'with', 'with', '.', 'EOS']       -2.2\n",
      "['be', 'honest', 'with', '.', 'EOS']       -2.31\n",
      "['take', 'with', 'with', '.', 'EOS']       -3.36\n",
      "['honest', 'honest', 'with', '.', 'EOS']       -3.63\n"
     ]
    }
   ],
   "source": [
    "translate(221, val_dataset, 5, m, input_lang.index2word, output_lang.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "['je', 'devrais', 'etre', 'heureuse', '.', 'EOS']\n",
      "MODEL ANSWER:\n",
      "['i', 'should', 'be', 'happy', '.', 'EOS']\n",
      "\n",
      "['i', 'should', 'be', 'happy', '.', 'EOS']       -0.79\n",
      "['i', 'should', 'be', 'happy', 'EOS']       -2.1\n",
      "['i', 'should', 'be', '.', '.', 'EOS']       -2.51\n",
      "['i', 'should', 'be', '.', 'EOS']       -3.32\n",
      "['i', 'can', 'be', 'happy', '.', 'EOS']       -3.69\n",
      "['i', 'should', 'be', 'friends', '.', 'EOS']       -3.88\n",
      "['i', 'll', 'be', 'happy', '.', 'EOS']       -4.48\n",
      "['i', 'should', 'be', 'be', '.', 'EOS']       -4.69\n",
      "['i', 'can', 'be', 'happy', 'EOS']       -4.78\n",
      "['i', 'should', 'be', 'wrong', '.', 'EOS']       -4.85\n",
      "['i', 'should', 'be', 'this', '.', 'EOS']       -4.86\n",
      "['i', 'should', 'be', 'being', '.', 'EOS']       -5.11\n",
      "['i', 'can', 'be', '.', '.', 'EOS']       -5.37\n",
      "['i', 'should', 'be', 'friends', 'EOS']       -5.43\n",
      "['i', 'should', 'be', 'EOS']       -5.44\n",
      "['i', 'should', 'be', 'drink', '.', 'EOS']       -5.58\n",
      "['i', 'll', 'be', 'happy', 'EOS']       -5.61\n",
      "['i', 'should', 'be', 'ready', '.', 'EOS']       -5.65\n",
      "['i', 'should', 'be', 'nervous', '.', 'EOS']       -5.75\n",
      "['i', 'should', 'be', 'nice', '.', 'EOS']       -5.77\n",
      "['i', 'should', 'be', 'all', '.', 'EOS']       -5.78\n",
      "['i', 'should', 'be', 'wrong', 'EOS']       -5.92\n",
      "['i', 'should', 'better', 'happy', '.', 'EOS']       -6.0\n",
      "['i', 'should', 'be', 'you', '.', 'EOS']       -6.03\n",
      "['i', 'can', 'be', '.', 'EOS']       -6.1\n"
     ]
    }
   ],
   "source": [
    "translate(50, val_dataset, 25, m, input_lang.index2word, output_lang.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_szg3yF3vWn_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydAkemdIR0qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8JmKUWfR0qd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUyMPRzZR0qe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "vdbLKfzPR0qB",
    "Xzu9e8QJR0qZ"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
