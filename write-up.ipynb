{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short textual write-up looking to explain the repo, the steps taken and the results achieved. No coding will be done here, but we will paste results and content from elsewhere in the repo.\n",
    "\n",
    "It is hard to know the right amount of detail to go into. There is also commenting done in the other notebooks and in the Python functions' files. But I may have explained something too much and something else too little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t9E_mHER0p5"
   },
   "source": [
    "## What the repo contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVvbDsLPvWn_"
   },
   "source": [
    "This repo started as an exercise in learning PyTorch and understanding the attentional seq2seq architecture in full detail. We set up a toy French to English translation task, __implement the attentional seq2seq architecture of [Leung et al. (2015)](https://arxiv.org/pdf/1508.04025)__ and experiment with the effects of hyperparameters to find a good combination. Then the final model is investigated a bit.\n",
    "\n",
    "I have borrowed heavily from the [practical-pytorch](https://github.com/spro/practical-pytorch) repo by [spro](https://github.com/spro), in particular, [this notebook](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb). This resource provided the starting point and answered many of the initial questions I had. However, all the code I have borrowed has been double-checked, sometimes fixed, sometimes reworked. And I have integrated this with my own code for training and plotting the learning curves, beam-search decoding, etc.\n",
    "\n",
    "The translation task has been greatly simplified here for ease of compute, yet the same code should be able to handle much more involved seq2seq learning problems. All the computations here have been done using an Apple M2 Max machine, and the time taken, as reported in the legends of learning curves, is for that machine.\n",
    "\n",
    "__Final result in a nutshell.__ Training on 5k French-English sentence pairs of length 2 to 5 tokens (inclusive), we are able to reach the cross-entropy score of 1.39:\n",
    "\n",
    "<img src=\"results/5e-03_1_32_{'h_size':90,'dropout':0.2,'n_layers':2,'att_method':'general','c':'final_model'}.png\" alt=\"pic\" width=\"300\"/>\n",
    "                  \n",
    "When we beam-search from this model, we find..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Leung paper](https://arxiv.org/pdf/1508.04025), one of the pioneering works on attention. We implement the architecture proposed therein.\n",
    "\n",
    "The [paper](https://arxiv.org/pdf/1506.03099) proposing Scheduled Sampling. There is a set of helpful illustrations at the top of page 4. We implement Scheduled Sampling for the decoder we use.\n",
    "\n",
    "[practical-pytorch](https://github.com/spro/practical-pytorch) repo. Provided the starting point for this work.\n",
    "\n",
    "Oxford [Deep Learnig for NLP](https://github.com/oxford-cs-deepnlp-2017/lectures) lecture course. Good for understanding the broader research context at the time the Leung paper emerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUyMPRzZR0qe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The dataset is available here. \n",
    "\n",
    "Create the \"datasets\" folder, place the \"eng-fra.txt\" file in there. The \"dataprep.ipynb\" notebook should be end-to-end executable.\n",
    "\n",
    "We clean the file and simplify the corpus in terms of maximum length and number of words encountered. The vocabulary for both French and English ends up consisting of about 700 words each.\n",
    "\n",
    "The dataprep notebook should reproduce exactly upon re-run. These are the files one ends up with after executing the notebook:\n",
    "\n",
    "<img src=\"write-up_pics/a.png\" alt=\"pic\" width=\"150\"/>\n",
    "\n",
    "where trial1 and trial2 are just shortened datasets that can be useful for debugging and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we wish to implement is summarised in [the Leung paper](https://arxiv.org/pdf/1508.04025), page 3, as well as in many blogs\n",
    "\n",
    "This has been coded up, in a batched form, in model_functions.py. We provide commenting throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and hyperparameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have a model now. What are reasonable hyperparameter choices? Let's spend some time finding good hyperparameters, though we will not optimise for the very best possible.\n",
    "\n",
    "Start with a guess and see what happens\n",
    "\n",
    "<img src=\"results/5e-03_1_32_{'h_size':30,'dropout':0,'n_layers':2,'att_method':'dot','c':'first'}.png\" alt=\"pic\" width=\"300\"/>\n",
    "\n",
    "Ok, we're making reasonable choices and the learning rate, in particular, looks sound. Let's investigate what happens if we vary the number of layers and the hidden dimension:\n",
    "\n",
    "<img src=\"results/atlases/hsize-layers.png\" alt=\"pic\" width=\"500\"/>\n",
    "\n",
    "It's not clear that having 3 layers makes a difference. However, increasing the dimensionality to 90 looks like a good choice. Let's now experiment with dropout and changing the attention mechanism. We will here disregard the 'concat' attention mechanism, because it is more computationally costly and also because it does not seem to improve performance significantly. The latter is also reported in [the Leung paper](https://arxiv.org/pdf/1508.04025), page 8: \"For *content-based* functions, our implementation *concat* does not yield good performances and more analysis should be done to understand the reason.\"\n",
    "\n",
    "\n",
    "Ok, let's have a look:\n",
    "\n",
    "<img src=\"results/atlases/att_method-dropout.png\" alt=\"pic\" width=\"500\"/>\n",
    "\n",
    "Going from 'dot' to 'general' does seem to help. And increasing dropout to 0.2 looks sensible.\n",
    "\n",
    "Finally, let's quickly check if we should increase or decrease the decoder's learning rate, relative to the encoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some ideas: \n",
    "* Use pre-trained embeddings, instead of training the embedding matrices from scratch.\n",
    "* Plot and investigate attention patterns (as they do in [this notebook](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb)).\n",
    "* See what results are obtainable by non-attention seq2seq GRUs. Or try the transformer architecture.\n",
    "* Implement the architecture extension mentioned in the [The Leung paper](https://arxiv.org/pdf/1508.04025), page 5:\n",
    "  \n",
    "  <img src=\"write-up_pics/b.png\" alt=\"pic\" width=\"250\"/>\n",
    "* Find a suitable model on HuggingFace to fine-tune, perhaps a T5.\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "vdbLKfzPR0qB",
    "Xzu9e8QJR0qZ"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
